{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "GPU Name:  NVIDIA GeForce RTX 4080 SUPER\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "# device = 'cpu'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu124 True\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "# print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "# # device = 'cpu'\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print('Using device:', device)\n",
    "\n",
    "# import torch, torchvision\n",
    "# print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# import mmaction\n",
    "# print(mmaction.__version__)\n",
    "\n",
    "# import mmcv\n",
    "# print(mmcv.__version__)\n",
    "\n",
    "#     # Check MMCV installation\n",
    "# from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "# print(get_compiling_cuda_version())\n",
    "# print(get_compiler_version())\n",
    "\n",
    "#     # Check MMEngine installation\n",
    "# from mmengine.utils.dl_utils import collect_env\n",
    "# print(collect_env())\n",
    "\n",
    "# from mmaction.apis import inference_recognizer, init_recognizer\n",
    "# from mmengine import Config\n",
    "\n",
    "# from operator import itemgetter\n",
    "\n",
    "# import os.path as osp\n",
    "# import mmengine\n",
    "# from mmengine.runner import Runner\n",
    "\n",
    "# cfg = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/uniformerv2-tiny-p244-w877_in1k-pre_8xb8-amp-32x2x1-30e_KINETICS_TEST.py'\n",
    "# cfg = Config.fromfile(cfg)\n",
    "\n",
    "# # checkpoint = '/Users/eddie/Trauma THOMPSON/Trauma THOMPSON/VideoSwin/exps/best_acc_top1_epoch_3.pth'\n",
    "#     # Set up working dir to save files and logs.\n",
    "# cfg.work_dir = './exps/timesformer'\n",
    "\n",
    "#     # Create work_dir    \n",
    "# mmengine.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "\n",
    "# model = init_recognizer(cfg, device='cuda:0')\n",
    "# runner = Runner.from_cfg(cfg)\n",
    "# runner.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "\n",
    "# model.cpu()\n",
    "# del model\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu124 True\n",
      "1.2.0\n",
      "2.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddie\\anaconda3\\envs\\openmmlab\\Lib\\site-packages\\mmengine\\optim\\optimizer\\zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n",
      "MSVC 194134120\n",
      "OrderedDict([('sys.platform', 'win32'), ('Python', '3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]'), ('CUDA available', True), ('MUSA available', False), ('numpy_random_seed', 2147483648), ('GPU 0', 'NVIDIA GeForce RTX 4080 SUPER'), ('CUDA_HOME', 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.4'), ('NVCC', 'Cuda compilation tools, release 12.4, V12.4.99'), ('MSVC', 'n/a, reason: fileno'), ('PyTorch', '2.4.1+cu124'), ('PyTorch compiling details', 'PyTorch built with:\\n  - C++ Version: 201703\\n  - MSVC 192930154\\n  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\\n  - OpenMP 2019\\n  - LAPACK is enabled (usually provided by MKL)\\n  - CPU capability usage: AVX2\\n  - CUDA Runtime 12.4\\n  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\\n  - CuDNN 90.1\\n  - Magma 2.5.4\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \\n'), ('TorchVision', '0.19.1+cu124'), ('OpenCV', '4.10.0'), ('MMEngine', '0.10.5')])\n",
      "Config:\n",
      "ann_file_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt'\n",
      "ann_file_train = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_train_balanced.txt'\n",
      "ann_file_val = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt'\n",
      "auto_scale_lr = dict(base_batch_size=8, enable=False)\n",
      "data_root = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train/'\n",
      "data_root_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "dataset_type = 'RawframeDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=3, max_keep_ckpts=5, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=12,\n",
      "        embed_dims=384,\n",
      "        img_size=224,\n",
      "        mlp_ratio=4,\n",
      "        norm_cfg=dict(eps=1e-06, type='LN'),\n",
      "        num_frames=32,\n",
      "        num_heads=6,\n",
      "        patch_size=16,\n",
      "        pretrained=\n",
      "        '/Users/eddie/Downloads/vit-base-p16_videomaev2-vit-g-dist-k710-pre_16x4x1_kinetics-400_20230510-3e7f93b2 (1)',\n",
      "        qkv_bias=True,\n",
      "        type='VisionTransformer'),\n",
      "    cls_head=dict(\n",
      "        average_clips='prob',\n",
      "        in_channels=384,\n",
      "        num_classes=160,\n",
      "        type='TimeSformerHead'),\n",
      "    data_preprocessor=dict(\n",
      "        format_shape='NCTHW',\n",
      "        mean=[\n",
      "            114.75,\n",
      "            114.75,\n",
      "            114.75,\n",
      "        ],\n",
      "        std=[\n",
      "            57.375,\n",
      "            57.375,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='ActionDataPreprocessor'),\n",
      "    type='Recognizer3D')\n",
      "optim_wrapper = dict(\n",
      "    constructor='SwinOptimWrapperConstructor',\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=0.000125, type='AdamW', weight_decay=0.02),\n",
      "    paramwise_cfg=dict(\n",
      "        absolute_pos_embed=dict(decay_mult=0.0),\n",
      "        backbone=dict(lr_mult=0.1),\n",
      "        norm=dict(decay_mult=0.0),\n",
      "        relative_position_bias_table=dict(decay_mult=0.0)),\n",
      "    type='AmpOptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=2.5,\n",
      "        start_factor=0.1,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        T_max=30,\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=30,\n",
      "        eta_min=0,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=4,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='ThreeCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(type='AccMetric')\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=4,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='ThreeCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=25, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_train_balanced.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                224,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(flip_ratio=0.5, type='Flip'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(clip_len=32, frame_interval=2, num_clips=1, type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        224,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(flip_ratio=0.5, type='Flip'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(type='AccMetric')\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='CenterCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './exps/videomae_anticipation_regular'\n",
      "\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1292769136\n",
      "    GPU 0: NVIDIA GeForce RTX 4080 SUPER\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.4\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.99\n",
      "    MSVC: n/a, reason: fileno\n",
      "    PyTorch: 2.4.1+cu124\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 201703\n",
      "  - MSVC 192930154\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.4\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 90.1\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.19.1+cu124\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1292769136\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt'\n",
      "ann_file_train = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_train_balanced.txt'\n",
      "ann_file_val = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt'\n",
      "auto_scale_lr = dict(base_batch_size=8, enable=False)\n",
      "data_root = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train/'\n",
      "data_root_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "dataset_type = 'RawframeDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=3, max_keep_ckpts=5, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=12,\n",
      "        embed_dims=384,\n",
      "        img_size=224,\n",
      "        mlp_ratio=4,\n",
      "        norm_cfg=dict(eps=1e-06, type='LN'),\n",
      "        num_frames=32,\n",
      "        num_heads=6,\n",
      "        patch_size=16,\n",
      "        pretrained=None,\n",
      "        qkv_bias=True,\n",
      "        type='VisionTransformer'),\n",
      "    cls_head=dict(\n",
      "        average_clips='prob',\n",
      "        in_channels=384,\n",
      "        num_classes=160,\n",
      "        type='TimeSformerHead'),\n",
      "    data_preprocessor=dict(\n",
      "        format_shape='NCTHW',\n",
      "        mean=[\n",
      "            114.75,\n",
      "            114.75,\n",
      "            114.75,\n",
      "        ],\n",
      "        std=[\n",
      "            57.375,\n",
      "            57.375,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='ActionDataPreprocessor'),\n",
      "    type='Recognizer3D')\n",
      "optim_wrapper = dict(\n",
      "    constructor='SwinOptimWrapperConstructor',\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=0.000125, type='AdamW', weight_decay=0.02),\n",
      "    paramwise_cfg=dict(\n",
      "        absolute_pos_embed=dict(decay_mult=0.0),\n",
      "        backbone=dict(lr_mult=0.1),\n",
      "        norm=dict(decay_mult=0.0),\n",
      "        relative_position_bias_table=dict(decay_mult=0.0)),\n",
      "    type='AmpOptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=2.5,\n",
      "        start_factor=0.1,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        T_max=30,\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=30,\n",
      "        eta_min=0,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=4,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='ThreeCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(type='AccMetric')\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=4,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='ThreeCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=25, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_train_balanced.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                224,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(flip_ratio=0.5, type='Flip'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(clip_len=32, frame_interval=2, num_clips=1, type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        224,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(flip_ratio=0.5, type='Flip'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(type='AccMetric')\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='CenterCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './exps/videomae_anticipation_regular'\n",
      "\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.patch_embed.projection.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.patch_embed.projection.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.patch_embed.projection.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.patch_embed.projection.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.norm1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.norm1.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.norm1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.norm1.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.attn.q_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.attn.q_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.attn.v_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.attn.v_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.norm2.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.norm2.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.norm2.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.norm2.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.mlp.layers.0.0.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.mlp.layers.0.0.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.mlp.layers.0.0.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.mlp.layers.0.0.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.mlp.layers.1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.mlp.layers.1.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.mlp.layers.1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.0.mlp.layers.1.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.norm1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.norm1.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.norm1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.norm1.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.attn.q_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.attn.q_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.attn.v_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.attn.v_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.norm2.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.norm2.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.norm2.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.norm2.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.mlp.layers.0.0.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.mlp.layers.0.0.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.mlp.layers.0.0.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.mlp.layers.0.0.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.mlp.layers.1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.mlp.layers.1.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.mlp.layers.1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.1.mlp.layers.1.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.norm1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.norm1.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.norm1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.norm1.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.attn.q_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.attn.q_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.attn.v_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.attn.v_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.norm2.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.norm2.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.norm2.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.norm2.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.mlp.layers.0.0.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.mlp.layers.0.0.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.mlp.layers.0.0.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.mlp.layers.0.0.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.mlp.layers.1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.mlp.layers.1.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.mlp.layers.1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.2.mlp.layers.1.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.norm1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.norm1.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.norm1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.norm1.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.attn.q_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.attn.q_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.attn.v_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.attn.v_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.norm2.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.norm2.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.norm2.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.norm2.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.mlp.layers.0.0.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.mlp.layers.0.0.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.mlp.layers.0.0.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.mlp.layers.0.0.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.mlp.layers.1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.mlp.layers.1.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.mlp.layers.1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.3.mlp.layers.1.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.norm1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.norm1.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.norm1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.norm1.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.attn.q_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.attn.q_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.attn.v_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.attn.v_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.norm2.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.norm2.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.norm2.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.norm2.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.mlp.layers.0.0.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.mlp.layers.0.0.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.mlp.layers.0.0.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.mlp.layers.0.0.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.mlp.layers.1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.mlp.layers.1.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.mlp.layers.1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.4.mlp.layers.1.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.norm1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.norm1.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.norm1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.norm1.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.attn.q_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.attn.q_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.attn.v_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.attn.v_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.norm2.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.norm2.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.norm2.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.norm2.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.mlp.layers.0.0.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.mlp.layers.0.0.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.mlp.layers.0.0.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.mlp.layers.0.0.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.mlp.layers.1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.mlp.layers.1.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.mlp.layers.1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.5.mlp.layers.1.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.norm1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.norm1.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.norm1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.norm1.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.attn.q_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.attn.q_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.attn.v_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.attn.v_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.norm2.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.norm2.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.norm2.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.norm2.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.mlp.layers.0.0.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.mlp.layers.0.0.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.mlp.layers.0.0.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.mlp.layers.0.0.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.mlp.layers.1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.mlp.layers.1.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.mlp.layers.1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.6.mlp.layers.1.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.norm1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.norm1.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.norm1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.norm1.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.attn.q_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.attn.q_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.attn.v_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.attn.v_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.norm2.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.norm2.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.norm2.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.norm2.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.mlp.layers.0.0.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.mlp.layers.0.0.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.mlp.layers.0.0.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.mlp.layers.0.0.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.mlp.layers.1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.mlp.layers.1.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.mlp.layers.1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.7.mlp.layers.1.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.norm1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.norm1.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.norm1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.norm1.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.attn.q_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.attn.q_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.attn.v_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.attn.v_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.norm2.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.norm2.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.norm2.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.norm2.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.mlp.layers.0.0.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.mlp.layers.0.0.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.mlp.layers.0.0.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.mlp.layers.0.0.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.mlp.layers.1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.mlp.layers.1.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.mlp.layers.1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.8.mlp.layers.1.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.norm1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.norm1.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.norm1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.norm1.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.attn.q_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.attn.q_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.attn.v_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.attn.v_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.norm2.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.norm2.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.norm2.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.norm2.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.mlp.layers.0.0.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.mlp.layers.0.0.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.mlp.layers.0.0.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.mlp.layers.0.0.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.mlp.layers.1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.mlp.layers.1.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.mlp.layers.1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.9.mlp.layers.1.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.norm1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.norm1.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.norm1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.norm1.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.attn.q_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.attn.q_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.attn.v_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.attn.v_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.norm2.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.norm2.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.norm2.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.norm2.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.mlp.layers.0.0.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.mlp.layers.0.0.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.mlp.layers.0.0.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.mlp.layers.0.0.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.mlp.layers.1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.mlp.layers.1.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.mlp.layers.1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.10.mlp.layers.1.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.norm1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.norm1.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.norm1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.norm1.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.attn.q_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.attn.q_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.attn.v_bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.attn.v_bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.norm2.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.norm2.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.norm2.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.norm2.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.mlp.layers.0.0.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.mlp.layers.0.0.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.mlp.layers.0.0.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.mlp.layers.0.0.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.mlp.layers.1.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.mlp.layers.1.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.mlp.layers.1.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.blocks.11.mlp.layers.1.bias: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.fc_norm.weight: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.fc_norm.weight: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.fc_norm.bias: lr = 1.25e-05\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.fc_norm.bias: weight_decay = 0.0\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.cls_head.fc_cls.weight: lr = 0.000125\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.cls_head.fc_cls.weight: weight_decay = 0.02\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.cls_head.fc_cls.bias: lr = 0.000125\n",
      "03/07 00:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.cls_head.fc_cls.bias: weight_decay = 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddie\\anaconda3\\envs\\openmmlab\\Lib\\site-packages\\mmengine\\optim\\optimizer\\amp_optimizer_wrapper.py:97: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.loss_scaler = scaler_type()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/07 00:42:24 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/07 00:42:24 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "03/07 00:42:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular.\n",
      "03/07 00:43:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 100/5225]  base_lr: 1.3353e-05 lr: 1.3353e-06  eta: 13:21:15  time: 0.1758  data_time: 0.0033  memory: 10434  loss: 5.1281  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 5.1281\n",
      "03/07 00:43:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 200/5225]  base_lr: 1.4214e-05 lr: 1.4214e-06  eta: 9:48:31  time: 0.1951  data_time: 0.0017  memory: 10434  loss: 5.0505  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 5.0505\n",
      "03/07 00:43:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 300/5225]  base_lr: 1.5075e-05 lr: 1.5075e-06  eta: 8:34:34  time: 0.1751  data_time: 0.0006  memory: 10434  loss: 4.9443  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.9443\n",
      "03/07 00:43:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 400/5225]  base_lr: 1.5937e-05 lr: 1.5937e-06  eta: 7:56:19  time: 0.1700  data_time: 0.0019  memory: 10434  loss: 4.8814  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.8814\n",
      "03/07 00:44:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 500/5225]  base_lr: 1.6798e-05 lr: 1.6798e-06  eta: 7:33:17  time: 0.1642  data_time: 0.0015  memory: 10434  loss: 4.9671  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.9671\n",
      "03/07 00:44:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 600/5225]  base_lr: 1.7659e-05 lr: 1.7659e-06  eta: 7:17:37  time: 0.1639  data_time: 0.0018  memory: 10434  loss: 4.7754  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.7754\n",
      "03/07 00:44:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 700/5225]  base_lr: 1.8521e-05 lr: 1.8521e-06  eta: 7:05:48  time: 0.1662  data_time: 0.0019  memory: 10434  loss: 4.9311  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.9311\n",
      "03/07 00:44:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 800/5225]  base_lr: 1.9382e-05 lr: 1.9382e-06  eta: 6:57:27  time: 0.1669  data_time: 0.0031  memory: 10434  loss: 4.7448  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 4.7448\n",
      "03/07 00:45:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 900/5225]  base_lr: 2.0243e-05 lr: 2.0243e-06  eta: 6:50:19  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 4.7353  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.7353\n",
      "03/07 00:45:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 00:45:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1000/5225]  base_lr: 2.1105e-05 lr: 2.1105e-06  eta: 6:44:31  time: 0.1654  data_time: 0.0018  memory: 10434  loss: 4.7325  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.7325\n",
      "03/07 00:45:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1100/5225]  base_lr: 2.1966e-05 lr: 2.1966e-06  eta: 6:39:48  time: 0.1635  data_time: 0.0026  memory: 10434  loss: 4.7159  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.7159\n",
      "03/07 00:46:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1200/5225]  base_lr: 2.2828e-05 lr: 2.2828e-06  eta: 6:35:52  time: 0.1649  data_time: 0.0015  memory: 10434  loss: 4.6153  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.6153\n",
      "03/07 00:46:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1300/5225]  base_lr: 2.3689e-05 lr: 2.3689e-06  eta: 6:32:24  time: 0.1641  data_time: 0.0002  memory: 10434  loss: 4.7742  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.7742\n",
      "03/07 00:46:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1400/5225]  base_lr: 2.4550e-05 lr: 2.4550e-06  eta: 6:29:24  time: 0.1647  data_time: 0.0011  memory: 10434  loss: 4.6487  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.6487\n",
      "03/07 00:46:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1500/5225]  base_lr: 2.5412e-05 lr: 2.5412e-06  eta: 6:27:10  time: 0.1784  data_time: 0.0007  memory: 10434  loss: 4.6960  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.6960\n",
      "03/07 00:47:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1600/5225]  base_lr: 2.6273e-05 lr: 2.6273e-06  eta: 6:24:50  time: 0.1635  data_time: 0.0011  memory: 10434  loss: 4.7240  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.7240\n",
      "03/07 00:47:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1700/5225]  base_lr: 2.7134e-05 lr: 2.7134e-06  eta: 6:22:42  time: 0.1642  data_time: 0.0009  memory: 10434  loss: 4.6905  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.6905\n",
      "03/07 00:47:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1800/5225]  base_lr: 2.7996e-05 lr: 2.7996e-06  eta: 6:20:49  time: 0.1650  data_time: 0.0032  memory: 10434  loss: 4.7836  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.7836\n",
      "03/07 00:48:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1900/5225]  base_lr: 2.8857e-05 lr: 2.8857e-06  eta: 6:19:04  time: 0.1642  data_time: 0.0025  memory: 10434  loss: 4.6387  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.6387\n",
      "03/07 00:48:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 00:48:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2000/5225]  base_lr: 2.9718e-05 lr: 2.9718e-06  eta: 6:17:27  time: 0.1644  data_time: 0.0017  memory: 10434  loss: 4.4889  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.4889\n",
      "03/07 00:48:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2100/5225]  base_lr: 3.0580e-05 lr: 3.0580e-06  eta: 6:16:00  time: 0.1650  data_time: 0.0014  memory: 10434  loss: 4.6019  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.6019\n",
      "03/07 00:48:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2200/5225]  base_lr: 3.1441e-05 lr: 3.1441e-06  eta: 6:14:43  time: 0.1642  data_time: 0.0017  memory: 10434  loss: 4.6333  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.6333\n",
      "03/07 00:49:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2300/5225]  base_lr: 3.2302e-05 lr: 3.2302e-06  eta: 6:13:35  time: 0.1633  data_time: 0.0021  memory: 10434  loss: 4.4545  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.4545\n",
      "03/07 00:49:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2400/5225]  base_lr: 3.3164e-05 lr: 3.3164e-06  eta: 6:12:13  time: 0.1628  data_time: 0.0017  memory: 10434  loss: 4.6851  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.6851\n",
      "03/07 00:49:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2500/5225]  base_lr: 3.4025e-05 lr: 3.4025e-06  eta: 6:10:57  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 4.6606  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.6606\n",
      "03/07 00:49:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2600/5225]  base_lr: 3.4886e-05 lr: 3.4886e-06  eta: 6:09:46  time: 0.1637  data_time: 0.0019  memory: 10434  loss: 4.5968  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 4.5968\n",
      "03/07 00:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2700/5225]  base_lr: 3.5748e-05 lr: 3.5748e-06  eta: 6:08:41  time: 0.1639  data_time: 0.0017  memory: 10434  loss: 4.5430  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 4.5430\n",
      "03/07 00:50:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2800/5225]  base_lr: 3.6609e-05 lr: 3.6609e-06  eta: 6:07:39  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 4.3350  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 4.3350\n",
      "03/07 00:50:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2900/5225]  base_lr: 3.7470e-05 lr: 3.7470e-06  eta: 6:06:46  time: 0.1643  data_time: 0.0020  memory: 10434  loss: 4.4777  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.4777\n",
      "03/07 00:51:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 00:51:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3000/5225]  base_lr: 3.8332e-05 lr: 3.8332e-06  eta: 6:05:57  time: 0.1637  data_time: 0.0019  memory: 10434  loss: 4.4596  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.4596\n",
      "03/07 00:51:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3100/5225]  base_lr: 3.9193e-05 lr: 3.9193e-06  eta: 6:05:17  time: 0.1642  data_time: 0.0027  memory: 10434  loss: 4.7217  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.7217\n",
      "03/07 00:51:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3200/5225]  base_lr: 4.0054e-05 lr: 4.0054e-06  eta: 6:04:32  time: 0.1653  data_time: 0.0035  memory: 10434  loss: 4.3779  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.3779\n",
      "03/07 00:51:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3300/5225]  base_lr: 4.0916e-05 lr: 4.0916e-06  eta: 6:03:49  time: 0.1650  data_time: 0.0019  memory: 10434  loss: 4.3361  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.3361\n",
      "03/07 00:52:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3400/5225]  base_lr: 4.1777e-05 lr: 4.1777e-06  eta: 6:03:07  time: 0.1644  data_time: 0.0023  memory: 10434  loss: 4.4369  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.4369\n",
      "03/07 00:52:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3500/5225]  base_lr: 4.2638e-05 lr: 4.2638e-06  eta: 6:02:26  time: 0.1658  data_time: 0.0031  memory: 10434  loss: 4.3851  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 4.3851\n",
      "03/07 00:52:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3600/5225]  base_lr: 4.3500e-05 lr: 4.3500e-06  eta: 6:01:47  time: 0.1667  data_time: 0.0019  memory: 10434  loss: 4.1789  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1789\n",
      "03/07 00:52:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3700/5225]  base_lr: 4.4361e-05 lr: 4.4361e-06  eta: 6:01:14  time: 0.1642  data_time: 0.0023  memory: 10434  loss: 4.2922  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.2922\n",
      "03/07 00:53:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3800/5225]  base_lr: 4.5222e-05 lr: 4.5222e-06  eta: 6:00:48  time: 0.1637  data_time: 0.0007  memory: 10434  loss: 4.1420  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1420\n",
      "03/07 00:53:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3900/5225]  base_lr: 4.6084e-05 lr: 4.6084e-06  eta: 6:00:12  time: 0.1650  data_time: 0.0005  memory: 10434  loss: 4.3129  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.3129\n",
      "03/07 00:53:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 00:53:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4000/5225]  base_lr: 4.6945e-05 lr: 4.6945e-06  eta: 5:59:38  time: 0.1658  data_time: 0.0034  memory: 10434  loss: 4.4124  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.4124\n",
      "03/07 00:54:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4100/5225]  base_lr: 4.7806e-05 lr: 4.7806e-06  eta: 5:59:06  time: 0.1658  data_time: 0.0023  memory: 10434  loss: 4.3879  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.3879\n",
      "03/07 00:54:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4200/5225]  base_lr: 4.8668e-05 lr: 4.8668e-06  eta: 5:58:34  time: 0.1641  data_time: 0.0025  memory: 10434  loss: 4.4800  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.4800\n",
      "03/07 00:54:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4300/5225]  base_lr: 4.9529e-05 lr: 4.9529e-06  eta: 5:58:00  time: 0.1636  data_time: 0.0017  memory: 10434  loss: 4.2793  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2793\n",
      "03/07 00:54:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4400/5225]  base_lr: 5.0390e-05 lr: 5.0390e-06  eta: 5:57:31  time: 0.1675  data_time: 0.0015  memory: 10434  loss: 4.3943  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.3943\n",
      "03/07 00:55:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4500/5225]  base_lr: 5.1252e-05 lr: 5.1252e-06  eta: 5:57:08  time: 0.1651  data_time: 0.0026  memory: 10434  loss: 4.3196  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 4.3196\n",
      "03/07 00:55:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4600/5225]  base_lr: 5.2113e-05 lr: 5.2113e-06  eta: 5:56:37  time: 0.1649  data_time: 0.0022  memory: 10434  loss: 4.3539  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.3539\n",
      "03/07 00:55:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4700/5225]  base_lr: 5.2975e-05 lr: 5.2975e-06  eta: 5:56:07  time: 0.1663  data_time: 0.0010  memory: 10434  loss: 4.5337  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.5337\n",
      "03/07 00:55:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4800/5225]  base_lr: 5.3836e-05 lr: 5.3836e-06  eta: 5:55:37  time: 0.1647  data_time: 0.0020  memory: 10434  loss: 4.5229  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.5229\n",
      "03/07 00:56:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4900/5225]  base_lr: 5.4697e-05 lr: 5.4697e-06  eta: 5:55:07  time: 0.1650  data_time: 0.0007  memory: 10434  loss: 4.2350  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2350\n",
      "03/07 00:56:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 00:56:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][5000/5225]  base_lr: 5.5559e-05 lr: 5.5559e-06  eta: 5:54:37  time: 0.1648  data_time: 0.0021  memory: 10434  loss: 4.3710  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.3710\n",
      "03/07 00:56:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][5100/5225]  base_lr: 5.6420e-05 lr: 5.6420e-06  eta: 5:54:16  time: 0.1675  data_time: 0.0017  memory: 10434  loss: 4.4296  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.4296\n",
      "03/07 00:57:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][5200/5225]  base_lr: 5.7281e-05 lr: 5.7281e-06  eta: 5:53:53  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 4.2271  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 4.2271\n",
      "03/07 00:57:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 00:57:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][5225/5225]  base_lr: 5.7497e-05 lr: 5.7497e-06  eta: 5:53:44  time: 0.1604  data_time: 0.0019  memory: 10434  loss: 4.1651  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1651\n",
      "03/07 00:57:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][100/647]    eta: 0:00:55  time: 0.0639  data_time: 0.0338  memory: 861  \n",
      "03/07 00:57:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][200/647]    eta: 0:00:36  time: 0.0590  data_time: 0.0288  memory: 861  \n",
      "03/07 00:57:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][300/647]    eta: 0:00:26  time: 0.0667  data_time: 0.0367  memory: 861  \n",
      "03/07 00:57:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][400/647]    eta: 0:00:17  time: 0.0673  data_time: 0.0232  memory: 861  \n",
      "03/07 00:57:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][500/647]    eta: 0:00:10  time: 0.0734  data_time: 0.0420  memory: 861  \n",
      "03/07 00:57:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][600/647]    eta: 0:00:03  time: 0.0631  data_time: 0.0326  memory: 861  \n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[13]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[13]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[11]\n",
      "[11]\n",
      "[22]\n",
      "[104]\n",
      "[104]\n",
      "[11]\n",
      "[11]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[11]\n",
      "[104]\n",
      "[11]\n",
      "[104]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[11]\n",
      "[11]\n",
      "[24]\n",
      "[11]\n",
      "[24]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[13]\n",
      "[104]\n",
      "[11]\n",
      "[13]\n",
      "[98]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[24]\n",
      "[11]\n",
      "[11]\n",
      "[24]\n",
      "[11]\n",
      "[11]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[24]\n",
      "[41]\n",
      "[93]\n",
      "[41]\n",
      "[41]\n",
      "[65]\n",
      "[41]\n",
      "[65]\n",
      "[65]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[65]\n",
      "[65]\n",
      "[41]\n",
      "[41]\n",
      "[65]\n",
      "[65]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[65]\n",
      "[65]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[65]\n",
      "[65]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[65]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[65]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[65]\n",
      "[41]\n",
      "[41]\n",
      "[117]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[65]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[35]\n",
      "[121]\n",
      "[35]\n",
      "[41]\n",
      "[41]\n",
      "[35]\n",
      "[35]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[24]\n",
      "[104]\n",
      "[102]\n",
      "[41]\n",
      "[102]\n",
      "[103]\n",
      "[24]\n",
      "[78]\n",
      "[22]\n",
      "[81]\n",
      "[102]\n",
      "[102]\n",
      "[24]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[41]\n",
      "[103]\n",
      "[103]\n",
      "[104]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[103]\n",
      "[121]\n",
      "[121]\n",
      "[103]\n",
      "[103]\n",
      "[22]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[103]\n",
      "[103]\n",
      "[121]\n",
      "[121]\n",
      "[58]\n",
      "[24]\n",
      "[98]\n",
      "[81]\n",
      "[24]\n",
      "[103]\n",
      "[121]\n",
      "[58]\n",
      "[14]\n",
      "[76]\n",
      "[58]\n",
      "[24]\n",
      "[65]\n",
      "[81]\n",
      "[103]\n",
      "[24]\n",
      "[58]\n",
      "[24]\n",
      "[103]\n",
      "[58]\n",
      "[58]\n",
      "[24]\n",
      "[104]\n",
      "[103]\n",
      "[11]\n",
      "[121]\n",
      "[119]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[119]\n",
      "[119]\n",
      "[119]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[119]\n",
      "[119]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[119]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[65]\n",
      "[65]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[106]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[106]\n",
      "[106]\n",
      "[104]\n",
      "[106]\n",
      "[106]\n",
      "[106]\n",
      "[106]\n",
      "[106]\n",
      "[41]\n",
      "[106]\n",
      "[106]\n",
      "[41]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[106]\n",
      "[106]\n",
      "[106]\n",
      "[41]\n",
      "[93]\n",
      "[93]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[106]\n",
      "[41]\n",
      "[41]\n",
      "[93]\n",
      "[65]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[22]\n",
      "[76]\n",
      "[24]\n",
      "[22]\n",
      "[72]\n",
      "[81]\n",
      "[24]\n",
      "[24]\n",
      "[22]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[22]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[72]\n",
      "[76]\n",
      "[78]\n",
      "[13]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[76]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[72]\n",
      "[76]\n",
      "[78]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[76]\n",
      "[76]\n",
      "[81]\n",
      "[81]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[76]\n",
      "[13]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[72]\n",
      "[72]\n",
      "[72]\n",
      "[72]\n",
      "[72]\n",
      "[76]\n",
      "[72]\n",
      "[22]\n",
      "[11]\n",
      "[22]\n",
      "[76]\n",
      "[76]\n",
      "[72]\n",
      "[104]\n",
      "[72]\n",
      "[72]\n",
      "[72]\n",
      "[22]\n",
      "[76]\n",
      "[76]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[93]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[65]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[35]\n",
      "[41]\n",
      "[121]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[103]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[11]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[41]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[106]\n",
      "[106]\n",
      "[106]\n",
      "[14]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[106]\n",
      "[72]\n",
      "[104]\n",
      "[104]\n",
      "[13]\n",
      "[13]\n",
      "[81]\n",
      "[65]\n",
      "[13]\n",
      "[24]\n",
      "[113]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[81]\n",
      "[72]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[35]\n",
      "[41]\n",
      "[41]\n",
      "[35]\n",
      "[35]\n",
      "[35]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[39]\n",
      "[14]\n",
      "[14]\n",
      "[39]\n",
      "[14]\n",
      "[121]\n",
      "[35]\n",
      "[35]\n",
      "[35]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "03/07 00:57:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][647/647]    acc/top1: 0.0216  acc/top5: 0.1036  acc/mean1: 0.0400  data_time: 0.0396  time: 0.0707\n",
      "03/07 00:57:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.0216 acc/top1 at 1 epoch is saved to best_acc_top1_epoch_1.pth.\n",
      "03/07 00:58:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 100/5225]  base_lr: 5.8198e-05 lr: 5.8198e-06  eta: 5:53:25  time: 0.1650  data_time: 0.0032  memory: 10434  loss: 4.2642  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2642\n",
      "03/07 00:58:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 200/5225]  base_lr: 5.9057e-05 lr: 5.9057e-06  eta: 5:52:59  time: 0.1660  data_time: 0.0022  memory: 10434  loss: 3.9514  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.9514\n",
      "03/07 00:58:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 300/5225]  base_lr: 5.9916e-05 lr: 5.9916e-06  eta: 5:52:33  time: 0.1658  data_time: 0.0027  memory: 10434  loss: 4.3389  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.3389\n",
      "03/07 00:59:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 400/5225]  base_lr: 6.0775e-05 lr: 6.0775e-06  eta: 5:52:07  time: 0.1658  data_time: 0.0019  memory: 10434  loss: 3.7872  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7872\n",
      "03/07 00:59:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 500/5225]  base_lr: 6.1634e-05 lr: 6.1634e-06  eta: 5:51:44  time: 0.1676  data_time: 0.0017  memory: 10434  loss: 4.0709  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0709\n",
      "03/07 00:59:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 600/5225]  base_lr: 6.2493e-05 lr: 6.2493e-06  eta: 5:51:20  time: 0.1659  data_time: 0.0008  memory: 10434  loss: 4.1162  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 4.1162\n",
      "03/07 00:59:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 700/5225]  base_lr: 6.3352e-05 lr: 6.3352e-06  eta: 5:50:54  time: 0.1641  data_time: 0.0017  memory: 10434  loss: 4.3724  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.3724\n",
      "03/07 01:00:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:00:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 800/5225]  base_lr: 6.4211e-05 lr: 6.4211e-06  eta: 5:50:28  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 4.2991  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2991\n",
      "03/07 01:00:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 900/5225]  base_lr: 6.5070e-05 lr: 6.5070e-06  eta: 5:50:04  time: 0.1648  data_time: 0.0011  memory: 10434  loss: 4.3455  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 4.3455\n",
      "03/07 01:00:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1000/5225]  base_lr: 6.5929e-05 lr: 6.5929e-06  eta: 5:49:40  time: 0.1650  data_time: 0.0013  memory: 10434  loss: 4.1646  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1646\n",
      "03/07 01:00:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1100/5225]  base_lr: 6.6788e-05 lr: 6.6788e-06  eta: 5:49:15  time: 0.1642  data_time: 0.0014  memory: 10434  loss: 4.2003  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2003\n",
      "03/07 01:01:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1200/5225]  base_lr: 6.7647e-05 lr: 6.7647e-06  eta: 5:48:52  time: 0.1638  data_time: 0.0012  memory: 10434  loss: 4.0615  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 4.0615\n",
      "03/07 01:01:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1300/5225]  base_lr: 6.8506e-05 lr: 6.8506e-06  eta: 5:48:26  time: 0.1650  data_time: 0.0027  memory: 10434  loss: 4.0360  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0360\n",
      "03/07 01:01:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1400/5225]  base_lr: 6.9365e-05 lr: 6.9365e-06  eta: 5:48:03  time: 0.1654  data_time: 0.0011  memory: 10434  loss: 4.0345  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0345\n",
      "03/07 01:02:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1500/5225]  base_lr: 7.0224e-05 lr: 7.0224e-06  eta: 5:47:42  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 3.9231  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9231\n",
      "03/07 01:02:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1600/5225]  base_lr: 7.1083e-05 lr: 7.1083e-06  eta: 5:47:16  time: 0.1627  data_time: 0.0019  memory: 10434  loss: 4.4768  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.4768\n",
      "03/07 01:02:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1700/5225]  base_lr: 7.1942e-05 lr: 7.1942e-06  eta: 5:46:52  time: 0.1677  data_time: 0.0020  memory: 10434  loss: 3.9032  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.9032\n",
      "03/07 01:02:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:02:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1800/5225]  base_lr: 7.2801e-05 lr: 7.2801e-06  eta: 5:46:30  time: 0.1654  data_time: 0.0019  memory: 10434  loss: 3.9220  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9220\n",
      "03/07 01:03:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1900/5225]  base_lr: 7.3660e-05 lr: 7.3660e-06  eta: 5:46:07  time: 0.1625  data_time: 0.0017  memory: 10434  loss: 4.1724  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 4.1724\n",
      "03/07 01:03:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2000/5225]  base_lr: 7.4519e-05 lr: 7.4519e-06  eta: 5:45:41  time: 0.1626  data_time: 0.0019  memory: 10434  loss: 3.9791  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9791\n",
      "03/07 01:03:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2100/5225]  base_lr: 7.5378e-05 lr: 7.5378e-06  eta: 5:45:16  time: 0.1648  data_time: 0.0017  memory: 10434  loss: 4.0546  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.0546\n",
      "03/07 01:03:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2200/5225]  base_lr: 7.6237e-05 lr: 7.6237e-06  eta: 5:44:54  time: 0.1643  data_time: 0.0018  memory: 10434  loss: 3.8400  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8400\n",
      "03/07 01:04:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2300/5225]  base_lr: 7.7096e-05 lr: 7.7096e-06  eta: 5:44:31  time: 0.1630  data_time: 0.0019  memory: 10434  loss: 4.0083  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 4.0083\n",
      "03/07 01:04:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2400/5225]  base_lr: 7.7955e-05 lr: 7.7955e-06  eta: 5:44:07  time: 0.1634  data_time: 0.0019  memory: 10434  loss: 3.9313  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9313\n",
      "03/07 01:04:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2500/5225]  base_lr: 7.8814e-05 lr: 7.8814e-06  eta: 5:43:43  time: 0.1629  data_time: 0.0018  memory: 10434  loss: 4.1417  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1417\n",
      "03/07 01:05:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2600/5225]  base_lr: 7.9673e-05 lr: 7.9673e-06  eta: 5:43:20  time: 0.1630  data_time: 0.0019  memory: 10434  loss: 3.8991  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 3.8991\n",
      "03/07 01:05:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2700/5225]  base_lr: 8.0532e-05 lr: 8.0532e-06  eta: 5:42:56  time: 0.1629  data_time: 0.0017  memory: 10434  loss: 3.8371  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8371\n",
      "03/07 01:05:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:05:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2800/5225]  base_lr: 8.1391e-05 lr: 8.1391e-06  eta: 5:42:33  time: 0.1633  data_time: 0.0018  memory: 10434  loss: 3.9978  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9978\n",
      "03/07 01:05:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2900/5225]  base_lr: 8.2250e-05 lr: 8.2250e-06  eta: 5:42:10  time: 0.1628  data_time: 0.0018  memory: 10434  loss: 3.6031  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.6031\n",
      "03/07 01:06:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3000/5225]  base_lr: 8.3109e-05 lr: 8.3109e-06  eta: 5:41:47  time: 0.1632  data_time: 0.0019  memory: 10434  loss: 4.0223  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 4.0223\n",
      "03/07 01:06:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3100/5225]  base_lr: 8.3968e-05 lr: 8.3968e-06  eta: 5:41:24  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 3.9432  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.9432\n",
      "03/07 01:06:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3200/5225]  base_lr: 8.4827e-05 lr: 8.4827e-06  eta: 5:41:02  time: 0.1641  data_time: 0.0018  memory: 10434  loss: 3.9796  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 3.9796\n",
      "03/07 01:06:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3300/5225]  base_lr: 8.5686e-05 lr: 8.5686e-06  eta: 5:40:40  time: 0.1632  data_time: 0.0017  memory: 10434  loss: 3.9764  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9764\n",
      "03/07 01:07:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3400/5225]  base_lr: 8.6545e-05 lr: 8.6545e-06  eta: 5:40:17  time: 0.1626  data_time: 0.0019  memory: 10434  loss: 3.7701  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7701\n",
      "03/07 01:07:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3500/5225]  base_lr: 8.7403e-05 lr: 8.7403e-06  eta: 5:39:54  time: 0.1629  data_time: 0.0019  memory: 10434  loss: 3.6102  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.6102\n",
      "03/07 01:07:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3600/5225]  base_lr: 8.8262e-05 lr: 8.8262e-06  eta: 5:39:32  time: 0.1627  data_time: 0.0018  memory: 10434  loss: 3.8654  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8654\n",
      "03/07 01:08:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3700/5225]  base_lr: 8.9121e-05 lr: 8.9121e-06  eta: 5:39:11  time: 0.1651  data_time: 0.0018  memory: 10434  loss: 3.8025  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.8025\n",
      "03/07 01:08:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:08:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3800/5225]  base_lr: 8.9980e-05 lr: 8.9980e-06  eta: 5:38:51  time: 0.1664  data_time: 0.0019  memory: 10434  loss: 3.8962  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8962\n",
      "03/07 01:08:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3900/5225]  base_lr: 9.0839e-05 lr: 9.0839e-06  eta: 5:38:32  time: 0.1652  data_time: 0.0018  memory: 10434  loss: 3.5060  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.5060\n",
      "03/07 01:08:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4000/5225]  base_lr: 9.1698e-05 lr: 9.1698e-06  eta: 5:38:12  time: 0.1647  data_time: 0.0019  memory: 10434  loss: 3.7973  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.7973\n",
      "03/07 01:09:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4100/5225]  base_lr: 9.2557e-05 lr: 9.2557e-06  eta: 5:37:52  time: 0.1626  data_time: 0.0017  memory: 10434  loss: 3.7663  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.7663\n",
      "03/07 01:09:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4200/5225]  base_lr: 9.3416e-05 lr: 9.3416e-06  eta: 5:37:30  time: 0.1627  data_time: 0.0018  memory: 10434  loss: 3.8046  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.8046\n",
      "03/07 01:09:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4300/5225]  base_lr: 9.4275e-05 lr: 9.4275e-06  eta: 5:37:08  time: 0.1629  data_time: 0.0016  memory: 10434  loss: 3.9255  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9255\n",
      "03/07 01:09:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4400/5225]  base_lr: 9.5134e-05 lr: 9.5134e-06  eta: 5:36:48  time: 0.1629  data_time: 0.0019  memory: 10434  loss: 3.5774  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.5774\n",
      "03/07 01:10:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4500/5225]  base_lr: 9.5993e-05 lr: 9.5993e-06  eta: 5:36:27  time: 0.1635  data_time: 0.0020  memory: 10434  loss: 3.7543  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.7543\n",
      "03/07 01:10:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4600/5225]  base_lr: 9.6852e-05 lr: 9.6852e-06  eta: 5:36:06  time: 0.1637  data_time: 0.0017  memory: 10434  loss: 3.4383  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.4383\n",
      "03/07 01:10:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4700/5225]  base_lr: 9.7711e-05 lr: 9.7711e-06  eta: 5:35:44  time: 0.1624  data_time: 0.0019  memory: 10434  loss: 3.6004  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.6004\n",
      "03/07 01:10:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:11:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4800/5225]  base_lr: 9.8570e-05 lr: 9.8570e-06  eta: 5:35:23  time: 0.1640  data_time: 0.0020  memory: 10434  loss: 3.9616  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9616\n",
      "03/07 01:11:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4900/5225]  base_lr: 9.9429e-05 lr: 9.9429e-06  eta: 5:35:03  time: 0.1636  data_time: 0.0017  memory: 10434  loss: 3.7848  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.7848\n",
      "03/07 01:11:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][5000/5225]  base_lr: 1.0029e-04 lr: 1.0029e-05  eta: 5:34:42  time: 0.1623  data_time: 0.0017  memory: 10434  loss: 3.8078  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8078\n",
      "03/07 01:11:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][5100/5225]  base_lr: 1.0115e-04 lr: 1.0115e-05  eta: 5:34:21  time: 0.1626  data_time: 0.0017  memory: 10434  loss: 3.7308  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.7308\n",
      "03/07 01:12:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][5200/5225]  base_lr: 1.0201e-04 lr: 1.0201e-05  eta: 5:34:01  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 3.8487  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8487\n",
      "03/07 01:12:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:12:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][5225/5225]  base_lr: 1.0222e-04 lr: 1.0222e-05  eta: 5:33:55  time: 0.1603  data_time: 0.0019  memory: 10434  loss: 3.6306  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.6306\n",
      "03/07 01:12:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][100/647]    eta: 0:00:17  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "03/07 01:12:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][200/647]    eta: 0:00:13  time: 0.0310  data_time: 0.0009  memory: 861  \n",
      "03/07 01:12:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][300/647]    eta: 0:00:10  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "03/07 01:12:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][400/647]    eta: 0:00:07  time: 0.0309  data_time: 0.0009  memory: 861  \n",
      "03/07 01:12:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][500/647]    eta: 0:00:04  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "03/07 01:12:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][600/647]    eta: 0:00:01  time: 0.0310  data_time: 0.0009  memory: 861  \n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[14]\n",
      "[11]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[16]\n",
      "[16]\n",
      "[16]\n",
      "[11]\n",
      "[11]\n",
      "[16]\n",
      "[14]\n",
      "[14]\n",
      "[16]\n",
      "[14]\n",
      "[16]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[16]\n",
      "[16]\n",
      "[16]\n",
      "[16]\n",
      "[11]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[16]\n",
      "[16]\n",
      "[16]\n",
      "[16]\n",
      "[16]\n",
      "[14]\n",
      "[14]\n",
      "[16]\n",
      "[69]\n",
      "[94]\n",
      "[94]\n",
      "[69]\n",
      "[94]\n",
      "[94]\n",
      "[94]\n",
      "[94]\n",
      "[94]\n",
      "[53]\n",
      "[30]\n",
      "[94]\n",
      "[94]\n",
      "[94]\n",
      "[94]\n",
      "[94]\n",
      "[94]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[94]\n",
      "[94]\n",
      "[94]\n",
      "[115]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[94]\n",
      "[94]\n",
      "[115]\n",
      "[113]\n",
      "[67]\n",
      "[94]\n",
      "[30]\n",
      "[113]\n",
      "[66]\n",
      "[41]\n",
      "[94]\n",
      "[113]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[69]\n",
      "[94]\n",
      "[94]\n",
      "[66]\n",
      "[66]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[30]\n",
      "[27]\n",
      "[66]\n",
      "[113]\n",
      "[66]\n",
      "[113]\n",
      "[113]\n",
      "[111]\n",
      "[95]\n",
      "[34]\n",
      "[111]\n",
      "[109]\n",
      "[34]\n",
      "[109]\n",
      "[36]\n",
      "[34]\n",
      "[34]\n",
      "[109]\n",
      "[22]\n",
      "[14]\n",
      "[10]\n",
      "[115]\n",
      "[16]\n",
      "[16]\n",
      "[22]\n",
      "[86]\n",
      "[14]\n",
      "[14]\n",
      "[16]\n",
      "[16]\n",
      "[10]\n",
      "[9]\n",
      "[95]\n",
      "[95]\n",
      "[16]\n",
      "[30]\n",
      "[16]\n",
      "[16]\n",
      "[14]\n",
      "[122]\n",
      "[9]\n",
      "[122]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[16]\n",
      "[16]\n",
      "[86]\n",
      "[53]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[122]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[16]\n",
      "[14]\n",
      "[27]\n",
      "[86]\n",
      "[16]\n",
      "[9]\n",
      "[9]\n",
      "[14]\n",
      "[14]\n",
      "[6]\n",
      "[22]\n",
      "[67]\n",
      "[30]\n",
      "[16]\n",
      "[14]\n",
      "[9]\n",
      "[16]\n",
      "[9]\n",
      "[16]\n",
      "[9]\n",
      "[16]\n",
      "[14]\n",
      "[9]\n",
      "[14]\n",
      "[59]\n",
      "[54]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[119]\n",
      "[71]\n",
      "[53]\n",
      "[95]\n",
      "[54]\n",
      "[53]\n",
      "[95]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[54]\n",
      "[59]\n",
      "[95]\n",
      "[71]\n",
      "[53]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[91]\n",
      "[30]\n",
      "[63]\n",
      "[63]\n",
      "[94]\n",
      "[94]\n",
      "[63]\n",
      "[94]\n",
      "[69]\n",
      "[69]\n",
      "[94]\n",
      "[94]\n",
      "[69]\n",
      "[69]\n",
      "[61]\n",
      "[61]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[61]\n",
      "[94]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[69]\n",
      "[53]\n",
      "[69]\n",
      "[69]\n",
      "[61]\n",
      "[27]\n",
      "[94]\n",
      "[53]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[53]\n",
      "[53]\n",
      "[66]\n",
      "[67]\n",
      "[67]\n",
      "[53]\n",
      "[66]\n",
      "[66]\n",
      "[69]\n",
      "[29]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[122]\n",
      "[122]\n",
      "[95]\n",
      "[95]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[122]\n",
      "[95]\n",
      "[95]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[95]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[74]\n",
      "[74]\n",
      "[86]\n",
      "[86]\n",
      "[74]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[74]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[74]\n",
      "[74]\n",
      "[86]\n",
      "[14]\n",
      "[14]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[86]\n",
      "[86]\n",
      "[14]\n",
      "[86]\n",
      "[86]\n",
      "[74]\n",
      "[86]\n",
      "[86]\n",
      "[14]\n",
      "[74]\n",
      "[74]\n",
      "[86]\n",
      "[86]\n",
      "[74]\n",
      "[74]\n",
      "[74]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[14]\n",
      "[74]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[74]\n",
      "[74]\n",
      "[14]\n",
      "[74]\n",
      "[74]\n",
      "[86]\n",
      "[74]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[22]\n",
      "[86]\n",
      "[74]\n",
      "[74]\n",
      "[74]\n",
      "[22]\n",
      "[14]\n",
      "[86]\n",
      "[86]\n",
      "[30]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[30]\n",
      "[66]\n",
      "[69]\n",
      "[94]\n",
      "[94]\n",
      "[94]\n",
      "[94]\n",
      "[30]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[94]\n",
      "[30]\n",
      "[94]\n",
      "[30]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[97]\n",
      "[49]\n",
      "[16]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[96]\n",
      "[96]\n",
      "[104]\n",
      "[96]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[14]\n",
      "[14]\n",
      "[104]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[34]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[105]\n",
      "[74]\n",
      "[14]\n",
      "[74]\n",
      "[30]\n",
      "[86]\n",
      "[86]\n",
      "[30]\n",
      "[74]\n",
      "[24]\n",
      "[113]\n",
      "[113]\n",
      "[86]\n",
      "[86]\n",
      "[113]\n",
      "[14]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[30]\n",
      "[113]\n",
      "[115]\n",
      "[95]\n",
      "[111]\n",
      "[111]\n",
      "[95]\n",
      "[111]\n",
      "[111]\n",
      "[69]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[95]\n",
      "[36]\n",
      "[34]\n",
      "[36]\n",
      "[121]\n",
      "[53]\n",
      "[121]\n",
      "[121]\n",
      "[53]\n",
      "[53]\n",
      "03/07 01:12:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][647/647]    acc/top1: 0.0309  acc/top5: 0.1499  acc/mean1: 0.0470  data_time: 0.0008  time: 0.0311\n",
      "03/07 01:12:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_1.pth is removed\n",
      "03/07 01:12:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.0309 acc/top1 at 2 epoch is saved to best_acc_top1_epoch_2.pth.\n",
      "03/07 01:12:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 100/5225]  base_lr: 1.0223e-04 lr: 1.0223e-05  eta: 5:33:36  time: 0.1631  data_time: 0.0017  memory: 10434  loss: 3.7139  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 3.7139\n",
      "03/07 01:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 200/5225]  base_lr: 1.0309e-04 lr: 1.0309e-05  eta: 5:33:16  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 3.8115  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.8115\n",
      "03/07 01:13:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 300/5225]  base_lr: 1.0394e-04 lr: 1.0394e-05  eta: 5:32:56  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 3.6326  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.6326\n",
      "03/07 01:13:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 400/5225]  base_lr: 1.0479e-04 lr: 1.0479e-05  eta: 5:32:36  time: 0.1632  data_time: 0.0019  memory: 10434  loss: 3.8039  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8039\n",
      "03/07 01:13:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 500/5225]  base_lr: 1.0564e-04 lr: 1.0564e-05  eta: 5:32:15  time: 0.1626  data_time: 0.0019  memory: 10434  loss: 3.5269  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.5269\n",
      "03/07 01:14:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:14:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 600/5225]  base_lr: 1.0649e-04 lr: 1.0649e-05  eta: 5:31:55  time: 0.1631  data_time: 0.0020  memory: 10434  loss: 3.7016  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.7016\n",
      "03/07 01:14:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 700/5225]  base_lr: 1.0735e-04 lr: 1.0735e-05  eta: 5:31:35  time: 0.1624  data_time: 0.0018  memory: 10434  loss: 3.7780  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7780\n",
      "03/07 01:14:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 800/5225]  base_lr: 1.0820e-04 lr: 1.0820e-05  eta: 5:31:17  time: 0.1661  data_time: 0.0018  memory: 10434  loss: 3.9040  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9040\n",
      "03/07 01:15:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 900/5225]  base_lr: 1.0905e-04 lr: 1.0905e-05  eta: 5:30:58  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 3.4052  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.4052\n",
      "03/07 01:15:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1000/5225]  base_lr: 1.0990e-04 lr: 1.0990e-05  eta: 5:30:38  time: 0.1638  data_time: 0.0020  memory: 10434  loss: 3.3032  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.3032\n",
      "03/07 01:15:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1100/5225]  base_lr: 1.1075e-04 lr: 1.1075e-05  eta: 5:30:18  time: 0.1639  data_time: 0.0019  memory: 10434  loss: 3.7334  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7334\n",
      "03/07 01:15:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1200/5225]  base_lr: 1.1160e-04 lr: 1.1160e-05  eta: 5:29:59  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 3.2505  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.2505\n",
      "03/07 01:16:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1300/5225]  base_lr: 1.1246e-04 lr: 1.1246e-05  eta: 5:29:39  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 3.2753  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.2753\n",
      "03/07 01:16:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1400/5225]  base_lr: 1.1331e-04 lr: 1.1331e-05  eta: 5:29:19  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 3.3545  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.3545\n",
      "03/07 01:16:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1500/5225]  base_lr: 1.1416e-04 lr: 1.1416e-05  eta: 5:29:00  time: 0.1642  data_time: 0.0019  memory: 10434  loss: 3.5684  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.5684\n",
      "03/07 01:16:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:16:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1600/5225]  base_lr: 1.1501e-04 lr: 1.1501e-05  eta: 5:28:40  time: 0.1627  data_time: 0.0018  memory: 10434  loss: 3.2701  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.2701\n",
      "03/07 01:17:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1700/5225]  base_lr: 1.1586e-04 lr: 1.1586e-05  eta: 5:28:21  time: 0.1622  data_time: 0.0016  memory: 10434  loss: 3.5928  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.5928\n",
      "03/07 01:17:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1800/5225]  base_lr: 1.1672e-04 lr: 1.1672e-05  eta: 5:28:01  time: 0.1627  data_time: 0.0018  memory: 10434  loss: 3.4166  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.4166\n",
      "03/07 01:17:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1900/5225]  base_lr: 1.1757e-04 lr: 1.1757e-05  eta: 5:27:42  time: 0.1632  data_time: 0.0017  memory: 10434  loss: 3.3471  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.3471\n",
      "03/07 01:18:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2000/5225]  base_lr: 1.1842e-04 lr: 1.1842e-05  eta: 5:27:23  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 3.3657  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.3657\n",
      "03/07 01:18:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2100/5225]  base_lr: 1.1927e-04 lr: 1.1927e-05  eta: 5:27:03  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 3.4717  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.4717\n",
      "03/07 01:18:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2200/5225]  base_lr: 1.2012e-04 lr: 1.2012e-05  eta: 5:26:44  time: 0.1652  data_time: 0.0019  memory: 10434  loss: 3.8963  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8963\n",
      "03/07 01:18:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2300/5225]  base_lr: 1.2098e-04 lr: 1.2098e-05  eta: 5:26:26  time: 0.1643  data_time: 0.0019  memory: 10434  loss: 3.9783  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9783\n",
      "03/07 01:19:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2400/5225]  base_lr: 1.2183e-04 lr: 1.2183e-05  eta: 5:26:07  time: 0.1632  data_time: 0.0019  memory: 10434  loss: 3.4120  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.4120\n",
      "03/07 01:19:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2500/5225]  base_lr: 1.2268e-04 lr: 1.2268e-05  eta: 5:25:48  time: 0.1639  data_time: 0.0020  memory: 10434  loss: 3.2958  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.2958\n",
      "03/07 01:19:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:19:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2600/5225]  base_lr: 1.2353e-04 lr: 1.2353e-05  eta: 5:25:29  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 3.2254  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.2254\n",
      "03/07 01:19:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2700/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:25:10  time: 0.1629  data_time: 0.0016  memory: 10434  loss: 3.3794  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.3794\n",
      "03/07 01:20:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2800/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:24:50  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 3.6297  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.6297\n",
      "03/07 01:20:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2900/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:24:31  time: 0.1629  data_time: 0.0015  memory: 10434  loss: 3.3407  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.3407\n",
      "03/07 01:20:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3000/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:24:13  time: 0.1639  data_time: 0.0017  memory: 10434  loss: 3.5520  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.5520\n",
      "03/07 01:21:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3100/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:23:55  time: 0.1637  data_time: 0.0016  memory: 10434  loss: 3.3875  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.3875\n",
      "03/07 01:21:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3200/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:23:36  time: 0.1627  data_time: 0.0015  memory: 10434  loss: 3.4401  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.4401\n",
      "03/07 01:21:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3300/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:23:16  time: 0.1623  data_time: 0.0015  memory: 10434  loss: 3.3169  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.3169\n",
      "03/07 01:21:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3400/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:22:58  time: 0.1632  data_time: 0.0016  memory: 10434  loss: 3.6010  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.6010\n",
      "03/07 01:22:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3500/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:22:39  time: 0.1631  data_time: 0.0017  memory: 10434  loss: 3.3723  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.3723\n",
      "03/07 01:22:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:22:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3600/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:22:20  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 3.3826  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.3826\n",
      "03/07 01:22:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3700/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:22:02  time: 0.1631  data_time: 0.0015  memory: 10434  loss: 3.3363  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.3363\n",
      "03/07 01:22:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3800/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:21:43  time: 0.1630  data_time: 0.0018  memory: 10434  loss: 3.5355  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.5355\n",
      "03/07 01:23:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3900/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:21:24  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 3.4412  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.4412\n",
      "03/07 01:23:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4000/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:21:06  time: 0.1637  data_time: 0.0016  memory: 10434  loss: 2.8456  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.8456\n",
      "03/07 01:23:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4100/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:20:47  time: 0.1629  data_time: 0.0015  memory: 10434  loss: 3.5669  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.5669\n",
      "03/07 01:24:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4200/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:20:28  time: 0.1633  data_time: 0.0016  memory: 10434  loss: 3.2678  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.2678\n",
      "03/07 01:24:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4300/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:20:09  time: 0.1622  data_time: 0.0016  memory: 10434  loss: 3.4210  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.4210\n",
      "03/07 01:24:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4400/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:19:50  time: 0.1632  data_time: 0.0017  memory: 10434  loss: 3.3745  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 3.3745\n",
      "03/07 01:24:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4500/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:19:32  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 3.1132  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.1132\n",
      "03/07 01:24:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:25:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4600/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:19:14  time: 0.1621  data_time: 0.0018  memory: 10434  loss: 3.6316  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.6316\n",
      "03/07 01:25:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4700/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:18:56  time: 0.1646  data_time: 0.0018  memory: 10434  loss: 3.0378  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.0378\n",
      "03/07 01:25:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4800/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:18:38  time: 0.1629  data_time: 0.0017  memory: 10434  loss: 3.5770  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.5770\n",
      "03/07 01:25:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4900/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:18:19  time: 0.1624  data_time: 0.0017  memory: 10434  loss: 3.4571  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.4571\n",
      "03/07 01:26:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][5000/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:18:01  time: 0.1623  data_time: 0.0017  memory: 10434  loss: 3.2193  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.2193\n",
      "03/07 01:26:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][5100/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:17:42  time: 0.1628  data_time: 0.0018  memory: 10434  loss: 3.3995  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.3995\n",
      "03/07 01:26:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][5200/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:17:25  time: 0.1654  data_time: 0.0018  memory: 10434  loss: 3.0314  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.0314\n",
      "03/07 01:26:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:26:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][5225/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 5:17:20  time: 0.1616  data_time: 0.0015  memory: 10434  loss: 3.2454  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 3.2454\n",
      "03/07 01:26:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "03/07 01:26:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][100/647]    eta: 0:00:17  time: 0.0311  data_time: 0.0009  memory: 861  \n",
      "03/07 01:26:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][200/647]    eta: 0:00:13  time: 0.0311  data_time: 0.0009  memory: 861  \n",
      "03/07 01:26:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][300/647]    eta: 0:00:10  time: 0.0312  data_time: 0.0009  memory: 861  \n",
      "03/07 01:27:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][400/647]    eta: 0:00:07  time: 0.0308  data_time: 0.0007  memory: 861  \n",
      "03/07 01:27:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][500/647]    eta: 0:00:04  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "03/07 01:27:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][600/647]    eta: 0:00:01  time: 0.0309  data_time: 0.0008  memory: 861  \n",
      "[9]\n",
      "[30]\n",
      "[9]\n",
      "[13]\n",
      "[13]\n",
      "[18]\n",
      "[21]\n",
      "[21]\n",
      "[9]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[18]\n",
      "[18]\n",
      "[9]\n",
      "[13]\n",
      "[18]\n",
      "[18]\n",
      "[9]\n",
      "[9]\n",
      "[22]\n",
      "[13]\n",
      "[30]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[22]\n",
      "[22]\n",
      "[13]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[30]\n",
      "[30]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[18]\n",
      "[21]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[21]\n",
      "[22]\n",
      "[22]\n",
      "[2]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[18]\n",
      "[2]\n",
      "[18]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[22]\n",
      "[22]\n",
      "[24]\n",
      "[13]\n",
      "[2]\n",
      "[2]\n",
      "[24]\n",
      "[5]\n",
      "[22]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[9]\n",
      "[112]\n",
      "[24]\n",
      "[61]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[19]\n",
      "[30]\n",
      "[91]\n",
      "[19]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[27]\n",
      "[19]\n",
      "[41]\n",
      "[19]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[91]\n",
      "[91]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[30]\n",
      "[19]\n",
      "[41]\n",
      "[19]\n",
      "[41]\n",
      "[91]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[91]\n",
      "[30]\n",
      "[41]\n",
      "[19]\n",
      "[36]\n",
      "[36]\n",
      "[36]\n",
      "[39]\n",
      "[30]\n",
      "[41]\n",
      "[38]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[36]\n",
      "[36]\n",
      "[19]\n",
      "[19]\n",
      "[112]\n",
      "[32]\n",
      "[112]\n",
      "[50]\n",
      "[36]\n",
      "[19]\n",
      "[19]\n",
      "[11]\n",
      "[9]\n",
      "[9]\n",
      "[117]\n",
      "[9]\n",
      "[9]\n",
      "[87]\n",
      "[73]\n",
      "[11]\n",
      "[112]\n",
      "[9]\n",
      "[9]\n",
      "[22]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[87]\n",
      "[31]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[9]\n",
      "[9]\n",
      "[112]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[57]\n",
      "[53]\n",
      "[9]\n",
      "[53]\n",
      "[57]\n",
      "[53]\n",
      "[53]\n",
      "[30]\n",
      "[9]\n",
      "[30]\n",
      "[30]\n",
      "[9]\n",
      "[57]\n",
      "[9]\n",
      "[9]\n",
      "[105]\n",
      "[9]\n",
      "[9]\n",
      "[91]\n",
      "[112]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[30]\n",
      "[30]\n",
      "[57]\n",
      "[22]\n",
      "[55]\n",
      "[71]\n",
      "[71]\n",
      "[55]\n",
      "[71]\n",
      "[55]\n",
      "[55]\n",
      "[57]\n",
      "[55]\n",
      "[119]\n",
      "[119]\n",
      "[55]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[57]\n",
      "[71]\n",
      "[71]\n",
      "[57]\n",
      "[55]\n",
      "[55]\n",
      "[71]\n",
      "[71]\n",
      "[57]\n",
      "[67]\n",
      "[67]\n",
      "[70]\n",
      "[67]\n",
      "[67]\n",
      "[63]\n",
      "[67]\n",
      "[67]\n",
      "[63]\n",
      "[63]\n",
      "[63]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[61]\n",
      "[67]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[67]\n",
      "[67]\n",
      "[67]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[66]\n",
      "[67]\n",
      "[69]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[70]\n",
      "[49]\n",
      "[98]\n",
      "[121]\n",
      "[122]\n",
      "[122]\n",
      "[49]\n",
      "[71]\n",
      "[122]\n",
      "[71]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[98]\n",
      "[98]\n",
      "[122]\n",
      "[122]\n",
      "[49]\n",
      "[49]\n",
      "[121]\n",
      "[122]\n",
      "[49]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[71]\n",
      "[71]\n",
      "[98]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[90]\n",
      "[74]\n",
      "[87]\n",
      "[90]\n",
      "[74]\n",
      "[77]\n",
      "[87]\n",
      "[77]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[90]\n",
      "[90]\n",
      "[87]\n",
      "[90]\n",
      "[74]\n",
      "[74]\n",
      "[87]\n",
      "[90]\n",
      "[81]\n",
      "[82]\n",
      "[82]\n",
      "[74]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[87]\n",
      "[74]\n",
      "[81]\n",
      "[74]\n",
      "[74]\n",
      "[87]\n",
      "[74]\n",
      "[74]\n",
      "[74]\n",
      "[82]\n",
      "[82]\n",
      "[90]\n",
      "[90]\n",
      "[74]\n",
      "[82]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[73]\n",
      "[87]\n",
      "[74]\n",
      "[77]\n",
      "[87]\n",
      "[77]\n",
      "[73]\n",
      "[72]\n",
      "[73]\n",
      "[73]\n",
      "[73]\n",
      "[77]\n",
      "[74]\n",
      "[73]\n",
      "[83]\n",
      "[73]\n",
      "[73]\n",
      "[73]\n",
      "[87]\n",
      "[74]\n",
      "[74]\n",
      "[73]\n",
      "[73]\n",
      "[73]\n",
      "[73]\n",
      "[74]\n",
      "[30]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[112]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[71]\n",
      "[49]\n",
      "[49]\n",
      "[61]\n",
      "[116]\n",
      "[50]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[102]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[103]\n",
      "[102]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[101]\n",
      "[96]\n",
      "[96]\n",
      "[104]\n",
      "[2]\n",
      "[96]\n",
      "[92]\n",
      "[96]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[61]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[71]\n",
      "[71]\n",
      "[119]\n",
      "[71]\n",
      "[34]\n",
      "[49]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[71]\n",
      "[95]\n",
      "[98]\n",
      "[98]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[112]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[39]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[19]\n",
      "[69]\n",
      "[112]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[19]\n",
      "[19]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[113]\n",
      "[118]\n",
      "[50]\n",
      "[50]\n",
      "[50]\n",
      "[121]\n",
      "[50]\n",
      "[19]\n",
      "[19]\n",
      "[50]\n",
      "[19]\n",
      "03/07 01:27:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][647/647]    acc/top1: 0.0634  acc/top5: 0.2473  acc/mean1: 0.0974  data_time: 0.0009  time: 0.0311\n",
      "03/07 01:27:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_2.pth is removed\n",
      "03/07 01:27:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.0634 acc/top1 at 3 epoch is saved to best_acc_top1_epoch_3.pth.\n",
      "03/07 01:27:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 100/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:17:02  time: 0.1619  data_time: 0.0016  memory: 10434  loss: 3.2691  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.2691\n",
      "03/07 01:27:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 200/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:16:44  time: 0.1636  data_time: 0.0017  memory: 10434  loss: 3.0998  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.0998\n",
      "03/07 01:27:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 300/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:16:27  time: 0.1650  data_time: 0.0019  memory: 10434  loss: 2.6194  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.6194\n",
      "03/07 01:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:28:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 400/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:16:09  time: 0.1624  data_time: 0.0015  memory: 10434  loss: 3.1067  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.1067\n",
      "03/07 01:28:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 500/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:15:51  time: 0.1637  data_time: 0.0019  memory: 10434  loss: 3.4139  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.4139\n",
      "03/07 01:28:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 600/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:15:33  time: 0.1642  data_time: 0.0016  memory: 10434  loss: 3.5400  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.5400\n",
      "03/07 01:29:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 700/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:15:15  time: 0.1635  data_time: 0.0015  memory: 10434  loss: 3.1888  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.1888\n",
      "03/07 01:29:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 800/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:14:57  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 3.4462  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.4462\n",
      "03/07 01:29:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 900/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:14:39  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 2.9456  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.9456\n",
      "03/07 01:29:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1000/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:14:21  time: 0.1644  data_time: 0.0017  memory: 10434  loss: 3.1173  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.1173\n",
      "03/07 01:30:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1100/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:14:03  time: 0.1627  data_time: 0.0017  memory: 10434  loss: 3.1747  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.1747\n",
      "03/07 01:30:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1200/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:13:45  time: 0.1625  data_time: 0.0016  memory: 10434  loss: 2.9984  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.9984\n",
      "03/07 01:30:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1300/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:13:27  time: 0.1636  data_time: 0.0017  memory: 10434  loss: 3.4226  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.4226\n",
      "03/07 01:30:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:30:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1400/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:13:09  time: 0.1638  data_time: 0.0015  memory: 10434  loss: 2.8913  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.8913\n",
      "03/07 01:31:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1500/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:12:52  time: 0.1640  data_time: 0.0016  memory: 10434  loss: 2.9709  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.9709\n",
      "03/07 01:31:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1600/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:12:34  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 3.3244  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.3244\n",
      "03/07 01:31:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1700/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:12:16  time: 0.1631  data_time: 0.0017  memory: 10434  loss: 3.1203  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.1203\n",
      "03/07 01:32:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1800/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:11:58  time: 0.1624  data_time: 0.0018  memory: 10434  loss: 2.9816  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.9816\n",
      "03/07 01:32:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1900/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:11:40  time: 0.1625  data_time: 0.0016  memory: 10434  loss: 3.0099  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.0099\n",
      "03/07 01:32:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2000/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:11:22  time: 0.1623  data_time: 0.0017  memory: 10434  loss: 2.9373  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.9373\n",
      "03/07 01:32:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2100/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:11:06  time: 0.1655  data_time: 0.0018  memory: 10434  loss: 3.0365  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.0365\n",
      "03/07 01:33:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2200/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:10:48  time: 0.1626  data_time: 0.0018  memory: 10434  loss: 2.9215  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.9215\n",
      "03/07 01:33:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2300/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:10:30  time: 0.1624  data_time: 0.0015  memory: 10434  loss: 3.1527  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.1527\n",
      "03/07 01:33:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:33:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2400/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:10:12  time: 0.1628  data_time: 0.0016  memory: 10434  loss: 3.4503  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.4503\n",
      "03/07 01:33:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2500/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:09:55  time: 0.1641  data_time: 0.0017  memory: 10434  loss: 3.0503  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.0503\n",
      "03/07 01:34:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2600/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:09:37  time: 0.1628  data_time: 0.0014  memory: 10434  loss: 3.3568  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.3568\n",
      "03/07 01:34:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2700/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:09:19  time: 0.1633  data_time: 0.0020  memory: 10434  loss: 2.7160  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.7160\n",
      "03/07 01:34:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2800/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:09:01  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 2.8147  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.8147\n",
      "03/07 01:35:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2900/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:08:43  time: 0.1633  data_time: 0.0018  memory: 10434  loss: 3.0875  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.0875\n",
      "03/07 01:35:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3000/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:08:26  time: 0.1632  data_time: 0.0016  memory: 10434  loss: 2.6974  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6974\n",
      "03/07 01:35:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3100/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:08:08  time: 0.1636  data_time: 0.0017  memory: 10434  loss: 3.0597  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.0597\n",
      "03/07 01:35:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3200/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:07:51  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 2.6784  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.6784\n",
      "03/07 01:36:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3300/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:07:33  time: 0.1621  data_time: 0.0016  memory: 10434  loss: 2.6767  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.6767\n",
      "03/07 01:36:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:36:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3400/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:07:15  time: 0.1630  data_time: 0.0018  memory: 10434  loss: 3.5096  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 3.5096\n",
      "03/07 01:36:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3500/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:06:57  time: 0.1637  data_time: 0.0016  memory: 10434  loss: 3.2455  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.2455\n",
      "03/07 01:36:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3600/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:06:40  time: 0.1640  data_time: 0.0017  memory: 10434  loss: 2.6893  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6893\n",
      "03/07 01:37:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3700/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:06:23  time: 0.1648  data_time: 0.0017  memory: 10434  loss: 3.0234  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.0234\n",
      "03/07 01:37:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3800/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:06:05  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 3.1919  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.1919\n",
      "03/07 01:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3900/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:05:47  time: 0.1629  data_time: 0.0016  memory: 10434  loss: 2.7058  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.7058\n",
      "03/07 01:38:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4000/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:05:29  time: 0.1625  data_time: 0.0016  memory: 10434  loss: 2.9043  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.9043\n",
      "03/07 01:38:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4100/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:05:11  time: 0.1624  data_time: 0.0016  memory: 10434  loss: 2.7349  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.7349\n",
      "03/07 01:38:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4200/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:04:54  time: 0.1657  data_time: 0.0018  memory: 10434  loss: 3.2698  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.2698\n",
      "03/07 01:38:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4300/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:04:38  time: 0.1645  data_time: 0.0016  memory: 10434  loss: 3.1645  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.1645\n",
      "03/07 01:38:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:39:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4400/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:04:20  time: 0.1636  data_time: 0.0015  memory: 10434  loss: 2.7467  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.7467\n",
      "03/07 01:39:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4500/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:04:03  time: 0.1623  data_time: 0.0016  memory: 10434  loss: 3.1473  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.1473\n",
      "03/07 01:39:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4600/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:03:46  time: 0.1644  data_time: 0.0018  memory: 10434  loss: 3.2647  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.2647\n",
      "03/07 01:39:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4700/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:03:28  time: 0.1628  data_time: 0.0015  memory: 10434  loss: 3.3629  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.3629\n",
      "03/07 01:40:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4800/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:03:10  time: 0.1631  data_time: 0.0017  memory: 10434  loss: 2.7619  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.7619\n",
      "03/07 01:40:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4900/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:02:53  time: 0.1628  data_time: 0.0016  memory: 10434  loss: 3.2093  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.2093\n",
      "03/07 01:40:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][5000/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:02:36  time: 0.1642  data_time: 0.0017  memory: 10434  loss: 3.1390  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.1390\n",
      "03/07 01:41:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][5100/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:02:18  time: 0.1642  data_time: 0.0019  memory: 10434  loss: 3.0757  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.0757\n",
      "03/07 01:41:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][5200/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:02:01  time: 0.1641  data_time: 0.0015  memory: 10434  loss: 2.7197  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.7197\n",
      "03/07 01:41:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:41:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][5225/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 5:01:56  time: 0.1595  data_time: 0.0019  memory: 10434  loss: 2.6789  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.6789\n",
      "03/07 01:41:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][100/647]    eta: 0:00:17  time: 0.0309  data_time: 0.0007  memory: 861  \n",
      "03/07 01:41:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][200/647]    eta: 0:00:13  time: 0.0310  data_time: 0.0006  memory: 861  \n",
      "03/07 01:41:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][300/647]    eta: 0:00:10  time: 0.0311  data_time: 0.0008  memory: 861  \n",
      "03/07 01:41:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][400/647]    eta: 0:00:07  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "03/07 01:41:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][500/647]    eta: 0:00:04  time: 0.0311  data_time: 0.0006  memory: 861  \n",
      "03/07 01:41:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][600/647]    eta: 0:00:01  time: 0.0311  data_time: 0.0009  memory: 861  \n",
      "[20]\n",
      "[28]\n",
      "[17]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[4]\n",
      "[17]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[28]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[13]\n",
      "[20]\n",
      "[4]\n",
      "[20]\n",
      "[20]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[4]\n",
      "[20]\n",
      "[20]\n",
      "[28]\n",
      "[106]\n",
      "[28]\n",
      "[106]\n",
      "[106]\n",
      "[30]\n",
      "[30]\n",
      "[28]\n",
      "[20]\n",
      "[20]\n",
      "[17]\n",
      "[20]\n",
      "[17]\n",
      "[20]\n",
      "[17]\n",
      "[20]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[4]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[4]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[4]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[4]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[41]\n",
      "[30]\n",
      "[93]\n",
      "[41]\n",
      "[30]\n",
      "[91]\n",
      "[28]\n",
      "[28]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[30]\n",
      "[33]\n",
      "[93]\n",
      "[33]\n",
      "[93]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[30]\n",
      "[30]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[41]\n",
      "[30]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[33]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[30]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[60]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[42]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[73]\n",
      "[9]\n",
      "[47]\n",
      "[115]\n",
      "[47]\n",
      "[47]\n",
      "[73]\n",
      "[73]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[47]\n",
      "[10]\n",
      "[47]\n",
      "[51]\n",
      "[51]\n",
      "[86]\n",
      "[29]\n",
      "[47]\n",
      "[16]\n",
      "[9]\n",
      "[47]\n",
      "[54]\n",
      "[54]\n",
      "[47]\n",
      "[47]\n",
      "[54]\n",
      "[9]\n",
      "[9]\n",
      "[26]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[47]\n",
      "[54]\n",
      "[54]\n",
      "[47]\n",
      "[54]\n",
      "[54]\n",
      "[47]\n",
      "[47]\n",
      "[9]\n",
      "[63]\n",
      "[30]\n",
      "[9]\n",
      "[47]\n",
      "[47]\n",
      "[9]\n",
      "[112]\n",
      "[47]\n",
      "[73]\n",
      "[63]\n",
      "[112]\n",
      "[47]\n",
      "[10]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[9]\n",
      "[51]\n",
      "[51]\n",
      "[51]\n",
      "[47]\n",
      "[58]\n",
      "[47]\n",
      "[47]\n",
      "[58]\n",
      "[71]\n",
      "[71]\n",
      "[51]\n",
      "[51]\n",
      "[47]\n",
      "[47]\n",
      "[58]\n",
      "[58]\n",
      "[47]\n",
      "[47]\n",
      "[58]\n",
      "[51]\n",
      "[9]\n",
      "[51]\n",
      "[47]\n",
      "[47]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[70]\n",
      "[27]\n",
      "[63]\n",
      "[28]\n",
      "[19]\n",
      "[27]\n",
      "[27]\n",
      "[28]\n",
      "[47]\n",
      "[69]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[28]\n",
      "[69]\n",
      "[66]\n",
      "[28]\n",
      "[28]\n",
      "[28]\n",
      "[28]\n",
      "[69]\n",
      "[69]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[27]\n",
      "[27]\n",
      "[69]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[66]\n",
      "[69]\n",
      "[67]\n",
      "[47]\n",
      "[66]\n",
      "[50]\n",
      "[69]\n",
      "[28]\n",
      "[49]\n",
      "[95]\n",
      "[121]\n",
      "[122]\n",
      "[122]\n",
      "[121]\n",
      "[122]\n",
      "[122]\n",
      "[121]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[121]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[49]\n",
      "[122]\n",
      "[95]\n",
      "[100]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[95]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[74]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[86]\n",
      "[90]\n",
      "[90]\n",
      "[86]\n",
      "[86]\n",
      "[90]\n",
      "[86]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[88]\n",
      "[90]\n",
      "[86]\n",
      "[88]\n",
      "[80]\n",
      "[90]\n",
      "[90]\n",
      "[88]\n",
      "[88]\n",
      "[88]\n",
      "[88]\n",
      "[86]\n",
      "[88]\n",
      "[88]\n",
      "[88]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[86]\n",
      "[90]\n",
      "[90]\n",
      "[88]\n",
      "[75]\n",
      "[73]\n",
      "[88]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[88]\n",
      "[88]\n",
      "[88]\n",
      "[73]\n",
      "[88]\n",
      "[88]\n",
      "[90]\n",
      "[73]\n",
      "[90]\n",
      "[88]\n",
      "[75]\n",
      "[73]\n",
      "[88]\n",
      "[88]\n",
      "[88]\n",
      "[75]\n",
      "[86]\n",
      "[86]\n",
      "[73]\n",
      "[73]\n",
      "[73]\n",
      "[88]\n",
      "[74]\n",
      "[88]\n",
      "[88]\n",
      "[73]\n",
      "[73]\n",
      "[88]\n",
      "[88]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[93]\n",
      "[31]\n",
      "[112]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[60]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[112]\n",
      "[91]\n",
      "[112]\n",
      "[91]\n",
      "[91]\n",
      "[35]\n",
      "[49]\n",
      "[49]\n",
      "[35]\n",
      "[49]\n",
      "[35]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[40]\n",
      "[40]\n",
      "[40]\n",
      "[101]\n",
      "[40]\n",
      "[62]\n",
      "[62]\n",
      "[62]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[103]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[102]\n",
      "[96]\n",
      "[96]\n",
      "[104]\n",
      "[96]\n",
      "[104]\n",
      "[104]\n",
      "[96]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[95]\n",
      "[35]\n",
      "[95]\n",
      "[35]\n",
      "[35]\n",
      "[35]\n",
      "[49]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[95]\n",
      "[100]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[39]\n",
      "[39]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[115]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[121]\n",
      "[19]\n",
      "[109]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "03/07 01:41:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][647/647]    acc/top1: 0.0526  acc/top5: 0.2658  acc/mean1: 0.0876  data_time: 0.0008  time: 0.0313\n",
      "03/07 01:42:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:42:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 100/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 5:01:39  time: 0.1624  data_time: 0.0017  memory: 10434  loss: 2.4794  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4794\n",
      "03/07 01:42:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 200/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 5:01:22  time: 0.1630  data_time: 0.0016  memory: 10434  loss: 2.7363  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.7363\n",
      "03/07 01:42:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 300/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 5:01:04  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 2.6935  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.6935\n",
      "03/07 01:42:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 400/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 5:00:47  time: 0.1634  data_time: 0.0018  memory: 10434  loss: 3.1726  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.1726\n",
      "03/07 01:43:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 500/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 5:00:30  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 2.6286  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.6286\n",
      "03/07 01:43:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 600/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 5:00:12  time: 0.1622  data_time: 0.0017  memory: 10434  loss: 2.9802  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.9802\n",
      "03/07 01:43:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 700/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:59:55  time: 0.1634  data_time: 0.0018  memory: 10434  loss: 2.9931  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.9931\n",
      "03/07 01:43:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 800/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:59:37  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 2.9773  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.9773\n",
      "03/07 01:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 900/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:59:20  time: 0.1624  data_time: 0.0017  memory: 10434  loss: 2.6900  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6900\n",
      "03/07 01:44:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1000/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:59:02  time: 0.1625  data_time: 0.0016  memory: 10434  loss: 2.4039  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.4039\n",
      "03/07 01:44:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:44:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1100/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:58:45  time: 0.1643  data_time: 0.0015  memory: 10434  loss: 2.8621  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.8621\n",
      "03/07 01:45:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1200/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:58:28  time: 0.1640  data_time: 0.0017  memory: 10434  loss: 3.3151  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.3151\n",
      "03/07 01:45:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1300/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:58:11  time: 0.1626  data_time: 0.0017  memory: 10434  loss: 2.8341  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.8341\n",
      "03/07 01:45:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1400/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:57:53  time: 0.1628  data_time: 0.0018  memory: 10434  loss: 2.7715  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.7715\n",
      "03/07 01:45:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1500/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:57:36  time: 0.1634  data_time: 0.0015  memory: 10434  loss: 3.2821  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.2821\n",
      "03/07 01:46:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1600/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:57:19  time: 0.1628  data_time: 0.0017  memory: 10434  loss: 2.7051  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.7051\n",
      "03/07 01:46:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1700/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:57:01  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 2.5711  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.5711\n",
      "03/07 01:46:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1800/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:56:44  time: 0.1641  data_time: 0.0016  memory: 10434  loss: 3.0793  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.0793\n",
      "03/07 01:46:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1900/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:56:27  time: 0.1627  data_time: 0.0015  memory: 10434  loss: 2.7038  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.7038\n",
      "03/07 01:47:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2000/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:56:10  time: 0.1628  data_time: 0.0017  memory: 10434  loss: 3.1281  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.1281\n",
      "03/07 01:47:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:47:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2100/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:55:53  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 2.7649  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.7649\n",
      "03/07 01:47:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2200/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:55:36  time: 0.1642  data_time: 0.0015  memory: 10434  loss: 2.4211  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.4211\n",
      "03/07 01:48:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2300/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:55:19  time: 0.1629  data_time: 0.0017  memory: 10434  loss: 2.5214  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5214\n",
      "03/07 01:48:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2400/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:55:01  time: 0.1621  data_time: 0.0015  memory: 10434  loss: 2.8146  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.8146\n",
      "03/07 01:48:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2500/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:54:44  time: 0.1628  data_time: 0.0017  memory: 10434  loss: 2.7818  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.7818\n",
      "03/07 01:48:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2600/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:54:26  time: 0.1623  data_time: 0.0016  memory: 10434  loss: 2.4713  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4713\n",
      "03/07 01:49:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2700/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:54:10  time: 0.1635  data_time: 0.0016  memory: 10434  loss: 2.5681  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.5681\n",
      "03/07 01:49:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2800/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:53:52  time: 0.1639  data_time: 0.0019  memory: 10434  loss: 2.5727  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5727\n",
      "03/07 01:49:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2900/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:53:35  time: 0.1629  data_time: 0.0016  memory: 10434  loss: 2.5896  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.5896\n",
      "03/07 01:49:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3000/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:53:18  time: 0.1645  data_time: 0.0017  memory: 10434  loss: 2.4862  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.4862\n",
      "03/07 01:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3100/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:53:01  time: 0.1625  data_time: 0.0017  memory: 10434  loss: 2.9377  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.9377\n",
      "03/07 01:50:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3200/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:52:44  time: 0.1625  data_time: 0.0017  memory: 10434  loss: 2.9057  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.9057\n",
      "03/07 01:50:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3300/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:52:27  time: 0.1625  data_time: 0.0020  memory: 10434  loss: 3.0570  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.0570\n",
      "03/07 01:51:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3400/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:52:10  time: 0.1644  data_time: 0.0016  memory: 10434  loss: 3.0125  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.0125\n",
      "03/07 01:51:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3500/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:51:53  time: 0.1623  data_time: 0.0016  memory: 10434  loss: 2.3742  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3742\n",
      "03/07 01:51:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3600/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:51:36  time: 0.1642  data_time: 0.0019  memory: 10434  loss: 3.3024  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.3024\n",
      "03/07 01:51:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3700/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:51:19  time: 0.1630  data_time: 0.0016  memory: 10434  loss: 2.5623  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.5623\n",
      "03/07 01:52:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3800/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:51:02  time: 0.1629  data_time: 0.0014  memory: 10434  loss: 2.6220  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.6220\n",
      "03/07 01:52:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3900/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:50:44  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 2.8852  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.8852\n",
      "03/07 01:52:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4000/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:50:27  time: 0.1642  data_time: 0.0018  memory: 10434  loss: 3.0632  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 3.0632\n",
      "03/07 01:52:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:52:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4100/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:50:10  time: 0.1628  data_time: 0.0018  memory: 10434  loss: 3.0456  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.0456\n",
      "03/07 01:53:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4200/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:49:53  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 3.0331  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.0331\n",
      "03/07 01:53:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4300/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:49:36  time: 0.1634  data_time: 0.0018  memory: 10434  loss: 2.8900  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.8900\n",
      "03/07 01:53:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4400/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:49:19  time: 0.1632  data_time: 0.0017  memory: 10434  loss: 2.7274  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.7274\n",
      "03/07 01:54:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4500/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:49:02  time: 0.1630  data_time: 0.0016  memory: 10434  loss: 2.6298  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.6298\n",
      "03/07 01:54:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4600/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:48:45  time: 0.1625  data_time: 0.0018  memory: 10434  loss: 2.5097  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.5097\n",
      "03/07 01:54:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4700/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:48:28  time: 0.1655  data_time: 0.0017  memory: 10434  loss: 2.9065  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.9065\n",
      "03/07 01:54:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4800/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:48:11  time: 0.1643  data_time: 0.0017  memory: 10434  loss: 2.7404  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.7404\n",
      "03/07 01:55:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4900/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:47:55  time: 0.1627  data_time: 0.0019  memory: 10434  loss: 2.4098  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.4098\n",
      "03/07 01:55:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][5000/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:47:37  time: 0.1626  data_time: 0.0016  memory: 10434  loss: 2.8698  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.8698\n",
      "03/07 01:55:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:55:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][5100/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:47:21  time: 0.1635  data_time: 0.0016  memory: 10434  loss: 2.3973  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3973\n",
      "03/07 01:55:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][5200/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:47:03  time: 0.1629  data_time: 0.0017  memory: 10434  loss: 3.0539  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.0539\n",
      "03/07 01:55:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:55:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][5225/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:46:59  time: 0.1602  data_time: 0.0017  memory: 10434  loss: 2.8849  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.8849\n",
      "03/07 01:56:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][100/647]    eta: 0:00:17  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "03/07 01:56:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][200/647]    eta: 0:00:13  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "03/07 01:56:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][300/647]    eta: 0:00:10  time: 0.0311  data_time: 0.0008  memory: 861  \n",
      "03/07 01:56:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][400/647]    eta: 0:00:07  time: 0.0309  data_time: 0.0008  memory: 861  \n",
      "03/07 01:56:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][500/647]    eta: 0:00:04  time: 0.0312  data_time: 0.0007  memory: 861  \n",
      "03/07 01:56:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][600/647]    eta: 0:00:01  time: 0.0309  data_time: 0.0007  memory: 861  \n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[13]\n",
      "[5]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[28]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[5]\n",
      "[14]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[13]\n",
      "[5]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[13]\n",
      "[13]\n",
      "[5]\n",
      "[13]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[26]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[23]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[16]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[41]\n",
      "[30]\n",
      "[91]\n",
      "[41]\n",
      "[30]\n",
      "[30]\n",
      "[28]\n",
      "[28]\n",
      "[41]\n",
      "[41]\n",
      "[29]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[27]\n",
      "[93]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[28]\n",
      "[28]\n",
      "[33]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[33]\n",
      "[33]\n",
      "[41]\n",
      "[42]\n",
      "[19]\n",
      "[30]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[41]\n",
      "[33]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[33]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[36]\n",
      "[41]\n",
      "[41]\n",
      "[38]\n",
      "[30]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[52]\n",
      "[55]\n",
      "[52]\n",
      "[33]\n",
      "[52]\n",
      "[46]\n",
      "[52]\n",
      "[73]\n",
      "[22]\n",
      "[55]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[48]\n",
      "[48]\n",
      "[55]\n",
      "[29]\n",
      "[52]\n",
      "[55]\n",
      "[6]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[46]\n",
      "[48]\n",
      "[48]\n",
      "[46]\n",
      "[46]\n",
      "[26]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[9]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[52]\n",
      "[52]\n",
      "[12]\n",
      "[63]\n",
      "[52]\n",
      "[12]\n",
      "[47]\n",
      "[12]\n",
      "[12]\n",
      "[63]\n",
      "[52]\n",
      "[12]\n",
      "[63]\n",
      "[63]\n",
      "[52]\n",
      "[12]\n",
      "[12]\n",
      "[52]\n",
      "[52]\n",
      "[12]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[12]\n",
      "[55]\n",
      "[44]\n",
      "[48]\n",
      "[52]\n",
      "[52]\n",
      "[48]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[44]\n",
      "[52]\n",
      "[48]\n",
      "[48]\n",
      "[52]\n",
      "[52]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[12]\n",
      "[12]\n",
      "[52]\n",
      "[66]\n",
      "[66]\n",
      "[66]\n",
      "[68]\n",
      "[66]\n",
      "[27]\n",
      "[61]\n",
      "[28]\n",
      "[63]\n",
      "[27]\n",
      "[27]\n",
      "[28]\n",
      "[66]\n",
      "[69]\n",
      "[68]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[61]\n",
      "[61]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[68]\n",
      "[27]\n",
      "[69]\n",
      "[66]\n",
      "[28]\n",
      "[28]\n",
      "[28]\n",
      "[7]\n",
      "[66]\n",
      "[69]\n",
      "[66]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[68]\n",
      "[27]\n",
      "[27]\n",
      "[69]\n",
      "[66]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[47]\n",
      "[69]\n",
      "[66]\n",
      "[66]\n",
      "[68]\n",
      "[69]\n",
      "[66]\n",
      "[66]\n",
      "[69]\n",
      "[28]\n",
      "[49]\n",
      "[98]\n",
      "[121]\n",
      "[122]\n",
      "[122]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[48]\n",
      "[122]\n",
      "[122]\n",
      "[98]\n",
      "[98]\n",
      "[122]\n",
      "[121]\n",
      "[122]\n",
      "[122]\n",
      "[121]\n",
      "[122]\n",
      "[122]\n",
      "[121]\n",
      "[122]\n",
      "[122]\n",
      "[98]\n",
      "[98]\n",
      "[48]\n",
      "[98]\n",
      "[98]\n",
      "[48]\n",
      "[98]\n",
      "[97]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[100]\n",
      "[98]\n",
      "[100]\n",
      "[98]\n",
      "[77]\n",
      "[75]\n",
      "[77]\n",
      "[77]\n",
      "[74]\n",
      "[77]\n",
      "[77]\n",
      "[77]\n",
      "[74]\n",
      "[77]\n",
      "[77]\n",
      "[73]\n",
      "[77]\n",
      "[77]\n",
      "[73]\n",
      "[73]\n",
      "[77]\n",
      "[86]\n",
      "[74]\n",
      "[77]\n",
      "[77]\n",
      "[77]\n",
      "[74]\n",
      "[75]\n",
      "[73]\n",
      "[77]\n",
      "[3]\n",
      "[77]\n",
      "[82]\n",
      "[82]\n",
      "[73]\n",
      "[73]\n",
      "[73]\n",
      "[73]\n",
      "[73]\n",
      "[73]\n",
      "[77]\n",
      "[77]\n",
      "[77]\n",
      "[77]\n",
      "[73]\n",
      "[77]\n",
      "[77]\n",
      "[74]\n",
      "[75]\n",
      "[73]\n",
      "[3]\n",
      "[81]\n",
      "[81]\n",
      "[77]\n",
      "[77]\n",
      "[75]\n",
      "[75]\n",
      "[81]\n",
      "[82]\n",
      "[73]\n",
      "[73]\n",
      "[73]\n",
      "[73]\n",
      "[73]\n",
      "[72]\n",
      "[73]\n",
      "[73]\n",
      "[77]\n",
      "[74]\n",
      "[74]\n",
      "[73]\n",
      "[74]\n",
      "[74]\n",
      "[74]\n",
      "[74]\n",
      "[73]\n",
      "[83]\n",
      "[73]\n",
      "[73]\n",
      "[73]\n",
      "[74]\n",
      "[74]\n",
      "[74]\n",
      "[74]\n",
      "[73]\n",
      "[73]\n",
      "[74]\n",
      "[74]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[93]\n",
      "[31]\n",
      "[31]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[60]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[35]\n",
      "[49]\n",
      "[49]\n",
      "[19]\n",
      "[49]\n",
      "[19]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[102]\n",
      "[104]\n",
      "[96]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[96]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[96]\n",
      "[104]\n",
      "[98]\n",
      "[97]\n",
      "[97]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[100]\n",
      "[35]\n",
      "[49]\n",
      "[49]\n",
      "[49]\n",
      "[49]\n",
      "[49]\n",
      "[95]\n",
      "[100]\n",
      "[95]\n",
      "[95]\n",
      "[98]\n",
      "[100]\n",
      "[100]\n",
      "[98]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[108]\n",
      "[108]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[106]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[111]\n",
      "[108]\n",
      "[113]\n",
      "[108]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[83]\n",
      "[83]\n",
      "[83]\n",
      "[83]\n",
      "[83]\n",
      "[83]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[36]\n",
      "[36]\n",
      "[36]\n",
      "[36]\n",
      "[110]\n",
      "[19]\n",
      "[110]\n",
      "[110]\n",
      "[108]\n",
      "[12]\n",
      "03/07 01:56:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][647/647]    acc/top1: 0.0726  acc/top5: 0.3369  acc/mean1: 0.1116  data_time: 0.0009  time: 0.0311\n",
      "03/07 01:56:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_3.pth is removed\n",
      "03/07 01:56:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.0726 acc/top1 at 5 epoch is saved to best_acc_top1_epoch_5.pth.\n",
      "03/07 01:56:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 100/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:46:43  time: 0.1666  data_time: 0.0018  memory: 10434  loss: 2.6398  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6398\n",
      "03/07 01:56:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 200/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:46:26  time: 0.1644  data_time: 0.0016  memory: 10434  loss: 2.6565  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6565\n",
      "03/07 01:57:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 300/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:46:09  time: 0.1628  data_time: 0.0018  memory: 10434  loss: 3.1573  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.1573\n",
      "03/07 01:57:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 400/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:45:52  time: 0.1625  data_time: 0.0016  memory: 10434  loss: 2.5004  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.5004\n",
      "03/07 01:57:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 500/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:45:35  time: 0.1626  data_time: 0.0015  memory: 10434  loss: 2.2405  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2405\n",
      "03/07 01:57:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 600/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:45:18  time: 0.1625  data_time: 0.0017  memory: 10434  loss: 2.6627  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.6627\n",
      "03/07 01:58:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 700/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:45:01  time: 0.1636  data_time: 0.0016  memory: 10434  loss: 3.4337  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 3.4337\n",
      "03/07 01:58:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 800/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:44:44  time: 0.1634  data_time: 0.0018  memory: 10434  loss: 2.6520  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6520\n",
      "03/07 01:58:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 01:58:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 900/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:44:27  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 3.1513  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.1513\n",
      "03/07 01:59:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1000/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:44:10  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 2.7251  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.7251\n",
      "03/07 01:59:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1100/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:43:53  time: 0.1626  data_time: 0.0015  memory: 10434  loss: 2.8121  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.8121\n",
      "03/07 01:59:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1200/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:43:36  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 2.5283  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.5283\n",
      "03/07 01:59:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1300/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:43:19  time: 0.1638  data_time: 0.0017  memory: 10434  loss: 2.4705  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.4705\n",
      "03/07 02:00:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1400/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:43:02  time: 0.1626  data_time: 0.0016  memory: 10434  loss: 2.8316  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.8316\n",
      "03/07 02:00:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1500/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:42:45  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 2.8598  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.8598\n",
      "03/07 02:00:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1600/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:42:28  time: 0.1624  data_time: 0.0017  memory: 10434  loss: 2.7783  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.7783\n",
      "03/07 02:00:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1700/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:42:12  time: 0.1652  data_time: 0.0017  memory: 10434  loss: 2.5937  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.5937\n",
      "03/07 02:01:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1800/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:41:55  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 3.0818  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.0818\n",
      "03/07 02:01:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:01:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1900/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:41:38  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 2.3741  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3741\n",
      "03/07 02:01:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2000/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:41:21  time: 0.1622  data_time: 0.0016  memory: 10434  loss: 2.3360  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.3360\n",
      "03/07 02:02:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2100/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:41:04  time: 0.1636  data_time: 0.0017  memory: 10434  loss: 2.8567  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.8567\n",
      "03/07 02:02:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2200/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:40:47  time: 0.1620  data_time: 0.0016  memory: 10434  loss: 3.0531  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.0531\n",
      "03/07 02:02:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2300/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:40:30  time: 0.1642  data_time: 0.0018  memory: 10434  loss: 2.5095  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.5095\n",
      "03/07 02:02:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2400/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:40:14  time: 0.1650  data_time: 0.0016  memory: 10434  loss: 2.8879  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.8879\n",
      "03/07 02:03:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2500/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:39:57  time: 0.1629  data_time: 0.0020  memory: 10434  loss: 2.6705  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6705\n",
      "03/07 02:03:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2600/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:39:40  time: 0.1621  data_time: 0.0017  memory: 10434  loss: 2.5235  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.5235\n",
      "03/07 02:03:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2700/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:39:23  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 2.6148  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.6148\n",
      "03/07 02:03:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2800/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:39:06  time: 0.1646  data_time: 0.0015  memory: 10434  loss: 2.6503  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.6503\n",
      "03/07 02:04:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:04:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2900/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:38:49  time: 0.1627  data_time: 0.0017  memory: 10434  loss: 2.4614  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4614\n",
      "03/07 02:04:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3000/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:38:32  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 2.7332  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.7332\n",
      "03/07 02:04:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3100/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:38:15  time: 0.1623  data_time: 0.0017  memory: 10434  loss: 2.5027  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.5027\n",
      "03/07 02:05:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3200/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:37:58  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 2.7069  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.7069\n",
      "03/07 02:05:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3300/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:37:41  time: 0.1631  data_time: 0.0017  memory: 10434  loss: 2.6738  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.6738\n",
      "03/07 02:05:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3400/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:37:25  time: 0.1639  data_time: 0.0015  memory: 10434  loss: 2.5735  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5735\n",
      "03/07 02:05:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3500/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:37:08  time: 0.1628  data_time: 0.0015  memory: 10434  loss: 2.4176  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.4176\n",
      "03/07 02:06:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3600/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:36:51  time: 0.1627  data_time: 0.0019  memory: 10434  loss: 2.8336  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.8336\n",
      "03/07 02:06:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3700/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:36:34  time: 0.1626  data_time: 0.0016  memory: 10434  loss: 2.3875  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3875\n",
      "03/07 02:06:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3800/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:36:17  time: 0.1646  data_time: 0.0015  memory: 10434  loss: 2.5802  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.5802\n",
      "03/07 02:06:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:06:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3900/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:36:00  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 2.4305  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.4305\n",
      "03/07 02:07:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4000/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:35:44  time: 0.1621  data_time: 0.0018  memory: 10434  loss: 2.3920  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.3920\n",
      "03/07 02:07:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4100/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:35:27  time: 0.1632  data_time: 0.0015  memory: 10434  loss: 2.2680  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2680\n",
      "03/07 02:07:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4200/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:35:10  time: 0.1624  data_time: 0.0017  memory: 10434  loss: 2.5092  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.5092\n",
      "03/07 02:08:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4300/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:34:53  time: 0.1624  data_time: 0.0017  memory: 10434  loss: 2.6565  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.6565\n",
      "03/07 02:08:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4400/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:34:36  time: 0.1624  data_time: 0.0017  memory: 10434  loss: 2.2276  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2276\n",
      "03/07 02:08:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4500/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:34:19  time: 0.1653  data_time: 0.0015  memory: 10434  loss: 2.8246  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.8246\n",
      "03/07 02:08:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4600/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:34:03  time: 0.1649  data_time: 0.0017  memory: 10434  loss: 3.1118  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.1118\n",
      "03/07 02:09:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4700/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:33:46  time: 0.1633  data_time: 0.0016  memory: 10434  loss: 2.1796  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1796\n",
      "03/07 02:09:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4800/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:33:29  time: 0.1632  data_time: 0.0017  memory: 10434  loss: 2.5851  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.5851\n",
      "03/07 02:09:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:09:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4900/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:33:12  time: 0.1640  data_time: 0.0016  memory: 10434  loss: 2.2462  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.2462\n",
      "03/07 02:09:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][5000/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:32:55  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 2.2366  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2366\n",
      "03/07 02:10:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][5100/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:32:39  time: 0.1630  data_time: 0.0016  memory: 10434  loss: 2.4602  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4602\n",
      "03/07 02:10:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][5200/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:32:22  time: 0.1627  data_time: 0.0017  memory: 10434  loss: 2.4319  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.4319\n",
      "03/07 02:10:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:10:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][5225/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:32:17  time: 0.1601  data_time: 0.0017  memory: 10434  loss: 2.5755  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.5755\n",
      "03/07 02:10:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
      "03/07 02:10:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][100/647]    eta: 0:00:17  time: 0.0311  data_time: 0.0007  memory: 861  \n",
      "03/07 02:10:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][200/647]    eta: 0:00:13  time: 0.0311  data_time: 0.0009  memory: 861  \n",
      "03/07 02:10:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][300/647]    eta: 0:00:10  time: 0.0311  data_time: 0.0007  memory: 861  \n",
      "03/07 02:10:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][400/647]    eta: 0:00:07  time: 0.0311  data_time: 0.0008  memory: 861  \n",
      "03/07 02:10:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][500/647]    eta: 0:00:04  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "03/07 02:10:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][600/647]    eta: 0:00:01  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "[22]\n",
      "[1]\n",
      "[17]\n",
      "[13]\n",
      "[5]\n",
      "[17]\n",
      "[5]\n",
      "[21]\n",
      "[17]\n",
      "[22]\n",
      "[23]\n",
      "[22]\n",
      "[22]\n",
      "[14]\n",
      "[17]\n",
      "[6]\n",
      "[17]\n",
      "[17]\n",
      "[5]\n",
      "[5]\n",
      "[23]\n",
      "[22]\n",
      "[13]\n",
      "[17]\n",
      "[5]\n",
      "[6]\n",
      "[1]\n",
      "[13]\n",
      "[13]\n",
      "[1]\n",
      "[22]\n",
      "[3]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[13]\n",
      "[1]\n",
      "[1]\n",
      "[13]\n",
      "[13]\n",
      "[106]\n",
      "[106]\n",
      "[106]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[17]\n",
      "[5]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[5]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[5]\n",
      "[23]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[5]\n",
      "[5]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[22]\n",
      "[23]\n",
      "[22]\n",
      "[22]\n",
      "[23]\n",
      "[22]\n",
      "[23]\n",
      "[23]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[22]\n",
      "[22]\n",
      "[24]\n",
      "[23]\n",
      "[23]\n",
      "[11]\n",
      "[13]\n",
      "[24]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[23]\n",
      "[23]\n",
      "[24]\n",
      "[41]\n",
      "[31]\n",
      "[33]\n",
      "[41]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[29]\n",
      "[31]\n",
      "[43]\n",
      "[29]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[31]\n",
      "[27]\n",
      "[41]\n",
      "[43]\n",
      "[43]\n",
      "[43]\n",
      "[27]\n",
      "[27]\n",
      "[33]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[36]\n",
      "[33]\n",
      "[33]\n",
      "[43]\n",
      "[43]\n",
      "[41]\n",
      "[30]\n",
      "[41]\n",
      "[43]\n",
      "[41]\n",
      "[41]\n",
      "[33]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[36]\n",
      "[33]\n",
      "[27]\n",
      "[36]\n",
      "[43]\n",
      "[36]\n",
      "[41]\n",
      "[41]\n",
      "[36]\n",
      "[30]\n",
      "[41]\n",
      "[43]\n",
      "[36]\n",
      "[41]\n",
      "[43]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[99]\n",
      "[13]\n",
      "[34]\n",
      "[33]\n",
      "[50]\n",
      "[34]\n",
      "[100]\n",
      "[34]\n",
      "[57]\n",
      "[55]\n",
      "[57]\n",
      "[36]\n",
      "[58]\n",
      "[58]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[58]\n",
      "[22]\n",
      "[58]\n",
      "[47]\n",
      "[47]\n",
      "[56]\n",
      "[55]\n",
      "[22]\n",
      "[56]\n",
      "[22]\n",
      "[47]\n",
      "[58]\n",
      "[47]\n",
      "[58]\n",
      "[47]\n",
      "[58]\n",
      "[9]\n",
      "[9]\n",
      "[22]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[47]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[52]\n",
      "[22]\n",
      "[44]\n",
      "[52]\n",
      "[10]\n",
      "[58]\n",
      "[10]\n",
      "[10]\n",
      "[44]\n",
      "[58]\n",
      "[23]\n",
      "[44]\n",
      "[44]\n",
      "[10]\n",
      "[23]\n",
      "[58]\n",
      "[23]\n",
      "[58]\n",
      "[56]\n",
      "[56]\n",
      "[52]\n",
      "[22]\n",
      "[58]\n",
      "[22]\n",
      "[58]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[45]\n",
      "[58]\n",
      "[58]\n",
      "[45]\n",
      "[58]\n",
      "[47]\n",
      "[47]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[45]\n",
      "[58]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[70]\n",
      "[31]\n",
      "[31]\n",
      "[27]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[29]\n",
      "[62]\n",
      "[27]\n",
      "[29]\n",
      "[51]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[27]\n",
      "[69]\n",
      "[69]\n",
      "[31]\n",
      "[40]\n",
      "[31]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[65]\n",
      "[27]\n",
      "[27]\n",
      "[69]\n",
      "[66]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[66]\n",
      "[69]\n",
      "[67]\n",
      "[69]\n",
      "[66]\n",
      "[67]\n",
      "[69]\n",
      "[29]\n",
      "[98]\n",
      "[98]\n",
      "[121]\n",
      "[122]\n",
      "[122]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[122]\n",
      "[122]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[122]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[45]\n",
      "[98]\n",
      "[121]\n",
      "[98]\n",
      "[45]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[100]\n",
      "[98]\n",
      "[100]\n",
      "[98]\n",
      "[81]\n",
      "[81]\n",
      "[85]\n",
      "[81]\n",
      "[74]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[85]\n",
      "[85]\n",
      "[78]\n",
      "[85]\n",
      "[74]\n",
      "[81]\n",
      "[81]\n",
      "[78]\n",
      "[80]\n",
      "[81]\n",
      "[85]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[85]\n",
      "[85]\n",
      "[85]\n",
      "[85]\n",
      "[85]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[85]\n",
      "[81]\n",
      "[81]\n",
      "[74]\n",
      "[81]\n",
      "[85]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[83]\n",
      "[85]\n",
      "[85]\n",
      "[85]\n",
      "[80]\n",
      "[81]\n",
      "[83]\n",
      "[81]\n",
      "[78]\n",
      "[74]\n",
      "[85]\n",
      "[78]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[85]\n",
      "[84]\n",
      "[85]\n",
      "[85]\n",
      "[85]\n",
      "[78]\n",
      "[74]\n",
      "[74]\n",
      "[78]\n",
      "[78]\n",
      "[85]\n",
      "[74]\n",
      "[74]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[93]\n",
      "[31]\n",
      "[31]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[31]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[71]\n",
      "[49]\n",
      "[49]\n",
      "[34]\n",
      "[49]\n",
      "[19]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[64]\n",
      "[102]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[92]\n",
      "[96]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[96]\n",
      "[96]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[106]\n",
      "[105]\n",
      "[106]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[117]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[112]\n",
      "[117]\n",
      "[112]\n",
      "[112]\n",
      "[117]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[113]\n",
      "[106]\n",
      "[31]\n",
      "[33]\n",
      "[31]\n",
      "[84]\n",
      "[31]\n",
      "[31]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[121]\n",
      "[108]\n",
      "[121]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "03/07 02:10:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [6][647/647]    acc/top1: 0.0696  acc/top5: 0.3509  acc/mean1: 0.1210  data_time: 0.0008  time: 0.0311\n",
      "03/07 02:11:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 100/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:32:01  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 2.6222  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.6222\n",
      "03/07 02:11:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 200/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:31:44  time: 0.1645  data_time: 0.0017  memory: 10434  loss: 2.7920  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.7920\n",
      "03/07 02:11:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 300/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:31:27  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 2.3810  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3810\n",
      "03/07 02:12:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 400/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:31:11  time: 0.1633  data_time: 0.0017  memory: 10434  loss: 2.4314  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.4314\n",
      "03/07 02:12:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 500/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:30:54  time: 0.1629  data_time: 0.0016  memory: 10434  loss: 2.5535  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5535\n",
      "03/07 02:12:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 600/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:30:37  time: 0.1635  data_time: 0.0016  memory: 10434  loss: 2.3949  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3949\n",
      "03/07 02:12:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:12:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 700/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:30:20  time: 0.1631  data_time: 0.0017  memory: 10434  loss: 2.2797  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.2797\n",
      "03/07 02:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 800/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:30:04  time: 0.1638  data_time: 0.0017  memory: 10434  loss: 2.5021  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5021\n",
      "03/07 02:13:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 900/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:29:47  time: 0.1628  data_time: 0.0016  memory: 10434  loss: 2.4408  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.4408\n",
      "03/07 02:13:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1000/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:29:31  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 2.6420  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6420\n",
      "03/07 02:13:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1100/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:29:14  time: 0.1629  data_time: 0.0016  memory: 10434  loss: 2.6238  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.6238\n",
      "03/07 02:14:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1200/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:28:57  time: 0.1643  data_time: 0.0015  memory: 10434  loss: 2.7068  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.7068\n",
      "03/07 02:14:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1300/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:28:40  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 2.6951  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6951\n",
      "03/07 02:14:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1400/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:28:24  time: 0.1639  data_time: 0.0015  memory: 10434  loss: 2.4209  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.4209\n",
      "03/07 02:15:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1500/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:28:08  time: 0.1635  data_time: 0.0016  memory: 10434  loss: 2.1753  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1753\n",
      "03/07 02:15:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1600/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:27:51  time: 0.1622  data_time: 0.0017  memory: 10434  loss: 2.3956  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.3956\n",
      "03/07 02:15:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:15:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1700/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:27:34  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 2.2210  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2210\n",
      "03/07 02:15:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1800/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:27:17  time: 0.1632  data_time: 0.0016  memory: 10434  loss: 2.7011  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.7011\n",
      "03/07 02:16:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1900/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:27:00  time: 0.1626  data_time: 0.0016  memory: 10434  loss: 2.7034  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.7034\n",
      "03/07 02:16:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2000/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:26:43  time: 0.1624  data_time: 0.0018  memory: 10434  loss: 2.1261  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1261\n",
      "03/07 02:16:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2100/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:26:26  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 2.5625  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.5625\n",
      "03/07 02:16:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2200/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:26:10  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 2.6838  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.6838\n",
      "03/07 02:17:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2300/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:25:53  time: 0.1634  data_time: 0.0019  memory: 10434  loss: 2.1909  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1909\n",
      "03/07 02:17:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2400/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:25:36  time: 0.1633  data_time: 0.0017  memory: 10434  loss: 2.2629  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.2629\n",
      "03/07 02:17:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2500/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:25:20  time: 0.1635  data_time: 0.0016  memory: 10434  loss: 2.7557  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.7557\n",
      "03/07 02:18:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2600/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:25:03  time: 0.1629  data_time: 0.0016  memory: 10434  loss: 2.3696  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3696\n",
      "03/07 02:18:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:18:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2700/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:24:46  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 2.2384  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2384\n",
      "03/07 02:18:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2800/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:24:29  time: 0.1639  data_time: 0.0016  memory: 10434  loss: 2.7229  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.7229\n",
      "03/07 02:18:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2900/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:24:13  time: 0.1623  data_time: 0.0016  memory: 10434  loss: 2.7264  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.7264\n",
      "03/07 02:19:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3000/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:23:56  time: 0.1629  data_time: 0.0016  memory: 10434  loss: 2.4659  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.4659\n",
      "03/07 02:19:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3100/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:23:39  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 2.4117  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4117\n",
      "03/07 02:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3200/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:23:23  time: 0.1633  data_time: 0.0018  memory: 10434  loss: 2.6941  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.6941\n",
      "03/07 02:19:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3300/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:23:06  time: 0.1645  data_time: 0.0016  memory: 10434  loss: 2.5681  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.5681\n",
      "03/07 02:20:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3400/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:22:49  time: 0.1625  data_time: 0.0018  memory: 10434  loss: 2.8010  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.8010\n",
      "03/07 02:20:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3500/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:22:32  time: 0.1636  data_time: 0.0017  memory: 10434  loss: 2.4723  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.4723\n",
      "03/07 02:20:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3600/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:22:16  time: 0.1657  data_time: 0.0016  memory: 10434  loss: 2.8066  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.8066\n",
      "03/07 02:20:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3700/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:21:59  time: 0.1638  data_time: 0.0016  memory: 10434  loss: 1.8617  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8617\n",
      "03/07 02:21:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3800/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:21:43  time: 0.1630  data_time: 0.0018  memory: 10434  loss: 2.5366  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.5366\n",
      "03/07 02:21:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3900/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:21:26  time: 0.1646  data_time: 0.0017  memory: 10434  loss: 2.4271  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.4271\n",
      "03/07 02:21:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4000/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:21:09  time: 0.1636  data_time: 0.0016  memory: 10434  loss: 2.2984  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2984\n",
      "03/07 02:22:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4100/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:20:53  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 2.1143  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.1143\n",
      "03/07 02:22:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4200/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:20:36  time: 0.1634  data_time: 0.0016  memory: 10434  loss: 2.2705  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2705\n",
      "03/07 02:22:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4300/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:20:19  time: 0.1647  data_time: 0.0015  memory: 10434  loss: 2.5145  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.5145\n",
      "03/07 02:22:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4400/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:20:03  time: 0.1629  data_time: 0.0016  memory: 10434  loss: 2.3790  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3790\n",
      "03/07 02:23:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4500/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:19:46  time: 0.1636  data_time: 0.0016  memory: 10434  loss: 2.5647  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5647\n",
      "03/07 02:23:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4600/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:19:29  time: 0.1633  data_time: 0.0018  memory: 10434  loss: 2.5049  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.5049\n",
      "03/07 02:23:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:23:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4700/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:19:13  time: 0.1635  data_time: 0.0016  memory: 10434  loss: 3.0013  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 3.0013\n",
      "03/07 02:24:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4800/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:18:56  time: 0.1625  data_time: 0.0016  memory: 10434  loss: 2.8517  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.8517\n",
      "03/07 02:24:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4900/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:18:39  time: 0.1633  data_time: 0.0015  memory: 10434  loss: 2.0685  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.0685\n",
      "03/07 02:24:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][5000/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:18:22  time: 0.1650  data_time: 0.0016  memory: 10434  loss: 2.7360  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.7360\n",
      "03/07 02:24:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][5100/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:18:06  time: 0.1666  data_time: 0.0017  memory: 10434  loss: 2.4254  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4254\n",
      "03/07 02:25:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][5200/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:17:50  time: 0.1640  data_time: 0.0016  memory: 10434  loss: 2.4819  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.4819\n",
      "03/07 02:25:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:25:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][5225/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 4:17:45  time: 0.1594  data_time: 0.0019  memory: 10434  loss: 2.9001  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.9001\n",
      "03/07 02:25:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][100/647]    eta: 0:00:17  time: 0.0312  data_time: 0.0009  memory: 861  \n",
      "03/07 02:25:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][200/647]    eta: 0:00:13  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "03/07 02:25:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][300/647]    eta: 0:00:10  time: 0.0312  data_time: 0.0009  memory: 861  \n",
      "03/07 02:25:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][400/647]    eta: 0:00:07  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "03/07 02:25:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][500/647]    eta: 0:00:04  time: 0.0311  data_time: 0.0009  memory: 861  \n",
      "03/07 02:25:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][600/647]    eta: 0:00:01  time: 0.0309  data_time: 0.0008  memory: 861  \n",
      "[14]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[13]\n",
      "[14]\n",
      "[5]\n",
      "[26]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[4]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[5]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[4]\n",
      "[5]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[14]\n",
      "[13]\n",
      "[1]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[28]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[4]\n",
      "[4]\n",
      "[14]\n",
      "[5]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[18]\n",
      "[18]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[5]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[22]\n",
      "[4]\n",
      "[26]\n",
      "[5]\n",
      "[23]\n",
      "[5]\n",
      "[22]\n",
      "[23]\n",
      "[5]\n",
      "[23]\n",
      "[23]\n",
      "[22]\n",
      "[23]\n",
      "[26]\n",
      "[26]\n",
      "[24]\n",
      "[24]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[4]\n",
      "[5]\n",
      "[26]\n",
      "[13]\n",
      "[26]\n",
      "[5]\n",
      "[4]\n",
      "[23]\n",
      "[23]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[23]\n",
      "[23]\n",
      "[26]\n",
      "[26]\n",
      "[24]\n",
      "[24]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[41]\n",
      "[30]\n",
      "[27]\n",
      "[41]\n",
      "[30]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[28]\n",
      "[9]\n",
      "[28]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[30]\n",
      "[30]\n",
      "[33]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[33]\n",
      "[33]\n",
      "[41]\n",
      "[43]\n",
      "[19]\n",
      "[30]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[33]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[33]\n",
      "[30]\n",
      "[41]\n",
      "[41]\n",
      "[39]\n",
      "[41]\n",
      "[41]\n",
      "[38]\n",
      "[39]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[50]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[14]\n",
      "[96]\n",
      "[14]\n",
      "[50]\n",
      "[35]\n",
      "[100]\n",
      "[14]\n",
      "[57]\n",
      "[59]\n",
      "[59]\n",
      "[33]\n",
      "[59]\n",
      "[9]\n",
      "[59]\n",
      "[85]\n",
      "[22]\n",
      "[22]\n",
      "[59]\n",
      "[59]\n",
      "[9]\n",
      "[9]\n",
      "[53]\n",
      "[53]\n",
      "[59]\n",
      "[55]\n",
      "[59]\n",
      "[9]\n",
      "[25]\n",
      "[53]\n",
      "[9]\n",
      "[53]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[24]\n",
      "[58]\n",
      "[9]\n",
      "[58]\n",
      "[58]\n",
      "[53]\n",
      "[58]\n",
      "[58]\n",
      "[9]\n",
      "[57]\n",
      "[57]\n",
      "[9]\n",
      "[9]\n",
      "[52]\n",
      "[9]\n",
      "[63]\n",
      "[52]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[63]\n",
      "[9]\n",
      "[9]\n",
      "[63]\n",
      "[63]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[52]\n",
      "[52]\n",
      "[9]\n",
      "[22]\n",
      "[12]\n",
      "[12]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[9]\n",
      "[9]\n",
      "[45]\n",
      "[45]\n",
      "[71]\n",
      "[53]\n",
      "[57]\n",
      "[46]\n",
      "[45]\n",
      "[45]\n",
      "[12]\n",
      "[12]\n",
      "[45]\n",
      "[57]\n",
      "[45]\n",
      "[45]\n",
      "[12]\n",
      "[12]\n",
      "[12]\n",
      "[45]\n",
      "[70]\n",
      "[28]\n",
      "[68]\n",
      "[68]\n",
      "[70]\n",
      "[29]\n",
      "[63]\n",
      "[28]\n",
      "[63]\n",
      "[28]\n",
      "[29]\n",
      "[28]\n",
      "[47]\n",
      "[66]\n",
      "[27]\n",
      "[67]\n",
      "[66]\n",
      "[69]\n",
      "[63]\n",
      "[63]\n",
      "[66]\n",
      "[70]\n",
      "[68]\n",
      "[68]\n",
      "[68]\n",
      "[70]\n",
      "[63]\n",
      "[28]\n",
      "[68]\n",
      "[70]\n",
      "[28]\n",
      "[47]\n",
      "[28]\n",
      "[47]\n",
      "[68]\n",
      "[68]\n",
      "[70]\n",
      "[68]\n",
      "[68]\n",
      "[69]\n",
      "[63]\n",
      "[27]\n",
      "[28]\n",
      "[68]\n",
      "[70]\n",
      "[68]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[47]\n",
      "[47]\n",
      "[66]\n",
      "[66]\n",
      "[67]\n",
      "[68]\n",
      "[70]\n",
      "[67]\n",
      "[69]\n",
      "[28]\n",
      "[98]\n",
      "[98]\n",
      "[110]\n",
      "[98]\n",
      "[122]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[122]\n",
      "[110]\n",
      "[98]\n",
      "[98]\n",
      "[110]\n",
      "[98]\n",
      "[98]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[72]\n",
      "[72]\n",
      "[86]\n",
      "[72]\n",
      "[74]\n",
      "[72]\n",
      "[90]\n",
      "[90]\n",
      "[74]\n",
      "[90]\n",
      "[82]\n",
      "[83]\n",
      "[90]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[72]\n",
      "[90]\n",
      "[86]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[86]\n",
      "[72]\n",
      "[74]\n",
      "[82]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[72]\n",
      "[72]\n",
      "[90]\n",
      "[90]\n",
      "[83]\n",
      "[90]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[86]\n",
      "[72]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[81]\n",
      "[81]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[87]\n",
      "[72]\n",
      "[83]\n",
      "[83]\n",
      "[90]\n",
      "[72]\n",
      "[74]\n",
      "[86]\n",
      "[72]\n",
      "[72]\n",
      "[82]\n",
      "[74]\n",
      "[83]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[72]\n",
      "[74]\n",
      "[74]\n",
      "[72]\n",
      "[72]\n",
      "[83]\n",
      "[72]\n",
      "[72]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[112]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[81]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[112]\n",
      "[112]\n",
      "[91]\n",
      "[112]\n",
      "[30]\n",
      "[30]\n",
      "[35]\n",
      "[49]\n",
      "[49]\n",
      "[96]\n",
      "[49]\n",
      "[96]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[100]\n",
      "[40]\n",
      "[40]\n",
      "[101]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[40]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[40]\n",
      "[40]\n",
      "[103]\n",
      "[103]\n",
      "[40]\n",
      "[103]\n",
      "[40]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[40]\n",
      "[97]\n",
      "[98]\n",
      "[104]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[98]\n",
      "[98]\n",
      "[96]\n",
      "[98]\n",
      "[97]\n",
      "[97]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[98]\n",
      "[96]\n",
      "[98]\n",
      "[97]\n",
      "[100]\n",
      "[97]\n",
      "[98]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[105]\n",
      "[105]\n",
      "[106]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[105]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[105]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[112]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[112]\n",
      "[112]\n",
      "[107]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[7]\n",
      "[71]\n",
      "[71]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[110]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[110]\n",
      "[107]\n",
      "[99]\n",
      "[107]\n",
      "[107]\n",
      "[99]\n",
      "03/07 02:25:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [7][647/647]    acc/top1: 0.0974  acc/top5: 0.3957  acc/mean1: 0.1595  data_time: 0.0009  time: 0.0311\n",
      "03/07 02:25:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_5.pth is removed\n",
      "03/07 02:25:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.0974 acc/top1 at 7 epoch is saved to best_acc_top1_epoch_7.pth.\n",
      "03/07 02:25:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 100/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:17:29  time: 0.1627  data_time: 0.0018  memory: 10434  loss: 2.6985  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6985\n",
      "03/07 02:26:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 200/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:17:12  time: 0.1633  data_time: 0.0018  memory: 10434  loss: 2.2704  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.2704\n",
      "03/07 02:26:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 300/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:16:55  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 2.3014  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3014\n",
      "03/07 02:26:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 400/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:16:38  time: 0.1625  data_time: 0.0017  memory: 10434  loss: 2.3105  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.3105\n",
      "03/07 02:26:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:26:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 500/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:16:22  time: 0.1639  data_time: 0.0016  memory: 10434  loss: 2.0565  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0565\n",
      "03/07 02:27:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 600/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:16:05  time: 0.1625  data_time: 0.0018  memory: 10434  loss: 2.1820  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1820\n",
      "03/07 02:27:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 700/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:15:48  time: 0.1632  data_time: 0.0016  memory: 10434  loss: 2.4973  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.4973\n",
      "03/07 02:27:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 800/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:15:32  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 2.5890  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.5890\n",
      "03/07 02:27:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 900/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:15:15  time: 0.1641  data_time: 0.0017  memory: 10434  loss: 2.8017  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.8017\n",
      "03/07 02:28:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1000/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:14:59  time: 0.1627  data_time: 0.0019  memory: 10434  loss: 2.4894  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4894\n",
      "03/07 02:28:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1100/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:14:42  time: 0.1631  data_time: 0.0020  memory: 10434  loss: 2.3902  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3902\n",
      "03/07 02:28:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1200/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:14:25  time: 0.1636  data_time: 0.0015  memory: 10434  loss: 2.2653  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2653\n",
      "03/07 02:29:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1300/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:14:09  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 2.7685  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.7685\n",
      "03/07 02:29:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1400/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:13:52  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 2.1919  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1919\n",
      "03/07 02:29:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:29:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1500/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:13:35  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 2.0615  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0615\n",
      "03/07 02:29:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1600/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:13:19  time: 0.1641  data_time: 0.0016  memory: 10434  loss: 2.5910  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.5910\n",
      "03/07 02:30:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1700/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:13:02  time: 0.1629  data_time: 0.0019  memory: 10434  loss: 2.2765  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.2765\n",
      "03/07 02:30:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1800/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:12:45  time: 0.1628  data_time: 0.0017  memory: 10434  loss: 2.5151  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.5151\n",
      "03/07 02:30:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1900/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:12:29  time: 0.1642  data_time: 0.0017  memory: 10434  loss: 2.4530  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.4530\n",
      "03/07 02:30:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2000/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:12:13  time: 0.1634  data_time: 0.0020  memory: 10434  loss: 2.1601  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1601\n",
      "03/07 02:31:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2100/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:11:56  time: 0.1634  data_time: 0.0016  memory: 10434  loss: 2.3266  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3266\n",
      "03/07 02:31:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2200/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:11:39  time: 0.1644  data_time: 0.0016  memory: 10434  loss: 2.5200  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.5200\n",
      "03/07 02:31:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2300/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:11:23  time: 0.1636  data_time: 0.0016  memory: 10434  loss: 2.8479  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.8479\n",
      "03/07 02:32:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2400/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:11:06  time: 0.1635  data_time: 0.0016  memory: 10434  loss: 2.0451  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0451\n",
      "03/07 02:32:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:32:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2500/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:10:49  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 2.4702  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.4702\n",
      "03/07 02:32:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2600/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:10:33  time: 0.1657  data_time: 0.0018  memory: 10434  loss: 2.4225  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.4225\n",
      "03/07 02:32:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2700/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:10:16  time: 0.1643  data_time: 0.0018  memory: 10434  loss: 2.2393  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.2393\n",
      "03/07 02:33:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2800/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:10:00  time: 0.1645  data_time: 0.0017  memory: 10434  loss: 2.0764  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0764\n",
      "03/07 02:33:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2900/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:09:43  time: 0.1630  data_time: 0.0018  memory: 10434  loss: 2.5907  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.5907\n",
      "03/07 02:33:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3000/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:09:26  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 2.3524  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3524\n",
      "03/07 02:34:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3100/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:09:10  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 1.9439  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9439\n",
      "03/07 02:34:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3200/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:08:53  time: 0.1626  data_time: 0.0017  memory: 10434  loss: 2.3867  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3867\n",
      "03/07 02:34:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3300/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:08:37  time: 0.1640  data_time: 0.0018  memory: 10434  loss: 2.1409  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1409\n",
      "03/07 02:34:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3400/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:08:20  time: 0.1633  data_time: 0.0018  memory: 10434  loss: 2.3173  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3173\n",
      "03/07 02:34:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:35:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3500/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:08:03  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 2.1310  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1310\n",
      "03/07 02:35:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3600/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:07:47  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 2.1495  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1495\n",
      "03/07 02:35:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3700/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:07:30  time: 0.1625  data_time: 0.0016  memory: 10434  loss: 2.1574  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1574\n",
      "03/07 02:35:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3800/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:07:13  time: 0.1631  data_time: 0.0016  memory: 10434  loss: 2.0775  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0775\n",
      "03/07 02:36:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3900/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:06:57  time: 0.1625  data_time: 0.0019  memory: 10434  loss: 2.3368  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.3368\n",
      "03/07 02:36:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4000/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:06:40  time: 0.1625  data_time: 0.0017  memory: 10434  loss: 2.6114  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6114\n",
      "03/07 02:36:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4100/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:06:24  time: 0.1648  data_time: 0.0017  memory: 10434  loss: 2.2848  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.2848\n",
      "03/07 02:36:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4200/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:06:07  time: 0.1640  data_time: 0.0018  memory: 10434  loss: 2.4299  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.4299\n",
      "03/07 02:37:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4300/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:05:50  time: 0.1633  data_time: 0.0017  memory: 10434  loss: 2.5629  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5629\n",
      "03/07 02:37:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4400/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:05:34  time: 0.1638  data_time: 0.0016  memory: 10434  loss: 2.2500  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2500\n",
      "03/07 02:37:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:37:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4500/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:05:17  time: 0.1639  data_time: 0.0015  memory: 10434  loss: 2.3897  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3897\n",
      "03/07 02:38:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4600/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:05:01  time: 0.1628  data_time: 0.0016  memory: 10434  loss: 2.3981  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.3981\n",
      "03/07 02:38:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4700/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:04:44  time: 0.1630  data_time: 0.0018  memory: 10434  loss: 2.8452  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.8452\n",
      "03/07 02:38:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4800/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:04:27  time: 0.1641  data_time: 0.0017  memory: 10434  loss: 2.7452  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.7452\n",
      "03/07 02:38:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4900/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:04:11  time: 0.1652  data_time: 0.0017  memory: 10434  loss: 2.4986  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4986\n",
      "03/07 02:39:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][5000/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:03:55  time: 0.1638  data_time: 0.0016  memory: 10434  loss: 2.1120  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1120\n",
      "03/07 02:39:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][5100/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:03:38  time: 0.1629  data_time: 0.0016  memory: 10434  loss: 2.4947  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4947\n",
      "03/07 02:39:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][5200/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:03:22  time: 0.1632  data_time: 0.0016  memory: 10434  loss: 2.5397  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.5397\n",
      "03/07 02:39:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:39:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][5225/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 4:03:17  time: 0.1597  data_time: 0.0019  memory: 10434  loss: 2.2715  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.2715\n",
      "03/07 02:39:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][100/647]    eta: 0:00:17  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "03/07 02:39:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][200/647]    eta: 0:00:13  time: 0.0311  data_time: 0.0010  memory: 861  \n",
      "03/07 02:39:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][300/647]    eta: 0:00:10  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "03/07 02:40:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][400/647]    eta: 0:00:07  time: 0.0311  data_time: 0.0008  memory: 861  \n",
      "03/07 02:40:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][500/647]    eta: 0:00:04  time: 0.0311  data_time: 0.0009  memory: 861  \n",
      "03/07 02:40:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][600/647]    eta: 0:00:01  time: 0.0311  data_time: 0.0008  memory: 861  \n",
      "[11]\n",
      "[28]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[14]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[5]\n",
      "[14]\n",
      "[6]\n",
      "[14]\n",
      "[14]\n",
      "[21]\n",
      "[14]\n",
      "[20]\n",
      "[5]\n",
      "[14]\n",
      "[5]\n",
      "[6]\n",
      "[13]\n",
      "[14]\n",
      "[5]\n",
      "[4]\n",
      "[5]\n",
      "[13]\n",
      "[21]\n",
      "[5]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[5]\n",
      "[1]\n",
      "[21]\n",
      "[13]\n",
      "[14]\n",
      "[28]\n",
      "[14]\n",
      "[10]\n",
      "[14]\n",
      "[13]\n",
      "[21]\n",
      "[14]\n",
      "[21]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[18]\n",
      "[18]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[14]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[18]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[5]\n",
      "[21]\n",
      "[11]\n",
      "[5]\n",
      "[21]\n",
      "[21]\n",
      "[23]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[11]\n",
      "[26]\n",
      "[25]\n",
      "[16]\n",
      "[25]\n",
      "[11]\n",
      "[25]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[13]\n",
      "[11]\n",
      "[11]\n",
      "[6]\n",
      "[5]\n",
      "[6]\n",
      "[25]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[23]\n",
      "[23]\n",
      "[11]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[11]\n",
      "[25]\n",
      "[25]\n",
      "[25]\n",
      "[16]\n",
      "[30]\n",
      "[30]\n",
      "[106]\n",
      "[30]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[31]\n",
      "[8]\n",
      "[29]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[27]\n",
      "[17]\n",
      "[42]\n",
      "[110]\n",
      "[42]\n",
      "[27]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[30]\n",
      "[41]\n",
      "[106]\n",
      "[19]\n",
      "[19]\n",
      "[27]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[19]\n",
      "[33]\n",
      "[27]\n",
      "[29]\n",
      "[18]\n",
      "[39]\n",
      "[39]\n",
      "[39]\n",
      "[38]\n",
      "[30]\n",
      "[19]\n",
      "[106]\n",
      "[37]\n",
      "[17]\n",
      "[42]\n",
      "[14]\n",
      "[14]\n",
      "[97]\n",
      "[97]\n",
      "[15]\n",
      "[97]\n",
      "[15]\n",
      "[15]\n",
      "[34]\n",
      "[97]\n",
      "[15]\n",
      "[57]\n",
      "[52]\n",
      "[57]\n",
      "[37]\n",
      "[59]\n",
      "[47]\n",
      "[57]\n",
      "[87]\n",
      "[9]\n",
      "[55]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[59]\n",
      "[46]\n",
      "[46]\n",
      "[56]\n",
      "[55]\n",
      "[57]\n",
      "[9]\n",
      "[52]\n",
      "[46]\n",
      "[59]\n",
      "[46]\n",
      "[59]\n",
      "[46]\n",
      "[59]\n",
      "[46]\n",
      "[46]\n",
      "[15]\n",
      "[58]\n",
      "[58]\n",
      "[59]\n",
      "[58]\n",
      "[46]\n",
      "[59]\n",
      "[58]\n",
      "[59]\n",
      "[57]\n",
      "[57]\n",
      "[59]\n",
      "[59]\n",
      "[52]\n",
      "[46]\n",
      "[51]\n",
      "[52]\n",
      "[10]\n",
      "[46]\n",
      "[46]\n",
      "[10]\n",
      "[51]\n",
      "[46]\n",
      "[46]\n",
      "[63]\n",
      "[51]\n",
      "[52]\n",
      "[10]\n",
      "[47]\n",
      "[52]\n",
      "[52]\n",
      "[56]\n",
      "[56]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[22]\n",
      "[56]\n",
      "[51]\n",
      "[51]\n",
      "[51]\n",
      "[51]\n",
      "[59]\n",
      "[52]\n",
      "[51]\n",
      "[51]\n",
      "[52]\n",
      "[53]\n",
      "[57]\n",
      "[51]\n",
      "[51]\n",
      "[51]\n",
      "[52]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[59]\n",
      "[9]\n",
      "[56]\n",
      "[51]\n",
      "[51]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[67]\n",
      "[28]\n",
      "[29]\n",
      "[51]\n",
      "[66]\n",
      "[66]\n",
      "[97]\n",
      "[67]\n",
      "[66]\n",
      "[69]\n",
      "[61]\n",
      "[67]\n",
      "[66]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[67]\n",
      "[66]\n",
      "[66]\n",
      "[66]\n",
      "[28]\n",
      "[51]\n",
      "[51]\n",
      "[51]\n",
      "[53]\n",
      "[30]\n",
      "[66]\n",
      "[30]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[29]\n",
      "[28]\n",
      "[66]\n",
      "[66]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[69]\n",
      "[67]\n",
      "[48]\n",
      "[47]\n",
      "[66]\n",
      "[66]\n",
      "[67]\n",
      "[51]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[28]\n",
      "[116]\n",
      "[53]\n",
      "[110]\n",
      "[122]\n",
      "[122]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[122]\n",
      "[99]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[122]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[122]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[99]\n",
      "[97]\n",
      "[45]\n",
      "[97]\n",
      "[99]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[99]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[71]\n",
      "[99]\n",
      "[99]\n",
      "[72]\n",
      "[60]\n",
      "[86]\n",
      "[90]\n",
      "[74]\n",
      "[73]\n",
      "[90]\n",
      "[90]\n",
      "[88]\n",
      "[90]\n",
      "[81]\n",
      "[84]\n",
      "[73]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[88]\n",
      "[90]\n",
      "[86]\n",
      "[90]\n",
      "[60]\n",
      "[60]\n",
      "[84]\n",
      "[73]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[73]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[84]\n",
      "[90]\n",
      "[90]\n",
      "[72]\n",
      "[60]\n",
      "[86]\n",
      "[87]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[88]\n",
      "[88]\n",
      "[81]\n",
      "[81]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[87]\n",
      "[88]\n",
      "[73]\n",
      "[84]\n",
      "[90]\n",
      "[88]\n",
      "[74]\n",
      "[73]\n",
      "[72]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[73]\n",
      "[87]\n",
      "[74]\n",
      "[74]\n",
      "[77]\n",
      "[87]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[112]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[81]\n",
      "[91]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[112]\n",
      "[91]\n",
      "[31]\n",
      "[97]\n",
      "[110]\n",
      "[49]\n",
      "[97]\n",
      "[49]\n",
      "[19]\n",
      "[71]\n",
      "[71]\n",
      "[101]\n",
      "[71]\n",
      "[101]\n",
      "[101]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[64]\n",
      "[102]\n",
      "[71]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[71]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[71]\n",
      "[103]\n",
      "[71]\n",
      "[97]\n",
      "[97]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[104]\n",
      "[104]\n",
      "[99]\n",
      "[97]\n",
      "[99]\n",
      "[99]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[100]\n",
      "[95]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[100]\n",
      "[95]\n",
      "[97]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[99]\n",
      "[99]\n",
      "[97]\n",
      "[97]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[105]\n",
      "[112]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[31]\n",
      "[31]\n",
      "[112]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[106]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[112]\n",
      "[112]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[107]\n",
      "[107]\n",
      "[111]\n",
      "[107]\n",
      "[107]\n",
      "03/07 02:40:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [8][647/647]    acc/top1: 0.1206  acc/top5: 0.3910  acc/mean1: 0.1736  data_time: 0.0008  time: 0.0311\n",
      "03/07 02:40:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_7.pth is removed\n",
      "03/07 02:40:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.1206 acc/top1 at 8 epoch is saved to best_acc_top1_epoch_8.pth.\n",
      "03/07 02:40:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 100/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 4:03:01  time: 0.1624  data_time: 0.0018  memory: 10434  loss: 2.6390  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.6390\n",
      "03/07 02:40:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:40:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 200/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 4:02:44  time: 0.1629  data_time: 0.0016  memory: 10434  loss: 1.8113  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8113\n",
      "03/07 02:40:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 300/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 4:02:27  time: 0.1640  data_time: 0.0017  memory: 10434  loss: 2.2914  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.2914\n",
      "03/07 02:41:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 400/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 4:02:11  time: 0.1623  data_time: 0.0018  memory: 10434  loss: 2.3637  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.3637\n",
      "03/07 02:41:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 500/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 4:01:54  time: 0.1643  data_time: 0.0020  memory: 10434  loss: 2.3661  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3661\n",
      "03/07 02:41:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 600/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 4:01:38  time: 0.1692  data_time: 0.0019  memory: 10434  loss: 2.1241  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1241\n",
      "03/07 02:42:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 700/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 4:01:21  time: 0.1629  data_time: 0.0020  memory: 10434  loss: 2.0216  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0216\n",
      "03/07 02:42:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 800/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 4:01:05  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 2.3514  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.3514\n",
      "03/07 02:42:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 900/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 4:00:48  time: 0.1647  data_time: 0.0019  memory: 10434  loss: 1.9659  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9659\n",
      "03/07 02:42:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1000/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 4:00:32  time: 0.1636  data_time: 0.0019  memory: 10434  loss: 2.2049  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.2049\n",
      "03/07 02:43:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1100/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 4:00:15  time: 0.1628  data_time: 0.0018  memory: 10434  loss: 2.4603  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.4603\n",
      "03/07 02:43:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:43:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1200/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:59:59  time: 0.1640  data_time: 0.0018  memory: 10434  loss: 2.2394  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2394\n",
      "03/07 02:43:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1300/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:59:42  time: 0.1640  data_time: 0.0020  memory: 10434  loss: 2.8691  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.8691\n",
      "03/07 02:43:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1400/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:59:26  time: 0.1633  data_time: 0.0018  memory: 10434  loss: 2.6302  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.6302\n",
      "03/07 02:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1500/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:59:09  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 2.7038  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.7038\n",
      "03/07 02:44:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1600/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:58:52  time: 0.1637  data_time: 0.0019  memory: 10434  loss: 1.9644  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9644\n",
      "03/07 02:44:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1700/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:58:36  time: 0.1651  data_time: 0.0019  memory: 10434  loss: 2.0102  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0102\n",
      "03/07 02:45:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1800/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:58:20  time: 0.1637  data_time: 0.0019  memory: 10434  loss: 2.3121  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.3121\n",
      "03/07 02:45:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1900/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:58:03  time: 0.1636  data_time: 0.0019  memory: 10434  loss: 1.7228  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7228\n",
      "03/07 02:45:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2000/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:57:47  time: 0.1636  data_time: 0.0020  memory: 10434  loss: 2.6155  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.6155\n",
      "03/07 02:45:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2100/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:57:30  time: 0.1640  data_time: 0.0020  memory: 10434  loss: 1.8194  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.8194\n",
      "03/07 02:46:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:46:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2200/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:57:14  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 2.0148  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0148\n",
      "03/07 02:46:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2300/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:56:57  time: 0.1637  data_time: 0.0020  memory: 10434  loss: 2.3441  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.3441\n",
      "03/07 02:46:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2400/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:56:41  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 2.2293  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2293\n",
      "03/07 02:46:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2500/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:56:24  time: 0.1639  data_time: 0.0019  memory: 10434  loss: 2.3273  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.3273\n",
      "03/07 02:47:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2600/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:56:08  time: 0.1645  data_time: 0.0020  memory: 10434  loss: 2.0267  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0267\n",
      "03/07 02:47:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2700/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:55:51  time: 0.1640  data_time: 0.0017  memory: 10434  loss: 2.5232  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5232\n",
      "03/07 02:47:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2800/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:55:35  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 2.1563  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1563\n",
      "03/07 02:48:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2900/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:55:18  time: 0.1636  data_time: 0.0020  memory: 10434  loss: 2.4096  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.4096\n",
      "03/07 02:48:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3000/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:55:02  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 2.3903  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.3903\n",
      "03/07 02:48:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3100/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:54:45  time: 0.1632  data_time: 0.0019  memory: 10434  loss: 2.4296  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.4296\n",
      "03/07 02:48:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:48:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3200/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:54:29  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 2.8609  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.8609\n",
      "03/07 02:49:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3300/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:54:12  time: 0.1632  data_time: 0.0019  memory: 10434  loss: 2.0154  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0154\n",
      "03/07 02:49:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3400/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:53:56  time: 0.1631  data_time: 0.0020  memory: 10434  loss: 2.3259  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.3259\n",
      "03/07 02:49:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3500/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:53:39  time: 0.1652  data_time: 0.0021  memory: 10434  loss: 2.4509  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.4509\n",
      "03/07 02:49:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3600/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:53:23  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 2.2365  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2365\n",
      "03/07 02:50:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3700/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:53:06  time: 0.1632  data_time: 0.0019  memory: 10434  loss: 2.1494  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1494\n",
      "03/07 02:50:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3800/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:52:49  time: 0.1628  data_time: 0.0019  memory: 10434  loss: 2.2134  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2134\n",
      "03/07 02:50:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3900/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:52:33  time: 0.1660  data_time: 0.0020  memory: 10434  loss: 2.4110  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4110\n",
      "03/07 02:51:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4000/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:52:17  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 2.0896  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0896\n",
      "03/07 02:51:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4100/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:52:00  time: 0.1626  data_time: 0.0020  memory: 10434  loss: 2.2629  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2629\n",
      "03/07 02:51:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:51:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4200/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:51:44  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 2.5434  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5434\n",
      "03/07 02:51:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4300/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:51:28  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 2.0903  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0903\n",
      "03/07 02:52:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4400/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:51:11  time: 0.1628  data_time: 0.0019  memory: 10434  loss: 2.3958  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.3958\n",
      "03/07 02:52:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4500/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:50:54  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 2.1843  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1843\n",
      "03/07 02:52:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4600/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:50:38  time: 0.1635  data_time: 0.0020  memory: 10434  loss: 1.7543  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7543\n",
      "03/07 02:52:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4700/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:50:21  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 2.4728  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.4728\n",
      "03/07 02:53:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4800/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:50:05  time: 0.1643  data_time: 0.0019  memory: 10434  loss: 2.3419  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3419\n",
      "03/07 02:53:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4900/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:49:48  time: 0.1637  data_time: 0.0020  memory: 10434  loss: 2.3337  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.3337\n",
      "03/07 02:53:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][5000/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:49:32  time: 0.1642  data_time: 0.0020  memory: 10434  loss: 2.1221  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1221\n",
      "03/07 02:54:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][5100/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:49:15  time: 0.1630  data_time: 0.0020  memory: 10434  loss: 2.2230  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2230\n",
      "03/07 02:54:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:54:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][5200/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:48:59  time: 0.1634  data_time: 0.0019  memory: 10434  loss: 2.2396  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.2396\n",
      "03/07 02:54:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:54:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][5225/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:48:54  time: 0.1592  data_time: 0.0018  memory: 10434  loss: 1.9342  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9342\n",
      "03/07 02:54:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
      "03/07 02:54:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][100/647]    eta: 0:00:17  time: 0.0313  data_time: 0.0008  memory: 861  \n",
      "03/07 02:54:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][200/647]    eta: 0:00:14  time: 0.0311  data_time: 0.0007  memory: 861  \n",
      "03/07 02:54:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][300/647]    eta: 0:00:10  time: 0.0313  data_time: 0.0009  memory: 861  \n",
      "03/07 02:54:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][400/647]    eta: 0:00:07  time: 0.0313  data_time: 0.0009  memory: 861  \n",
      "03/07 02:54:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][500/647]    eta: 0:00:04  time: 0.0313  data_time: 0.0010  memory: 861  \n",
      "03/07 02:54:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][600/647]    eta: 0:00:01  time: 0.0313  data_time: 0.0008  memory: 861  \n",
      "[13]\n",
      "[1]\n",
      "[18]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[21]\n",
      "[21]\n",
      "[14]\n",
      "[20]\n",
      "[21]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[18]\n",
      "[21]\n",
      "[18]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[13]\n",
      "[21]\n",
      "[14]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[13]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[14]\n",
      "[14]\n",
      "[18]\n",
      "[20]\n",
      "[14]\n",
      "[21]\n",
      "[1]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[28]\n",
      "[21]\n",
      "[18]\n",
      "[14]\n",
      "[21]\n",
      "[21]\n",
      "[13]\n",
      "[21]\n",
      "[18]\n",
      "[13]\n",
      "[21]\n",
      "[5]\n",
      "[13]\n",
      "[21]\n",
      "[21]\n",
      "[18]\n",
      "[18]\n",
      "[16]\n",
      "[20]\n",
      "[21]\n",
      "[13]\n",
      "[13]\n",
      "[18]\n",
      "[18]\n",
      "[21]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[21]\n",
      "[21]\n",
      "[0]\n",
      "[21]\n",
      "[16]\n",
      "[5]\n",
      "[21]\n",
      "[21]\n",
      "[4]\n",
      "[21]\n",
      "[5]\n",
      "[21]\n",
      "[21]\n",
      "[22]\n",
      "[21]\n",
      "[25]\n",
      "[16]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[20]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[16]\n",
      "[21]\n",
      "[16]\n",
      "[5]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[16]\n",
      "[16]\n",
      "[16]\n",
      "[20]\n",
      "[22]\n",
      "[23]\n",
      "[16]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[16]\n",
      "[43]\n",
      "[31]\n",
      "[34]\n",
      "[29]\n",
      "[30]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[28]\n",
      "[8]\n",
      "[29]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[27]\n",
      "[41]\n",
      "[109]\n",
      "[109]\n",
      "[42]\n",
      "[30]\n",
      "[27]\n",
      "[41]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[60]\n",
      "[60]\n",
      "[43]\n",
      "[42]\n",
      "[109]\n",
      "[30]\n",
      "[41]\n",
      "[43]\n",
      "[19]\n",
      "[19]\n",
      "[27]\n",
      "[19]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[19]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[38]\n",
      "[41]\n",
      "[41]\n",
      "[38]\n",
      "[31]\n",
      "[19]\n",
      "[106]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[57]\n",
      "[52]\n",
      "[59]\n",
      "[115]\n",
      "[56]\n",
      "[47]\n",
      "[57]\n",
      "[56]\n",
      "[9]\n",
      "[55]\n",
      "[52]\n",
      "[47]\n",
      "[52]\n",
      "[59]\n",
      "[45]\n",
      "[45]\n",
      "[56]\n",
      "[55]\n",
      "[56]\n",
      "[56]\n",
      "[52]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[59]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[15]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[10]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[52]\n",
      "[9]\n",
      "[7]\n",
      "[56]\n",
      "[10]\n",
      "[47]\n",
      "[47]\n",
      "[10]\n",
      "[44]\n",
      "[47]\n",
      "[47]\n",
      "[44]\n",
      "[44]\n",
      "[52]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[56]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[22]\n",
      "[8]\n",
      "[44]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[59]\n",
      "[53]\n",
      "[45]\n",
      "[45]\n",
      "[44]\n",
      "[56]\n",
      "[59]\n",
      "[45]\n",
      "[45]\n",
      "[56]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[56]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[29]\n",
      "[31]\n",
      "[29]\n",
      "[62]\n",
      "[28]\n",
      "[29]\n",
      "[7]\n",
      "[47]\n",
      "[66]\n",
      "[28]\n",
      "[28]\n",
      "[66]\n",
      "[69]\n",
      "[31]\n",
      "[63]\n",
      "[66]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[28]\n",
      "[28]\n",
      "[67]\n",
      "[66]\n",
      "[28]\n",
      "[53]\n",
      "[28]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[70]\n",
      "[30]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[29]\n",
      "[28]\n",
      "[66]\n",
      "[67]\n",
      "[66]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[47]\n",
      "[47]\n",
      "[66]\n",
      "[66]\n",
      "[67]\n",
      "[68]\n",
      "[68]\n",
      "[67]\n",
      "[69]\n",
      "[28]\n",
      "[98]\n",
      "[45]\n",
      "[121]\n",
      "[71]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[45]\n",
      "[121]\n",
      "[98]\n",
      "[98]\n",
      "[45]\n",
      "[121]\n",
      "[121]\n",
      "[98]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[45]\n",
      "[98]\n",
      "[45]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[71]\n",
      "[71]\n",
      "[98]\n",
      "[98]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[98]\n",
      "[98]\n",
      "[97]\n",
      "[71]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[98]\n",
      "[75]\n",
      "[75]\n",
      "[86]\n",
      "[72]\n",
      "[75]\n",
      "[78]\n",
      "[78]\n",
      "[90]\n",
      "[75]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[86]\n",
      "[88]\n",
      "[86]\n",
      "[75]\n",
      "[90]\n",
      "[88]\n",
      "[90]\n",
      "[75]\n",
      "[60]\n",
      "[83]\n",
      "[75]\n",
      "[82]\n",
      "[7]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[83]\n",
      "[83]\n",
      "[76]\n",
      "[76]\n",
      "[82]\n",
      "[90]\n",
      "[3]\n",
      "[90]\n",
      "[90]\n",
      "[75]\n",
      "[60]\n",
      "[83]\n",
      "[72]\n",
      "[90]\n",
      "[90]\n",
      "[82]\n",
      "[90]\n",
      "[82]\n",
      "[82]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[84]\n",
      "[83]\n",
      "[88]\n",
      "[90]\n",
      "[83]\n",
      "[83]\n",
      "[90]\n",
      "[72]\n",
      "[74]\n",
      "[73]\n",
      "[79]\n",
      "[82]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[73]\n",
      "[75]\n",
      "[74]\n",
      "[74]\n",
      "[77]\n",
      "[89]\n",
      "[83]\n",
      "[75]\n",
      "[88]\n",
      "[30]\n",
      "[30]\n",
      "[82]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[82]\n",
      "[82]\n",
      "[30]\n",
      "[31]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[112]\n",
      "[30]\n",
      "[60]\n",
      "[71]\n",
      "[49]\n",
      "[49]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[101]\n",
      "[101]\n",
      "[102]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[102]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[62]\n",
      "[102]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[101]\n",
      "[103]\n",
      "[103]\n",
      "[101]\n",
      "[103]\n",
      "[101]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[96]\n",
      "[100]\n",
      "[100]\n",
      "[104]\n",
      "[104]\n",
      "[100]\n",
      "[95]\n",
      "[96]\n",
      "[71]\n",
      "[96]\n",
      "[107]\n",
      "[95]\n",
      "[96]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[98]\n",
      "[98]\n",
      "[100]\n",
      "[98]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[106]\n",
      "[105]\n",
      "[112]\n",
      "[105]\n",
      "[112]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[109]\n",
      "[112]\n",
      "[105]\n",
      "[105]\n",
      "[109]\n",
      "[105]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[108]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[109]\n",
      "[111]\n",
      "[107]\n",
      "[71]\n",
      "[111]\n",
      "[111]\n",
      "[71]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[107]\n",
      "[107]\n",
      "03/07 02:54:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [9][647/647]    acc/top1: 0.1221  acc/top5: 0.4544  acc/mean1: 0.1699  data_time: 0.0009  time: 0.0313\n",
      "03/07 02:54:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_8.pth is removed\n",
      "03/07 02:54:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.1221 acc/top1 at 9 epoch is saved to best_acc_top1_epoch_9.pth.\n",
      "03/07 02:55:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 100/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:48:38  time: 0.1645  data_time: 0.0019  memory: 10434  loss: 2.2193  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2193\n",
      "03/07 02:55:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 200/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:48:22  time: 0.1633  data_time: 0.0020  memory: 10434  loss: 2.1655  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1655\n",
      "03/07 02:55:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 300/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:48:05  time: 0.1644  data_time: 0.0019  memory: 10434  loss: 2.4465  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4465\n",
      "03/07 02:55:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 400/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:47:48  time: 0.1637  data_time: 0.0019  memory: 10434  loss: 2.1034  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1034\n",
      "03/07 02:56:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 500/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:47:32  time: 0.1641  data_time: 0.0017  memory: 10434  loss: 2.1716  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1716\n",
      "03/07 02:56:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 600/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:47:15  time: 0.1627  data_time: 0.0021  memory: 10434  loss: 1.9954  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9954\n",
      "03/07 02:56:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 700/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:46:59  time: 0.1666  data_time: 0.0017  memory: 10434  loss: 2.7726  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.7726\n",
      "03/07 02:56:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 800/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:46:43  time: 0.1655  data_time: 0.0018  memory: 10434  loss: 2.1051  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1051\n",
      "03/07 02:57:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 900/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:46:26  time: 0.1636  data_time: 0.0021  memory: 10434  loss: 1.9720  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9720\n",
      "03/07 02:57:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 02:57:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1000/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:46:10  time: 0.1634  data_time: 0.0021  memory: 10434  loss: 2.1937  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1937\n",
      "03/07 02:57:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1100/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:45:53  time: 0.1643  data_time: 0.0018  memory: 10434  loss: 2.3538  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3538\n",
      "03/07 02:58:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1200/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:45:37  time: 0.1628  data_time: 0.0019  memory: 10434  loss: 2.0984  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0984\n",
      "03/07 02:58:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1300/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:45:20  time: 0.1630  data_time: 0.0020  memory: 10434  loss: 2.2767  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2767\n",
      "03/07 02:58:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1400/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:45:04  time: 0.1640  data_time: 0.0017  memory: 10434  loss: 1.8438  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.8438\n",
      "03/07 02:58:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1500/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:44:47  time: 0.1651  data_time: 0.0020  memory: 10434  loss: 2.4465  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.4465\n",
      "03/07 02:59:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1600/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:44:31  time: 0.1653  data_time: 0.0020  memory: 10434  loss: 1.9268  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9268\n",
      "03/07 02:59:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1700/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:44:14  time: 0.1647  data_time: 0.0020  memory: 10434  loss: 1.8214  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8214\n",
      "03/07 02:59:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1800/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:43:58  time: 0.1633  data_time: 0.0021  memory: 10434  loss: 2.0911  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.0911\n",
      "03/07 02:59:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1900/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:43:41  time: 0.1653  data_time: 0.0020  memory: 10434  loss: 2.0264  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0264\n",
      "03/07 03:00:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:00:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2000/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:43:25  time: 0.1629  data_time: 0.0018  memory: 10434  loss: 1.8943  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8943\n",
      "03/07 03:00:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2100/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:43:08  time: 0.1641  data_time: 0.0020  memory: 10434  loss: 1.9491  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9491\n",
      "03/07 03:00:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2200/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:42:52  time: 0.1658  data_time: 0.0020  memory: 10434  loss: 2.1664  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1664\n",
      "03/07 03:01:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2300/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:42:36  time: 0.1634  data_time: 0.0019  memory: 10434  loss: 1.8555  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8555\n",
      "03/07 03:01:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2400/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:42:19  time: 0.1642  data_time: 0.0018  memory: 10434  loss: 2.3741  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3741\n",
      "03/07 03:01:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2500/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:42:03  time: 0.1638  data_time: 0.0020  memory: 10434  loss: 2.2922  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2922\n",
      "03/07 03:01:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2600/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:41:46  time: 0.1634  data_time: 0.0019  memory: 10434  loss: 2.5647  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.5647\n",
      "03/07 03:02:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2700/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:41:30  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 2.0369  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0369\n",
      "03/07 03:02:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2800/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:41:13  time: 0.1627  data_time: 0.0019  memory: 10434  loss: 2.0861  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0861\n",
      "03/07 03:02:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2900/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:40:57  time: 0.1650  data_time: 0.0020  memory: 10434  loss: 2.3349  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.3349\n",
      "03/07 03:02:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:03:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3000/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:40:41  time: 0.1640  data_time: 0.0020  memory: 10434  loss: 1.9196  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9196\n",
      "03/07 03:03:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3100/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:40:24  time: 0.1643  data_time: 0.0019  memory: 10434  loss: 2.1925  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1925\n",
      "03/07 03:03:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3200/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:40:08  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 2.1866  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1866\n",
      "03/07 03:03:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3300/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:39:51  time: 0.1644  data_time: 0.0020  memory: 10434  loss: 1.8860  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8860\n",
      "03/07 03:04:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3400/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:39:35  time: 0.1630  data_time: 0.0021  memory: 10434  loss: 2.1151  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1151\n",
      "03/07 03:04:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3500/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:39:18  time: 0.1628  data_time: 0.0017  memory: 10434  loss: 1.9274  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9274\n",
      "03/07 03:04:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3600/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:39:02  time: 0.1650  data_time: 0.0019  memory: 10434  loss: 2.0209  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0209\n",
      "03/07 03:04:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3700/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:38:45  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 2.1427  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1427\n",
      "03/07 03:05:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3800/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:38:29  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 1.9050  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9050\n",
      "03/07 03:05:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3900/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:38:12  time: 0.1639  data_time: 0.0019  memory: 10434  loss: 2.2495  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.2495\n",
      "03/07 03:05:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:05:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4000/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:37:56  time: 0.1633  data_time: 0.0020  memory: 10434  loss: 1.9955  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9955\n",
      "03/07 03:06:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4100/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:37:39  time: 0.1641  data_time: 0.0020  memory: 10434  loss: 2.1015  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1015\n",
      "03/07 03:06:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4200/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:37:23  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 1.8033  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8033\n",
      "03/07 03:06:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4300/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:37:06  time: 0.1632  data_time: 0.0020  memory: 10434  loss: 2.2768  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2768\n",
      "03/07 03:06:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4400/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:36:50  time: 0.1649  data_time: 0.0020  memory: 10434  loss: 2.2699  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2699\n",
      "03/07 03:07:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4500/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:36:34  time: 0.1648  data_time: 0.0018  memory: 10434  loss: 1.9766  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9766\n",
      "03/07 03:07:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4600/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:36:17  time: 0.1636  data_time: 0.0020  memory: 10434  loss: 2.1981  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1981\n",
      "03/07 03:07:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4700/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:36:01  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 2.0881  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0881\n",
      "03/07 03:07:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4800/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:35:44  time: 0.1643  data_time: 0.0018  memory: 10434  loss: 2.5066  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5066\n",
      "03/07 03:08:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4900/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:35:28  time: 0.1634  data_time: 0.0020  memory: 10434  loss: 1.8340  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.8340\n",
      "03/07 03:08:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:08:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][5000/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:35:11  time: 0.1636  data_time: 0.0019  memory: 10434  loss: 2.2009  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.2009\n",
      "03/07 03:08:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][5100/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:34:55  time: 0.1657  data_time: 0.0018  memory: 10434  loss: 1.7745  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.7745\n",
      "03/07 03:09:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][5200/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:34:39  time: 0.1647  data_time: 0.0021  memory: 10434  loss: 1.9025  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9025\n",
      "03/07 03:09:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:09:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][5225/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:34:34  time: 0.1599  data_time: 0.0018  memory: 10434  loss: 2.0573  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0573\n",
      "03/07 03:09:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][100/647]    eta: 0:00:17  time: 0.0313  data_time: 0.0009  memory: 861  \n",
      "03/07 03:09:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][200/647]    eta: 0:00:14  time: 0.0311  data_time: 0.0008  memory: 861  \n",
      "03/07 03:09:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][300/647]    eta: 0:00:10  time: 0.0312  data_time: 0.0008  memory: 861  \n",
      "03/07 03:09:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][400/647]    eta: 0:00:07  time: 0.0312  data_time: 0.0008  memory: 861  \n",
      "03/07 03:09:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][500/647]    eta: 0:00:04  time: 0.0314  data_time: 0.0009  memory: 861  \n",
      "03/07 03:09:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][600/647]    eta: 0:00:01  time: 0.0311  data_time: 0.0008  memory: 861  \n",
      "[23]\n",
      "[1]\n",
      "[20]\n",
      "[11]\n",
      "[23]\n",
      "[11]\n",
      "[4]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[20]\n",
      "[20]\n",
      "[4]\n",
      "[20]\n",
      "[20]\n",
      "[11]\n",
      "[20]\n",
      "[20]\n",
      "[23]\n",
      "[1]\n",
      "[20]\n",
      "[23]\n",
      "[4]\n",
      "[5]\n",
      "[13]\n",
      "[21]\n",
      "[23]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[11]\n",
      "[25]\n",
      "[20]\n",
      "[12]\n",
      "[1]\n",
      "[23]\n",
      "[11]\n",
      "[17]\n",
      "[4]\n",
      "[20]\n",
      "[20]\n",
      "[11]\n",
      "[4]\n",
      "[21]\n",
      "[20]\n",
      "[4]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[20]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[20]\n",
      "[23]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[5]\n",
      "[14]\n",
      "[23]\n",
      "[4]\n",
      "[20]\n",
      "[23]\n",
      "[4]\n",
      "[5]\n",
      "[23]\n",
      "[21]\n",
      "[20]\n",
      "[20]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[25]\n",
      "[20]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[5]\n",
      "[20]\n",
      "[4]\n",
      "[20]\n",
      "[23]\n",
      "[20]\n",
      "[23]\n",
      "[23]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[23]\n",
      "[23]\n",
      "[26]\n",
      "[25]\n",
      "[24]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[20]\n",
      "[26]\n",
      "[43]\n",
      "[30]\n",
      "[34]\n",
      "[29]\n",
      "[30]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[28]\n",
      "[43]\n",
      "[29]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[35]\n",
      "[41]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[30]\n",
      "[30]\n",
      "[41]\n",
      "[42]\n",
      "[38]\n",
      "[19]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[43]\n",
      "[30]\n",
      "[41]\n",
      "[42]\n",
      "[19]\n",
      "[19]\n",
      "[30]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[36]\n",
      "[33]\n",
      "[67]\n",
      "[29]\n",
      "[42]\n",
      "[38]\n",
      "[39]\n",
      "[38]\n",
      "[38]\n",
      "[67]\n",
      "[36]\n",
      "[113]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[15]\n",
      "[34]\n",
      "[34]\n",
      "[15]\n",
      "[34]\n",
      "[57]\n",
      "[56]\n",
      "[57]\n",
      "[122]\n",
      "[57]\n",
      "[59]\n",
      "[57]\n",
      "[87]\n",
      "[22]\n",
      "[55]\n",
      "[57]\n",
      "[59]\n",
      "[59]\n",
      "[57]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[55]\n",
      "[57]\n",
      "[56]\n",
      "[59]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[59]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[54]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[59]\n",
      "[56]\n",
      "[54]\n",
      "[15]\n",
      "[55]\n",
      "[55]\n",
      "[58]\n",
      "[10]\n",
      "[55]\n",
      "[55]\n",
      "[58]\n",
      "[10]\n",
      "[63]\n",
      "[55]\n",
      "[59]\n",
      "[54]\n",
      "[58]\n",
      "[57]\n",
      "[54]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[23]\n",
      "[55]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[59]\n",
      "[59]\n",
      "[59]\n",
      "[59]\n",
      "[59]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[58]\n",
      "[57]\n",
      "[57]\n",
      "[58]\n",
      "[59]\n",
      "[9]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[31]\n",
      "[53]\n",
      "[53]\n",
      "[61]\n",
      "[67]\n",
      "[29]\n",
      "[63]\n",
      "[29]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[53]\n",
      "[47]\n",
      "[69]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[40]\n",
      "[69]\n",
      "[67]\n",
      "[65]\n",
      "[40]\n",
      "[70]\n",
      "[64]\n",
      "[53]\n",
      "[64]\n",
      "[53]\n",
      "[53]\n",
      "[40]\n",
      "[70]\n",
      "[40]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[29]\n",
      "[64]\n",
      "[40]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[47]\n",
      "[69]\n",
      "[70]\n",
      "[40]\n",
      "[67]\n",
      "[61]\n",
      "[70]\n",
      "[67]\n",
      "[69]\n",
      "[29]\n",
      "[116]\n",
      "[48]\n",
      "[121]\n",
      "[116]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[48]\n",
      "[121]\n",
      "[122]\n",
      "[44]\n",
      "[48]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[48]\n",
      "[99]\n",
      "[48]\n",
      "[99]\n",
      "[48]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[12]\n",
      "[99]\n",
      "[99]\n",
      "[48]\n",
      "[48]\n",
      "[12]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[72]\n",
      "[74]\n",
      "[86]\n",
      "[72]\n",
      "[74]\n",
      "[78]\n",
      "[78]\n",
      "[90]\n",
      "[74]\n",
      "[74]\n",
      "[81]\n",
      "[83]\n",
      "[89]\n",
      "[83]\n",
      "[85]\n",
      "[85]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[90]\n",
      "[85]\n",
      "[90]\n",
      "[80]\n",
      "[74]\n",
      "[84]\n",
      "[73]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[85]\n",
      "[85]\n",
      "[80]\n",
      "[80]\n",
      "[76]\n",
      "[90]\n",
      "[73]\n",
      "[90]\n",
      "[90]\n",
      "[74]\n",
      "[74]\n",
      "[84]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[90]\n",
      "[90]\n",
      "[74]\n",
      "[74]\n",
      "[81]\n",
      "[81]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[85]\n",
      "[87]\n",
      "[87]\n",
      "[73]\n",
      "[84]\n",
      "[90]\n",
      "[73]\n",
      "[74]\n",
      "[73]\n",
      "[72]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[85]\n",
      "[73]\n",
      "[74]\n",
      "[74]\n",
      "[74]\n",
      "[77]\n",
      "[73]\n",
      "[83]\n",
      "[73]\n",
      "[73]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[31]\n",
      "[112]\n",
      "[107]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[112]\n",
      "[91]\n",
      "[112]\n",
      "[91]\n",
      "[30]\n",
      "[71]\n",
      "[110]\n",
      "[49]\n",
      "[107]\n",
      "[49]\n",
      "[71]\n",
      "[40]\n",
      "[64]\n",
      "[102]\n",
      "[62]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[102]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[101]\n",
      "[62]\n",
      "[64]\n",
      "[64]\n",
      "[62]\n",
      "[62]\n",
      "[92]\n",
      "[103]\n",
      "[103]\n",
      "[92]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[64]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[62]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[62]\n",
      "[62]\n",
      "[62]\n",
      "[62]\n",
      "[102]\n",
      "[62]\n",
      "[62]\n",
      "[62]\n",
      "[62]\n",
      "[103]\n",
      "[62]\n",
      "[62]\n",
      "[62]\n",
      "[96]\n",
      "[2]\n",
      "[2]\n",
      "[79]\n",
      "[99]\n",
      "[99]\n",
      "[0]\n",
      "[92]\n",
      "[104]\n",
      "[104]\n",
      "[92]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[79]\n",
      "[96]\n",
      "[2]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[95]\n",
      "[107]\n",
      "[107]\n",
      "[99]\n",
      "[107]\n",
      "[95]\n",
      "[99]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[99]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[106]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[106]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[111]\n",
      "[111]\n",
      "[105]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[113]\n",
      "[107]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[107]\n",
      "[107]\n",
      "[107]\n",
      "[107]\n",
      "[107]\n",
      "03/07 03:09:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][647/647]    acc/top1: 0.1267  acc/top5: 0.4560  acc/mean1: 0.1871  data_time: 0.0010  time: 0.0313\n",
      "03/07 03:09:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_9.pth is removed\n",
      "03/07 03:09:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.1267 acc/top1 at 10 epoch is saved to best_acc_top1_epoch_10.pth.\n",
      "03/07 03:09:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 100/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:34:18  time: 0.1643  data_time: 0.0021  memory: 10434  loss: 2.1704  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1704\n",
      "03/07 03:10:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 200/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:34:02  time: 0.1637  data_time: 0.0020  memory: 10434  loss: 2.3712  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3712\n",
      "03/07 03:10:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 300/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:33:45  time: 0.1638  data_time: 0.0020  memory: 10434  loss: 2.1869  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1869\n",
      "03/07 03:10:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 400/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:33:29  time: 0.1645  data_time: 0.0020  memory: 10434  loss: 2.2830  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2830\n",
      "03/07 03:10:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 500/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:33:12  time: 0.1634  data_time: 0.0018  memory: 10434  loss: 1.7666  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7666\n",
      "03/07 03:11:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 600/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:32:56  time: 0.1636  data_time: 0.0021  memory: 10434  loss: 2.0079  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0079\n",
      "03/07 03:11:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 700/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:32:39  time: 0.1642  data_time: 0.0019  memory: 10434  loss: 2.0473  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0473\n",
      "03/07 03:11:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:11:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 800/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:32:23  time: 0.1652  data_time: 0.0020  memory: 10434  loss: 2.2447  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2447\n",
      "03/07 03:11:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 900/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:32:06  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 2.1523  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1523\n",
      "03/07 03:12:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1000/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:31:50  time: 0.1643  data_time: 0.0020  memory: 10434  loss: 1.8677  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.8677\n",
      "03/07 03:12:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1100/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:31:33  time: 0.1631  data_time: 0.0020  memory: 10434  loss: 2.2727  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.2727\n",
      "03/07 03:12:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1200/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:31:17  time: 0.1643  data_time: 0.0019  memory: 10434  loss: 2.0583  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0583\n",
      "03/07 03:13:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1300/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:31:00  time: 0.1636  data_time: 0.0021  memory: 10434  loss: 1.9769  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9769\n",
      "03/07 03:13:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1400/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:30:44  time: 0.1635  data_time: 0.0022  memory: 10434  loss: 2.5060  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.5060\n",
      "03/07 03:13:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1500/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:30:28  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 2.1681  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.1681\n",
      "03/07 03:13:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1600/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:30:11  time: 0.1636  data_time: 0.0019  memory: 10434  loss: 2.3835  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.3835\n",
      "03/07 03:14:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1700/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:29:55  time: 0.1640  data_time: 0.0020  memory: 10434  loss: 2.0799  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0799\n",
      "03/07 03:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:14:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1800/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:29:38  time: 0.1628  data_time: 0.0018  memory: 10434  loss: 2.2809  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.2809\n",
      "03/07 03:14:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1900/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:29:21  time: 0.1638  data_time: 0.0020  memory: 10434  loss: 1.9684  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9684\n",
      "03/07 03:14:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2000/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:29:05  time: 0.1662  data_time: 0.0020  memory: 10434  loss: 1.9355  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9355\n",
      "03/07 03:15:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2100/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:28:49  time: 0.1639  data_time: 0.0019  memory: 10434  loss: 2.1733  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1733\n",
      "03/07 03:15:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2200/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:28:32  time: 0.1645  data_time: 0.0020  memory: 10434  loss: 2.0230  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0230\n",
      "03/07 03:15:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2300/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:28:16  time: 0.1666  data_time: 0.0020  memory: 10434  loss: 2.1221  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1221\n",
      "03/07 03:16:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2400/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:28:00  time: 0.1645  data_time: 0.0020  memory: 10434  loss: 2.2810  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.2810\n",
      "03/07 03:16:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2500/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:27:43  time: 0.1641  data_time: 0.0020  memory: 10434  loss: 1.6564  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6564\n",
      "03/07 03:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2600/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:27:27  time: 0.1637  data_time: 0.0019  memory: 10434  loss: 1.8313  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8313\n",
      "03/07 03:16:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2700/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:27:10  time: 0.1637  data_time: 0.0019  memory: 10434  loss: 1.9693  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9693\n",
      "03/07 03:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:17:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2800/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:26:54  time: 0.1649  data_time: 0.0019  memory: 10434  loss: 1.9673  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9673\n",
      "03/07 03:17:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2900/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:26:37  time: 0.1636  data_time: 0.0019  memory: 10434  loss: 2.2070  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2070\n",
      "03/07 03:17:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3000/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:26:21  time: 0.1639  data_time: 0.0019  memory: 10434  loss: 2.3153  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.3153\n",
      "03/07 03:17:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3100/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:26:04  time: 0.1630  data_time: 0.0019  memory: 10434  loss: 1.9594  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9594\n",
      "03/07 03:18:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3200/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:25:48  time: 0.1637  data_time: 0.0021  memory: 10434  loss: 1.7786  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7786\n",
      "03/07 03:18:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3300/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:25:31  time: 0.1629  data_time: 0.0021  memory: 10434  loss: 2.0461  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0461\n",
      "03/07 03:18:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3400/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:25:15  time: 0.1635  data_time: 0.0020  memory: 10434  loss: 2.0314  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0314\n",
      "03/07 03:19:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3500/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:24:58  time: 0.1649  data_time: 0.0019  memory: 10434  loss: 2.0310  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.0310\n",
      "03/07 03:19:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3600/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:24:42  time: 0.1642  data_time: 0.0022  memory: 10434  loss: 1.8975  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8975\n",
      "03/07 03:19:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3700/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:24:25  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 2.0150  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0150\n",
      "03/07 03:19:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:19:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3800/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:24:09  time: 0.1634  data_time: 0.0019  memory: 10434  loss: 1.9315  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.9315\n",
      "03/07 03:20:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3900/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:23:52  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 1.9891  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9891\n",
      "03/07 03:20:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4000/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:23:36  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 2.4087  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.4087\n",
      "03/07 03:20:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4100/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:23:19  time: 0.1631  data_time: 0.0021  memory: 10434  loss: 2.3070  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3070\n",
      "03/07 03:20:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4200/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:23:03  time: 0.1635  data_time: 0.0021  memory: 10434  loss: 2.1505  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1505\n",
      "03/07 03:21:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4300/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:22:47  time: 0.1642  data_time: 0.0021  memory: 10434  loss: 2.2464  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2464\n",
      "03/07 03:21:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4400/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:22:30  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 1.8566  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.8566\n",
      "03/07 03:21:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4500/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:22:14  time: 0.1644  data_time: 0.0019  memory: 10434  loss: 2.0494  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.0494\n",
      "03/07 03:22:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4600/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:21:57  time: 0.1642  data_time: 0.0021  memory: 10434  loss: 2.3169  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3169\n",
      "03/07 03:22:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4700/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:21:41  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 1.4518  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4518\n",
      "03/07 03:22:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:22:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4800/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:21:24  time: 0.1659  data_time: 0.0020  memory: 10434  loss: 1.9363  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9363\n",
      "03/07 03:22:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4900/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:21:08  time: 0.1630  data_time: 0.0019  memory: 10434  loss: 2.2060  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2060\n",
      "03/07 03:23:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][5000/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:20:51  time: 0.1630  data_time: 0.0019  memory: 10434  loss: 2.0118  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0118\n",
      "03/07 03:23:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][5100/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:20:35  time: 0.1662  data_time: 0.0020  memory: 10434  loss: 1.9522  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.9522\n",
      "03/07 03:23:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][5200/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:20:19  time: 0.1652  data_time: 0.0019  memory: 10434  loss: 2.1591  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1591\n",
      "03/07 03:23:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:23:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][5225/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:20:15  time: 0.1614  data_time: 0.0018  memory: 10434  loss: 2.3203  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.3203\n",
      "03/07 03:23:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][100/647]    eta: 0:00:17  time: 0.0312  data_time: 0.0008  memory: 861  \n",
      "03/07 03:23:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][200/647]    eta: 0:00:14  time: 0.0311  data_time: 0.0009  memory: 861  \n",
      "03/07 03:23:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][300/647]    eta: 0:00:10  time: 0.0312  data_time: 0.0009  memory: 861  \n",
      "03/07 03:23:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][400/647]    eta: 0:00:07  time: 0.0311  data_time: 0.0008  memory: 861  \n",
      "03/07 03:24:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][500/647]    eta: 0:00:04  time: 0.0313  data_time: 0.0010  memory: 861  \n",
      "03/07 03:24:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][600/647]    eta: 0:00:01  time: 0.0312  data_time: 0.0009  memory: 861  \n",
      "[0]\n",
      "[1]\n",
      "[11]\n",
      "[11]\n",
      "[5]\n",
      "[11]\n",
      "[5]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[5]\n",
      "[12]\n",
      "[26]\n",
      "[11]\n",
      "[11]\n",
      "[21]\n",
      "[20]\n",
      "[20]\n",
      "[11]\n",
      "[5]\n",
      "[5]\n",
      "[11]\n",
      "[5]\n",
      "[11]\n",
      "[5]\n",
      "[21]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[5]\n",
      "[1]\n",
      "[12]\n",
      "[11]\n",
      "[17]\n",
      "[29]\n",
      "[20]\n",
      "[25]\n",
      "[11]\n",
      "[12]\n",
      "[5]\n",
      "[9]\n",
      "[5]\n",
      "[11]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[14]\n",
      "[11]\n",
      "[18]\n",
      "[18]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[5]\n",
      "[14]\n",
      "[14]\n",
      "[18]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[11]\n",
      "[5]\n",
      "[5]\n",
      "[0]\n",
      "[5]\n",
      "[26]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[26]\n",
      "[5]\n",
      "[5]\n",
      "[26]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[26]\n",
      "[16]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[26]\n",
      "[21]\n",
      "[5]\n",
      "[26]\n",
      "[4]\n",
      "[16]\n",
      "[11]\n",
      "[20]\n",
      "[12]\n",
      "[23]\n",
      "[26]\n",
      "[26]\n",
      "[11]\n",
      "[11]\n",
      "[23]\n",
      "[23]\n",
      "[26]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[25]\n",
      "[25]\n",
      "[25]\n",
      "[43]\n",
      "[67]\n",
      "[28]\n",
      "[29]\n",
      "[28]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[28]\n",
      "[43]\n",
      "[29]\n",
      "[68]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[29]\n",
      "[27]\n",
      "[29]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[28]\n",
      "[28]\n",
      "[41]\n",
      "[43]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[43]\n",
      "[43]\n",
      "[34]\n",
      "[39]\n",
      "[41]\n",
      "[43]\n",
      "[19]\n",
      "[19]\n",
      "[66]\n",
      "[36]\n",
      "[41]\n",
      "[43]\n",
      "[41]\n",
      "[43]\n",
      "[41]\n",
      "[43]\n",
      "[36]\n",
      "[36]\n",
      "[41]\n",
      "[41]\n",
      "[42]\n",
      "[38]\n",
      "[37]\n",
      "[35]\n",
      "[38]\n",
      "[39]\n",
      "[36]\n",
      "[42]\n",
      "[19]\n",
      "[43]\n",
      "[42]\n",
      "[43]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[16]\n",
      "[34]\n",
      "[16]\n",
      "[15]\n",
      "[43]\n",
      "[15]\n",
      "[16]\n",
      "[57]\n",
      "[52]\n",
      "[52]\n",
      "[55]\n",
      "[52]\n",
      "[47]\n",
      "[47]\n",
      "[57]\n",
      "[0]\n",
      "[55]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[47]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[52]\n",
      "[48]\n",
      "[54]\n",
      "[48]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[52]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[53]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[56]\n",
      "[56]\n",
      "[48]\n",
      "[53]\n",
      "[52]\n",
      "[53]\n",
      "[25]\n",
      "[51]\n",
      "[55]\n",
      "[53]\n",
      "[10]\n",
      "[10]\n",
      "[55]\n",
      "[53]\n",
      "[53]\n",
      "[44]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[47]\n",
      "[53]\n",
      "[9]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[25]\n",
      "[52]\n",
      "[12]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[53]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[53]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[52]\n",
      "[56]\n",
      "[30]\n",
      "[53]\n",
      "[53]\n",
      "[30]\n",
      "[67]\n",
      "[29]\n",
      "[63]\n",
      "[67]\n",
      "[67]\n",
      "[28]\n",
      "[29]\n",
      "[53]\n",
      "[47]\n",
      "[69]\n",
      "[28]\n",
      "[28]\n",
      "[30]\n",
      "[69]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[28]\n",
      "[65]\n",
      "[30]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[69]\n",
      "[30]\n",
      "[69]\n",
      "[69]\n",
      "[28]\n",
      "[29]\n",
      "[52]\n",
      "[48]\n",
      "[48]\n",
      "[30]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[53]\n",
      "[47]\n",
      "[68]\n",
      "[69]\n",
      "[67]\n",
      "[68]\n",
      "[68]\n",
      "[68]\n",
      "[69]\n",
      "[28]\n",
      "[98]\n",
      "[53]\n",
      "[109]\n",
      "[116]\n",
      "[121]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[121]\n",
      "[109]\n",
      "[53]\n",
      "[44]\n",
      "[121]\n",
      "[44]\n",
      "[44]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[97]\n",
      "[7]\n",
      "[97]\n",
      "[53]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[53]\n",
      "[97]\n",
      "[97]\n",
      "[7]\n",
      "[53]\n",
      "[98]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[97]\n",
      "[72]\n",
      "[81]\n",
      "[86]\n",
      "[72]\n",
      "[74]\n",
      "[77]\n",
      "[77]\n",
      "[78]\n",
      "[74]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[77]\n",
      "[86]\n",
      "[78]\n",
      "[72]\n",
      "[74]\n",
      "[86]\n",
      "[73]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[73]\n",
      "[76]\n",
      "[76]\n",
      "[77]\n",
      "[73]\n",
      "[76]\n",
      "[90]\n",
      "[72]\n",
      "[74]\n",
      "[86]\n",
      "[72]\n",
      "[76]\n",
      "[76]\n",
      "[78]\n",
      "[78]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[83]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[86]\n",
      "[86]\n",
      "[90]\n",
      "[72]\n",
      "[76]\n",
      "[73]\n",
      "[76]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[83]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[73]\n",
      "[88]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[73]\n",
      "[83]\n",
      "[76]\n",
      "[73]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[56]\n",
      "[30]\n",
      "[112]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[108]\n",
      "[91]\n",
      "[81]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[108]\n",
      "[112]\n",
      "[91]\n",
      "[112]\n",
      "[30]\n",
      "[30]\n",
      "[97]\n",
      "[110]\n",
      "[97]\n",
      "[43]\n",
      "[34]\n",
      "[43]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[92]\n",
      "[101]\n",
      "[103]\n",
      "[101]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[101]\n",
      "[101]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[100]\n",
      "[103]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[103]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[97]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[34]\n",
      "[95]\n",
      "[97]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[97]\n",
      "[97]\n",
      "[100]\n",
      "[97]\n",
      "[97]\n",
      "[100]\n",
      "[97]\n",
      "[105]\n",
      "[105]\n",
      "[106]\n",
      "[106]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[112]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[112]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[106]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[100]\n",
      "03/07 03:24:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][647/647]    acc/top1: 0.1499  acc/top5: 0.4822  acc/mean1: 0.2241  data_time: 0.0009  time: 0.0312\n",
      "03/07 03:24:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_10.pth is removed\n",
      "03/07 03:24:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.1499 acc/top1 at 11 epoch is saved to best_acc_top1_epoch_11.pth.\n",
      "03/07 03:24:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 100/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:19:58  time: 0.1635  data_time: 0.0020  memory: 10434  loss: 2.0381  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0381\n",
      "03/07 03:24:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 200/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:19:42  time: 0.1645  data_time: 0.0020  memory: 10434  loss: 2.2187  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.2187\n",
      "03/07 03:24:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 300/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:19:25  time: 0.1646  data_time: 0.0020  memory: 10434  loss: 2.3290  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.3290\n",
      "03/07 03:25:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 400/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:19:09  time: 0.1650  data_time: 0.0019  memory: 10434  loss: 1.6569  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6569\n",
      "03/07 03:25:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 500/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:18:52  time: 0.1642  data_time: 0.0021  memory: 10434  loss: 2.3285  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3285\n",
      "03/07 03:25:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 600/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:18:36  time: 0.1628  data_time: 0.0020  memory: 10434  loss: 2.1049  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1049\n",
      "03/07 03:26:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 700/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:18:19  time: 0.1643  data_time: 0.0020  memory: 10434  loss: 2.1753  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1753\n",
      "03/07 03:26:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 800/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:18:03  time: 0.1726  data_time: 0.0027  memory: 10434  loss: 1.8373  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8373\n",
      "03/07 03:26:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 900/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:17:53  time: 0.1661  data_time: 0.0020  memory: 10434  loss: 2.0253  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0253\n",
      "03/07 03:26:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1000/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:17:37  time: 0.1638  data_time: 0.0020  memory: 10434  loss: 1.8009  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.8009\n",
      "03/07 03:27:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1100/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:17:20  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 2.2410  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.2410\n",
      "03/07 03:27:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1200/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:17:04  time: 0.1643  data_time: 0.0019  memory: 10434  loss: 1.7950  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7950\n",
      "03/07 03:27:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1300/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:16:47  time: 0.1645  data_time: 0.0019  memory: 10434  loss: 2.0326  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0326\n",
      "03/07 03:28:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1400/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:16:31  time: 0.1632  data_time: 0.0019  memory: 10434  loss: 2.0037  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0037\n",
      "03/07 03:28:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1500/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:16:14  time: 0.1636  data_time: 0.0019  memory: 10434  loss: 2.0343  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0343\n",
      "03/07 03:28:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:28:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1600/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:15:58  time: 0.1650  data_time: 0.0018  memory: 10434  loss: 1.9462  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9462\n",
      "03/07 03:28:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1700/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:15:41  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 1.9804  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9804\n",
      "03/07 03:29:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1800/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:15:25  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 2.1187  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1187\n",
      "03/07 03:29:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1900/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:15:08  time: 0.1631  data_time: 0.0020  memory: 10434  loss: 2.1876  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1876\n",
      "03/07 03:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2000/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:14:52  time: 0.1641  data_time: 0.0020  memory: 10434  loss: 1.6382  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6382\n",
      "03/07 03:29:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2100/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:14:35  time: 0.1638  data_time: 0.0018  memory: 10434  loss: 1.9390  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9390\n",
      "03/07 03:30:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2200/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:14:19  time: 0.1642  data_time: 0.0017  memory: 10434  loss: 1.5503  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5503\n",
      "03/07 03:30:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2300/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:14:02  time: 0.1631  data_time: 0.0020  memory: 10434  loss: 1.7554  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7554\n",
      "03/07 03:30:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2400/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:13:46  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 1.4743  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4743\n",
      "03/07 03:31:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2500/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:13:30  time: 0.1650  data_time: 0.0019  memory: 10434  loss: 1.7154  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7154\n",
      "03/07 03:31:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:31:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2600/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:13:13  time: 0.1634  data_time: 0.0019  memory: 10434  loss: 1.3351  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3351\n",
      "03/07 03:31:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2700/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:12:57  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 2.3273  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3273\n",
      "03/07 03:31:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2800/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:12:40  time: 0.1682  data_time: 0.0019  memory: 10434  loss: 2.2457  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2457\n",
      "03/07 03:32:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2900/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:12:24  time: 0.1624  data_time: 0.0017  memory: 10434  loss: 2.2060  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.2060\n",
      "03/07 03:32:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3000/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:12:07  time: 0.1626  data_time: 0.0017  memory: 10434  loss: 1.7957  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7957\n",
      "03/07 03:32:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3100/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:11:51  time: 0.1648  data_time: 0.0019  memory: 10434  loss: 1.3972  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3972\n",
      "03/07 03:32:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3200/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:11:34  time: 0.1664  data_time: 0.0018  memory: 10434  loss: 1.8468  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8468\n",
      "03/07 03:33:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3300/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:11:18  time: 0.1629  data_time: 0.0016  memory: 10434  loss: 2.2304  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2304\n",
      "03/07 03:33:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3400/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:11:01  time: 0.1632  data_time: 0.0015  memory: 10434  loss: 1.8949  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8949\n",
      "03/07 03:33:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3500/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:10:45  time: 0.1636  data_time: 0.0017  memory: 10434  loss: 1.8881  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8881\n",
      "03/07 03:33:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:34:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3600/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:10:28  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 2.0798  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0798\n",
      "03/07 03:34:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3700/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:10:12  time: 0.1622  data_time: 0.0018  memory: 10434  loss: 2.2106  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2106\n",
      "03/07 03:34:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3800/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:09:55  time: 0.1625  data_time: 0.0017  memory: 10434  loss: 1.5693  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5693\n",
      "03/07 03:34:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3900/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:09:39  time: 0.1639  data_time: 0.0016  memory: 10434  loss: 1.9608  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9608\n",
      "03/07 03:35:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4000/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:09:22  time: 0.1626  data_time: 0.0016  memory: 10434  loss: 2.1484  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1484\n",
      "03/07 03:35:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4100/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:09:06  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 2.4463  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.4463\n",
      "03/07 03:35:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4200/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:08:49  time: 0.1629  data_time: 0.0018  memory: 10434  loss: 2.1566  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1566\n",
      "03/07 03:35:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4300/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:08:33  time: 0.1635  data_time: 0.0016  memory: 10434  loss: 2.1496  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1496\n",
      "03/07 03:36:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4400/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:08:16  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 1.6897  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.6897\n",
      "03/07 03:36:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4500/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:07:59  time: 0.1632  data_time: 0.0017  memory: 10434  loss: 1.9643  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9643\n",
      "03/07 03:36:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:36:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4600/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:07:43  time: 0.1643  data_time: 0.0018  memory: 10434  loss: 1.9310  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9310\n",
      "03/07 03:37:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4700/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:07:27  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 1.5809  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.5809\n",
      "03/07 03:37:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4800/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:07:10  time: 0.1626  data_time: 0.0019  memory: 10434  loss: 2.1229  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1229\n",
      "03/07 03:37:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4900/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:06:54  time: 0.1630  data_time: 0.0020  memory: 10434  loss: 2.0683  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0683\n",
      "03/07 03:37:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][5000/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:06:37  time: 0.1639  data_time: 0.0018  memory: 10434  loss: 1.7601  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7601\n",
      "03/07 03:38:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][5100/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:06:20  time: 0.1629  data_time: 0.0018  memory: 10434  loss: 2.0420  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.0420\n",
      "03/07 03:38:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][5200/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:06:04  time: 0.1634  data_time: 0.0016  memory: 10434  loss: 2.3729  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.3729\n",
      "03/07 03:38:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:38:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][5225/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 3:06:00  time: 0.1593  data_time: 0.0019  memory: 10434  loss: 1.8732  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8732\n",
      "03/07 03:38:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 12 epochs\n",
      "03/07 03:38:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][100/647]    eta: 0:00:17  time: 0.0310  data_time: 0.0009  memory: 861  \n",
      "03/07 03:38:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][200/647]    eta: 0:00:13  time: 0.0310  data_time: 0.0006  memory: 861  \n",
      "03/07 03:38:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][300/647]    eta: 0:00:10  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "03/07 03:38:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][400/647]    eta: 0:00:07  time: 0.0311  data_time: 0.0009  memory: 861  \n",
      "03/07 03:38:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][500/647]    eta: 0:00:04  time: 0.0312  data_time: 0.0009  memory: 861  \n",
      "03/07 03:38:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][600/647]    eta: 0:00:01  time: 0.0309  data_time: 0.0007  memory: 861  \n",
      "[11]\n",
      "[1]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[11]\n",
      "[13]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[5]\n",
      "[13]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[21]\n",
      "[17]\n",
      "[18]\n",
      "[11]\n",
      "[11]\n",
      "[5]\n",
      "[11]\n",
      "[13]\n",
      "[11]\n",
      "[0]\n",
      "[13]\n",
      "[5]\n",
      "[13]\n",
      "[5]\n",
      "[13]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[5]\n",
      "[1]\n",
      "[13]\n",
      "[11]\n",
      "[17]\n",
      "[13]\n",
      "[17]\n",
      "[18]\n",
      "[11]\n",
      "[21]\n",
      "[21]\n",
      "[9]\n",
      "[4]\n",
      "[18]\n",
      "[14]\n",
      "[4]\n",
      "[5]\n",
      "[14]\n",
      "[11]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[11]\n",
      "[5]\n",
      "[14]\n",
      "[13]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[5]\n",
      "[5]\n",
      "[0]\n",
      "[21]\n",
      "[11]\n",
      "[5]\n",
      "[21]\n",
      "[21]\n",
      "[2]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[22]\n",
      "[23]\n",
      "[25]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[25]\n",
      "[21]\n",
      "[5]\n",
      "[11]\n",
      "[4]\n",
      "[2]\n",
      "[11]\n",
      "[20]\n",
      "[5]\n",
      "[6]\n",
      "[25]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[25]\n",
      "[23]\n",
      "[11]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[25]\n",
      "[25]\n",
      "[25]\n",
      "[25]\n",
      "[43]\n",
      "[67]\n",
      "[34]\n",
      "[106]\n",
      "[30]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[7]\n",
      "[43]\n",
      "[105]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[93]\n",
      "[13]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[30]\n",
      "[30]\n",
      "[41]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[30]\n",
      "[34]\n",
      "[42]\n",
      "[19]\n",
      "[19]\n",
      "[30]\n",
      "[19]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[34]\n",
      "[34]\n",
      "[30]\n",
      "[41]\n",
      "[35]\n",
      "[38]\n",
      "[35]\n",
      "[35]\n",
      "[38]\n",
      "[30]\n",
      "[19]\n",
      "[42]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[94]\n",
      "[51]\n",
      "[57]\n",
      "[122]\n",
      "[54]\n",
      "[46]\n",
      "[57]\n",
      "[87]\n",
      "[0]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[45]\n",
      "[58]\n",
      "[51]\n",
      "[51]\n",
      "[51]\n",
      "[56]\n",
      "[57]\n",
      "[56]\n",
      "[59]\n",
      "[48]\n",
      "[58]\n",
      "[48]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[54]\n",
      "[54]\n",
      "[15]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[48]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[57]\n",
      "[57]\n",
      "[58]\n",
      "[58]\n",
      "[52]\n",
      "[10]\n",
      "[15]\n",
      "[56]\n",
      "[55]\n",
      "[58]\n",
      "[9]\n",
      "[15]\n",
      "[55]\n",
      "[52]\n",
      "[9]\n",
      "[44]\n",
      "[44]\n",
      "[9]\n",
      "[9]\n",
      "[58]\n",
      "[56]\n",
      "[9]\n",
      "[9]\n",
      "[56]\n",
      "[56]\n",
      "[25]\n",
      "[52]\n",
      "[9]\n",
      "[8]\n",
      "[44]\n",
      "[56]\n",
      "[44]\n",
      "[44]\n",
      "[48]\n",
      "[52]\n",
      "[44]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[56]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[48]\n",
      "[58]\n",
      "[44]\n",
      "[8]\n",
      "[8]\n",
      "[48]\n",
      "[8]\n",
      "[44]\n",
      "[8]\n",
      "[56]\n",
      "[30]\n",
      "[31]\n",
      "[53]\n",
      "[30]\n",
      "[67]\n",
      "[29]\n",
      "[63]\n",
      "[63]\n",
      "[63]\n",
      "[28]\n",
      "[29]\n",
      "[7]\n",
      "[53]\n",
      "[69]\n",
      "[27]\n",
      "[28]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[68]\n",
      "[69]\n",
      "[63]\n",
      "[68]\n",
      "[68]\n",
      "[69]\n",
      "[53]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[29]\n",
      "[63]\n",
      "[69]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[68]\n",
      "[69]\n",
      "[67]\n",
      "[68]\n",
      "[68]\n",
      "[68]\n",
      "[69]\n",
      "[28]\n",
      "[98]\n",
      "[48]\n",
      "[110]\n",
      "[97]\n",
      "[122]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[48]\n",
      "[121]\n",
      "[44]\n",
      "[44]\n",
      "[48]\n",
      "[121]\n",
      "[121]\n",
      "[49]\n",
      "[49]\n",
      "[121]\n",
      "[121]\n",
      "[49]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[48]\n",
      "[99]\n",
      "[52]\n",
      "[99]\n",
      "[52]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[99]\n",
      "[99]\n",
      "[97]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[98]\n",
      "[97]\n",
      "[99]\n",
      "[97]\n",
      "[52]\n",
      "[98]\n",
      "[98]\n",
      "[99]\n",
      "[71]\n",
      "[97]\n",
      "[97]\n",
      "[89]\n",
      "[77]\n",
      "[86]\n",
      "[89]\n",
      "[80]\n",
      "[77]\n",
      "[77]\n",
      "[90]\n",
      "[89]\n",
      "[78]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[78]\n",
      "[86]\n",
      "[90]\n",
      "[80]\n",
      "[60]\n",
      "[86]\n",
      "[73]\n",
      "[80]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[80]\n",
      "[80]\n",
      "[88]\n",
      "[90]\n",
      "[73]\n",
      "[90]\n",
      "[90]\n",
      "[72]\n",
      "[60]\n",
      "[83]\n",
      "[88]\n",
      "[80]\n",
      "[80]\n",
      "[90]\n",
      "[90]\n",
      "[82]\n",
      "[82]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[90]\n",
      "[83]\n",
      "[83]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[73]\n",
      "[72]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[73]\n",
      "[87]\n",
      "[74]\n",
      "[74]\n",
      "[77]\n",
      "[73]\n",
      "[83]\n",
      "[73]\n",
      "[73]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[105]\n",
      "[107]\n",
      "[112]\n",
      "[106]\n",
      "[107]\n",
      "[30]\n",
      "[112]\n",
      "[30]\n",
      "[81]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[112]\n",
      "[30]\n",
      "[112]\n",
      "[30]\n",
      "[31]\n",
      "[71]\n",
      "[49]\n",
      "[49]\n",
      "[71]\n",
      "[49]\n",
      "[19]\n",
      "[71]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[101]\n",
      "[40]\n",
      "[64]\n",
      "[102]\n",
      "[102]\n",
      "[92]\n",
      "[92]\n",
      "[103]\n",
      "[92]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[92]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[92]\n",
      "[103]\n",
      "[102]\n",
      "[102]\n",
      "[40]\n",
      "[92]\n",
      "[103]\n",
      "[103]\n",
      "[101]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[92]\n",
      "[2]\n",
      "[2]\n",
      "[92]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[92]\n",
      "[92]\n",
      "[104]\n",
      "[92]\n",
      "[92]\n",
      "[2]\n",
      "[92]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[104]\n",
      "[92]\n",
      "[97]\n",
      "[35]\n",
      "[35]\n",
      "[35]\n",
      "[34]\n",
      "[35]\n",
      "[97]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[97]\n",
      "[97]\n",
      "[100]\n",
      "[97]\n",
      "[97]\n",
      "[100]\n",
      "[97]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[71]\n",
      "[111]\n",
      "[112]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[107]\n",
      "[109]\n",
      "[107]\n",
      "[107]\n",
      "[107]\n",
      "03/07 03:38:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][647/647]    acc/top1: 0.1499  acc/top5: 0.4760  acc/mean1: 0.2070  data_time: 0.0008  time: 0.0312\n",
      "03/07 03:39:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 100/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:05:43  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 2.2846  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2846\n",
      "03/07 03:39:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 200/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:05:27  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 1.7337  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7337\n",
      "03/07 03:39:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:39:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 300/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:05:10  time: 0.1641  data_time: 0.0017  memory: 10434  loss: 1.6713  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6713\n",
      "03/07 03:39:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 400/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:04:54  time: 0.1638  data_time: 0.0016  memory: 10434  loss: 1.6588  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6588\n",
      "03/07 03:40:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 500/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:04:37  time: 0.1628  data_time: 0.0017  memory: 10434  loss: 1.5746  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5746\n",
      "03/07 03:40:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 600/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:04:21  time: 0.1640  data_time: 0.0018  memory: 10434  loss: 1.7322  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7322\n",
      "03/07 03:40:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 700/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:04:04  time: 0.1639  data_time: 0.0018  memory: 10434  loss: 2.1728  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1728\n",
      "03/07 03:40:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 800/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:03:48  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 2.0760  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0760\n",
      "03/07 03:41:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 900/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:03:31  time: 0.1642  data_time: 0.0018  memory: 10434  loss: 1.8143  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8143\n",
      "03/07 03:41:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1000/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:03:15  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.5139  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5139\n",
      "03/07 03:41:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1100/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:02:58  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 1.9317  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.9317\n",
      "03/07 03:42:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1200/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:02:42  time: 0.1635  data_time: 0.0016  memory: 10434  loss: 1.7141  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7141\n",
      "03/07 03:42:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:42:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1300/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:02:25  time: 0.1636  data_time: 0.0019  memory: 10434  loss: 2.0300  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.0300\n",
      "03/07 03:42:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1400/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:02:09  time: 0.1640  data_time: 0.0017  memory: 10434  loss: 1.5112  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5112\n",
      "03/07 03:42:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1500/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:01:53  time: 0.1647  data_time: 0.0019  memory: 10434  loss: 1.7220  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7220\n",
      "03/07 03:43:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1600/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:01:36  time: 0.1633  data_time: 0.0016  memory: 10434  loss: 2.1504  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1504\n",
      "03/07 03:43:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1700/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:01:20  time: 0.1632  data_time: 0.0019  memory: 10434  loss: 1.6045  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6045\n",
      "03/07 03:43:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1800/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:01:03  time: 0.1638  data_time: 0.0017  memory: 10434  loss: 1.6347  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6347\n",
      "03/07 03:43:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1900/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:00:47  time: 0.1628  data_time: 0.0019  memory: 10434  loss: 2.0551  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0551\n",
      "03/07 03:44:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2000/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:00:30  time: 0.1628  data_time: 0.0019  memory: 10434  loss: 1.8975  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8975\n",
      "03/07 03:44:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2100/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 3:00:14  time: 0.1643  data_time: 0.0017  memory: 10434  loss: 1.8698  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8698\n",
      "03/07 03:44:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2200/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:59:57  time: 0.1652  data_time: 0.0018  memory: 10434  loss: 1.9212  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9212\n",
      "03/07 03:45:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:45:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2300/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:59:41  time: 0.1625  data_time: 0.0016  memory: 10434  loss: 2.1513  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1513\n",
      "03/07 03:45:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2400/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:59:24  time: 0.1629  data_time: 0.0019  memory: 10434  loss: 1.8993  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.8993\n",
      "03/07 03:45:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2500/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:59:08  time: 0.1632  data_time: 0.0017  memory: 10434  loss: 1.8764  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8764\n",
      "03/07 03:45:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2600/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:58:51  time: 0.1635  data_time: 0.0020  memory: 10434  loss: 2.0476  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.0476\n",
      "03/07 03:46:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2700/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:58:35  time: 0.1629  data_time: 0.0017  memory: 10434  loss: 1.9618  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9618\n",
      "03/07 03:46:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2800/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:58:18  time: 0.1630  data_time: 0.0019  memory: 10434  loss: 1.9017  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9017\n",
      "03/07 03:46:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2900/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:58:02  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 2.0097  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0097\n",
      "03/07 03:47:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3000/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:57:45  time: 0.1645  data_time: 0.0015  memory: 10434  loss: 2.1438  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1438\n",
      "03/07 03:47:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3100/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:57:29  time: 0.1640  data_time: 0.0017  memory: 10434  loss: 1.6196  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6196\n",
      "03/07 03:47:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3200/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:57:13  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.6528  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.6528\n",
      "03/07 03:47:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:47:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3300/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:56:56  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 1.8399  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8399\n",
      "03/07 03:48:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3400/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:56:40  time: 0.1633  data_time: 0.0018  memory: 10434  loss: 1.9484  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9484\n",
      "03/07 03:48:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3500/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:56:23  time: 0.1630  data_time: 0.0019  memory: 10434  loss: 2.1392  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1392\n",
      "03/07 03:48:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3600/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:56:07  time: 0.1632  data_time: 0.0017  memory: 10434  loss: 1.9550  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9550\n",
      "03/07 03:48:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3700/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:55:50  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 1.7176  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7176\n",
      "03/07 03:49:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3800/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:55:34  time: 0.1642  data_time: 0.0016  memory: 10434  loss: 1.8743  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8743\n",
      "03/07 03:49:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3900/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:55:17  time: 0.1648  data_time: 0.0018  memory: 10434  loss: 1.4583  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4583\n",
      "03/07 03:49:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4000/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:55:01  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 2.1527  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1527\n",
      "03/07 03:50:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4100/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:54:44  time: 0.1629  data_time: 0.0019  memory: 10434  loss: 2.0045  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0045\n",
      "03/07 03:50:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4200/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:54:28  time: 0.1633  data_time: 0.0017  memory: 10434  loss: 2.0282  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0282\n",
      "03/07 03:50:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:50:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4300/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:54:11  time: 0.1665  data_time: 0.0018  memory: 10434  loss: 2.0196  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0196\n",
      "03/07 03:50:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4400/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:53:55  time: 0.1647  data_time: 0.0017  memory: 10434  loss: 1.9948  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9948\n",
      "03/07 03:51:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4500/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:53:39  time: 0.1637  data_time: 0.0017  memory: 10434  loss: 1.7082  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7082\n",
      "03/07 03:51:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4600/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:53:22  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 1.8461  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8461\n",
      "03/07 03:51:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4700/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:53:06  time: 0.1654  data_time: 0.0017  memory: 10434  loss: 2.2029  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.2029\n",
      "03/07 03:51:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4800/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:52:49  time: 0.1627  data_time: 0.0019  memory: 10434  loss: 1.9065  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9065\n",
      "03/07 03:52:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4900/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:52:33  time: 0.1631  data_time: 0.0017  memory: 10434  loss: 1.6451  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6451\n",
      "03/07 03:52:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][5000/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:52:16  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 2.0142  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0142\n",
      "03/07 03:52:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][5100/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:52:00  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 1.6460  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6460\n",
      "03/07 03:53:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][5200/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:51:43  time: 0.1635  data_time: 0.0016  memory: 10434  loss: 1.8591  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8591\n",
      "03/07 03:53:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:53:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][5225/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:51:39  time: 0.1606  data_time: 0.0019  memory: 10434  loss: 2.1529  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.1529\n",
      "03/07 03:53:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][100/647]    eta: 0:00:17  time: 0.0312  data_time: 0.0008  memory: 861  \n",
      "03/07 03:53:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][200/647]    eta: 0:00:13  time: 0.0311  data_time: 0.0007  memory: 861  \n",
      "03/07 03:53:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][300/647]    eta: 0:00:10  time: 0.0312  data_time: 0.0008  memory: 861  \n",
      "03/07 03:53:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][400/647]    eta: 0:00:07  time: 0.0310  data_time: 0.0009  memory: 861  \n",
      "03/07 03:53:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][500/647]    eta: 0:00:04  time: 0.0312  data_time: 0.0009  memory: 861  \n",
      "03/07 03:53:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][600/647]    eta: 0:00:01  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "[14]\n",
      "[1]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[5]\n",
      "[8]\n",
      "[14]\n",
      "[11]\n",
      "[5]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[21]\n",
      "[17]\n",
      "[17]\n",
      "[11]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[6]\n",
      "[5]\n",
      "[5]\n",
      "[21]\n",
      "[8]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[5]\n",
      "[1]\n",
      "[23]\n",
      "[14]\n",
      "[17]\n",
      "[106]\n",
      "[17]\n",
      "[16]\n",
      "[14]\n",
      "[5]\n",
      "[14]\n",
      "[0]\n",
      "[5]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[14]\n",
      "[16]\n",
      "[18]\n",
      "[18]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[5]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[5]\n",
      "[5]\n",
      "[0]\n",
      "[21]\n",
      "[11]\n",
      "[0]\n",
      "[21]\n",
      "[21]\n",
      "[23]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[23]\n",
      "[22]\n",
      "[23]\n",
      "[26]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[16]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[4]\n",
      "[11]\n",
      "[23]\n",
      "[14]\n",
      "[5]\n",
      "[23]\n",
      "[16]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[23]\n",
      "[23]\n",
      "[14]\n",
      "[24]\n",
      "[24]\n",
      "[16]\n",
      "[24]\n",
      "[26]\n",
      "[16]\n",
      "[16]\n",
      "[26]\n",
      "[43]\n",
      "[31]\n",
      "[30]\n",
      "[106]\n",
      "[30]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[44]\n",
      "[8]\n",
      "[55]\n",
      "[68]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[29]\n",
      "[27]\n",
      "[36]\n",
      "[42]\n",
      "[14]\n",
      "[42]\n",
      "[30]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[43]\n",
      "[42]\n",
      "[34]\n",
      "[30]\n",
      "[41]\n",
      "[43]\n",
      "[19]\n",
      "[19]\n",
      "[30]\n",
      "[36]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[36]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[38]\n",
      "[38]\n",
      "[41]\n",
      "[36]\n",
      "[115]\n",
      "[36]\n",
      "[106]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[14]\n",
      "[14]\n",
      "[34]\n",
      "[34]\n",
      "[15]\n",
      "[34]\n",
      "[15]\n",
      "[15]\n",
      "[34]\n",
      "[15]\n",
      "[34]\n",
      "[57]\n",
      "[51]\n",
      "[57]\n",
      "[55]\n",
      "[51]\n",
      "[47]\n",
      "[57]\n",
      "[55]\n",
      "[0]\n",
      "[55]\n",
      "[57]\n",
      "[54]\n",
      "[55]\n",
      "[57]\n",
      "[51]\n",
      "[51]\n",
      "[51]\n",
      "[55]\n",
      "[57]\n",
      "[56]\n",
      "[59]\n",
      "[53]\n",
      "[58]\n",
      "[53]\n",
      "[57]\n",
      "[54]\n",
      "[58]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[53]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[57]\n",
      "[57]\n",
      "[58]\n",
      "[10]\n",
      "[52]\n",
      "[10]\n",
      "[55]\n",
      "[51]\n",
      "[54]\n",
      "[53]\n",
      "[10]\n",
      "[54]\n",
      "[44]\n",
      "[54]\n",
      "[10]\n",
      "[44]\n",
      "[44]\n",
      "[10]\n",
      "[54]\n",
      "[47]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[23]\n",
      "[50]\n",
      "[44]\n",
      "[56]\n",
      "[44]\n",
      "[56]\n",
      "[9]\n",
      "[9]\n",
      "[51]\n",
      "[9]\n",
      "[59]\n",
      "[53]\n",
      "[56]\n",
      "[44]\n",
      "[44]\n",
      "[57]\n",
      "[57]\n",
      "[9]\n",
      "[9]\n",
      "[57]\n",
      "[9]\n",
      "[53]\n",
      "[50]\n",
      "[44]\n",
      "[44]\n",
      "[56]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[67]\n",
      "[29]\n",
      "[63]\n",
      "[63]\n",
      "[63]\n",
      "[28]\n",
      "[29]\n",
      "[51]\n",
      "[47]\n",
      "[69]\n",
      "[27]\n",
      "[28]\n",
      "[53]\n",
      "[69]\n",
      "[27]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[68]\n",
      "[69]\n",
      "[67]\n",
      "[40]\n",
      "[63]\n",
      "[65]\n",
      "[67]\n",
      "[47]\n",
      "[64]\n",
      "[47]\n",
      "[64]\n",
      "[47]\n",
      "[47]\n",
      "[68]\n",
      "[68]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[29]\n",
      "[63]\n",
      "[69]\n",
      "[67]\n",
      "[53]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[53]\n",
      "[50]\n",
      "[68]\n",
      "[40]\n",
      "[67]\n",
      "[68]\n",
      "[68]\n",
      "[67]\n",
      "[69]\n",
      "[28]\n",
      "[98]\n",
      "[53]\n",
      "[121]\n",
      "[116]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[53]\n",
      "[53]\n",
      "[44]\n",
      "[44]\n",
      "[53]\n",
      "[121]\n",
      "[121]\n",
      "[53]\n",
      "[53]\n",
      "[121]\n",
      "[53]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[53]\n",
      "[95]\n",
      "[53]\n",
      "[99]\n",
      "[53]\n",
      "[97]\n",
      "[97]\n",
      "[95]\n",
      "[95]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[97]\n",
      "[95]\n",
      "[97]\n",
      "[97]\n",
      "[95]\n",
      "[53]\n",
      "[97]\n",
      "[95]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[72]\n",
      "[80]\n",
      "[90]\n",
      "[72]\n",
      "[80]\n",
      "[77]\n",
      "[77]\n",
      "[78]\n",
      "[80]\n",
      "[74]\n",
      "[81]\n",
      "[7]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[80]\n",
      "[77]\n",
      "[86]\n",
      "[90]\n",
      "[80]\n",
      "[60]\n",
      "[73]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[76]\n",
      "[80]\n",
      "[73]\n",
      "[76]\n",
      "[90]\n",
      "[80]\n",
      "[60]\n",
      "[73]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[90]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[87]\n",
      "[72]\n",
      "[73]\n",
      "[73]\n",
      "[90]\n",
      "[72]\n",
      "[74]\n",
      "[73]\n",
      "[72]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[73]\n",
      "[72]\n",
      "[74]\n",
      "[74]\n",
      "[77]\n",
      "[76]\n",
      "[73]\n",
      "[77]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[83]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[81]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[71]\n",
      "[111]\n",
      "[49]\n",
      "[96]\n",
      "[71]\n",
      "[43]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[92]\n",
      "[92]\n",
      "[103]\n",
      "[101]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[100]\n",
      "[100]\n",
      "[103]\n",
      "[92]\n",
      "[103]\n",
      "[102]\n",
      "[102]\n",
      "[40]\n",
      "[101]\n",
      "[103]\n",
      "[103]\n",
      "[101]\n",
      "[100]\n",
      "[102]\n",
      "[100]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[92]\n",
      "[1]\n",
      "[96]\n",
      "[92]\n",
      "[79]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[92]\n",
      "[92]\n",
      "[104]\n",
      "[92]\n",
      "[92]\n",
      "[96]\n",
      "[92]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[111]\n",
      "[96]\n",
      "[111]\n",
      "[97]\n",
      "[14]\n",
      "[95]\n",
      "[97]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[100]\n",
      "[95]\n",
      "[105]\n",
      "[105]\n",
      "[106]\n",
      "[112]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[112]\n",
      "[106]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[112]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[112]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[107]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[30]\n",
      "[111]\n",
      "[111]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[109]\n",
      "[108]\n",
      "[109]\n",
      "[100]\n",
      "03/07 03:53:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][647/647]    acc/top1: 0.1654  acc/top5: 0.4884  acc/mean1: 0.2184  data_time: 0.0009  time: 0.0311\n",
      "03/07 03:53:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_11.pth is removed\n",
      "03/07 03:53:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.1654 acc/top1 at 13 epoch is saved to best_acc_top1_epoch_13.pth.\n",
      "03/07 03:53:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:53:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 100/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:51:23  time: 0.1639  data_time: 0.0017  memory: 10434  loss: 1.7427  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7427\n",
      "03/07 03:53:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 200/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:51:06  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 1.9872  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9872\n",
      "03/07 03:54:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 300/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:50:50  time: 0.1631  data_time: 0.0020  memory: 10434  loss: 1.4447  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4447\n",
      "03/07 03:54:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 400/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:50:33  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 2.2316  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.2316\n",
      "03/07 03:54:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 500/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:50:17  time: 0.1648  data_time: 0.0019  memory: 10434  loss: 2.0263  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0263\n",
      "03/07 03:55:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 600/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:50:00  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 1.5360  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5360\n",
      "03/07 03:55:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 700/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:49:44  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 2.2213  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2213\n",
      "03/07 03:55:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 800/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:49:27  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 1.9298  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9298\n",
      "03/07 03:55:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 900/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:49:11  time: 0.1639  data_time: 0.0018  memory: 10434  loss: 1.9393  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9393\n",
      "03/07 03:56:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1000/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:48:54  time: 0.1640  data_time: 0.0018  memory: 10434  loss: 1.8697  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8697\n",
      "03/07 03:56:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:56:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1100/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:48:38  time: 0.1632  data_time: 0.0016  memory: 10434  loss: 1.5942  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5942\n",
      "03/07 03:56:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1200/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:48:21  time: 0.1650  data_time: 0.0019  memory: 10434  loss: 1.8715  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.8715\n",
      "03/07 03:56:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1300/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:48:05  time: 0.1662  data_time: 0.0019  memory: 10434  loss: 1.8726  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8726\n",
      "03/07 03:57:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1400/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:47:49  time: 0.1630  data_time: 0.0018  memory: 10434  loss: 1.8149  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8149\n",
      "03/07 03:57:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1500/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:47:32  time: 0.1640  data_time: 0.0018  memory: 10434  loss: 1.6572  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6572\n",
      "03/07 03:57:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1600/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:47:16  time: 0.1637  data_time: 0.0016  memory: 10434  loss: 1.8268  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8268\n",
      "03/07 03:58:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1700/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:46:59  time: 0.1632  data_time: 0.0017  memory: 10434  loss: 2.0723  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0723\n",
      "03/07 03:58:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1800/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:46:43  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 2.0154  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0154\n",
      "03/07 03:58:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1900/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:46:26  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.6973  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.6973\n",
      "03/07 03:58:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2000/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:46:10  time: 0.1634  data_time: 0.0019  memory: 10434  loss: 1.7188  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7188\n",
      "03/07 03:59:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 03:59:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2100/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:45:53  time: 0.1643  data_time: 0.0018  memory: 10434  loss: 2.1238  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1238\n",
      "03/07 03:59:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2200/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:45:37  time: 0.1634  data_time: 0.0016  memory: 10434  loss: 1.7893  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7893\n",
      "03/07 03:59:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2300/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:45:21  time: 0.1632  data_time: 0.0017  memory: 10434  loss: 1.6558  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6558\n",
      "03/07 03:59:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2400/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:45:04  time: 0.1641  data_time: 0.0017  memory: 10434  loss: 1.2788  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2788\n",
      "03/07 04:00:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2500/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:44:48  time: 0.1631  data_time: 0.0015  memory: 10434  loss: 1.7122  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7122\n",
      "03/07 04:00:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2600/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:44:31  time: 0.1641  data_time: 0.0018  memory: 10434  loss: 1.5599  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5599\n",
      "03/07 04:00:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2700/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:44:15  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.7771  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7771\n",
      "03/07 04:01:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2800/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:43:58  time: 0.1640  data_time: 0.0017  memory: 10434  loss: 1.8520  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.8520\n",
      "03/07 04:01:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2900/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:43:42  time: 0.1634  data_time: 0.0018  memory: 10434  loss: 1.8975  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8975\n",
      "03/07 04:01:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3000/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:43:25  time: 0.1630  data_time: 0.0016  memory: 10434  loss: 1.4677  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4677\n",
      "03/07 04:01:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:01:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3100/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:43:09  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 1.7349  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7349\n",
      "03/07 04:02:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3200/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:42:52  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 1.5435  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5435\n",
      "03/07 04:02:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3300/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:42:36  time: 0.1630  data_time: 0.0018  memory: 10434  loss: 1.7208  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7208\n",
      "03/07 04:02:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3400/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:42:20  time: 0.1659  data_time: 0.0016  memory: 10434  loss: 2.0517  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0517\n",
      "03/07 04:03:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3500/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:42:03  time: 0.1655  data_time: 0.0017  memory: 10434  loss: 1.8287  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8287\n",
      "03/07 04:03:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3600/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:41:47  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 1.9455  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9455\n",
      "03/07 04:03:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3700/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:41:30  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 1.5894  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.5894\n",
      "03/07 04:03:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3800/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:41:14  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 1.4156  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.4156\n",
      "03/07 04:04:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3900/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:40:57  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 1.8325  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8325\n",
      "03/07 04:04:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4000/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:40:41  time: 0.1638  data_time: 0.0018  memory: 10434  loss: 1.6595  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6595\n",
      "03/07 04:04:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:04:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4100/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:40:24  time: 0.1646  data_time: 0.0017  memory: 10434  loss: 2.1440  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1440\n",
      "03/07 04:04:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4200/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:40:08  time: 0.1648  data_time: 0.0017  memory: 10434  loss: 1.8428  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8428\n",
      "03/07 04:05:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4300/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:39:52  time: 0.1639  data_time: 0.0019  memory: 10434  loss: 2.1379  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1379\n",
      "03/07 04:05:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4400/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:39:35  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 1.6046  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.6046\n",
      "03/07 04:05:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4500/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:39:19  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 1.7415  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7415\n",
      "03/07 04:06:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4600/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:39:02  time: 0.1644  data_time: 0.0018  memory: 10434  loss: 2.2869  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.2869\n",
      "03/07 04:06:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4700/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:38:46  time: 0.1652  data_time: 0.0019  memory: 10434  loss: 1.3228  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3228\n",
      "03/07 04:06:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4800/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:38:29  time: 0.1633  data_time: 0.0017  memory: 10434  loss: 1.7173  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7173\n",
      "03/07 04:06:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4900/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:38:13  time: 0.1644  data_time: 0.0017  memory: 10434  loss: 1.8103  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8103\n",
      "03/07 04:07:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][5000/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:37:56  time: 0.1634  data_time: 0.0019  memory: 10434  loss: 1.6038  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6038\n",
      "03/07 04:07:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:07:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][5100/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:37:40  time: 0.1628  data_time: 0.0018  memory: 10434  loss: 2.1319  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1319\n",
      "03/07 04:07:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][5200/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:37:24  time: 0.1639  data_time: 0.0017  memory: 10434  loss: 1.5030  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5030\n",
      "03/07 04:07:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:07:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][5225/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:37:19  time: 0.1595  data_time: 0.0019  memory: 10434  loss: 1.7533  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7533\n",
      "03/07 04:07:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][100/647]    eta: 0:00:17  time: 0.0311  data_time: 0.0009  memory: 861  \n",
      "03/07 04:07:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][200/647]    eta: 0:00:13  time: 0.0311  data_time: 0.0006  memory: 861  \n",
      "03/07 04:07:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][300/647]    eta: 0:00:10  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "03/07 04:07:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][400/647]    eta: 0:00:07  time: 0.0311  data_time: 0.0007  memory: 861  \n",
      "03/07 04:07:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][500/647]    eta: 0:00:04  time: 0.0311  data_time: 0.0007  memory: 861  \n",
      "03/07 04:08:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][600/647]    eta: 0:00:01  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "[14]\n",
      "[1]\n",
      "[18]\n",
      "[14]\n",
      "[13]\n",
      "[2]\n",
      "[13]\n",
      "[21]\n",
      "[17]\n",
      "[11]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[18]\n",
      "[4]\n",
      "[18]\n",
      "[18]\n",
      "[5]\n",
      "[20]\n",
      "[13]\n",
      "[14]\n",
      "[13]\n",
      "[14]\n",
      "[3]\n",
      "[13]\n",
      "[5]\n",
      "[13]\n",
      "[1]\n",
      "[3]\n",
      "[11]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[13]\n",
      "[1]\n",
      "[13]\n",
      "[14]\n",
      "[18]\n",
      "[1]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[1]\n",
      "[4]\n",
      "[14]\n",
      "[1]\n",
      "[18]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[14]\n",
      "[20]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[6]\n",
      "[13]\n",
      "[13]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[5]\n",
      "[21]\n",
      "[0]\n",
      "[4]\n",
      "[11]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[25]\n",
      "[24]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[1]\n",
      "[11]\n",
      "[3]\n",
      "[4]\n",
      "[12]\n",
      "[22]\n",
      "[26]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[22]\n",
      "[23]\n",
      "[26]\n",
      "[24]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[25]\n",
      "[25]\n",
      "[26]\n",
      "[43]\n",
      "[67]\n",
      "[30]\n",
      "[106]\n",
      "[27]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[31]\n",
      "[31]\n",
      "[105]\n",
      "[30]\n",
      "[30]\n",
      "[93]\n",
      "[31]\n",
      "[93]\n",
      "[27]\n",
      "[41]\n",
      "[116]\n",
      "[41]\n",
      "[116]\n",
      "[30]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[30]\n",
      "[41]\n",
      "[42]\n",
      "[19]\n",
      "[41]\n",
      "[30]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[34]\n",
      "[33]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[66]\n",
      "[115]\n",
      "[41]\n",
      "[111]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[65]\n",
      "[57]\n",
      "[59]\n",
      "[57]\n",
      "[87]\n",
      "[0]\n",
      "[55]\n",
      "[57]\n",
      "[57]\n",
      "[56]\n",
      "[57]\n",
      "[44]\n",
      "[44]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[56]\n",
      "[59]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[59]\n",
      "[58]\n",
      "[58]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[59]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[56]\n",
      "[56]\n",
      "[58]\n",
      "[58]\n",
      "[56]\n",
      "[9]\n",
      "[26]\n",
      "[56]\n",
      "[55]\n",
      "[58]\n",
      "[9]\n",
      "[55]\n",
      "[55]\n",
      "[9]\n",
      "[56]\n",
      "[44]\n",
      "[55]\n",
      "[9]\n",
      "[54]\n",
      "[58]\n",
      "[59]\n",
      "[9]\n",
      "[9]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[9]\n",
      "[56]\n",
      "[44]\n",
      "[59]\n",
      "[59]\n",
      "[53]\n",
      "[56]\n",
      "[44]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[56]\n",
      "[56]\n",
      "[12]\n",
      "[56]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[31]\n",
      "[29]\n",
      "[63]\n",
      "[29]\n",
      "[63]\n",
      "[29]\n",
      "[29]\n",
      "[53]\n",
      "[53]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[65]\n",
      "[30]\n",
      "[30]\n",
      "[47]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[68]\n",
      "[68]\n",
      "[69]\n",
      "[30]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[29]\n",
      "[63]\n",
      "[69]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[53]\n",
      "[53]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[68]\n",
      "[70]\n",
      "[67]\n",
      "[69]\n",
      "[70]\n",
      "[98]\n",
      "[53]\n",
      "[110]\n",
      "[116]\n",
      "[122]\n",
      "[110]\n",
      "[111]\n",
      "[110]\n",
      "[110]\n",
      "[44]\n",
      "[110]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[121]\n",
      "[111]\n",
      "[98]\n",
      "[110]\n",
      "[110]\n",
      "[44]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[108]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[99]\n",
      "[99]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[99]\n",
      "[99]\n",
      "[71]\n",
      "[99]\n",
      "[99]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[52]\n",
      "[52]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[89]\n",
      "[77]\n",
      "[86]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[77]\n",
      "[78]\n",
      "[89]\n",
      "[74]\n",
      "[7]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[89]\n",
      "[88]\n",
      "[87]\n",
      "[90]\n",
      "[72]\n",
      "[60]\n",
      "[87]\n",
      "[87]\n",
      "[89]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[87]\n",
      "[90]\n",
      "[90]\n",
      "[72]\n",
      "[60]\n",
      "[87]\n",
      "[87]\n",
      "[60]\n",
      "[60]\n",
      "[90]\n",
      "[90]\n",
      "[60]\n",
      "[60]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[83]\n",
      "[85]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[73]\n",
      "[72]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[87]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[74]\n",
      "[74]\n",
      "[77]\n",
      "[89]\n",
      "[83]\n",
      "[78]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[105]\n",
      "[31]\n",
      "[112]\n",
      "[31]\n",
      "[31]\n",
      "[112]\n",
      "[112]\n",
      "[91]\n",
      "[82]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[112]\n",
      "[91]\n",
      "[112]\n",
      "[30]\n",
      "[31]\n",
      "[71]\n",
      "[111]\n",
      "[49]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[71]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[100]\n",
      "[100]\n",
      "[103]\n",
      "[71]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[101]\n",
      "[103]\n",
      "[71]\n",
      "[100]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[79]\n",
      "[96]\n",
      "[92]\n",
      "[79]\n",
      "[79]\n",
      "[99]\n",
      "[96]\n",
      "[92]\n",
      "[100]\n",
      "[104]\n",
      "[92]\n",
      "[79]\n",
      "[96]\n",
      "[92]\n",
      "[79]\n",
      "[96]\n",
      "[97]\n",
      "[92]\n",
      "[99]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[111]\n",
      "[107]\n",
      "[107]\n",
      "[97]\n",
      "[107]\n",
      "[95]\n",
      "[99]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[71]\n",
      "[111]\n",
      "[100]\n",
      "[98]\n",
      "[98]\n",
      "[100]\n",
      "[111]\n",
      "[105]\n",
      "[105]\n",
      "[108]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[105]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[115]\n",
      "[105]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[105]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[110]\n",
      "[112]\n",
      "[108]\n",
      "[107]\n",
      "[111]\n",
      "[111]\n",
      "[105]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[110]\n",
      "[111]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[109]\n",
      "[108]\n",
      "[109]\n",
      "[107]\n",
      "03/07 04:08:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][647/647]    acc/top1: 0.1824  acc/top5: 0.4869  acc/mean1: 0.2552  data_time: 0.0008  time: 0.0311\n",
      "03/07 04:08:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_13.pth is removed\n",
      "03/07 04:08:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.1824 acc/top1 at 14 epoch is saved to best_acc_top1_epoch_14.pth.\n",
      "03/07 04:08:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 100/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:37:03  time: 0.1626  data_time: 0.0017  memory: 10434  loss: 1.4118  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4118\n",
      "03/07 04:08:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 200/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:36:46  time: 0.1647  data_time: 0.0015  memory: 10434  loss: 1.9920  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9920\n",
      "03/07 04:08:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 300/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:36:30  time: 0.1643  data_time: 0.0017  memory: 10434  loss: 1.6084  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6084\n",
      "03/07 04:09:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 400/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:36:14  time: 0.1630  data_time: 0.0019  memory: 10434  loss: 2.0679  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0679\n",
      "03/07 04:09:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 500/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:35:57  time: 0.1634  data_time: 0.0018  memory: 10434  loss: 1.6073  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6073\n",
      "03/07 04:09:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 600/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:35:41  time: 0.1631  data_time: 0.0017  memory: 10434  loss: 1.5927  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5927\n",
      "03/07 04:09:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 700/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:35:24  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 1.5265  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5265\n",
      "03/07 04:10:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 800/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:35:08  time: 0.1636  data_time: 0.0017  memory: 10434  loss: 1.8485  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8485\n",
      "03/07 04:10:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:10:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 900/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:34:51  time: 0.1634  data_time: 0.0018  memory: 10434  loss: 1.7912  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7912\n",
      "03/07 04:10:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1000/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:34:35  time: 0.1639  data_time: 0.0018  memory: 10434  loss: 1.7100  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7100\n",
      "03/07 04:11:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1100/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:34:18  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 2.0251  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.0251\n",
      "03/07 04:11:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1200/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:34:02  time: 0.1642  data_time: 0.0020  memory: 10434  loss: 1.6460  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6460\n",
      "03/07 04:11:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1300/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:33:46  time: 0.1641  data_time: 0.0018  memory: 10434  loss: 2.0640  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0640\n",
      "03/07 04:11:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1400/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:33:29  time: 0.1639  data_time: 0.0018  memory: 10434  loss: 1.9107  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9107\n",
      "03/07 04:12:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1500/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:33:13  time: 0.1638  data_time: 0.0017  memory: 10434  loss: 1.6000  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.6000\n",
      "03/07 04:12:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1600/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:32:56  time: 0.1630  data_time: 0.0016  memory: 10434  loss: 2.4504  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.4504\n",
      "03/07 04:12:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1700/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:32:40  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.9290  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9290\n",
      "03/07 04:12:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1800/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:32:23  time: 0.1641  data_time: 0.0018  memory: 10434  loss: 1.8175  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8175\n",
      "03/07 04:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:13:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1900/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:32:07  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.7139  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7139\n",
      "03/07 04:13:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2000/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:31:50  time: 0.1633  data_time: 0.0016  memory: 10434  loss: 1.7600  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7600\n",
      "03/07 04:13:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2100/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:31:34  time: 0.1631  data_time: 0.0017  memory: 10434  loss: 1.5122  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5122\n",
      "03/07 04:14:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2200/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:31:17  time: 0.1628  data_time: 0.0018  memory: 10434  loss: 1.3260  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3260\n",
      "03/07 04:14:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2300/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:31:01  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 1.2777  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2777\n",
      "03/07 04:14:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2400/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:30:45  time: 0.1669  data_time: 0.0019  memory: 10434  loss: 1.8235  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8235\n",
      "03/07 04:14:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2500/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:30:28  time: 0.1658  data_time: 0.0018  memory: 10434  loss: 1.3248  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3248\n",
      "03/07 04:15:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2600/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:30:12  time: 0.1636  data_time: 0.0017  memory: 10434  loss: 1.7213  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7213\n",
      "03/07 04:15:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2700/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:29:55  time: 0.1628  data_time: 0.0017  memory: 10434  loss: 1.6194  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6194\n",
      "03/07 04:15:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2800/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:29:39  time: 0.1638  data_time: 0.0017  memory: 10434  loss: 1.7870  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7870\n",
      "03/07 04:15:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:16:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2900/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:29:22  time: 0.1632  data_time: 0.0017  memory: 10434  loss: 2.0037  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0037\n",
      "03/07 04:16:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3000/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:29:06  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 1.6740  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6740\n",
      "03/07 04:16:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3100/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:28:49  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 1.7187  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.7187\n",
      "03/07 04:16:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3200/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:28:33  time: 0.1640  data_time: 0.0017  memory: 10434  loss: 1.3686  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3686\n",
      "03/07 04:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3300/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:28:17  time: 0.1634  data_time: 0.0015  memory: 10434  loss: 1.7819  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7819\n",
      "03/07 04:17:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3400/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:28:00  time: 0.1628  data_time: 0.0018  memory: 10434  loss: 1.2857  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2857\n",
      "03/07 04:17:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3500/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:27:44  time: 0.1640  data_time: 0.0017  memory: 10434  loss: 1.3431  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3431\n",
      "03/07 04:17:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3600/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:27:27  time: 0.1633  data_time: 0.0018  memory: 10434  loss: 1.4370  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4370\n",
      "03/07 04:18:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3700/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:27:11  time: 0.1628  data_time: 0.0018  memory: 10434  loss: 1.7330  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7330\n",
      "03/07 04:18:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3800/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:26:54  time: 0.1640  data_time: 0.0017  memory: 10434  loss: 1.6700  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.6700\n",
      "03/07 04:18:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:18:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3900/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:26:38  time: 0.1649  data_time: 0.0019  memory: 10434  loss: 1.5387  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5387\n",
      "03/07 04:19:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4000/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:26:21  time: 0.1644  data_time: 0.0018  memory: 10434  loss: 1.4954  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4954\n",
      "03/07 04:19:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4100/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:26:05  time: 0.1631  data_time: 0.0017  memory: 10434  loss: 1.6898  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6898\n",
      "03/07 04:19:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4200/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:25:49  time: 0.1627  data_time: 0.0018  memory: 10434  loss: 1.9081  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9081\n",
      "03/07 04:19:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4300/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:25:32  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 2.1467  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1467\n",
      "03/07 04:20:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4400/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:25:16  time: 0.1638  data_time: 0.0018  memory: 10434  loss: 1.0256  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0256\n",
      "03/07 04:20:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4500/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:24:59  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 2.1472  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1472\n",
      "03/07 04:20:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4600/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:24:43  time: 0.1644  data_time: 0.0019  memory: 10434  loss: 1.8567  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8567\n",
      "03/07 04:20:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4700/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:24:26  time: 0.1655  data_time: 0.0017  memory: 10434  loss: 1.5957  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5957\n",
      "03/07 04:21:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4800/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:24:10  time: 0.1630  data_time: 0.0018  memory: 10434  loss: 1.8625  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8625\n",
      "03/07 04:21:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:21:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4900/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:23:53  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 1.6154  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6154\n",
      "03/07 04:21:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][5000/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:23:37  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 1.7634  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7634\n",
      "03/07 04:22:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][5100/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:23:21  time: 0.1645  data_time: 0.0017  memory: 10434  loss: 1.9140  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.9140\n",
      "03/07 04:22:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][5200/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:23:04  time: 0.1631  data_time: 0.0017  memory: 10434  loss: 1.8766  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8766\n",
      "03/07 04:22:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:22:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][5225/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:23:00  time: 0.1597  data_time: 0.0020  memory: 10434  loss: 1.8158  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.8158\n",
      "03/07 04:22:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 15 epochs\n",
      "03/07 04:22:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][100/647]    eta: 0:00:17  time: 0.0309  data_time: 0.0008  memory: 861  \n",
      "03/07 04:22:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][200/647]    eta: 0:00:13  time: 0.0310  data_time: 0.0009  memory: 861  \n",
      "03/07 04:22:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][300/647]    eta: 0:00:10  time: 0.0312  data_time: 0.0009  memory: 861  \n",
      "03/07 04:22:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][400/647]    eta: 0:00:07  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "03/07 04:22:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][500/647]    eta: 0:00:04  time: 0.0311  data_time: 0.0009  memory: 861  \n",
      "03/07 04:22:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][600/647]    eta: 0:00:01  time: 0.0310  data_time: 0.0009  memory: 861  \n",
      "[14]\n",
      "[1]\n",
      "[17]\n",
      "[14]\n",
      "[4]\n",
      "[11]\n",
      "[4]\n",
      "[21]\n",
      "[17]\n",
      "[14]\n",
      "[6]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[6]\n",
      "[17]\n",
      "[20]\n",
      "[5]\n",
      "[14]\n",
      "[5]\n",
      "[14]\n",
      "[13]\n",
      "[14]\n",
      "[23]\n",
      "[4]\n",
      "[4]\n",
      "[5]\n",
      "[4]\n",
      "[4]\n",
      "[11]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[12]\n",
      "[23]\n",
      "[23]\n",
      "[11]\n",
      "[17]\n",
      "[13]\n",
      "[14]\n",
      "[20]\n",
      "[14]\n",
      "[5]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n",
      "[18]\n",
      "[6]\n",
      "[4]\n",
      "[5]\n",
      "[14]\n",
      "[8]\n",
      "[18]\n",
      "[18]\n",
      "[17]\n",
      "[18]\n",
      "[11]\n",
      "[6]\n",
      "[13]\n",
      "[13]\n",
      "[17]\n",
      "[18]\n",
      "[14]\n",
      "[17]\n",
      "[18]\n",
      "[5]\n",
      "[5]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n",
      "[11]\n",
      "[0]\n",
      "[4]\n",
      "[5]\n",
      "[23]\n",
      "[4]\n",
      "[11]\n",
      "[11]\n",
      "[23]\n",
      "[22]\n",
      "[23]\n",
      "[26]\n",
      "[16]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[5]\n",
      "[11]\n",
      "[6]\n",
      "[11]\n",
      "[3]\n",
      "[4]\n",
      "[12]\n",
      "[23]\n",
      "[26]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[24]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[6]\n",
      "[6]\n",
      "[26]\n",
      "[8]\n",
      "[67]\n",
      "[4]\n",
      "[106]\n",
      "[27]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[45]\n",
      "[8]\n",
      "[4]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[93]\n",
      "[27]\n",
      "[29]\n",
      "[116]\n",
      "[42]\n",
      "[116]\n",
      "[30]\n",
      "[30]\n",
      "[4]\n",
      "[41]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[4]\n",
      "[4]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[30]\n",
      "[41]\n",
      "[42]\n",
      "[19]\n",
      "[19]\n",
      "[4]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[36]\n",
      "[33]\n",
      "[27]\n",
      "[36]\n",
      "[41]\n",
      "[38]\n",
      "[38]\n",
      "[21]\n",
      "[36]\n",
      "[27]\n",
      "[36]\n",
      "[42]\n",
      "[32]\n",
      "[42]\n",
      "[42]\n",
      "[32]\n",
      "[96]\n",
      "[34]\n",
      "[96]\n",
      "[34]\n",
      "[34]\n",
      "[15]\n",
      "[96]\n",
      "[34]\n",
      "[96]\n",
      "[96]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[55]\n",
      "[57]\n",
      "[46]\n",
      "[57]\n",
      "[89]\n",
      "[0]\n",
      "[56]\n",
      "[57]\n",
      "[53]\n",
      "[56]\n",
      "[57]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[15]\n",
      "[53]\n",
      "[8]\n",
      "[48]\n",
      "[52]\n",
      "[53]\n",
      "[58]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[58]\n",
      "[8]\n",
      "[58]\n",
      "[58]\n",
      "[53]\n",
      "[53]\n",
      "[58]\n",
      "[53]\n",
      "[57]\n",
      "[57]\n",
      "[8]\n",
      "[53]\n",
      "[52]\n",
      "[56]\n",
      "[55]\n",
      "[51]\n",
      "[55]\n",
      "[53]\n",
      "[53]\n",
      "[15]\n",
      "[55]\n",
      "[53]\n",
      "[53]\n",
      "[44]\n",
      "[51]\n",
      "[52]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[47]\n",
      "[55]\n",
      "[57]\n",
      "[56]\n",
      "[44]\n",
      "[56]\n",
      "[52]\n",
      "[52]\n",
      "[56]\n",
      "[52]\n",
      "[57]\n",
      "[57]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[8]\n",
      "[52]\n",
      "[57]\n",
      "[52]\n",
      "[53]\n",
      "[8]\n",
      "[56]\n",
      "[52]\n",
      "[56]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[67]\n",
      "[29]\n",
      "[63]\n",
      "[67]\n",
      "[62]\n",
      "[29]\n",
      "[29]\n",
      "[46]\n",
      "[48]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[48]\n",
      "[47]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[69]\n",
      "[67]\n",
      "[65]\n",
      "[67]\n",
      "[48]\n",
      "[52]\n",
      "[48]\n",
      "[52]\n",
      "[48]\n",
      "[48]\n",
      "[68]\n",
      "[30]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[29]\n",
      "[64]\n",
      "[53]\n",
      "[67]\n",
      "[48]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[53]\n",
      "[53]\n",
      "[70]\n",
      "[69]\n",
      "[67]\n",
      "[68]\n",
      "[68]\n",
      "[67]\n",
      "[69]\n",
      "[51]\n",
      "[98]\n",
      "[53]\n",
      "[110]\n",
      "[116]\n",
      "[122]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[118]\n",
      "[48]\n",
      "[121]\n",
      "[122]\n",
      "[44]\n",
      "[53]\n",
      "[121]\n",
      "[121]\n",
      "[49]\n",
      "[118]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[111]\n",
      "[121]\n",
      "[121]\n",
      "[53]\n",
      "[99]\n",
      "[12]\n",
      "[99]\n",
      "[52]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[12]\n",
      "[53]\n",
      "[12]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[12]\n",
      "[12]\n",
      "[52]\n",
      "[52]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[100]\n",
      "[100]\n",
      "[99]\n",
      "[72]\n",
      "[77]\n",
      "[86]\n",
      "[89]\n",
      "[80]\n",
      "[77]\n",
      "[77]\n",
      "[90]\n",
      "[80]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[90]\n",
      "[86]\n",
      "[90]\n",
      "[80]\n",
      "[60]\n",
      "[86]\n",
      "[3]\n",
      "[80]\n",
      "[7]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[77]\n",
      "[90]\n",
      "[3]\n",
      "[90]\n",
      "[90]\n",
      "[72]\n",
      "[60]\n",
      "[84]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[90]\n",
      "[90]\n",
      "[75]\n",
      "[75]\n",
      "[81]\n",
      "[7]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[87]\n",
      "[87]\n",
      "[83]\n",
      "[84]\n",
      "[90]\n",
      "[72]\n",
      "[75]\n",
      "[73]\n",
      "[72]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[83]\n",
      "[88]\n",
      "[88]\n",
      "[30]\n",
      "[30]\n",
      "[83]\n",
      "[91]\n",
      "[30]\n",
      "[31]\n",
      "[112]\n",
      "[30]\n",
      "[31]\n",
      "[30]\n",
      "[112]\n",
      "[30]\n",
      "[81]\n",
      "[91]\n",
      "[30]\n",
      "[100]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[112]\n",
      "[91]\n",
      "[112]\n",
      "[30]\n",
      "[71]\n",
      "[97]\n",
      "[116]\n",
      "[49]\n",
      "[96]\n",
      "[14]\n",
      "[71]\n",
      "[71]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[100]\n",
      "[71]\n",
      "[92]\n",
      "[101]\n",
      "[71]\n",
      "[64]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[92]\n",
      "[92]\n",
      "[71]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[101]\n",
      "[100]\n",
      "[71]\n",
      "[100]\n",
      "[92]\n",
      "[100]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[100]\n",
      "[96]\n",
      "[100]\n",
      "[100]\n",
      "[0]\n",
      "[100]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[100]\n",
      "[92]\n",
      "[100]\n",
      "[96]\n",
      "[97]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[96]\n",
      "[96]\n",
      "[111]\n",
      "[100]\n",
      "[116]\n",
      "[95]\n",
      "[99]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[99]\n",
      "[111]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[100]\n",
      "[111]\n",
      "[105]\n",
      "[105]\n",
      "[106]\n",
      "[106]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[106]\n",
      "[110]\n",
      "[108]\n",
      "[112]\n",
      "[109]\n",
      "[112]\n",
      "[110]\n",
      "[112]\n",
      "[109]\n",
      "[111]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[112]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[107]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[106]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[106]\n",
      "[113]\n",
      "[113]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[100]\n",
      "03/07 04:22:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][647/647]    acc/top1: 0.1978  acc/top5: 0.5301  acc/mean1: 0.2495  data_time: 0.0008  time: 0.0311\n",
      "03/07 04:22:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_14.pth is removed\n",
      "03/07 04:22:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.1978 acc/top1 at 15 epoch is saved to best_acc_top1_epoch_15.pth.\n",
      "03/07 04:22:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 100/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:22:44  time: 0.1639  data_time: 0.0017  memory: 10434  loss: 1.4055  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4055\n",
      "03/07 04:23:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 200/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:22:27  time: 0.1640  data_time: 0.0017  memory: 10434  loss: 1.7081  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7081\n",
      "03/07 04:23:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 300/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:22:11  time: 0.1640  data_time: 0.0017  memory: 10434  loss: 1.4958  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4958\n",
      "03/07 04:23:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 400/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:21:54  time: 0.1641  data_time: 0.0020  memory: 10434  loss: 1.5969  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5969\n",
      "03/07 04:24:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 500/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:21:38  time: 0.1630  data_time: 0.0018  memory: 10434  loss: 1.8934  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8934\n",
      "03/07 04:24:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 600/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:21:21  time: 0.1637  data_time: 0.0017  memory: 10434  loss: 2.0847  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0847\n",
      "03/07 04:24:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:24:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 700/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:21:05  time: 0.1643  data_time: 0.0018  memory: 10434  loss: 1.4728  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4728\n",
      "03/07 04:24:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 800/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:20:48  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 1.8702  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8702\n",
      "03/07 04:25:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 900/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:20:32  time: 0.1642  data_time: 0.0017  memory: 10434  loss: 1.7407  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7407\n",
      "03/07 04:25:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1000/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:20:16  time: 0.1643  data_time: 0.0017  memory: 10434  loss: 1.8375  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8375\n",
      "03/07 04:25:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1100/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:19:59  time: 0.1633  data_time: 0.0017  memory: 10434  loss: 1.7860  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7860\n",
      "03/07 04:26:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1200/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:19:43  time: 0.1649  data_time: 0.0018  memory: 10434  loss: 1.7111  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7111\n",
      "03/07 04:26:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1300/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:19:26  time: 0.1646  data_time: 0.0017  memory: 10434  loss: 1.4634  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4634\n",
      "03/07 04:26:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1400/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:19:10  time: 0.1672  data_time: 0.0017  memory: 10434  loss: 1.8551  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8551\n",
      "03/07 04:26:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1500/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:18:54  time: 0.1650  data_time: 0.0018  memory: 10434  loss: 1.0817  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0817\n",
      "03/07 04:27:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1600/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:18:37  time: 0.1635  data_time: 0.0015  memory: 10434  loss: 1.2896  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2896\n",
      "03/07 04:27:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:27:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1700/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:18:21  time: 0.1630  data_time: 0.0019  memory: 10434  loss: 1.4202  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4202\n",
      "03/07 04:27:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1800/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:18:04  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 1.9939  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.9939\n",
      "03/07 04:27:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1900/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:17:48  time: 0.1646  data_time: 0.0018  memory: 10434  loss: 1.4727  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4727\n",
      "03/07 04:28:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2000/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:17:32  time: 0.1628  data_time: 0.0019  memory: 10434  loss: 1.5862  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5862\n",
      "03/07 04:28:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2100/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:17:15  time: 0.1629  data_time: 0.0017  memory: 10434  loss: 1.8489  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8489\n",
      "03/07 04:28:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2200/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:16:59  time: 0.1634  data_time: 0.0018  memory: 10434  loss: 1.7046  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7046\n",
      "03/07 04:29:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2300/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:16:42  time: 0.1643  data_time: 0.0017  memory: 10434  loss: 1.6562  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6562\n",
      "03/07 04:29:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2400/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:16:26  time: 0.1641  data_time: 0.0017  memory: 10434  loss: 1.4918  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.4918\n",
      "03/07 04:29:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2500/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:16:09  time: 0.1637  data_time: 0.0017  memory: 10434  loss: 1.5460  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5460\n",
      "03/07 04:29:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2600/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:15:53  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 1.6393  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6393\n",
      "03/07 04:29:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:30:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2700/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:15:36  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 1.2897  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2897\n",
      "03/07 04:30:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2800/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:15:20  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 1.5018  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5018\n",
      "03/07 04:30:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2900/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:15:04  time: 0.1639  data_time: 0.0020  memory: 10434  loss: 1.6051  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6051\n",
      "03/07 04:30:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3000/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:14:47  time: 0.1653  data_time: 0.0018  memory: 10434  loss: 1.8915  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8915\n",
      "03/07 04:31:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3100/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:14:31  time: 0.1647  data_time: 0.0017  memory: 10434  loss: 1.5867  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5867\n",
      "03/07 04:31:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3200/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:14:14  time: 0.1634  data_time: 0.0018  memory: 10434  loss: 1.4933  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.4933\n",
      "03/07 04:31:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3300/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:13:58  time: 0.1632  data_time: 0.0017  memory: 10434  loss: 1.5152  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5152\n",
      "03/07 04:32:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3400/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:13:41  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 1.5329  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5329\n",
      "03/07 04:32:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3500/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:13:25  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 1.4852  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4852\n",
      "03/07 04:32:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3600/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:13:08  time: 0.1640  data_time: 0.0018  memory: 10434  loss: 2.0553  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.0553\n",
      "03/07 04:32:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:32:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3700/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:12:52  time: 0.1643  data_time: 0.0018  memory: 10434  loss: 1.8679  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8679\n",
      "03/07 04:33:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3800/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:12:36  time: 0.1637  data_time: 0.0019  memory: 10434  loss: 1.4331  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4331\n",
      "03/07 04:33:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3900/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:12:19  time: 0.1628  data_time: 0.0019  memory: 10434  loss: 1.6454  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6454\n",
      "03/07 04:33:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4000/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:12:03  time: 0.1630  data_time: 0.0019  memory: 10434  loss: 1.5364  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5364\n",
      "03/07 04:33:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4100/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:11:46  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.5855  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5855\n",
      "03/07 04:34:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4200/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:11:30  time: 0.1628  data_time: 0.0016  memory: 10434  loss: 1.8650  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8650\n",
      "03/07 04:34:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4300/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:11:13  time: 0.1639  data_time: 0.0018  memory: 10434  loss: 1.5364  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5364\n",
      "03/07 04:34:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4400/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:10:57  time: 0.1639  data_time: 0.0019  memory: 10434  loss: 1.9296  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9296\n",
      "03/07 04:35:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4500/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:10:41  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 1.7125  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7125\n",
      "03/07 04:35:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4600/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:10:24  time: 0.1633  data_time: 0.0018  memory: 10434  loss: 1.4947  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4947\n",
      "03/07 04:35:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:35:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4700/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:10:08  time: 0.1649  data_time: 0.0019  memory: 10434  loss: 1.5330  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5330\n",
      "03/07 04:35:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4800/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:09:51  time: 0.1642  data_time: 0.0019  memory: 10434  loss: 1.3104  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3104\n",
      "03/07 04:36:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4900/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:09:35  time: 0.1635  data_time: 0.0016  memory: 10434  loss: 1.6723  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6723\n",
      "03/07 04:36:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][5000/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:09:18  time: 0.1627  data_time: 0.0018  memory: 10434  loss: 1.5948  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5948\n",
      "03/07 04:36:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][5100/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:09:02  time: 0.1650  data_time: 0.0018  memory: 10434  loss: 1.6590  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6590\n",
      "03/07 04:36:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][5200/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:08:46  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 1.4884  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4884\n",
      "03/07 04:37:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:37:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][5225/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:08:41  time: 0.1609  data_time: 0.0020  memory: 10434  loss: 1.6395  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.6395\n",
      "03/07 04:37:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][100/647]    eta: 0:00:17  time: 0.0311  data_time: 0.0009  memory: 861  \n",
      "03/07 04:37:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][200/647]    eta: 0:00:13  time: 0.0309  data_time: 0.0007  memory: 861  \n",
      "03/07 04:37:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][300/647]    eta: 0:00:10  time: 0.0311  data_time: 0.0008  memory: 861  \n",
      "03/07 04:37:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][400/647]    eta: 0:00:07  time: 0.0311  data_time: 0.0006  memory: 861  \n",
      "03/07 04:37:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][500/647]    eta: 0:00:04  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "03/07 04:37:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][600/647]    eta: 0:00:01  time: 0.0311  data_time: 0.0007  memory: 861  \n",
      "[0]\n",
      "[13]\n",
      "[17]\n",
      "[14]\n",
      "[13]\n",
      "[2]\n",
      "[4]\n",
      "[21]\n",
      "[17]\n",
      "[14]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[4]\n",
      "[17]\n",
      "[18]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[14]\n",
      "[13]\n",
      "[14]\n",
      "[0]\n",
      "[4]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[3]\n",
      "[5]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[17]\n",
      "[13]\n",
      "[20]\n",
      "[20]\n",
      "[14]\n",
      "[5]\n",
      "[5]\n",
      "[0]\n",
      "[4]\n",
      "[18]\n",
      "[14]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[8]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[5]\n",
      "[13]\n",
      "[13]\n",
      "[17]\n",
      "[18]\n",
      "[16]\n",
      "[18]\n",
      "[18]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[0]\n",
      "[4]\n",
      "[20]\n",
      "[5]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[5]\n",
      "[9]\n",
      "[9]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[25]\n",
      "[16]\n",
      "[24]\n",
      "[16]\n",
      "[26]\n",
      "[26]\n",
      "[20]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[13]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[16]\n",
      "[9]\n",
      "[5]\n",
      "[20]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[16]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[26]\n",
      "[43]\n",
      "[67]\n",
      "[34]\n",
      "[106]\n",
      "[30]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[45]\n",
      "[7]\n",
      "[115]\n",
      "[68]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[29]\n",
      "[13]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[30]\n",
      "[30]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[42]\n",
      "[34]\n",
      "[30]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[19]\n",
      "[30]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[33]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[38]\n",
      "[5]\n",
      "[5]\n",
      "[36]\n",
      "[115]\n",
      "[36]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[14]\n",
      "[14]\n",
      "[96]\n",
      "[97]\n",
      "[34]\n",
      "[34]\n",
      "[15]\n",
      "[96]\n",
      "[34]\n",
      "[19]\n",
      "[14]\n",
      "[57]\n",
      "[56]\n",
      "[57]\n",
      "[122]\n",
      "[54]\n",
      "[45]\n",
      "[57]\n",
      "[89]\n",
      "[0]\n",
      "[55]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[57]\n",
      "[44]\n",
      "[44]\n",
      "[46]\n",
      "[55]\n",
      "[57]\n",
      "[56]\n",
      "[15]\n",
      "[6]\n",
      "[58]\n",
      "[45]\n",
      "[57]\n",
      "[6]\n",
      "[58]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[53]\n",
      "[58]\n",
      "[58]\n",
      "[55]\n",
      "[57]\n",
      "[57]\n",
      "[58]\n",
      "[9]\n",
      "[56]\n",
      "[55]\n",
      "[55]\n",
      "[55]\n",
      "[55]\n",
      "[53]\n",
      "[55]\n",
      "[55]\n",
      "[55]\n",
      "[55]\n",
      "[45]\n",
      "[44]\n",
      "[55]\n",
      "[9]\n",
      "[54]\n",
      "[53]\n",
      "[45]\n",
      "[55]\n",
      "[55]\n",
      "[55]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[55]\n",
      "[55]\n",
      "[56]\n",
      "[56]\n",
      "[44]\n",
      "[56]\n",
      "[45]\n",
      "[45]\n",
      "[55]\n",
      "[45]\n",
      "[57]\n",
      "[53]\n",
      "[45]\n",
      "[44]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[12]\n",
      "[45]\n",
      "[56]\n",
      "[56]\n",
      "[53]\n",
      "[6]\n",
      "[56]\n",
      "[7]\n",
      "[56]\n",
      "[30]\n",
      "[7]\n",
      "[6]\n",
      "[30]\n",
      "[31]\n",
      "[29]\n",
      "[63]\n",
      "[29]\n",
      "[63]\n",
      "[29]\n",
      "[29]\n",
      "[46]\n",
      "[48]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[68]\n",
      "[40]\n",
      "[27]\n",
      "[65]\n",
      "[48]\n",
      "[48]\n",
      "[52]\n",
      "[53]\n",
      "[48]\n",
      "[53]\n",
      "[68]\n",
      "[68]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[29]\n",
      "[68]\n",
      "[40]\n",
      "[67]\n",
      "[48]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[53]\n",
      "[69]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[68]\n",
      "[68]\n",
      "[69]\n",
      "[28]\n",
      "[98]\n",
      "[53]\n",
      "[110]\n",
      "[116]\n",
      "[122]\n",
      "[110]\n",
      "[121]\n",
      "[121]\n",
      "[110]\n",
      "[44]\n",
      "[122]\n",
      "[122]\n",
      "[44]\n",
      "[122]\n",
      "[122]\n",
      "[110]\n",
      "[49]\n",
      "[110]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[71]\n",
      "[98]\n",
      "[71]\n",
      "[71]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[48]\n",
      "[48]\n",
      "[12]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[71]\n",
      "[71]\n",
      "[99]\n",
      "[53]\n",
      "[53]\n",
      "[98]\n",
      "[98]\n",
      "[99]\n",
      "[71]\n",
      "[98]\n",
      "[71]\n",
      "[72]\n",
      "[77]\n",
      "[73]\n",
      "[72]\n",
      "[80]\n",
      "[77]\n",
      "[77]\n",
      "[78]\n",
      "[72]\n",
      "[79]\n",
      "[7]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[77]\n",
      "[87]\n",
      "[90]\n",
      "[72]\n",
      "[80]\n",
      "[86]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[77]\n",
      "[72]\n",
      "[87]\n",
      "[90]\n",
      "[90]\n",
      "[72]\n",
      "[60]\n",
      "[86]\n",
      "[72]\n",
      "[80]\n",
      "[80]\n",
      "[90]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[81]\n",
      "[81]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[86]\n",
      "[86]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[73]\n",
      "[72]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[74]\n",
      "[72]\n",
      "[77]\n",
      "[78]\n",
      "[83]\n",
      "[78]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[83]\n",
      "[83]\n",
      "[105]\n",
      "[30]\n",
      "[112]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[112]\n",
      "[30]\n",
      "[81]\n",
      "[81]\n",
      "[30]\n",
      "[100]\n",
      "[30]\n",
      "[91]\n",
      "[112]\n",
      "[30]\n",
      "[71]\n",
      "[112]\n",
      "[30]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[98]\n",
      "[71]\n",
      "[14]\n",
      "[71]\n",
      "[71]\n",
      "[92]\n",
      "[102]\n",
      "[92]\n",
      "[101]\n",
      "[101]\n",
      "[102]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[101]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[92]\n",
      "[103]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[102]\n",
      "[103]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[100]\n",
      "[104]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[98]\n",
      "[97]\n",
      "[92]\n",
      "[100]\n",
      "[92]\n",
      "[104]\n",
      "[92]\n",
      "[109]\n",
      "[79]\n",
      "[97]\n",
      "[97]\n",
      "[109]\n",
      "[100]\n",
      "[97]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[98]\n",
      "[100]\n",
      "[98]\n",
      "[98]\n",
      "[100]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[88]\n",
      "[112]\n",
      "[115]\n",
      "[105]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[105]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[106]\n",
      "[106]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[110]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "03/07 04:37:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][647/647]    acc/top1: 0.1978  acc/top5: 0.5379  acc/mean1: 0.2428  data_time: 0.0009  time: 0.0311\n",
      "03/07 04:37:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 100/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:08:25  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 1.2919  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2919\n",
      "03/07 04:37:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 200/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:08:09  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 1.6070  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6070\n",
      "03/07 04:38:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 300/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:07:52  time: 0.1632  data_time: 0.0019  memory: 10434  loss: 1.5210  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5210\n",
      "03/07 04:38:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:38:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 400/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:07:36  time: 0.1637  data_time: 0.0019  memory: 10434  loss: 1.8604  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.8604\n",
      "03/07 04:38:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 500/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:07:19  time: 0.1650  data_time: 0.0017  memory: 10434  loss: 2.0631  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.0631\n",
      "03/07 04:38:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 600/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:07:03  time: 0.1652  data_time: 0.0020  memory: 10434  loss: 1.5011  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5011\n",
      "03/07 04:39:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 700/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:06:46  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 1.2825  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2825\n",
      "03/07 04:39:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 800/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:06:30  time: 0.1633  data_time: 0.0017  memory: 10434  loss: 1.6641  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6641\n",
      "03/07 04:39:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 900/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:06:14  time: 0.1637  data_time: 0.0020  memory: 10434  loss: 1.6634  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6634\n",
      "03/07 04:40:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1000/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:05:57  time: 0.1629  data_time: 0.0019  memory: 10434  loss: 1.5709  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.5709\n",
      "03/07 04:40:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1100/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:05:41  time: 0.1637  data_time: 0.0017  memory: 10434  loss: 1.4729  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4729\n",
      "03/07 04:40:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1200/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:05:24  time: 0.1640  data_time: 0.0018  memory: 10434  loss: 1.7233  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7233\n",
      "03/07 04:40:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1300/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:05:08  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 1.7205  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7205\n",
      "03/07 04:41:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:41:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1400/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:04:51  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 1.5420  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5420\n",
      "03/07 04:41:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1500/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:04:35  time: 0.1639  data_time: 0.0017  memory: 10434  loss: 1.4402  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.4402\n",
      "03/07 04:41:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1600/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:04:19  time: 0.1639  data_time: 0.0018  memory: 10434  loss: 1.5405  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5405\n",
      "03/07 04:42:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1700/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:04:02  time: 0.1641  data_time: 0.0017  memory: 10434  loss: 1.3302  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3302\n",
      "03/07 04:42:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1800/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:03:46  time: 0.1628  data_time: 0.0018  memory: 10434  loss: 2.0291  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.0291\n",
      "03/07 04:42:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1900/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:03:29  time: 0.1636  data_time: 0.0016  memory: 10434  loss: 1.7057  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7057\n",
      "03/07 04:42:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2000/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:03:13  time: 0.1634  data_time: 0.0016  memory: 10434  loss: 1.6816  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6816\n",
      "03/07 04:43:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2100/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:02:56  time: 0.1638  data_time: 0.0019  memory: 10434  loss: 1.6393  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6393\n",
      "03/07 04:43:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2200/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:02:40  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 1.4404  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4404\n",
      "03/07 04:43:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2300/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:02:23  time: 0.1627  data_time: 0.0018  memory: 10434  loss: 1.4344  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4344\n",
      "03/07 04:43:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:43:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2400/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:02:07  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 1.8276  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8276\n",
      "03/07 04:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2500/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:01:51  time: 0.1629  data_time: 0.0017  memory: 10434  loss: 1.0466  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0466\n",
      "03/07 04:44:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2600/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:01:34  time: 0.1630  data_time: 0.0018  memory: 10434  loss: 1.6486  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6486\n",
      "03/07 04:44:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2700/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:01:18  time: 0.1645  data_time: 0.0019  memory: 10434  loss: 1.8358  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8358\n",
      "03/07 04:45:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2800/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:01:01  time: 0.1647  data_time: 0.0018  memory: 10434  loss: 1.7743  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.7743\n",
      "03/07 04:45:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2900/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:00:45  time: 0.1633  data_time: 0.0017  memory: 10434  loss: 1.6392  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6392\n",
      "03/07 04:45:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3000/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:00:28  time: 0.1642  data_time: 0.0018  memory: 10434  loss: 1.8480  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8480\n",
      "03/07 04:45:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3100/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 2:00:12  time: 0.1625  data_time: 0.0019  memory: 10434  loss: 2.2722  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2722\n",
      "03/07 04:46:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3200/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:59:56  time: 0.1635  data_time: 0.0016  memory: 10434  loss: 1.6539  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6539\n",
      "03/07 04:46:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3300/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:59:39  time: 0.1638  data_time: 0.0018  memory: 10434  loss: 1.5984  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5984\n",
      "03/07 04:46:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:46:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3400/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:59:23  time: 0.1639  data_time: 0.0019  memory: 10434  loss: 1.5381  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5381\n",
      "03/07 04:46:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3500/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:59:06  time: 0.1638  data_time: 0.0020  memory: 10434  loss: 1.5001  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5001\n",
      "03/07 04:47:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3600/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:58:50  time: 0.1652  data_time: 0.0018  memory: 10434  loss: 1.6006  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6006\n",
      "03/07 04:47:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3700/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:58:33  time: 0.1638  data_time: 0.0019  memory: 10434  loss: 1.7766  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7766\n",
      "03/07 04:47:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3800/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:58:17  time: 0.1643  data_time: 0.0017  memory: 10434  loss: 1.3980  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3980\n",
      "03/07 04:48:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3900/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:58:01  time: 0.1643  data_time: 0.0019  memory: 10434  loss: 1.1822  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.1822\n",
      "03/07 04:48:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4000/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:57:44  time: 0.1632  data_time: 0.0019  memory: 10434  loss: 1.2067  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2067\n",
      "03/07 04:48:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4100/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:57:28  time: 0.1649  data_time: 0.0018  memory: 10434  loss: 1.9572  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9572\n",
      "03/07 04:48:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4200/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:57:11  time: 0.1642  data_time: 0.0017  memory: 10434  loss: 1.7803  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7803\n",
      "03/07 04:49:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4300/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:56:55  time: 0.1638  data_time: 0.0019  memory: 10434  loss: 1.0225  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0225\n",
      "03/07 04:49:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:49:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4400/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:56:38  time: 0.1632  data_time: 0.0016  memory: 10434  loss: 1.9129  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9129\n",
      "03/07 04:49:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4500/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:56:22  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 1.5678  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5678\n",
      "03/07 04:49:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4600/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:56:06  time: 0.1647  data_time: 0.0017  memory: 10434  loss: 1.4797  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4797\n",
      "03/07 04:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4700/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:55:49  time: 0.1632  data_time: 0.0016  memory: 10434  loss: 1.3348  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3348\n",
      "03/07 04:50:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4800/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:55:33  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 1.3993  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3993\n",
      "03/07 04:50:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4900/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:55:16  time: 0.1668  data_time: 0.0018  memory: 10434  loss: 1.1139  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1139\n",
      "03/07 04:51:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][5000/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:55:00  time: 0.1642  data_time: 0.0019  memory: 10434  loss: 1.9268  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9268\n",
      "03/07 04:51:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][5100/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:54:43  time: 0.1636  data_time: 0.0019  memory: 10434  loss: 1.6236  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.6236\n",
      "03/07 04:51:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][5200/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:54:27  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 1.9968  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9968\n",
      "03/07 04:51:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:51:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][5225/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:54:23  time: 0.1614  data_time: 0.0019  memory: 10434  loss: 1.5638  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5638\n",
      "03/07 04:51:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][100/647]    eta: 0:00:17  time: 0.0313  data_time: 0.0009  memory: 861  \n",
      "03/07 04:51:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][200/647]    eta: 0:00:14  time: 0.0311  data_time: 0.0007  memory: 861  \n",
      "03/07 04:51:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][300/647]    eta: 0:00:10  time: 0.0311  data_time: 0.0008  memory: 861  \n",
      "03/07 04:51:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][400/647]    eta: 0:00:07  time: 0.0310  data_time: 0.0006  memory: 861  \n",
      "03/07 04:51:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][500/647]    eta: 0:00:04  time: 0.0311  data_time: 0.0007  memory: 861  \n",
      "03/07 04:51:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][600/647]    eta: 0:00:01  time: 0.0312  data_time: 0.0010  memory: 861  \n",
      "[0]\n",
      "[13]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[11]\n",
      "[13]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[13]\n",
      "[17]\n",
      "[18]\n",
      "[5]\n",
      "[14]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[3]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[3]\n",
      "[3]\n",
      "[11]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[11]\n",
      "[14]\n",
      "[13]\n",
      "[20]\n",
      "[7]\n",
      "[13]\n",
      "[13]\n",
      "[4]\n",
      "[0]\n",
      "[7]\n",
      "[11]\n",
      "[13]\n",
      "[1]\n",
      "[5]\n",
      "[13]\n",
      "[8]\n",
      "[11]\n",
      "[18]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[21]\n",
      "[13]\n",
      "[13]\n",
      "[17]\n",
      "[18]\n",
      "[14]\n",
      "[14]\n",
      "[18]\n",
      "[7]\n",
      "[5]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n",
      "[11]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[23]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[11]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[13]\n",
      "[11]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[15]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[24]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[11]\n",
      "[25]\n",
      "[25]\n",
      "[26]\n",
      "[43]\n",
      "[31]\n",
      "[34]\n",
      "[106]\n",
      "[30]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[82]\n",
      "[30]\n",
      "[41]\n",
      "[111]\n",
      "[109]\n",
      "[116]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[4]\n",
      "[4]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[30]\n",
      "[34]\n",
      "[106]\n",
      "[19]\n",
      "[19]\n",
      "[4]\n",
      "[19]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[34]\n",
      "[34]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[35]\n",
      "[35]\n",
      "[35]\n",
      "[34]\n",
      "[66]\n",
      "[34]\n",
      "[111]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[97]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[89]\n",
      "[56]\n",
      "[57]\n",
      "[105]\n",
      "[56]\n",
      "[54]\n",
      "[57]\n",
      "[89]\n",
      "[0]\n",
      "[56]\n",
      "[57]\n",
      "[54]\n",
      "[56]\n",
      "[57]\n",
      "[44]\n",
      "[44]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[58]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[58]\n",
      "[58]\n",
      "[57]\n",
      "[58]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[55]\n",
      "[56]\n",
      "[54]\n",
      "[53]\n",
      "[53]\n",
      "[56]\n",
      "[44]\n",
      "[54]\n",
      "[56]\n",
      "[44]\n",
      "[55]\n",
      "[53]\n",
      "[54]\n",
      "[53]\n",
      "[59]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[56]\n",
      "[44]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[29]\n",
      "[63]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[46]\n",
      "[53]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[31]\n",
      "[69]\n",
      "[67]\n",
      "[63]\n",
      "[69]\n",
      "[31]\n",
      "[31]\n",
      "[69]\n",
      "[31]\n",
      "[40]\n",
      "[63]\n",
      "[65]\n",
      "[31]\n",
      "[31]\n",
      "[64]\n",
      "[64]\n",
      "[67]\n",
      "[53]\n",
      "[47]\n",
      "[47]\n",
      "[45]\n",
      "[31]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[29]\n",
      "[64]\n",
      "[45]\n",
      "[67]\n",
      "[31]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[53]\n",
      "[53]\n",
      "[70]\n",
      "[31]\n",
      "[69]\n",
      "[40]\n",
      "[70]\n",
      "[67]\n",
      "[69]\n",
      "[28]\n",
      "[116]\n",
      "[53]\n",
      "[110]\n",
      "[116]\n",
      "[122]\n",
      "[110]\n",
      "[109]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[122]\n",
      "[44]\n",
      "[110]\n",
      "[122]\n",
      "[110]\n",
      "[49]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[49]\n",
      "[116]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[71]\n",
      "[100]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[99]\n",
      "[100]\n",
      "[100]\n",
      "[99]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[100]\n",
      "[99]\n",
      "[100]\n",
      "[97]\n",
      "[97]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[99]\n",
      "[72]\n",
      "[77]\n",
      "[73]\n",
      "[72]\n",
      "[76]\n",
      "[77]\n",
      "[77]\n",
      "[78]\n",
      "[72]\n",
      "[79]\n",
      "[82]\n",
      "[7]\n",
      "[88]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[85]\n",
      "[89]\n",
      "[88]\n",
      "[88]\n",
      "[90]\n",
      "[60]\n",
      "[60]\n",
      "[73]\n",
      "[80]\n",
      "[79]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[88]\n",
      "[88]\n",
      "[73]\n",
      "[90]\n",
      "[90]\n",
      "[72]\n",
      "[60]\n",
      "[88]\n",
      "[72]\n",
      "[80]\n",
      "[80]\n",
      "[90]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[73]\n",
      "[86]\n",
      "[90]\n",
      "[72]\n",
      "[78]\n",
      "[73]\n",
      "[72]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[83]\n",
      "[88]\n",
      "[88]\n",
      "[30]\n",
      "[30]\n",
      "[83]\n",
      "[83]\n",
      "[105]\n",
      "[31]\n",
      "[112]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[91]\n",
      "[91]\n",
      "[82]\n",
      "[91]\n",
      "[100]\n",
      "[100]\n",
      "[31]\n",
      "[91]\n",
      "[91]\n",
      "[112]\n",
      "[91]\n",
      "[112]\n",
      "[87]\n",
      "[31]\n",
      "[97]\n",
      "[99]\n",
      "[49]\n",
      "[79]\n",
      "[71]\n",
      "[79]\n",
      "[40]\n",
      "[96]\n",
      "[102]\n",
      "[102]\n",
      "[101]\n",
      "[101]\n",
      "[98]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[92]\n",
      "[101]\n",
      "[92]\n",
      "[101]\n",
      "[103]\n",
      "[101]\n",
      "[103]\n",
      "[101]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[71]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[40]\n",
      "[101]\n",
      "[102]\n",
      "[101]\n",
      "[101]\n",
      "[92]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[92]\n",
      "[102]\n",
      "[102]\n",
      "[98]\n",
      "[79]\n",
      "[96]\n",
      "[92]\n",
      "[79]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[104]\n",
      "[92]\n",
      "[79]\n",
      "[96]\n",
      "[92]\n",
      "[79]\n",
      "[96]\n",
      "[97]\n",
      "[92]\n",
      "[99]\n",
      "[100]\n",
      "[104]\n",
      "[92]\n",
      "[33]\n",
      "[79]\n",
      "[107]\n",
      "[79]\n",
      "[34]\n",
      "[95]\n",
      "[79]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[97]\n",
      "[100]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[106]\n",
      "[106]\n",
      "[106]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[105]\n",
      "[106]\n",
      "[112]\n",
      "[88]\n",
      "[105]\n",
      "[110]\n",
      "[105]\n",
      "[109]\n",
      "[111]\n",
      "[109]\n",
      "[109]\n",
      "[89]\n",
      "[112]\n",
      "[112]\n",
      "[108]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[107]\n",
      "[107]\n",
      "[105]\n",
      "[105]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[107]\n",
      "[107]\n",
      "[107]\n",
      "[113]\n",
      "[113]\n",
      "[106]\n",
      "[106]\n",
      "[112]\n",
      "[110]\n",
      "[111]\n",
      "[109]\n",
      "[111]\n",
      "[109]\n",
      "[107]\n",
      "[107]\n",
      "[107]\n",
      "[107]\n",
      "[107]\n",
      "03/07 04:51:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][647/647]    acc/top1: 0.1994  acc/top5: 0.5317  acc/mean1: 0.2526  data_time: 0.0009  time: 0.0312\n",
      "03/07 04:51:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_15.pth is removed\n",
      "03/07 04:51:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.1994 acc/top1 at 17 epoch is saved to best_acc_top1_epoch_17.pth.\n",
      "03/07 04:52:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 100/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:54:06  time: 0.1638  data_time: 0.0019  memory: 10434  loss: 1.0505  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.0505\n",
      "03/07 04:52:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:52:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 200/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:53:50  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 1.4673  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4673\n",
      "03/07 04:52:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 300/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:53:34  time: 0.1643  data_time: 0.0017  memory: 10434  loss: 1.5945  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5945\n",
      "03/07 04:53:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 400/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:53:17  time: 0.1657  data_time: 0.0020  memory: 10434  loss: 1.4096  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4096\n",
      "03/07 04:53:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 500/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:53:01  time: 0.1638  data_time: 0.0018  memory: 10434  loss: 1.5260  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5260\n",
      "03/07 04:53:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 600/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:52:44  time: 0.1630  data_time: 0.0018  memory: 10434  loss: 1.6885  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6885\n",
      "03/07 04:53:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 700/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:52:28  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 1.2753  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.2753\n",
      "03/07 04:54:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 800/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:52:11  time: 0.1641  data_time: 0.0018  memory: 10434  loss: 1.3486  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.3486\n",
      "03/07 04:54:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 900/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:51:55  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 1.8762  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8762\n",
      "03/07 04:54:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1000/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:51:39  time: 0.1632  data_time: 0.0016  memory: 10434  loss: 1.4487  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4487\n",
      "03/07 04:55:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1100/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:51:22  time: 0.1649  data_time: 0.0019  memory: 10434  loss: 1.6753  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6753\n",
      "03/07 04:55:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:55:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1200/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:51:06  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 1.4900  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4900\n",
      "03/07 04:55:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1300/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:50:49  time: 0.1642  data_time: 0.0019  memory: 10434  loss: 1.5947  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5947\n",
      "03/07 04:55:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1400/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:50:33  time: 0.1632  data_time: 0.0019  memory: 10434  loss: 1.6199  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6199\n",
      "03/07 04:56:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1500/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:50:16  time: 0.1633  data_time: 0.0018  memory: 10434  loss: 1.3301  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.3301\n",
      "03/07 04:56:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1600/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:50:00  time: 0.1641  data_time: 0.0016  memory: 10434  loss: 1.9524  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9524\n",
      "03/07 04:56:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1700/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:49:44  time: 0.1660  data_time: 0.0019  memory: 10434  loss: 1.7368  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7368\n",
      "03/07 04:56:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1800/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:49:27  time: 0.1652  data_time: 0.0018  memory: 10434  loss: 1.6405  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6405\n",
      "03/07 04:57:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1900/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:49:11  time: 0.1630  data_time: 0.0019  memory: 10434  loss: 1.6892  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6892\n",
      "03/07 04:57:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2000/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:48:54  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 2.0002  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0002\n",
      "03/07 04:57:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2100/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:48:38  time: 0.1632  data_time: 0.0017  memory: 10434  loss: 2.1878  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1878\n",
      "03/07 04:57:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 04:58:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2200/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:48:21  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 1.7035  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7035\n",
      "03/07 04:58:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2300/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:48:05  time: 0.1636  data_time: 0.0019  memory: 10434  loss: 1.8338  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8338\n",
      "03/07 04:58:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2400/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:47:49  time: 0.1633  data_time: 0.0017  memory: 10434  loss: 1.5091  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5091\n",
      "03/07 04:58:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2500/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:47:32  time: 0.1630  data_time: 0.0019  memory: 10434  loss: 1.4860  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4860\n",
      "03/07 04:59:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2600/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:47:16  time: 0.1645  data_time: 0.0020  memory: 10434  loss: 1.5824  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5824\n",
      "03/07 04:59:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2700/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:46:59  time: 0.1648  data_time: 0.0019  memory: 10434  loss: 1.1673  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.1673\n",
      "03/07 04:59:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2800/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:46:43  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 1.6565  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6565\n",
      "03/07 04:59:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2900/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:46:26  time: 0.1640  data_time: 0.0015  memory: 10434  loss: 1.7919  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7919\n",
      "03/07 05:00:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3000/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:46:10  time: 0.1633  data_time: 0.0017  memory: 10434  loss: 1.8549  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.8549\n",
      "03/07 05:00:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3100/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:45:54  time: 0.1644  data_time: 0.0017  memory: 10434  loss: 1.7409  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7409\n",
      "03/07 05:00:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:00:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3200/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:45:37  time: 0.1654  data_time: 0.0018  memory: 10434  loss: 2.1107  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1107\n",
      "03/07 05:01:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3300/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:45:21  time: 0.1632  data_time: 0.0017  memory: 10434  loss: 1.1849  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1849\n",
      "03/07 05:01:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3400/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:45:04  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 1.4152  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4152\n",
      "03/07 05:01:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3500/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:44:48  time: 0.1635  data_time: 0.0020  memory: 10434  loss: 1.5120  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5120\n",
      "03/07 05:01:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3600/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:44:32  time: 0.1641  data_time: 0.0018  memory: 10434  loss: 1.4626  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4626\n",
      "03/07 05:02:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3700/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:44:15  time: 0.1629  data_time: 0.0017  memory: 10434  loss: 1.3179  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3179\n",
      "03/07 05:02:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3800/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:43:59  time: 0.1632  data_time: 0.0017  memory: 10434  loss: 1.2759  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2759\n",
      "03/07 05:02:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3900/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:43:42  time: 0.1647  data_time: 0.0017  memory: 10434  loss: 1.5392  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5392\n",
      "03/07 05:02:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4000/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:43:26  time: 0.1659  data_time: 0.0018  memory: 10434  loss: 1.3885  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3885\n",
      "03/07 05:03:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4100/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:43:10  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.5033  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5033\n",
      "03/07 05:03:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:03:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4200/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:42:53  time: 0.1632  data_time: 0.0020  memory: 10434  loss: 1.5798  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5798\n",
      "03/07 05:03:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4300/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:42:37  time: 0.1652  data_time: 0.0018  memory: 10434  loss: 1.2413  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2413\n",
      "03/07 05:04:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4400/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:42:20  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 1.1470  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1470\n",
      "03/07 05:04:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4500/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:42:04  time: 0.1648  data_time: 0.0018  memory: 10434  loss: 1.3729  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3729\n",
      "03/07 05:04:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4600/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:41:47  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 1.2219  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.2219\n",
      "03/07 05:04:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4700/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:41:31  time: 0.1647  data_time: 0.0019  memory: 10434  loss: 1.5878  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5878\n",
      "03/07 05:05:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4800/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:41:15  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 1.4064  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.4064\n",
      "03/07 05:05:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4900/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:40:58  time: 0.1634  data_time: 0.0018  memory: 10434  loss: 1.3077  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3077\n",
      "03/07 05:05:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][5000/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:40:42  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 0.9924  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.9924\n",
      "03/07 05:05:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][5100/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:40:25  time: 0.1645  data_time: 0.0020  memory: 10434  loss: 1.5443  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5443\n",
      "03/07 05:06:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:06:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][5200/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:40:09  time: 0.1644  data_time: 0.0018  memory: 10434  loss: 1.7259  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7259\n",
      "03/07 05:06:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:06:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][5225/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:40:05  time: 0.1598  data_time: 0.0019  memory: 10434  loss: 2.2527  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.2527\n",
      "03/07 05:06:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 18 epochs\n",
      "03/07 05:06:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][100/647]    eta: 0:00:17  time: 0.0312  data_time: 0.0010  memory: 861  \n",
      "03/07 05:06:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][200/647]    eta: 0:00:14  time: 0.0311  data_time: 0.0007  memory: 861  \n",
      "03/07 05:06:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][300/647]    eta: 0:00:10  time: 0.0312  data_time: 0.0008  memory: 861  \n",
      "03/07 05:06:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][400/647]    eta: 0:00:07  time: 0.0309  data_time: 0.0007  memory: 861  \n",
      "03/07 05:06:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][500/647]    eta: 0:00:04  time: 0.0312  data_time: 0.0008  memory: 861  \n",
      "03/07 05:06:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][600/647]    eta: 0:00:01  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "[0]\n",
      "[1]\n",
      "[17]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[4]\n",
      "[21]\n",
      "[17]\n",
      "[20]\n",
      "[5]\n",
      "[6]\n",
      "[23]\n",
      "[17]\n",
      "[17]\n",
      "[1]\n",
      "[17]\n",
      "[18]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[10]\n",
      "[1]\n",
      "[14]\n",
      "[0]\n",
      "[4]\n",
      "[4]\n",
      "[5]\n",
      "[4]\n",
      "[4]\n",
      "[5]\n",
      "[20]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[20]\n",
      "[5]\n",
      "[1]\n",
      "[23]\n",
      "[5]\n",
      "[17]\n",
      "[1]\n",
      "[17]\n",
      "[20]\n",
      "[1]\n",
      "[5]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[4]\n",
      "[4]\n",
      "[5]\n",
      "[4]\n",
      "[8]\n",
      "[17]\n",
      "[18]\n",
      "[11]\n",
      "[17]\n",
      "[11]\n",
      "[4]\n",
      "[1]\n",
      "[1]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[17]\n",
      "[18]\n",
      "[5]\n",
      "[5]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[4]\n",
      "[4]\n",
      "[5]\n",
      "[4]\n",
      "[5]\n",
      "[2]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[25]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[5]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[23]\n",
      "[26]\n",
      "[2]\n",
      "[5]\n",
      "[20]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[16]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[25]\n",
      "[25]\n",
      "[26]\n",
      "[43]\n",
      "[30]\n",
      "[4]\n",
      "[28]\n",
      "[30]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[45]\n",
      "[47]\n",
      "[4]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[93]\n",
      "[30]\n",
      "[29]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[30]\n",
      "[30]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[4]\n",
      "[4]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[30]\n",
      "[41]\n",
      "[106]\n",
      "[19]\n",
      "[19]\n",
      "[4]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[36]\n",
      "[27]\n",
      "[36]\n",
      "[41]\n",
      "[38]\n",
      "[38]\n",
      "[21]\n",
      "[36]\n",
      "[27]\n",
      "[36]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[96]\n",
      "[97]\n",
      "[96]\n",
      "[97]\n",
      "[97]\n",
      "[34]\n",
      "[97]\n",
      "[97]\n",
      "[35]\n",
      "[97]\n",
      "[96]\n",
      "[57]\n",
      "[52]\n",
      "[57]\n",
      "[122]\n",
      "[54]\n",
      "[45]\n",
      "[57]\n",
      "[89]\n",
      "[0]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[54]\n",
      "[57]\n",
      "[44]\n",
      "[44]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[59]\n",
      "[54]\n",
      "[58]\n",
      "[54]\n",
      "[52]\n",
      "[57]\n",
      "[58]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[53]\n",
      "[53]\n",
      "[58]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[10]\n",
      "[52]\n",
      "[54]\n",
      "[44]\n",
      "[51]\n",
      "[54]\n",
      "[53]\n",
      "[54]\n",
      "[15]\n",
      "[55]\n",
      "[54]\n",
      "[54]\n",
      "[44]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[53]\n",
      "[45]\n",
      "[53]\n",
      "[54]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[45]\n",
      "[55]\n",
      "[56]\n",
      "[56]\n",
      "[44]\n",
      "[56]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[52]\n",
      "[53]\n",
      "[44]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[52]\n",
      "[52]\n",
      "[45]\n",
      "[52]\n",
      "[52]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[52]\n",
      "[55]\n",
      "[30]\n",
      "[7]\n",
      "[48]\n",
      "[30]\n",
      "[31]\n",
      "[29]\n",
      "[63]\n",
      "[29]\n",
      "[29]\n",
      "[29]\n",
      "[29]\n",
      "[46]\n",
      "[48]\n",
      "[69]\n",
      "[27]\n",
      "[27]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[65]\n",
      "[48]\n",
      "[45]\n",
      "[52]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[48]\n",
      "[48]\n",
      "[45]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[29]\n",
      "[51]\n",
      "[69]\n",
      "[48]\n",
      "[48]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[53]\n",
      "[53]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[28]\n",
      "[97]\n",
      "[53]\n",
      "[110]\n",
      "[116]\n",
      "[122]\n",
      "[110]\n",
      "[121]\n",
      "[110]\n",
      "[110]\n",
      "[54]\n",
      "[110]\n",
      "[122]\n",
      "[44]\n",
      "[110]\n",
      "[122]\n",
      "[110]\n",
      "[53]\n",
      "[110]\n",
      "[110]\n",
      "[121]\n",
      "[122]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[71]\n",
      "[52]\n",
      "[99]\n",
      "[52]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[48]\n",
      "[53]\n",
      "[52]\n",
      "[99]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[52]\n",
      "[99]\n",
      "[99]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[97]\n",
      "[52]\n",
      "[72]\n",
      "[77]\n",
      "[86]\n",
      "[72]\n",
      "[76]\n",
      "[77]\n",
      "[77]\n",
      "[77]\n",
      "[75]\n",
      "[79]\n",
      "[7]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[76]\n",
      "[87]\n",
      "[90]\n",
      "[72]\n",
      "[75]\n",
      "[73]\n",
      "[80]\n",
      "[79]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[73]\n",
      "[90]\n",
      "[90]\n",
      "[72]\n",
      "[60]\n",
      "[73]\n",
      "[72]\n",
      "[1]\n",
      "[1]\n",
      "[77]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[86]\n",
      "[86]\n",
      "[90]\n",
      "[72]\n",
      "[78]\n",
      "[73]\n",
      "[72]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[75]\n",
      "[75]\n",
      "[77]\n",
      "[76]\n",
      "[83]\n",
      "[78]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[82]\n",
      "[83]\n",
      "[105]\n",
      "[31]\n",
      "[112]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[112]\n",
      "[30]\n",
      "[81]\n",
      "[82]\n",
      "[100]\n",
      "[100]\n",
      "[79]\n",
      "[91]\n",
      "[112]\n",
      "[112]\n",
      "[71]\n",
      "[112]\n",
      "[87]\n",
      "[71]\n",
      "[97]\n",
      "[111]\n",
      "[49]\n",
      "[96]\n",
      "[14]\n",
      "[71]\n",
      "[71]\n",
      "[101]\n",
      "[101]\n",
      "[102]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[92]\n",
      "[92]\n",
      "[101]\n",
      "[101]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[71]\n",
      "[92]\n",
      "[101]\n",
      "[100]\n",
      "[101]\n",
      "[92]\n",
      "[92]\n",
      "[100]\n",
      "[92]\n",
      "[71]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[101]\n",
      "[79]\n",
      "[92]\n",
      "[101]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[102]\n",
      "[102]\n",
      "[92]\n",
      "[1]\n",
      "[96]\n",
      "[92]\n",
      "[92]\n",
      "[0]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[96]\n",
      "[92]\n",
      "[79]\n",
      "[97]\n",
      "[97]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[97]\n",
      "[97]\n",
      "[107]\n",
      "[97]\n",
      "[107]\n",
      "[95]\n",
      "[97]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[97]\n",
      "[97]\n",
      "[100]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[108]\n",
      "[108]\n",
      "[112]\n",
      "[108]\n",
      "[112]\n",
      "[110]\n",
      "[112]\n",
      "[108]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[107]\n",
      "[111]\n",
      "[111]\n",
      "[105]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[106]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[110]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[109]\n",
      "[107]\n",
      "[107]\n",
      "[107]\n",
      "[107]\n",
      "[106]\n",
      "03/07 05:06:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][647/647]    acc/top1: 0.2427  acc/top5: 0.5595  acc/mean1: 0.2975  data_time: 0.0009  time: 0.0312\n",
      "03/07 05:06:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_17.pth is removed\n",
      "03/07 05:06:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.2427 acc/top1 at 18 epoch is saved to best_acc_top1_epoch_18.pth.\n",
      "03/07 05:06:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 100/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:39:48  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.5679  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5679\n",
      "03/07 05:07:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 200/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:39:32  time: 0.1635  data_time: 0.0020  memory: 10434  loss: 1.2850  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2850\n",
      "03/07 05:07:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 300/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:39:15  time: 0.1645  data_time: 0.0018  memory: 10434  loss: 1.3444  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3444\n",
      "03/07 05:07:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 400/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:38:59  time: 0.1642  data_time: 0.0017  memory: 10434  loss: 1.4948  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4948\n",
      "03/07 05:08:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 500/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:38:43  time: 0.1634  data_time: 0.0019  memory: 10434  loss: 1.2985  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2985\n",
      "03/07 05:08:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 600/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:38:26  time: 0.1628  data_time: 0.0017  memory: 10434  loss: 1.8410  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8410\n",
      "03/07 05:08:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 700/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:38:10  time: 0.1640  data_time: 0.0017  memory: 10434  loss: 1.8647  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8647\n",
      "03/07 05:08:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 800/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:37:53  time: 0.1667  data_time: 0.0018  memory: 10434  loss: 1.3760  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3760\n",
      "03/07 05:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 900/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:37:37  time: 0.1629  data_time: 0.0018  memory: 10434  loss: 1.5966  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5966\n",
      "03/07 05:09:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:09:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1000/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:37:21  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 1.4186  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4186\n",
      "03/07 05:09:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1100/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:37:04  time: 0.1648  data_time: 0.0020  memory: 10434  loss: 1.6235  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6235\n",
      "03/07 05:09:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1200/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:36:48  time: 0.1638  data_time: 0.0020  memory: 10434  loss: 1.4370  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4370\n",
      "03/07 05:10:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1300/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:36:31  time: 0.1631  data_time: 0.0017  memory: 10434  loss: 1.7119  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.7119\n",
      "03/07 05:10:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1400/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:36:15  time: 0.1630  data_time: 0.0019  memory: 10434  loss: 1.1684  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.1684\n",
      "03/07 05:10:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1500/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:35:58  time: 0.1640  data_time: 0.0018  memory: 10434  loss: 1.4846  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4846\n",
      "03/07 05:11:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1600/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:35:42  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 1.4220  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4220\n",
      "03/07 05:11:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1700/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:35:26  time: 0.1639  data_time: 0.0019  memory: 10434  loss: 1.2477  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2477\n",
      "03/07 05:11:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1800/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:35:09  time: 0.1636  data_time: 0.0019  memory: 10434  loss: 1.7332  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7332\n",
      "03/07 05:11:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1900/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:34:53  time: 0.1642  data_time: 0.0017  memory: 10434  loss: 1.2144  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2144\n",
      "03/07 05:12:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:12:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2000/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:34:36  time: 0.1634  data_time: 0.0020  memory: 10434  loss: 1.3244  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3244\n",
      "03/07 05:12:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2100/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:34:20  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 1.2770  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2770\n",
      "03/07 05:12:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2200/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:34:03  time: 0.1630  data_time: 0.0019  memory: 10434  loss: 1.4530  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4530\n",
      "03/07 05:12:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2300/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:33:47  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 1.7190  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.7190\n",
      "03/07 05:13:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2400/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:33:31  time: 0.1645  data_time: 0.0018  memory: 10434  loss: 1.4265  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4265\n",
      "03/07 05:13:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2500/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:33:14  time: 0.1639  data_time: 0.0017  memory: 10434  loss: 1.4473  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4473\n",
      "03/07 05:13:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2600/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:32:58  time: 0.1643  data_time: 0.0016  memory: 10434  loss: 1.9654  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9654\n",
      "03/07 05:14:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2700/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:32:41  time: 0.1633  data_time: 0.0018  memory: 10434  loss: 1.4154  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.4154\n",
      "03/07 05:14:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2800/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:32:25  time: 0.1644  data_time: 0.0019  memory: 10434  loss: 1.8317  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8317\n",
      "03/07 05:14:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2900/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:32:08  time: 0.1641  data_time: 0.0018  memory: 10434  loss: 1.5123  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5123\n",
      "03/07 05:14:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:14:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3000/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:31:52  time: 0.1647  data_time: 0.0019  memory: 10434  loss: 1.3230  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3230\n",
      "03/07 05:15:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3100/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:31:36  time: 0.1638  data_time: 0.0016  memory: 10434  loss: 1.7699  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7699\n",
      "03/07 05:15:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3200/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:31:19  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 1.8739  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8739\n",
      "03/07 05:15:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3300/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:31:03  time: 0.1627  data_time: 0.0019  memory: 10434  loss: 1.4064  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4064\n",
      "03/07 05:15:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3400/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:30:46  time: 0.1648  data_time: 0.0018  memory: 10434  loss: 1.6239  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.6239\n",
      "03/07 05:16:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3500/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:30:30  time: 0.1634  data_time: 0.0018  memory: 10434  loss: 1.9555  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9555\n",
      "03/07 05:16:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3600/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:30:13  time: 0.1638  data_time: 0.0018  memory: 10434  loss: 1.8279  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8279\n",
      "03/07 05:16:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3700/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:29:57  time: 0.1634  data_time: 0.0016  memory: 10434  loss: 1.4049  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4049\n",
      "03/07 05:17:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3800/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:29:41  time: 0.1643  data_time: 0.0018  memory: 10434  loss: 1.2308  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2308\n",
      "03/07 05:17:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3900/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:29:24  time: 0.1643  data_time: 0.0019  memory: 10434  loss: 1.5337  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5337\n",
      "03/07 05:17:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:17:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4000/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:29:08  time: 0.1637  data_time: 0.0019  memory: 10434  loss: 1.6889  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6889\n",
      "03/07 05:17:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4100/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:28:51  time: 0.1633  data_time: 0.0018  memory: 10434  loss: 1.5895  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5895\n",
      "03/07 05:18:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4200/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:28:35  time: 0.1639  data_time: 0.0019  memory: 10434  loss: 1.6256  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6256\n",
      "03/07 05:18:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4300/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:28:18  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 1.5782  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5782\n",
      "03/07 05:18:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4400/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:28:02  time: 0.1658  data_time: 0.0019  memory: 10434  loss: 1.5109  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5109\n",
      "03/07 05:18:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4500/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:27:46  time: 0.1650  data_time: 0.0020  memory: 10434  loss: 1.6292  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6292\n",
      "03/07 05:19:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4600/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:27:29  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.6657  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6657\n",
      "03/07 05:19:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4700/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:27:13  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 1.6953  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6953\n",
      "03/07 05:19:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4800/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:26:56  time: 0.1633  data_time: 0.0018  memory: 10434  loss: 1.9446  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.9446\n",
      "03/07 05:20:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4900/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:26:40  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 1.6730  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.6730\n",
      "03/07 05:20:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:20:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][5000/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:26:24  time: 0.1630  data_time: 0.0018  memory: 10434  loss: 1.4363  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4363\n",
      "03/07 05:20:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][5100/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:26:07  time: 0.1659  data_time: 0.0017  memory: 10434  loss: 1.5281  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5281\n",
      "03/07 05:20:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][5200/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:25:51  time: 0.1654  data_time: 0.0019  memory: 10434  loss: 1.6149  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.6149\n",
      "03/07 05:20:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:20:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][5225/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:25:47  time: 0.1611  data_time: 0.0021  memory: 10434  loss: 1.4337  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4337\n",
      "03/07 05:21:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][100/647]    eta: 0:00:17  time: 0.0311  data_time: 0.0009  memory: 861  \n",
      "03/07 05:21:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][200/647]    eta: 0:00:13  time: 0.0309  data_time: 0.0008  memory: 861  \n",
      "03/07 05:21:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][300/647]    eta: 0:00:10  time: 0.0311  data_time: 0.0010  memory: 861  \n",
      "03/07 05:21:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][400/647]    eta: 0:00:07  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "03/07 05:21:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][500/647]    eta: 0:00:04  time: 0.0310  data_time: 0.0009  memory: 861  \n",
      "03/07 05:21:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][600/647]    eta: 0:00:01  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "[0]\n",
      "[13]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[2]\n",
      "[4]\n",
      "[8]\n",
      "[14]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[17]\n",
      "[13]\n",
      "[17]\n",
      "[18]\n",
      "[5]\n",
      "[5]\n",
      "[4]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[3]\n",
      "[13]\n",
      "[3]\n",
      "[13]\n",
      "[4]\n",
      "[3]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[13]\n",
      "[17]\n",
      "[20]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[13]\n",
      "[8]\n",
      "[17]\n",
      "[18]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[4]\n",
      "[13]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[18]\n",
      "[2]\n",
      "[5]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[4]\n",
      "[2]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[26]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[5]\n",
      "[0]\n",
      "[13]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[12]\n",
      "[22]\n",
      "[26]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[24]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[11]\n",
      "[25]\n",
      "[25]\n",
      "[26]\n",
      "[43]\n",
      "[31]\n",
      "[4]\n",
      "[28]\n",
      "[27]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[7]\n",
      "[14]\n",
      "[34]\n",
      "[30]\n",
      "[30]\n",
      "[93]\n",
      "[31]\n",
      "[93]\n",
      "[13]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[30]\n",
      "[30]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[4]\n",
      "[4]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[39]\n",
      "[34]\n",
      "[106]\n",
      "[19]\n",
      "[19]\n",
      "[3]\n",
      "[34]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[34]\n",
      "[34]\n",
      "[3]\n",
      "[41]\n",
      "[35]\n",
      "[38]\n",
      "[5]\n",
      "[41]\n",
      "[36]\n",
      "[115]\n",
      "[34]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[96]\n",
      "[5]\n",
      "[96]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[97]\n",
      "[96]\n",
      "[34]\n",
      "[8]\n",
      "[96]\n",
      "[57]\n",
      "[52]\n",
      "[57]\n",
      "[122]\n",
      "[54]\n",
      "[45]\n",
      "[57]\n",
      "[89]\n",
      "[0]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[55]\n",
      "[57]\n",
      "[44]\n",
      "[44]\n",
      "[52]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[15]\n",
      "[52]\n",
      "[58]\n",
      "[48]\n",
      "[52]\n",
      "[57]\n",
      "[48]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[58]\n",
      "[58]\n",
      "[57]\n",
      "[58]\n",
      "[53]\n",
      "[48]\n",
      "[58]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[53]\n",
      "[52]\n",
      "[55]\n",
      "[44]\n",
      "[51]\n",
      "[55]\n",
      "[53]\n",
      "[54]\n",
      "[55]\n",
      "[55]\n",
      "[54]\n",
      "[54]\n",
      "[44]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[53]\n",
      "[45]\n",
      "[53]\n",
      "[55]\n",
      "[55]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[0]\n",
      "[55]\n",
      "[12]\n",
      "[56]\n",
      "[44]\n",
      "[56]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[51]\n",
      "[51]\n",
      "[53]\n",
      "[44]\n",
      "[44]\n",
      "[51]\n",
      "[57]\n",
      "[52]\n",
      "[52]\n",
      "[44]\n",
      "[52]\n",
      "[52]\n",
      "[48]\n",
      "[4]\n",
      "[56]\n",
      "[51]\n",
      "[55]\n",
      "[31]\n",
      "[48]\n",
      "[48]\n",
      "[30]\n",
      "[31]\n",
      "[29]\n",
      "[63]\n",
      "[67]\n",
      "[7]\n",
      "[29]\n",
      "[29]\n",
      "[46]\n",
      "[48]\n",
      "[69]\n",
      "[28]\n",
      "[27]\n",
      "[69]\n",
      "[69]\n",
      "[28]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[68]\n",
      "[40]\n",
      "[27]\n",
      "[65]\n",
      "[48]\n",
      "[45]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[68]\n",
      "[68]\n",
      "[40]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[29]\n",
      "[29]\n",
      "[69]\n",
      "[67]\n",
      "[48]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[40]\n",
      "[40]\n",
      "[40]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[40]\n",
      "[68]\n",
      "[69]\n",
      "[28]\n",
      "[97]\n",
      "[53]\n",
      "[110]\n",
      "[116]\n",
      "[122]\n",
      "[110]\n",
      "[121]\n",
      "[110]\n",
      "[110]\n",
      "[45]\n",
      "[110]\n",
      "[44]\n",
      "[44]\n",
      "[110]\n",
      "[122]\n",
      "[110]\n",
      "[48]\n",
      "[110]\n",
      "[110]\n",
      "[44]\n",
      "[122]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[52]\n",
      "[71]\n",
      "[52]\n",
      "[99]\n",
      "[52]\n",
      "[100]\n",
      "[100]\n",
      "[99]\n",
      "[48]\n",
      "[48]\n",
      "[52]\n",
      "[52]\n",
      "[48]\n",
      "[100]\n",
      "[100]\n",
      "[97]\n",
      "[100]\n",
      "[100]\n",
      "[97]\n",
      "[100]\n",
      "[52]\n",
      "[7]\n",
      "[100]\n",
      "[52]\n",
      "[52]\n",
      "[100]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[72]\n",
      "[77]\n",
      "[73]\n",
      "[72]\n",
      "[75]\n",
      "[76]\n",
      "[77]\n",
      "[77]\n",
      "[75]\n",
      "[79]\n",
      "[81]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[86]\n",
      "[85]\n",
      "[86]\n",
      "[85]\n",
      "[87]\n",
      "[76]\n",
      "[85]\n",
      "[78]\n",
      "[75]\n",
      "[75]\n",
      "[73]\n",
      "[87]\n",
      "[75]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[76]\n",
      "[76]\n",
      "[76]\n",
      "[76]\n",
      "[73]\n",
      "[76]\n",
      "[90]\n",
      "[75]\n",
      "[75]\n",
      "[73]\n",
      "[87]\n",
      "[75]\n",
      "[75]\n",
      "[77]\n",
      "[77]\n",
      "[75]\n",
      "[75]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[3]\n",
      "[86]\n",
      "[88]\n",
      "[72]\n",
      "[76]\n",
      "[73]\n",
      "[79]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[3]\n",
      "[87]\n",
      "[75]\n",
      "[75]\n",
      "[77]\n",
      "[76]\n",
      "[73]\n",
      "[76]\n",
      "[88]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[105]\n",
      "[31]\n",
      "[112]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[112]\n",
      "[91]\n",
      "[82]\n",
      "[91]\n",
      "[30]\n",
      "[100]\n",
      "[30]\n",
      "[91]\n",
      "[112]\n",
      "[112]\n",
      "[91]\n",
      "[112]\n",
      "[30]\n",
      "[71]\n",
      "[97]\n",
      "[99]\n",
      "[99]\n",
      "[96]\n",
      "[71]\n",
      "[71]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[71]\n",
      "[101]\n",
      "[101]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[101]\n",
      "[92]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[103]\n",
      "[71]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[101]\n",
      "[103]\n",
      "[102]\n",
      "[101]\n",
      "[100]\n",
      "[102]\n",
      "[100]\n",
      "[102]\n",
      "[100]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[96]\n",
      "[96]\n",
      "[2]\n",
      "[0]\n",
      "[2]\n",
      "[0]\n",
      "[0]\n",
      "[92]\n",
      "[100]\n",
      "[104]\n",
      "[92]\n",
      "[0]\n",
      "[96]\n",
      "[92]\n",
      "[2]\n",
      "[96]\n",
      "[97]\n",
      "[2]\n",
      "[100]\n",
      "[100]\n",
      "[104]\n",
      "[92]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[34]\n",
      "[95]\n",
      "[97]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[97]\n",
      "[100]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[110]\n",
      "[112]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[112]\n",
      "[112]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[106]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[107]\n",
      "[109]\n",
      "[110]\n",
      "[107]\n",
      "[106]\n",
      "03/07 05:21:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][647/647]    acc/top1: 0.2473  acc/top5: 0.5641  acc/mean1: 0.2828  data_time: 0.0009  time: 0.0311\n",
      "03/07 05:21:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_18.pth is removed\n",
      "03/07 05:21:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.2473 acc/top1 at 19 epoch is saved to best_acc_top1_epoch_19.pth.\n",
      "03/07 05:21:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 100/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:25:30  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 1.4957  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4957\n",
      "03/07 05:21:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 200/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:25:14  time: 0.1651  data_time: 0.0018  memory: 10434  loss: 1.6143  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6143\n",
      "03/07 05:22:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 300/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:24:57  time: 0.1638  data_time: 0.0017  memory: 10434  loss: 1.3107  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3107\n",
      "03/07 05:22:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 400/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:24:41  time: 0.1642  data_time: 0.0018  memory: 10434  loss: 1.5605  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5605\n",
      "03/07 05:22:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 500/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:24:24  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 1.6851  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6851\n",
      "03/07 05:22:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 600/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:24:08  time: 0.1648  data_time: 0.0019  memory: 10434  loss: 1.3333  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3333\n",
      "03/07 05:23:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 700/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:23:52  time: 0.1645  data_time: 0.0019  memory: 10434  loss: 1.2518  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2518\n",
      "03/07 05:23:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:23:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 800/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:23:35  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 1.1293  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1293\n",
      "03/07 05:23:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 900/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:23:19  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 1.6827  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6827\n",
      "03/07 05:24:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1000/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:23:02  time: 0.1644  data_time: 0.0018  memory: 10434  loss: 1.5012  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5012\n",
      "03/07 05:24:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1100/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:22:46  time: 0.1644  data_time: 0.0018  memory: 10434  loss: 1.1674  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1674\n",
      "03/07 05:24:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1200/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:22:30  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 1.3170  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3170\n",
      "03/07 05:24:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1300/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:22:13  time: 0.1651  data_time: 0.0019  memory: 10434  loss: 1.4006  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4006\n",
      "03/07 05:25:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1400/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:21:57  time: 0.1651  data_time: 0.0019  memory: 10434  loss: 1.4509  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4509\n",
      "03/07 05:25:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1500/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:21:40  time: 0.1637  data_time: 0.0019  memory: 10434  loss: 1.5156  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5156\n",
      "03/07 05:25:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1600/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:21:24  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.7235  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7235\n",
      "03/07 05:25:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1700/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:21:07  time: 0.1637  data_time: 0.0019  memory: 10434  loss: 1.8983  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8983\n",
      "03/07 05:26:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:26:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1800/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:20:51  time: 0.1627  data_time: 0.0018  memory: 10434  loss: 1.1308  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1308\n",
      "03/07 05:26:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1900/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:20:35  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 1.6600  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6600\n",
      "03/07 05:26:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2000/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:20:18  time: 0.1647  data_time: 0.0018  memory: 10434  loss: 1.3794  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.3794\n",
      "03/07 05:27:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2100/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:20:02  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 1.5657  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5657\n",
      "03/07 05:27:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2200/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:19:45  time: 0.1630  data_time: 0.0018  memory: 10434  loss: 1.5332  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5332\n",
      "03/07 05:27:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2300/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:19:29  time: 0.1641  data_time: 0.0018  memory: 10434  loss: 1.4419  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4419\n",
      "03/07 05:27:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2400/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:19:12  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 1.5283  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5283\n",
      "03/07 05:28:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2500/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:18:56  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 1.3337  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3337\n",
      "03/07 05:28:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2600/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:18:40  time: 0.1644  data_time: 0.0019  memory: 10434  loss: 1.4025  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4025\n",
      "03/07 05:28:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2700/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:18:23  time: 0.1642  data_time: 0.0017  memory: 10434  loss: 1.1223  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1223\n",
      "03/07 05:28:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:28:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2800/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:18:07  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 1.0032  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.0032\n",
      "03/07 05:29:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2900/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:17:50  time: 0.1634  data_time: 0.0016  memory: 10434  loss: 1.7459  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7459\n",
      "03/07 05:29:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3000/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:17:34  time: 0.1638  data_time: 0.0017  memory: 10434  loss: 1.5914  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5914\n",
      "03/07 05:29:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3100/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:17:18  time: 0.1643  data_time: 0.0018  memory: 10434  loss: 1.7028  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7028\n",
      "03/07 05:30:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3200/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:17:01  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 1.6251  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6251\n",
      "03/07 05:30:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3300/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:16:45  time: 0.1632  data_time: 0.0019  memory: 10434  loss: 1.3397  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3397\n",
      "03/07 05:30:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3400/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:16:28  time: 0.1637  data_time: 0.0017  memory: 10434  loss: 1.5126  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5126\n",
      "03/07 05:30:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3500/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:16:12  time: 0.1648  data_time: 0.0019  memory: 10434  loss: 1.3825  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3825\n",
      "03/07 05:31:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3600/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:15:55  time: 0.1648  data_time: 0.0017  memory: 10434  loss: 1.0843  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0843\n",
      "03/07 05:31:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3700/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:15:39  time: 0.1640  data_time: 0.0017  memory: 10434  loss: 1.6826  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6826\n",
      "03/07 05:31:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:31:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3800/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:15:23  time: 0.1638  data_time: 0.0018  memory: 10434  loss: 1.1091  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.1091\n",
      "03/07 05:31:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3900/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:15:06  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 1.3616  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3616\n",
      "03/07 05:32:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4000/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:14:50  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 1.5696  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5696\n",
      "03/07 05:32:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4100/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:14:33  time: 0.1641  data_time: 0.0018  memory: 10434  loss: 1.2506  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2506\n",
      "03/07 05:32:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4200/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:14:17  time: 0.1660  data_time: 0.0017  memory: 10434  loss: 1.5099  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5099\n",
      "03/07 05:33:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4300/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:14:01  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 1.2393  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2393\n",
      "03/07 05:33:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4400/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:13:44  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.2157  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2157\n",
      "03/07 05:33:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4500/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:13:28  time: 0.1643  data_time: 0.0019  memory: 10434  loss: 1.3539  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3539\n",
      "03/07 05:33:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4600/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:13:11  time: 0.1643  data_time: 0.0020  memory: 10434  loss: 1.5728  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5728\n",
      "03/07 05:34:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4700/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:12:55  time: 0.1638  data_time: 0.0017  memory: 10434  loss: 1.1823  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1823\n",
      "03/07 05:34:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:34:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4800/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:12:38  time: 0.1638  data_time: 0.0018  memory: 10434  loss: 1.5557  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5557\n",
      "03/07 05:34:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4900/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:12:22  time: 0.1645  data_time: 0.0018  memory: 10434  loss: 1.6135  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6135\n",
      "03/07 05:34:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][5000/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:12:06  time: 0.1646  data_time: 0.0019  memory: 10434  loss: 1.2222  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2222\n",
      "03/07 05:35:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][5100/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:11:49  time: 0.1647  data_time: 0.0017  memory: 10434  loss: 1.4449  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4449\n",
      "03/07 05:35:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][5200/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:11:33  time: 0.1636  data_time: 0.0019  memory: 10434  loss: 1.1011  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1011\n",
      "03/07 05:35:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:35:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][5225/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:11:29  time: 0.1611  data_time: 0.0018  memory: 10434  loss: 1.7693  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7693\n",
      "03/07 05:35:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][100/647]    eta: 0:00:17  time: 0.0311  data_time: 0.0008  memory: 861  \n",
      "03/07 05:35:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][200/647]    eta: 0:00:13  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "03/07 05:35:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][300/647]    eta: 0:00:10  time: 0.0311  data_time: 0.0009  memory: 861  \n",
      "03/07 05:35:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][400/647]    eta: 0:00:07  time: 0.0310  data_time: 0.0009  memory: 861  \n",
      "03/07 05:35:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][500/647]    eta: 0:00:04  time: 0.0309  data_time: 0.0009  memory: 861  \n",
      "03/07 05:35:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][600/647]    eta: 0:00:01  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[2]\n",
      "[3]\n",
      "[2]\n",
      "[4]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[1]\n",
      "[17]\n",
      "[18]\n",
      "[5]\n",
      "[20]\n",
      "[5]\n",
      "[14]\n",
      "[13]\n",
      "[2]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[5]\n",
      "[1]\n",
      "[3]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[13]\n",
      "[11]\n",
      "[17]\n",
      "[1]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[13]\n",
      "[1]\n",
      "[2]\n",
      "[4]\n",
      "[2]\n",
      "[3]\n",
      "[1]\n",
      "[5]\n",
      "[5]\n",
      "[8]\n",
      "[11]\n",
      "[18]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[5]\n",
      "[13]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[2]\n",
      "[5]\n",
      "[5]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[26]\n",
      "[4]\n",
      "[5]\n",
      "[12]\n",
      "[5]\n",
      "[2]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[26]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[5]\n",
      "[2]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[26]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[24]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[11]\n",
      "[25]\n",
      "[25]\n",
      "[26]\n",
      "[5]\n",
      "[31]\n",
      "[4]\n",
      "[31]\n",
      "[30]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[4]\n",
      "[14]\n",
      "[4]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[13]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[30]\n",
      "[30]\n",
      "[4]\n",
      "[41]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[4]\n",
      "[4]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[30]\n",
      "[41]\n",
      "[42]\n",
      "[19]\n",
      "[19]\n",
      "[4]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[40]\n",
      "[41]\n",
      "[41]\n",
      "[35]\n",
      "[38]\n",
      "[5]\n",
      "[21]\n",
      "[36]\n",
      "[115]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[122]\n",
      "[54]\n",
      "[45]\n",
      "[57]\n",
      "[89]\n",
      "[0]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[55]\n",
      "[57]\n",
      "[44]\n",
      "[44]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[56]\n",
      "[6]\n",
      "[58]\n",
      "[45]\n",
      "[57]\n",
      "[6]\n",
      "[58]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[53]\n",
      "[48]\n",
      "[58]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[53]\n",
      "[52]\n",
      "[55]\n",
      "[55]\n",
      "[51]\n",
      "[55]\n",
      "[53]\n",
      "[54]\n",
      "[55]\n",
      "[55]\n",
      "[54]\n",
      "[15]\n",
      "[44]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[53]\n",
      "[45]\n",
      "[53]\n",
      "[55]\n",
      "[55]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[47]\n",
      "[55]\n",
      "[12]\n",
      "[56]\n",
      "[44]\n",
      "[56]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[53]\n",
      "[51]\n",
      "[53]\n",
      "[45]\n",
      "[56]\n",
      "[51]\n",
      "[57]\n",
      "[52]\n",
      "[12]\n",
      "[45]\n",
      "[52]\n",
      "[52]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[51]\n",
      "[55]\n",
      "[31]\n",
      "[48]\n",
      "[48]\n",
      "[40]\n",
      "[31]\n",
      "[29]\n",
      "[63]\n",
      "[64]\n",
      "[63]\n",
      "[29]\n",
      "[29]\n",
      "[46]\n",
      "[47]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[63]\n",
      "[65]\n",
      "[48]\n",
      "[48]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[40]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[29]\n",
      "[64]\n",
      "[69]\n",
      "[47]\n",
      "[48]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[48]\n",
      "[53]\n",
      "[70]\n",
      "[40]\n",
      "[40]\n",
      "[40]\n",
      "[40]\n",
      "[68]\n",
      "[69]\n",
      "[52]\n",
      "[97]\n",
      "[53]\n",
      "[110]\n",
      "[116]\n",
      "[122]\n",
      "[110]\n",
      "[121]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[110]\n",
      "[44]\n",
      "[44]\n",
      "[53]\n",
      "[122]\n",
      "[110]\n",
      "[53]\n",
      "[110]\n",
      "[110]\n",
      "[54]\n",
      "[122]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[52]\n",
      "[99]\n",
      "[52]\n",
      "[99]\n",
      "[52]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[48]\n",
      "[48]\n",
      "[52]\n",
      "[52]\n",
      "[48]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[52]\n",
      "[7]\n",
      "[100]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[72]\n",
      "[77]\n",
      "[73]\n",
      "[72]\n",
      "[80]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[75]\n",
      "[81]\n",
      "[81]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[85]\n",
      "[89]\n",
      "[76]\n",
      "[85]\n",
      "[90]\n",
      "[72]\n",
      "[74]\n",
      "[73]\n",
      "[80]\n",
      "[79]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[76]\n",
      "[88]\n",
      "[88]\n",
      "[73]\n",
      "[90]\n",
      "[90]\n",
      "[72]\n",
      "[60]\n",
      "[86]\n",
      "[72]\n",
      "[80]\n",
      "[80]\n",
      "[78]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[86]\n",
      "[86]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[73]\n",
      "[72]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[74]\n",
      "[75]\n",
      "[77]\n",
      "[76]\n",
      "[83]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[83]\n",
      "[83]\n",
      "[105]\n",
      "[31]\n",
      "[112]\n",
      "[31]\n",
      "[71]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[82]\n",
      "[91]\n",
      "[30]\n",
      "[100]\n",
      "[30]\n",
      "[91]\n",
      "[112]\n",
      "[30]\n",
      "[71]\n",
      "[30]\n",
      "[87]\n",
      "[71]\n",
      "[97]\n",
      "[99]\n",
      "[83]\n",
      "[96]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[102]\n",
      "[101]\n",
      "[71]\n",
      "[101]\n",
      "[101]\n",
      "[102]\n",
      "[101]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[101]\n",
      "[40]\n",
      "[64]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[92]\n",
      "[92]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[71]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[101]\n",
      "[103]\n",
      "[101]\n",
      "[101]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[92]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[96]\n",
      "[96]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[92]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[2]\n",
      "[96]\n",
      "[92]\n",
      "[2]\n",
      "[96]\n",
      "[97]\n",
      "[2]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[96]\n",
      "[79]\n",
      "[107]\n",
      "[96]\n",
      "[107]\n",
      "[100]\n",
      "[96]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[52]\n",
      "[52]\n",
      "[100]\n",
      "[96]\n",
      "[97]\n",
      "[100]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[107]\n",
      "[111]\n",
      "[111]\n",
      "[105]\n",
      "[111]\n",
      "[112]\n",
      "[106]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[115]\n",
      "[105]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[109]\n",
      "[108]\n",
      "[112]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[107]\n",
      "[111]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[111]\n",
      "[111]\n",
      "[106]\n",
      "[107]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[111]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[107]\n",
      "[109]\n",
      "[107]\n",
      "03/07 05:35:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][647/647]    acc/top1: 0.2581  acc/top5: 0.5827  acc/mean1: 0.2965  data_time: 0.0009  time: 0.0311\n",
      "03/07 05:35:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_19.pth is removed\n",
      "03/07 05:35:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.2581 acc/top1 at 20 epoch is saved to best_acc_top1_epoch_20.pth.\n",
      "03/07 05:36:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 100/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:11:12  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 1.2219  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2219\n",
      "03/07 05:36:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 200/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:10:56  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 1.5155  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5155\n",
      "03/07 05:36:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 300/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:10:39  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 1.4690  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4690\n",
      "03/07 05:37:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 400/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:10:23  time: 0.1632  data_time: 0.0017  memory: 10434  loss: 1.5299  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5299\n",
      "03/07 05:37:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:37:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 500/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:10:07  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 1.5969  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5969\n",
      "03/07 05:37:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 600/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:09:50  time: 0.1648  data_time: 0.0018  memory: 10434  loss: 1.7116  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7116\n",
      "03/07 05:37:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 700/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:09:34  time: 0.1638  data_time: 0.0018  memory: 10434  loss: 1.1380  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1380\n",
      "03/07 05:38:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 800/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:09:17  time: 0.1633  data_time: 0.0018  memory: 10434  loss: 1.8121  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8121\n",
      "03/07 05:38:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 900/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:09:01  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 1.3150  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3150\n",
      "03/07 05:38:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1000/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:08:45  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 1.2621  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.2621\n",
      "03/07 05:38:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1100/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:08:28  time: 0.1650  data_time: 0.0018  memory: 10434  loss: 1.3233  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3233\n",
      "03/07 05:39:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1200/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:08:12  time: 0.1631  data_time: 0.0017  memory: 10434  loss: 1.5850  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5850\n",
      "03/07 05:39:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1300/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:07:55  time: 0.1638  data_time: 0.0018  memory: 10434  loss: 1.4152  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4152\n",
      "03/07 05:39:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1400/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:07:39  time: 0.1651  data_time: 0.0020  memory: 10434  loss: 1.5060  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5060\n",
      "03/07 05:40:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:40:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1500/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:07:22  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.3471  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3471\n",
      "03/07 05:40:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1600/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:07:06  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 1.4034  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4034\n",
      "03/07 05:40:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1700/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:06:50  time: 0.1639  data_time: 0.0019  memory: 10434  loss: 1.7625  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7625\n",
      "03/07 05:40:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1800/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:06:33  time: 0.1642  data_time: 0.0018  memory: 10434  loss: 0.9216  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.9216\n",
      "03/07 05:41:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1900/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:06:17  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.5517  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5517\n",
      "03/07 05:41:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2000/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:06:00  time: 0.1630  data_time: 0.0018  memory: 10434  loss: 1.9188  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9188\n",
      "03/07 05:41:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2100/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:05:44  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 1.5660  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5660\n",
      "03/07 05:41:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2200/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:05:27  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 1.2451  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.2451\n",
      "03/07 05:42:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2300/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:05:11  time: 0.1634  data_time: 0.0020  memory: 10434  loss: 1.6806  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6806\n",
      "03/07 05:42:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2400/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:04:55  time: 0.1643  data_time: 0.0019  memory: 10434  loss: 0.8027  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8027\n",
      "03/07 05:42:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:42:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2500/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:04:38  time: 0.1658  data_time: 0.0019  memory: 10434  loss: 1.3744  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.3744\n",
      "03/07 05:43:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2600/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:04:22  time: 0.1635  data_time: 0.0016  memory: 10434  loss: 1.4715  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4715\n",
      "03/07 05:43:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2700/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:04:05  time: 0.1639  data_time: 0.0017  memory: 10434  loss: 1.3489  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3489\n",
      "03/07 05:43:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2800/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:03:49  time: 0.1642  data_time: 0.0016  memory: 10434  loss: 1.4946  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4946\n",
      "03/07 05:43:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2900/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:03:33  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 1.1893  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1893\n",
      "03/07 05:44:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3000/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:03:16  time: 0.1629  data_time: 0.0019  memory: 10434  loss: 1.1518  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1518\n",
      "03/07 05:44:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3100/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:03:00  time: 0.1639  data_time: 0.0018  memory: 10434  loss: 1.4423  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4423\n",
      "03/07 05:44:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3200/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:02:43  time: 0.1649  data_time: 0.0019  memory: 10434  loss: 1.1617  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1617\n",
      "03/07 05:45:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3300/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:02:27  time: 0.1656  data_time: 0.0018  memory: 10434  loss: 1.1654  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1654\n",
      "03/07 05:45:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3400/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:02:10  time: 0.1632  data_time: 0.0019  memory: 10434  loss: 1.4947  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4947\n",
      "03/07 05:45:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:45:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3500/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:01:54  time: 0.1637  data_time: 0.0020  memory: 10434  loss: 1.1882  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1882\n",
      "03/07 05:45:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3600/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:01:38  time: 0.1649  data_time: 0.0018  memory: 10434  loss: 1.5637  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5637\n",
      "03/07 05:46:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3700/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:01:21  time: 0.1629  data_time: 0.0018  memory: 10434  loss: 1.3254  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3254\n",
      "03/07 05:46:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3800/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:01:05  time: 0.1632  data_time: 0.0019  memory: 10434  loss: 1.2272  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2272\n",
      "03/07 05:46:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3900/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:00:48  time: 0.1633  data_time: 0.0018  memory: 10434  loss: 1.4231  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4231\n",
      "03/07 05:46:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4000/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:00:32  time: 0.1638  data_time: 0.0018  memory: 10434  loss: 1.6799  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6799\n",
      "03/07 05:47:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4100/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:00:15  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 1.5367  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5367\n",
      "03/07 05:47:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4200/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:59:59  time: 0.1634  data_time: 0.0019  memory: 10434  loss: 1.3455  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3455\n",
      "03/07 05:47:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4300/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:59:43  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 1.0897  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.0897\n",
      "03/07 05:48:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4400/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:59:26  time: 0.1641  data_time: 0.0016  memory: 10434  loss: 1.3180  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3180\n",
      "03/07 05:48:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:48:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4500/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:59:10  time: 0.1636  data_time: 0.0019  memory: 10434  loss: 1.3610  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3610\n",
      "03/07 05:48:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4600/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:58:53  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 1.4651  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4651\n",
      "03/07 05:48:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4700/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:58:37  time: 0.1644  data_time: 0.0019  memory: 10434  loss: 1.1728  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1728\n",
      "03/07 05:49:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4800/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:58:21  time: 0.1642  data_time: 0.0017  memory: 10434  loss: 1.3770  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3770\n",
      "03/07 05:49:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4900/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:58:04  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 1.6088  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6088\n",
      "03/07 05:49:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][5000/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:57:48  time: 0.1630  data_time: 0.0019  memory: 10434  loss: 1.4443  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4443\n",
      "03/07 05:49:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][5100/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:57:31  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 1.4669  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4669\n",
      "03/07 05:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][5200/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:57:15  time: 0.1630  data_time: 0.0018  memory: 10434  loss: 1.6175  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6175\n",
      "03/07 05:50:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:50:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][5225/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:57:11  time: 0.1592  data_time: 0.0020  memory: 10434  loss: 1.4195  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4195\n",
      "03/07 05:50:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 21 epochs\n",
      "03/07 05:50:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][100/647]    eta: 0:00:17  time: 0.0311  data_time: 0.0009  memory: 861  \n",
      "03/07 05:50:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][200/647]    eta: 0:00:13  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "03/07 05:50:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][300/647]    eta: 0:00:10  time: 0.0311  data_time: 0.0008  memory: 861  \n",
      "03/07 05:50:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][400/647]    eta: 0:00:07  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "03/07 05:50:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][500/647]    eta: 0:00:04  time: 0.0312  data_time: 0.0009  memory: 861  \n",
      "03/07 05:50:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][600/647]    eta: 0:00:01  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "[0]\n",
      "[1]\n",
      "[18]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[4]\n",
      "[21]\n",
      "[17]\n",
      "[11]\n",
      "[12]\n",
      "[6]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[1]\n",
      "[17]\n",
      "[18]\n",
      "[5]\n",
      "[5]\n",
      "[4]\n",
      "[14]\n",
      "[13]\n",
      "[2]\n",
      "[0]\n",
      "[4]\n",
      "[4]\n",
      "[5]\n",
      "[4]\n",
      "[3]\n",
      "[9]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[1]\n",
      "[1]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[1]\n",
      "[17]\n",
      "[20]\n",
      "[20]\n",
      "[5]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[6]\n",
      "[4]\n",
      "[5]\n",
      "[1]\n",
      "[8]\n",
      "[17]\n",
      "[18]\n",
      "[11]\n",
      "[17]\n",
      "[11]\n",
      "[5]\n",
      "[13]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[0]\n",
      "[5]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[26]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[5]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[16]\n",
      "[24]\n",
      "[16]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[21]\n",
      "[5]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[26]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[16]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[11]\n",
      "[8]\n",
      "[8]\n",
      "[26]\n",
      "[16]\n",
      "[31]\n",
      "[4]\n",
      "[31]\n",
      "[41]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[4]\n",
      "[31]\n",
      "[4]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[13]\n",
      "[29]\n",
      "[42]\n",
      "[14]\n",
      "[43]\n",
      "[30]\n",
      "[30]\n",
      "[4]\n",
      "[41]\n",
      "[11]\n",
      "[19]\n",
      "[19]\n",
      "[4]\n",
      "[4]\n",
      "[43]\n",
      "[43]\n",
      "[34]\n",
      "[39]\n",
      "[34]\n",
      "[14]\n",
      "[19]\n",
      "[19]\n",
      "[4]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[34]\n",
      "[34]\n",
      "[41]\n",
      "[36]\n",
      "[35]\n",
      "[38]\n",
      "[5]\n",
      "[5]\n",
      "[36]\n",
      "[41]\n",
      "[36]\n",
      "[42]\n",
      "[21]\n",
      "[43]\n",
      "[19]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[15]\n",
      "[15]\n",
      "[34]\n",
      "[15]\n",
      "[96]\n",
      "[8]\n",
      "[96]\n",
      "[96]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[122]\n",
      "[9]\n",
      "[45]\n",
      "[57]\n",
      "[89]\n",
      "[0]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[55]\n",
      "[57]\n",
      "[44]\n",
      "[44]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[56]\n",
      "[15]\n",
      "[55]\n",
      "[58]\n",
      "[46]\n",
      "[57]\n",
      "[6]\n",
      "[58]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[55]\n",
      "[55]\n",
      "[58]\n",
      "[58]\n",
      "[46]\n",
      "[58]\n",
      "[58]\n",
      "[55]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[10]\n",
      "[56]\n",
      "[55]\n",
      "[55]\n",
      "[51]\n",
      "[55]\n",
      "[53]\n",
      "[55]\n",
      "[55]\n",
      "[55]\n",
      "[55]\n",
      "[54]\n",
      "[44]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[10]\n",
      "[59]\n",
      "[9]\n",
      "[55]\n",
      "[55]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[0]\n",
      "[56]\n",
      "[12]\n",
      "[56]\n",
      "[44]\n",
      "[56]\n",
      "[46]\n",
      "[45]\n",
      "[55]\n",
      "[45]\n",
      "[52]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[51]\n",
      "[57]\n",
      "[52]\n",
      "[12]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[12]\n",
      "[55]\n",
      "[31]\n",
      "[47]\n",
      "[48]\n",
      "[31]\n",
      "[31]\n",
      "[29]\n",
      "[63]\n",
      "[67]\n",
      "[7]\n",
      "[29]\n",
      "[29]\n",
      "[46]\n",
      "[47]\n",
      "[69]\n",
      "[65]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[44]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[30]\n",
      "[63]\n",
      "[65]\n",
      "[48]\n",
      "[45]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[45]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[29]\n",
      "[29]\n",
      "[45]\n",
      "[47]\n",
      "[9]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[48]\n",
      "[53]\n",
      "[70]\n",
      "[48]\n",
      "[69]\n",
      "[45]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[52]\n",
      "[98]\n",
      "[53]\n",
      "[110]\n",
      "[12]\n",
      "[122]\n",
      "[110]\n",
      "[121]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[110]\n",
      "[44]\n",
      "[44]\n",
      "[53]\n",
      "[122]\n",
      "[110]\n",
      "[53]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[122]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[71]\n",
      "[52]\n",
      "[71]\n",
      "[52]\n",
      "[71]\n",
      "[99]\n",
      "[99]\n",
      "[48]\n",
      "[48]\n",
      "[52]\n",
      "[52]\n",
      "[48]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[100]\n",
      "[52]\n",
      "[44]\n",
      "[100]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[72]\n",
      "[77]\n",
      "[73]\n",
      "[72]\n",
      "[76]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[75]\n",
      "[81]\n",
      "[82]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[85]\n",
      "[87]\n",
      "[76]\n",
      "[87]\n",
      "[78]\n",
      "[72]\n",
      "[74]\n",
      "[86]\n",
      "[87]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[76]\n",
      "[76]\n",
      "[88]\n",
      "[73]\n",
      "[88]\n",
      "[90]\n",
      "[72]\n",
      "[75]\n",
      "[86]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[77]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[87]\n",
      "[87]\n",
      "[86]\n",
      "[86]\n",
      "[90]\n",
      "[72]\n",
      "[78]\n",
      "[73]\n",
      "[72]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[74]\n",
      "[75]\n",
      "[77]\n",
      "[76]\n",
      "[83]\n",
      "[78]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[83]\n",
      "[83]\n",
      "[105]\n",
      "[31]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[82]\n",
      "[82]\n",
      "[30]\n",
      "[100]\n",
      "[30]\n",
      "[91]\n",
      "[112]\n",
      "[112]\n",
      "[30]\n",
      "[112]\n",
      "[87]\n",
      "[71]\n",
      "[71]\n",
      "[99]\n",
      "[99]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[40]\n",
      "[64]\n",
      "[101]\n",
      "[92]\n",
      "[101]\n",
      "[101]\n",
      "[102]\n",
      "[101]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[101]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[103]\n",
      "[103]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[100]\n",
      "[92]\n",
      "[71]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[101]\n",
      "[103]\n",
      "[92]\n",
      "[101]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[62]\n",
      "[102]\n",
      "[92]\n",
      "[2]\n",
      "[0]\n",
      "[92]\n",
      "[0]\n",
      "[2]\n",
      "[0]\n",
      "[0]\n",
      "[92]\n",
      "[100]\n",
      "[104]\n",
      "[92]\n",
      "[0]\n",
      "[0]\n",
      "[92]\n",
      "[2]\n",
      "[97]\n",
      "[97]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[104]\n",
      "[92]\n",
      "[96]\n",
      "[79]\n",
      "[107]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[52]\n",
      "[100]\n",
      "[98]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[108]\n",
      "[108]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[33]\n",
      "[112]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[108]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[105]\n",
      "[110]\n",
      "[112]\n",
      "[111]\n",
      "[106]\n",
      "[107]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[110]\n",
      "[111]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[107]\n",
      "[109]\n",
      "[110]\n",
      "[107]\n",
      "[106]\n",
      "03/07 05:50:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][647/647]    acc/top1: 0.2581  acc/top5: 0.5873  acc/mean1: 0.3088  data_time: 0.0008  time: 0.0311\n",
      "03/07 05:50:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 100/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:56:54  time: 0.1661  data_time: 0.0018  memory: 10434  loss: 1.3344  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3344\n",
      "03/07 05:51:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 200/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:56:38  time: 0.1639  data_time: 0.0020  memory: 10434  loss: 1.1617  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1617\n",
      "03/07 05:51:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:51:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 300/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:56:22  time: 0.1639  data_time: 0.0020  memory: 10434  loss: 1.5283  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5283\n",
      "03/07 05:51:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 400/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:56:05  time: 0.1642  data_time: 0.0019  memory: 10434  loss: 1.4869  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4869\n",
      "03/07 05:51:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 500/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:55:49  time: 0.1640  data_time: 0.0016  memory: 10434  loss: 1.2958  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2958\n",
      "03/07 05:52:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 600/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:55:32  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 1.1837  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.1837\n",
      "03/07 05:52:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 700/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:55:16  time: 0.1637  data_time: 0.0019  memory: 10434  loss: 1.2987  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2987\n",
      "03/07 05:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 800/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:54:59  time: 0.1645  data_time: 0.0018  memory: 10434  loss: 1.3515  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3515\n",
      "03/07 05:53:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 900/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:54:43  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 0.9790  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9790\n",
      "03/07 05:53:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1000/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:54:27  time: 0.1645  data_time: 0.0018  memory: 10434  loss: 1.2690  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.2690\n",
      "03/07 05:53:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1100/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:54:10  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 1.0765  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0765\n",
      "03/07 05:53:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1200/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:53:54  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 1.1239  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1239\n",
      "03/07 05:54:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:54:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1300/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:53:37  time: 0.1636  data_time: 0.0017  memory: 10434  loss: 1.4120  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4120\n",
      "03/07 05:54:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1400/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:53:21  time: 0.1627  data_time: 0.0020  memory: 10434  loss: 1.2196  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2196\n",
      "03/07 05:54:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1500/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:53:04  time: 0.1646  data_time: 0.0019  memory: 10434  loss: 1.0105  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0105\n",
      "03/07 05:55:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1600/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:52:48  time: 0.1653  data_time: 0.0018  memory: 10434  loss: 1.5374  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5374\n",
      "03/07 05:55:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1700/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:52:32  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 1.7711  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7711\n",
      "03/07 05:55:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1800/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:52:15  time: 0.1650  data_time: 0.0019  memory: 10434  loss: 1.3880  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3880\n",
      "03/07 05:55:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1900/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:51:59  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 1.4334  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4334\n",
      "03/07 05:56:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2000/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:51:42  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 1.5825  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5825\n",
      "03/07 05:56:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2100/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:51:26  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 1.7195  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7195\n",
      "03/07 05:56:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2200/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:51:10  time: 0.1650  data_time: 0.0019  memory: 10434  loss: 1.3775  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3775\n",
      "03/07 05:56:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:56:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2300/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:50:53  time: 0.1654  data_time: 0.0019  memory: 10434  loss: 1.1710  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1710\n",
      "03/07 05:57:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2400/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:50:37  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 1.3153  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3153\n",
      "03/07 05:57:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2500/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:50:20  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.2910  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2910\n",
      "03/07 05:57:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2600/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:50:04  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 1.3190  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3190\n",
      "03/07 05:58:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2700/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:49:47  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 1.0513  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.0513\n",
      "03/07 05:58:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2800/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:49:31  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 1.1219  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1219\n",
      "03/07 05:58:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2900/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:49:15  time: 0.1657  data_time: 0.0019  memory: 10434  loss: 1.3482  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3482\n",
      "03/07 05:58:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3000/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:48:58  time: 0.1630  data_time: 0.0017  memory: 10434  loss: 1.1812  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1812\n",
      "03/07 05:59:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3100/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:48:42  time: 0.1638  data_time: 0.0018  memory: 10434  loss: 1.3605  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3605\n",
      "03/07 05:59:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3200/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:48:25  time: 0.1647  data_time: 0.0017  memory: 10434  loss: 1.4110  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4110\n",
      "03/07 05:59:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 05:59:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3300/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:48:09  time: 0.1646  data_time: 0.0019  memory: 10434  loss: 1.1315  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.1315\n",
      "03/07 05:59:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3400/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:47:53  time: 0.1641  data_time: 0.0017  memory: 10434  loss: 1.0217  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.0217\n",
      "03/07 06:00:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3500/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:47:36  time: 0.1637  data_time: 0.0016  memory: 10434  loss: 1.1776  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1776\n",
      "03/07 06:00:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3600/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:47:20  time: 0.1629  data_time: 0.0020  memory: 10434  loss: 1.1385  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1385\n",
      "03/07 06:00:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3700/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:47:03  time: 0.1649  data_time: 0.0018  memory: 10434  loss: 1.2705  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2705\n",
      "03/07 06:01:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3800/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:46:47  time: 0.1648  data_time: 0.0019  memory: 10434  loss: 1.4106  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4106\n",
      "03/07 06:01:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3900/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:46:30  time: 0.1639  data_time: 0.0019  memory: 10434  loss: 1.1578  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.1578\n",
      "03/07 06:01:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4000/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:46:14  time: 0.1653  data_time: 0.0019  memory: 10434  loss: 1.0449  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0449\n",
      "03/07 06:01:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4100/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:45:58  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 1.5487  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5487\n",
      "03/07 06:02:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4200/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:45:41  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 1.0760  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0760\n",
      "03/07 06:02:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:02:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4300/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:45:25  time: 0.1637  data_time: 0.0019  memory: 10434  loss: 1.4184  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4184\n",
      "03/07 06:02:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4400/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:45:08  time: 0.1664  data_time: 0.0018  memory: 10434  loss: 1.5779  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5779\n",
      "03/07 06:02:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4500/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:44:52  time: 0.1665  data_time: 0.0017  memory: 10434  loss: 1.6323  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6323\n",
      "03/07 06:03:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4600/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:44:36  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 0.9926  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9926\n",
      "03/07 06:03:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4700/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:44:19  time: 0.1645  data_time: 0.0018  memory: 10434  loss: 1.4258  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4258\n",
      "03/07 06:03:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4800/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:44:03  time: 0.1646  data_time: 0.0019  memory: 10434  loss: 1.2824  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2824\n",
      "03/07 06:04:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4900/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:43:46  time: 0.1638  data_time: 0.0018  memory: 10434  loss: 1.2702  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2702\n",
      "03/07 06:04:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][5000/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:43:30  time: 0.1638  data_time: 0.0019  memory: 10434  loss: 1.4477  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4477\n",
      "03/07 06:04:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][5100/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:43:14  time: 0.1646  data_time: 0.0018  memory: 10434  loss: 1.5766  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5766\n",
      "03/07 06:04:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][5200/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:42:57  time: 0.1643  data_time: 0.0018  memory: 10434  loss: 1.3389  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3389\n",
      "03/07 06:04:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:04:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][5225/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:42:53  time: 0.1602  data_time: 0.0019  memory: 10434  loss: 1.4467  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4467\n",
      "03/07 06:04:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][100/647]    eta: 0:00:17  time: 0.0311  data_time: 0.0010  memory: 861  \n",
      "03/07 06:05:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][200/647]    eta: 0:00:13  time: 0.0312  data_time: 0.0007  memory: 861  \n",
      "03/07 06:05:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][300/647]    eta: 0:00:10  time: 0.0311  data_time: 0.0008  memory: 861  \n",
      "03/07 06:05:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][400/647]    eta: 0:00:07  time: 0.0311  data_time: 0.0007  memory: 861  \n",
      "03/07 06:05:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][500/647]    eta: 0:00:04  time: 0.0312  data_time: 0.0008  memory: 861  \n",
      "03/07 06:05:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][600/647]    eta: 0:00:01  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "[0]\n",
      "[1]\n",
      "[17]\n",
      "[3]\n",
      "[3]\n",
      "[2]\n",
      "[4]\n",
      "[21]\n",
      "[17]\n",
      "[11]\n",
      "[5]\n",
      "[14]\n",
      "[14]\n",
      "[25]\n",
      "[17]\n",
      "[1]\n",
      "[17]\n",
      "[18]\n",
      "[5]\n",
      "[20]\n",
      "[20]\n",
      "[14]\n",
      "[13]\n",
      "[11]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[5]\n",
      "[1]\n",
      "[3]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[1]\n",
      "[23]\n",
      "[17]\n",
      "[17]\n",
      "[1]\n",
      "[17]\n",
      "[20]\n",
      "[20]\n",
      "[21]\n",
      "[20]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[14]\n",
      "[1]\n",
      "[5]\n",
      "[1]\n",
      "[8]\n",
      "[17]\n",
      "[17]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[5]\n",
      "[13]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[5]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n",
      "[11]\n",
      "[26]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[21]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[25]\n",
      "[20]\n",
      "[24]\n",
      "[16]\n",
      "[26]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[5]\n",
      "[11]\n",
      "[1]\n",
      "[11]\n",
      "[3]\n",
      "[20]\n",
      "[5]\n",
      "[22]\n",
      "[26]\n",
      "[11]\n",
      "[11]\n",
      "[20]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[24]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[11]\n",
      "[25]\n",
      "[25]\n",
      "[26]\n",
      "[43]\n",
      "[31]\n",
      "[4]\n",
      "[28]\n",
      "[27]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[4]\n",
      "[31]\n",
      "[4]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[93]\n",
      "[30]\n",
      "[29]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[27]\n",
      "[27]\n",
      "[4]\n",
      "[41]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[4]\n",
      "[4]\n",
      "[29]\n",
      "[42]\n",
      "[34]\n",
      "[39]\n",
      "[41]\n",
      "[42]\n",
      "[19]\n",
      "[19]\n",
      "[4]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[34]\n",
      "[27]\n",
      "[36]\n",
      "[35]\n",
      "[38]\n",
      "[5]\n",
      "[21]\n",
      "[36]\n",
      "[41]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[19]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[122]\n",
      "[9]\n",
      "[54]\n",
      "[57]\n",
      "[89]\n",
      "[0]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[55]\n",
      "[57]\n",
      "[44]\n",
      "[44]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[56]\n",
      "[52]\n",
      "[58]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[58]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[58]\n",
      "[57]\n",
      "[57]\n",
      "[58]\n",
      "[53]\n",
      "[58]\n",
      "[58]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[52]\n",
      "[56]\n",
      "[52]\n",
      "[44]\n",
      "[51]\n",
      "[55]\n",
      "[53]\n",
      "[54]\n",
      "[15]\n",
      "[44]\n",
      "[52]\n",
      "[15]\n",
      "[44]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[53]\n",
      "[59]\n",
      "[9]\n",
      "[55]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[0]\n",
      "[56]\n",
      "[12]\n",
      "[56]\n",
      "[44]\n",
      "[56]\n",
      "[16]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[57]\n",
      "[57]\n",
      "[56]\n",
      "[56]\n",
      "[51]\n",
      "[57]\n",
      "[52]\n",
      "[12]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[51]\n",
      "[56]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[27]\n",
      "[31]\n",
      "[29]\n",
      "[63]\n",
      "[29]\n",
      "[64]\n",
      "[29]\n",
      "[29]\n",
      "[7]\n",
      "[48]\n",
      "[69]\n",
      "[28]\n",
      "[27]\n",
      "[53]\n",
      "[69]\n",
      "[28]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[61]\n",
      "[29]\n",
      "[65]\n",
      "[48]\n",
      "[48]\n",
      "[52]\n",
      "[47]\n",
      "[29]\n",
      "[47]\n",
      "[68]\n",
      "[68]\n",
      "[45]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[29]\n",
      "[29]\n",
      "[45]\n",
      "[67]\n",
      "[48]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[62]\n",
      "[48]\n",
      "[53]\n",
      "[70]\n",
      "[53]\n",
      "[40]\n",
      "[40]\n",
      "[70]\n",
      "[67]\n",
      "[69]\n",
      "[28]\n",
      "[98]\n",
      "[53]\n",
      "[110]\n",
      "[98]\n",
      "[122]\n",
      "[110]\n",
      "[121]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[53]\n",
      "[44]\n",
      "[44]\n",
      "[53]\n",
      "[122]\n",
      "[110]\n",
      "[53]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[98]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[52]\n",
      "[99]\n",
      "[52]\n",
      "[99]\n",
      "[52]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[48]\n",
      "[48]\n",
      "[52]\n",
      "[52]\n",
      "[48]\n",
      "[100]\n",
      "[99]\n",
      "[97]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[52]\n",
      "[97]\n",
      "[100]\n",
      "[52]\n",
      "[52]\n",
      "[100]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[72]\n",
      "[77]\n",
      "[86]\n",
      "[72]\n",
      "[80]\n",
      "[76]\n",
      "[77]\n",
      "[77]\n",
      "[75]\n",
      "[81]\n",
      "[81]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[85]\n",
      "[89]\n",
      "[76]\n",
      "[87]\n",
      "[90]\n",
      "[80]\n",
      "[74]\n",
      "[73]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[76]\n",
      "[77]\n",
      "[88]\n",
      "[73]\n",
      "[90]\n",
      "[90]\n",
      "[72]\n",
      "[60]\n",
      "[86]\n",
      "[72]\n",
      "[80]\n",
      "[80]\n",
      "[77]\n",
      "[90]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[86]\n",
      "[86]\n",
      "[90]\n",
      "[72]\n",
      "[77]\n",
      "[73]\n",
      "[72]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[83]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[83]\n",
      "[83]\n",
      "[105]\n",
      "[31]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[112]\n",
      "[112]\n",
      "[91]\n",
      "[82]\n",
      "[91]\n",
      "[30]\n",
      "[100]\n",
      "[79]\n",
      "[91]\n",
      "[112]\n",
      "[112]\n",
      "[71]\n",
      "[112]\n",
      "[30]\n",
      "[71]\n",
      "[97]\n",
      "[99]\n",
      "[84]\n",
      "[96]\n",
      "[14]\n",
      "[71]\n",
      "[40]\n",
      "[96]\n",
      "[102]\n",
      "[102]\n",
      "[96]\n",
      "[96]\n",
      "[102]\n",
      "[101]\n",
      "[71]\n",
      "[71]\n",
      "[0]\n",
      "[101]\n",
      "[40]\n",
      "[62]\n",
      "[64]\n",
      "[102]\n",
      "[71]\n",
      "[92]\n",
      "[92]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[101]\n",
      "[99]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[102]\n",
      "[62]\n",
      "[102]\n",
      "[71]\n",
      "[96]\n",
      "[103]\n",
      "[92]\n",
      "[101]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[99]\n",
      "[62]\n",
      "[102]\n",
      "[71]\n",
      "[96]\n",
      "[96]\n",
      "[92]\n",
      "[79]\n",
      "[96]\n",
      "[0]\n",
      "[96]\n",
      "[92]\n",
      "[100]\n",
      "[104]\n",
      "[92]\n",
      "[0]\n",
      "[96]\n",
      "[92]\n",
      "[2]\n",
      "[96]\n",
      "[97]\n",
      "[92]\n",
      "[92]\n",
      "[100]\n",
      "[104]\n",
      "[92]\n",
      "[97]\n",
      "[97]\n",
      "[107]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[97]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[52]\n",
      "[100]\n",
      "[98]\n",
      "[97]\n",
      "[98]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[108]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[110]\n",
      "[105]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[112]\n",
      "[112]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[110]\n",
      "[110]\n",
      "[112]\n",
      "[111]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[110]\n",
      "[111]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[109]\n",
      "[110]\n",
      "[109]\n",
      "[106]\n",
      "03/07 06:05:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][647/647]    acc/top1: 0.2488  acc/top5: 0.5657  acc/mean1: 0.2895  data_time: 0.0008  time: 0.0312\n",
      "03/07 06:05:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:05:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 100/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:42:37  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 1.4400  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4400\n",
      "03/07 06:05:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 200/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:42:20  time: 0.1648  data_time: 0.0019  memory: 10434  loss: 1.1324  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.1324\n",
      "03/07 06:06:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 300/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:42:04  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 0.8141  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8141\n",
      "03/07 06:06:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 400/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:41:47  time: 0.1643  data_time: 0.0018  memory: 10434  loss: 1.2947  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2947\n",
      "03/07 06:06:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 500/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:41:31  time: 0.1642  data_time: 0.0019  memory: 10434  loss: 1.0601  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0601\n",
      "03/07 06:06:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 600/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:41:15  time: 0.1654  data_time: 0.0018  memory: 10434  loss: 1.2957  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2957\n",
      "03/07 06:07:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 700/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:40:58  time: 0.1650  data_time: 0.0018  memory: 10434  loss: 1.7726  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7726\n",
      "03/07 06:07:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 800/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:40:42  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 1.6584  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6584\n",
      "03/07 06:07:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 900/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:40:25  time: 0.1638  data_time: 0.0019  memory: 10434  loss: 1.3927  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3927\n",
      "03/07 06:08:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1000/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:40:09  time: 0.1636  data_time: 0.0017  memory: 10434  loss: 1.5437  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5437\n",
      "03/07 06:08:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:08:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1100/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:39:52  time: 0.1627  data_time: 0.0017  memory: 10434  loss: 1.1613  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1613\n",
      "03/07 06:08:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1200/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:39:36  time: 0.1645  data_time: 0.0018  memory: 10434  loss: 1.3692  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3692\n",
      "03/07 06:08:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1300/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:39:20  time: 0.1664  data_time: 0.0019  memory: 10434  loss: 1.6392  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.6392\n",
      "03/07 06:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1400/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:39:03  time: 0.1638  data_time: 0.0016  memory: 10434  loss: 1.5673  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5673\n",
      "03/07 06:09:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1500/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:38:47  time: 0.1646  data_time: 0.0018  memory: 10434  loss: 1.5149  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5149\n",
      "03/07 06:09:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1600/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:38:30  time: 0.1645  data_time: 0.0019  memory: 10434  loss: 1.8414  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8414\n",
      "03/07 06:09:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1700/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:38:14  time: 0.1646  data_time: 0.0019  memory: 10434  loss: 1.2544  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2544\n",
      "03/07 06:10:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1800/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:37:58  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 1.1303  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.1303\n",
      "03/07 06:10:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1900/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:37:41  time: 0.1634  data_time: 0.0019  memory: 10434  loss: 1.3556  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3556\n",
      "03/07 06:10:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2000/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:37:25  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 1.0452  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0452\n",
      "03/07 06:10:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:11:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2100/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:37:08  time: 0.1643  data_time: 0.0016  memory: 10434  loss: 1.3155  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3155\n",
      "03/07 06:11:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2200/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:36:52  time: 0.1650  data_time: 0.0018  memory: 10434  loss: 1.4782  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4782\n",
      "03/07 06:11:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2300/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:36:35  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 1.2765  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2765\n",
      "03/07 06:11:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2400/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:36:19  time: 0.1648  data_time: 0.0019  memory: 10434  loss: 1.3144  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3144\n",
      "03/07 06:12:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2500/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:36:03  time: 0.1643  data_time: 0.0018  memory: 10434  loss: 1.0189  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0189\n",
      "03/07 06:12:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2600/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:35:46  time: 0.1641  data_time: 0.0020  memory: 10434  loss: 1.3446  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3446\n",
      "03/07 06:12:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2700/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:35:30  time: 0.1638  data_time: 0.0019  memory: 10434  loss: 1.1054  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.1054\n",
      "03/07 06:12:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2800/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:35:13  time: 0.1636  data_time: 0.0019  memory: 10434  loss: 1.2559  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2559\n",
      "03/07 06:13:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2900/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:34:57  time: 0.1638  data_time: 0.0020  memory: 10434  loss: 1.5592  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5592\n",
      "03/07 06:13:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3000/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:34:41  time: 0.1647  data_time: 0.0018  memory: 10434  loss: 1.1844  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.1844\n",
      "03/07 06:13:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:13:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3100/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:34:24  time: 0.1643  data_time: 0.0019  memory: 10434  loss: 0.9119  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.9119\n",
      "03/07 06:14:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3200/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:34:08  time: 0.1645  data_time: 0.0017  memory: 10434  loss: 1.4289  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4289\n",
      "03/07 06:14:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3300/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:33:51  time: 0.1671  data_time: 0.0018  memory: 10434  loss: 1.9431  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9431\n",
      "03/07 06:14:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3400/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:33:35  time: 0.1645  data_time: 0.0018  memory: 10434  loss: 0.8898  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8898\n",
      "03/07 06:14:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3500/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:33:18  time: 0.1660  data_time: 0.0018  memory: 10434  loss: 1.2632  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.2632\n",
      "03/07 06:15:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3600/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:33:02  time: 0.1638  data_time: 0.0019  memory: 10434  loss: 1.1905  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.1905\n",
      "03/07 06:15:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3700/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:32:46  time: 0.1642  data_time: 0.0018  memory: 10434  loss: 1.2520  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2520\n",
      "03/07 06:15:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3800/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:32:29  time: 0.1636  data_time: 0.0020  memory: 10434  loss: 1.4722  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4722\n",
      "03/07 06:15:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3900/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:32:13  time: 0.1633  data_time: 0.0016  memory: 10434  loss: 1.1183  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1183\n",
      "03/07 06:16:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4000/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:31:56  time: 0.1634  data_time: 0.0020  memory: 10434  loss: 1.1659  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1659\n",
      "03/07 06:16:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:16:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4100/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:31:40  time: 0.1646  data_time: 0.0019  memory: 10434  loss: 1.5669  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.5669\n",
      "03/07 06:16:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4200/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:31:24  time: 0.1650  data_time: 0.0018  memory: 10434  loss: 0.9180  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9180\n",
      "03/07 06:17:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4300/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:31:07  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 1.2494  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2494\n",
      "03/07 06:17:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4400/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:30:51  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 1.3477  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3477\n",
      "03/07 06:17:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4500/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:30:34  time: 0.1647  data_time: 0.0019  memory: 10434  loss: 1.3493  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3493\n",
      "03/07 06:17:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4600/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:30:18  time: 0.1641  data_time: 0.0018  memory: 10434  loss: 1.5446  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5446\n",
      "03/07 06:18:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4700/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:30:01  time: 0.1635  data_time: 0.0017  memory: 10434  loss: 0.9639  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 0.9639\n",
      "03/07 06:18:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4800/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:29:45  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 1.4333  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4333\n",
      "03/07 06:18:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4900/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:29:29  time: 0.1654  data_time: 0.0020  memory: 10434  loss: 1.7050  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7050\n",
      "03/07 06:18:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][5000/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:29:12  time: 0.1644  data_time: 0.0017  memory: 10434  loss: 1.0831  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0831\n",
      "03/07 06:19:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:19:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][5100/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:28:56  time: 0.1639  data_time: 0.0020  memory: 10434  loss: 1.5746  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5746\n",
      "03/07 06:19:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][5200/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:28:39  time: 0.1642  data_time: 0.0016  memory: 10434  loss: 1.4399  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4399\n",
      "03/07 06:19:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:19:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][5225/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:28:35  time: 0.1617  data_time: 0.0020  memory: 10434  loss: 1.1431  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1431\n",
      "03/07 06:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][100/647]    eta: 0:00:17  time: 0.0311  data_time: 0.0010  memory: 861  \n",
      "03/07 06:19:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][200/647]    eta: 0:00:13  time: 0.0311  data_time: 0.0007  memory: 861  \n",
      "03/07 06:19:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][300/647]    eta: 0:00:10  time: 0.0311  data_time: 0.0006  memory: 861  \n",
      "03/07 06:19:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][400/647]    eta: 0:00:07  time: 0.0312  data_time: 0.0009  memory: 861  \n",
      "03/07 06:19:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][500/647]    eta: 0:00:04  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "03/07 06:19:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][600/647]    eta: 0:00:01  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "[14]\n",
      "[1]\n",
      "[17]\n",
      "[14]\n",
      "[13]\n",
      "[2]\n",
      "[4]\n",
      "[21]\n",
      "[17]\n",
      "[11]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[1]\n",
      "[17]\n",
      "[18]\n",
      "[5]\n",
      "[20]\n",
      "[4]\n",
      "[14]\n",
      "[13]\n",
      "[14]\n",
      "[3]\n",
      "[13]\n",
      "[4]\n",
      "[5]\n",
      "[1]\n",
      "[3]\n",
      "[10]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[13]\n",
      "[22]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[1]\n",
      "[14]\n",
      "[20]\n",
      "[14]\n",
      "[13]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[14]\n",
      "[1]\n",
      "[5]\n",
      "[14]\n",
      "[8]\n",
      "[17]\n",
      "[18]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[1]\n",
      "[13]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[5]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[0]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[4]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[4]\n",
      "[0]\n",
      "[1]\n",
      "[11]\n",
      "[3]\n",
      "[4]\n",
      "[12]\n",
      "[22]\n",
      "[15]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[16]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[17]\n",
      "[25]\n",
      "[25]\n",
      "[26]\n",
      "[43]\n",
      "[31]\n",
      "[4]\n",
      "[31]\n",
      "[27]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[13]\n",
      "[29]\n",
      "[42]\n",
      "[14]\n",
      "[43]\n",
      "[27]\n",
      "[27]\n",
      "[27]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[4]\n",
      "[4]\n",
      "[43]\n",
      "[43]\n",
      "[34]\n",
      "[27]\n",
      "[34]\n",
      "[43]\n",
      "[19]\n",
      "[19]\n",
      "[4]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[50]\n",
      "[27]\n",
      "[36]\n",
      "[35]\n",
      "[38]\n",
      "[5]\n",
      "[5]\n",
      "[36]\n",
      "[41]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[43]\n",
      "[19]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[122]\n",
      "[54]\n",
      "[54]\n",
      "[57]\n",
      "[89]\n",
      "[0]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[55]\n",
      "[57]\n",
      "[44]\n",
      "[44]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[15]\n",
      "[46]\n",
      "[58]\n",
      "[54]\n",
      "[57]\n",
      "[6]\n",
      "[58]\n",
      "[54]\n",
      "[54]\n",
      "[51]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[53]\n",
      "[53]\n",
      "[58]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[53]\n",
      "[56]\n",
      "[55]\n",
      "[44]\n",
      "[51]\n",
      "[55]\n",
      "[53]\n",
      "[54]\n",
      "[15]\n",
      "[44]\n",
      "[54]\n",
      "[53]\n",
      "[44]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[53]\n",
      "[59]\n",
      "[53]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[0]\n",
      "[56]\n",
      "[12]\n",
      "[56]\n",
      "[44]\n",
      "[56]\n",
      "[44]\n",
      "[45]\n",
      "[55]\n",
      "[53]\n",
      "[51]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[51]\n",
      "[12]\n",
      "[12]\n",
      "[12]\n",
      "[44]\n",
      "[12]\n",
      "[12]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[12]\n",
      "[56]\n",
      "[31]\n",
      "[31]\n",
      "[53]\n",
      "[27]\n",
      "[31]\n",
      "[29]\n",
      "[62]\n",
      "[29]\n",
      "[7]\n",
      "[29]\n",
      "[29]\n",
      "[7]\n",
      "[53]\n",
      "[69]\n",
      "[28]\n",
      "[67]\n",
      "[53]\n",
      "[69]\n",
      "[44]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[63]\n",
      "[65]\n",
      "[53]\n",
      "[48]\n",
      "[51]\n",
      "[48]\n",
      "[47]\n",
      "[53]\n",
      "[53]\n",
      "[68]\n",
      "[45]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[29]\n",
      "[29]\n",
      "[69]\n",
      "[53]\n",
      "[48]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[44]\n",
      "[53]\n",
      "[53]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[28]\n",
      "[98]\n",
      "[53]\n",
      "[110]\n",
      "[12]\n",
      "[122]\n",
      "[110]\n",
      "[111]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[110]\n",
      "[44]\n",
      "[44]\n",
      "[53]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[110]\n",
      "[110]\n",
      "[54]\n",
      "[49]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[99]\n",
      "[52]\n",
      "[99]\n",
      "[52]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[48]\n",
      "[48]\n",
      "[53]\n",
      "[48]\n",
      "[48]\n",
      "[100]\n",
      "[99]\n",
      "[97]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[52]\n",
      "[7]\n",
      "[12]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[72]\n",
      "[77]\n",
      "[73]\n",
      "[72]\n",
      "[80]\n",
      "[76]\n",
      "[77]\n",
      "[77]\n",
      "[75]\n",
      "[74]\n",
      "[82]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[85]\n",
      "[89]\n",
      "[76]\n",
      "[73]\n",
      "[78]\n",
      "[80]\n",
      "[74]\n",
      "[73]\n",
      "[80]\n",
      "[79]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[76]\n",
      "[76]\n",
      "[76]\n",
      "[73]\n",
      "[88]\n",
      "[90]\n",
      "[72]\n",
      "[60]\n",
      "[73]\n",
      "[72]\n",
      "[80]\n",
      "[80]\n",
      "[77]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[86]\n",
      "[86]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[73]\n",
      "[72]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[74]\n",
      "[72]\n",
      "[77]\n",
      "[76]\n",
      "[83]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[83]\n",
      "[83]\n",
      "[105]\n",
      "[31]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[82]\n",
      "[91]\n",
      "[30]\n",
      "[82]\n",
      "[79]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[71]\n",
      "[30]\n",
      "[30]\n",
      "[71]\n",
      "[97]\n",
      "[99]\n",
      "[84]\n",
      "[96]\n",
      "[14]\n",
      "[96]\n",
      "[40]\n",
      "[96]\n",
      "[101]\n",
      "[102]\n",
      "[96]\n",
      "[96]\n",
      "[102]\n",
      "[102]\n",
      "[100]\n",
      "[100]\n",
      "[0]\n",
      "[101]\n",
      "[40]\n",
      "[62]\n",
      "[64]\n",
      "[102]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[79]\n",
      "[79]\n",
      "[103]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[101]\n",
      "[103]\n",
      "[92]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[100]\n",
      "[62]\n",
      "[102]\n",
      "[99]\n",
      "[96]\n",
      "[96]\n",
      "[92]\n",
      "[79]\n",
      "[96]\n",
      "[0]\n",
      "[96]\n",
      "[92]\n",
      "[100]\n",
      "[104]\n",
      "[92]\n",
      "[0]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[104]\n",
      "[92]\n",
      "[79]\n",
      "[79]\n",
      "[107]\n",
      "[96]\n",
      "[100]\n",
      "[100]\n",
      "[97]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[52]\n",
      "[100]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[108]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[106]\n",
      "[108]\n",
      "[109]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[110]\n",
      "[105]\n",
      "[108]\n",
      "[110]\n",
      "[108]\n",
      "[110]\n",
      "[109]\n",
      "[112]\n",
      "[110]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[107]\n",
      "[111]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[112]\n",
      "[111]\n",
      "[106]\n",
      "[106]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[106]\n",
      "[113]\n",
      "[113]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[109]\n",
      "[110]\n",
      "[107]\n",
      "[106]\n",
      "03/07 06:19:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][647/647]    acc/top1: 0.2612  acc/top5: 0.5858  acc/mean1: 0.3195  data_time: 0.0008  time: 0.0312\n",
      "03/07 06:19:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_20.pth is removed\n",
      "03/07 06:19:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.2612 acc/top1 at 23 epoch is saved to best_acc_top1_epoch_23.pth.\n",
      "03/07 06:20:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 100/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:28:19  time: 0.1632  data_time: 0.0019  memory: 10434  loss: 1.3369  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3369\n",
      "03/07 06:20:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 200/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:28:02  time: 0.1634  data_time: 0.0020  memory: 10434  loss: 0.9288  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.9288\n",
      "03/07 06:20:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 300/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:27:46  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 1.4009  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4009\n",
      "03/07 06:21:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 400/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:27:30  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 1.4295  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4295\n",
      "03/07 06:21:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 500/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:27:13  time: 0.1641  data_time: 0.0020  memory: 10434  loss: 1.4532  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4532\n",
      "03/07 06:21:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 600/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:26:57  time: 0.1643  data_time: 0.0018  memory: 10434  loss: 1.1995  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1995\n",
      "03/07 06:21:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 700/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:26:40  time: 0.1646  data_time: 0.0020  memory: 10434  loss: 1.5513  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5513\n",
      "03/07 06:22:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 800/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:26:24  time: 0.1652  data_time: 0.0019  memory: 10434  loss: 1.5396  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5396\n",
      "03/07 06:22:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:22:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 900/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:26:08  time: 0.1645  data_time: 0.0019  memory: 10434  loss: 1.2527  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2527\n",
      "03/07 06:22:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1000/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:25:51  time: 0.1639  data_time: 0.0019  memory: 10434  loss: 1.6726  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6726\n",
      "03/07 06:22:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1100/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:25:35  time: 0.1634  data_time: 0.0017  memory: 10434  loss: 1.3048  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3048\n",
      "03/07 06:23:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1200/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:25:18  time: 0.1648  data_time: 0.0020  memory: 10434  loss: 1.6702  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.6702\n",
      "03/07 06:23:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1300/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:25:02  time: 0.1633  data_time: 0.0020  memory: 10434  loss: 1.1887  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1887\n",
      "03/07 06:23:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1400/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:24:45  time: 0.1650  data_time: 0.0018  memory: 10434  loss: 1.3539  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3539\n",
      "03/07 06:24:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1500/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:24:29  time: 0.1634  data_time: 0.0018  memory: 10434  loss: 1.1921  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1921\n",
      "03/07 06:24:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1600/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:24:13  time: 0.1634  data_time: 0.0019  memory: 10434  loss: 1.5053  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5053\n",
      "03/07 06:24:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1700/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:23:56  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 1.2745  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.2745\n",
      "03/07 06:24:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1800/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:23:40  time: 0.1650  data_time: 0.0017  memory: 10434  loss: 1.4205  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4205\n",
      "03/07 06:24:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:25:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1900/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:23:23  time: 0.1635  data_time: 0.0019  memory: 10434  loss: 1.2572  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2572\n",
      "03/07 06:25:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2000/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:23:07  time: 0.1641  data_time: 0.0020  memory: 10434  loss: 1.4494  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4494\n",
      "03/07 06:25:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2100/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:22:51  time: 0.1638  data_time: 0.0019  memory: 10434  loss: 0.9749  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9749\n",
      "03/07 06:25:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2200/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:22:34  time: 0.1645  data_time: 0.0018  memory: 10434  loss: 1.2599  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2599\n",
      "03/07 06:26:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2300/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:22:18  time: 0.1636  data_time: 0.0017  memory: 10434  loss: 1.2684  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2684\n",
      "03/07 06:26:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2400/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:22:01  time: 0.1654  data_time: 0.0019  memory: 10434  loss: 1.2225  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2225\n",
      "03/07 06:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2500/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:21:45  time: 0.1651  data_time: 0.0019  memory: 10434  loss: 1.6951  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6951\n",
      "03/07 06:27:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2600/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:21:28  time: 0.1632  data_time: 0.0019  memory: 10434  loss: 0.8279  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8279\n",
      "03/07 06:27:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2700/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:21:12  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 1.4034  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4034\n",
      "03/07 06:27:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2800/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:20:56  time: 0.1651  data_time: 0.0021  memory: 10434  loss: 0.9692  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.9692\n",
      "03/07 06:27:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:27:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2900/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:20:39  time: 0.1641  data_time: 0.0020  memory: 10434  loss: 1.1885  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1885\n",
      "03/07 06:28:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3000/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:20:23  time: 0.1635  data_time: 0.0020  memory: 10434  loss: 1.5645  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5645\n",
      "03/07 06:28:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3100/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:20:06  time: 0.1639  data_time: 0.0018  memory: 10434  loss: 1.3143  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3143\n",
      "03/07 06:28:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3200/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:19:50  time: 0.1636  data_time: 0.0019  memory: 10434  loss: 0.8620  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8620\n",
      "03/07 06:28:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3300/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:19:33  time: 0.1646  data_time: 0.0018  memory: 10434  loss: 1.3398  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.3398\n",
      "03/07 06:29:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3400/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:19:17  time: 0.1637  data_time: 0.0020  memory: 10434  loss: 1.8472  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8472\n",
      "03/07 06:29:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3500/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:19:01  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.3967  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.3967\n",
      "03/07 06:29:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3600/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:18:44  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.3292  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3292\n",
      "03/07 06:30:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3700/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:18:28  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 1.1634  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1634\n",
      "03/07 06:30:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3800/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:18:11  time: 0.1643  data_time: 0.0018  memory: 10434  loss: 1.4244  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4244\n",
      "03/07 06:30:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:30:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3900/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:17:55  time: 0.1642  data_time: 0.0019  memory: 10434  loss: 1.5218  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5218\n",
      "03/07 06:30:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4000/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:17:39  time: 0.1652  data_time: 0.0019  memory: 10434  loss: 1.5027  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5027\n",
      "03/07 06:31:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4100/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:17:22  time: 0.1651  data_time: 0.0019  memory: 10434  loss: 1.5539  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5539\n",
      "03/07 06:31:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4200/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:17:06  time: 0.1644  data_time: 0.0019  memory: 10434  loss: 1.3080  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3080\n",
      "03/07 06:31:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4300/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:16:49  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 1.6817  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6817\n",
      "03/07 06:32:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4400/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:16:33  time: 0.1645  data_time: 0.0020  memory: 10434  loss: 1.1808  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1808\n",
      "03/07 06:32:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4500/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:16:16  time: 0.1628  data_time: 0.0020  memory: 10434  loss: 1.2672  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.2672\n",
      "03/07 06:32:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4600/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:16:00  time: 0.1644  data_time: 0.0020  memory: 10434  loss: 1.2693  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2693\n",
      "03/07 06:32:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4700/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:15:44  time: 0.1639  data_time: 0.0019  memory: 10434  loss: 1.1972  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.1972\n",
      "03/07 06:33:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4800/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:15:27  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.4221  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4221\n",
      "03/07 06:33:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:33:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4900/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:15:11  time: 0.1642  data_time: 0.0020  memory: 10434  loss: 1.2531  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2531\n",
      "03/07 06:33:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][5000/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:14:54  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 1.1296  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1296\n",
      "03/07 06:33:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][5100/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:14:38  time: 0.1636  data_time: 0.0019  memory: 10434  loss: 1.2444  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2444\n",
      "03/07 06:34:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][5200/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:14:22  time: 0.1637  data_time: 0.0018  memory: 10434  loss: 1.3517  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.3517\n",
      "03/07 06:34:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:34:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][5225/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:14:17  time: 0.1605  data_time: 0.0021  memory: 10434  loss: 1.9233  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.9233\n",
      "03/07 06:34:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 24 epochs\n",
      "03/07 06:34:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][100/647]    eta: 0:00:17  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "03/07 06:34:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][200/647]    eta: 0:00:13  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "03/07 06:34:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][300/647]    eta: 0:00:10  time: 0.0310  data_time: 0.0008  memory: 861  \n",
      "03/07 06:34:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][400/647]    eta: 0:00:07  time: 0.0310  data_time: 0.0009  memory: 861  \n",
      "03/07 06:34:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][500/647]    eta: 0:00:04  time: 0.0312  data_time: 0.0008  memory: 861  \n",
      "03/07 06:34:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][600/647]    eta: 0:00:01  time: 0.0309  data_time: 0.0008  memory: 861  \n",
      "[0]\n",
      "[1]\n",
      "[17]\n",
      "[3]\n",
      "[3]\n",
      "[2]\n",
      "[4]\n",
      "[21]\n",
      "[17]\n",
      "[11]\n",
      "[13]\n",
      "[22]\n",
      "[23]\n",
      "[14]\n",
      "[17]\n",
      "[1]\n",
      "[17]\n",
      "[18]\n",
      "[5]\n",
      "[20]\n",
      "[4]\n",
      "[14]\n",
      "[13]\n",
      "[14]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[5]\n",
      "[1]\n",
      "[3]\n",
      "[10]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[22]\n",
      "[23]\n",
      "[17]\n",
      "[17]\n",
      "[1]\n",
      "[17]\n",
      "[20]\n",
      "[20]\n",
      "[21]\n",
      "[1]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[1]\n",
      "[1]\n",
      "[5]\n",
      "[1]\n",
      "[8]\n",
      "[17]\n",
      "[2]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[21]\n",
      "[13]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[5]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[4]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[16]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[5]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[16]\n",
      "[11]\n",
      "[11]\n",
      "[10]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[16]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[25]\n",
      "[25]\n",
      "[25]\n",
      "[26]\n",
      "[47]\n",
      "[31]\n",
      "[4]\n",
      "[28]\n",
      "[27]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[44]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[30]\n",
      "[30]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[27]\n",
      "[27]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[19]\n",
      "[41]\n",
      "[4]\n",
      "[4]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[27]\n",
      "[34]\n",
      "[106]\n",
      "[19]\n",
      "[19]\n",
      "[4]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[34]\n",
      "[27]\n",
      "[41]\n",
      "[28]\n",
      "[38]\n",
      "[5]\n",
      "[21]\n",
      "[36]\n",
      "[41]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[57]\n",
      "[52]\n",
      "[57]\n",
      "[122]\n",
      "[54]\n",
      "[54]\n",
      "[57]\n",
      "[89]\n",
      "[0]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[55]\n",
      "[57]\n",
      "[44]\n",
      "[44]\n",
      "[57]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[15]\n",
      "[46]\n",
      "[58]\n",
      "[46]\n",
      "[57]\n",
      "[6]\n",
      "[58]\n",
      "[54]\n",
      "[54]\n",
      "[51]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[46]\n",
      "[58]\n",
      "[58]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[53]\n",
      "[52]\n",
      "[55]\n",
      "[55]\n",
      "[51]\n",
      "[55]\n",
      "[10]\n",
      "[54]\n",
      "[15]\n",
      "[44]\n",
      "[54]\n",
      "[53]\n",
      "[44]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[10]\n",
      "[45]\n",
      "[53]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[0]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[44]\n",
      "[56]\n",
      "[16]\n",
      "[45]\n",
      "[45]\n",
      "[53]\n",
      "[51]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[51]\n",
      "[57]\n",
      "[52]\n",
      "[12]\n",
      "[45]\n",
      "[47]\n",
      "[52]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[56]\n",
      "[31]\n",
      "[31]\n",
      "[53]\n",
      "[27]\n",
      "[31]\n",
      "[29]\n",
      "[63]\n",
      "[29]\n",
      "[63]\n",
      "[29]\n",
      "[29]\n",
      "[46]\n",
      "[53]\n",
      "[69]\n",
      "[28]\n",
      "[67]\n",
      "[53]\n",
      "[69]\n",
      "[27]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[63]\n",
      "[65]\n",
      "[48]\n",
      "[48]\n",
      "[47]\n",
      "[48]\n",
      "[47]\n",
      "[47]\n",
      "[68]\n",
      "[68]\n",
      "[45]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[29]\n",
      "[29]\n",
      "[69]\n",
      "[53]\n",
      "[48]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[48]\n",
      "[53]\n",
      "[70]\n",
      "[53]\n",
      "[70]\n",
      "[40]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[28]\n",
      "[98]\n",
      "[53]\n",
      "[110]\n",
      "[12]\n",
      "[122]\n",
      "[110]\n",
      "[111]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[110]\n",
      "[44]\n",
      "[44]\n",
      "[53]\n",
      "[122]\n",
      "[110]\n",
      "[53]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[122]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[71]\n",
      "[52]\n",
      "[99]\n",
      "[52]\n",
      "[71]\n",
      "[99]\n",
      "[99]\n",
      "[48]\n",
      "[48]\n",
      "[52]\n",
      "[52]\n",
      "[48]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[52]\n",
      "[45]\n",
      "[100]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[72]\n",
      "[77]\n",
      "[73]\n",
      "[72]\n",
      "[80]\n",
      "[76]\n",
      "[77]\n",
      "[77]\n",
      "[75]\n",
      "[74]\n",
      "[82]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[85]\n",
      "[75]\n",
      "[76]\n",
      "[87]\n",
      "[90]\n",
      "[80]\n",
      "[74]\n",
      "[73]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[76]\n",
      "[76]\n",
      "[88]\n",
      "[73]\n",
      "[88]\n",
      "[90]\n",
      "[72]\n",
      "[75]\n",
      "[86]\n",
      "[72]\n",
      "[80]\n",
      "[80]\n",
      "[77]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[80]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[86]\n",
      "[86]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[73]\n",
      "[72]\n",
      "[81]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[83]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[83]\n",
      "[83]\n",
      "[105]\n",
      "[31]\n",
      "[112]\n",
      "[31]\n",
      "[31]\n",
      "[112]\n",
      "[112]\n",
      "[91]\n",
      "[82]\n",
      "[91]\n",
      "[30]\n",
      "[100]\n",
      "[30]\n",
      "[91]\n",
      "[112]\n",
      "[112]\n",
      "[71]\n",
      "[112]\n",
      "[87]\n",
      "[71]\n",
      "[97]\n",
      "[99]\n",
      "[84]\n",
      "[96]\n",
      "[71]\n",
      "[71]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[101]\n",
      "[101]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[71]\n",
      "[92]\n",
      "[101]\n",
      "[40]\n",
      "[62]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[101]\n",
      "[92]\n",
      "[71]\n",
      "[79]\n",
      "[101]\n",
      "[100]\n",
      "[101]\n",
      "[99]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[100]\n",
      "[71]\n",
      "[92]\n",
      "[2]\n",
      "[99]\n",
      "[62]\n",
      "[102]\n",
      "[99]\n",
      "[96]\n",
      "[96]\n",
      "[92]\n",
      "[79]\n",
      "[96]\n",
      "[0]\n",
      "[96]\n",
      "[99]\n",
      "[100]\n",
      "[104]\n",
      "[92]\n",
      "[0]\n",
      "[96]\n",
      "[92]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[92]\n",
      "[99]\n",
      "[100]\n",
      "[99]\n",
      "[92]\n",
      "[109]\n",
      "[79]\n",
      "[107]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[52]\n",
      "[100]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[108]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[108]\n",
      "[109]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[109]\n",
      "[112]\n",
      "[109]\n",
      "[111]\n",
      "[109]\n",
      "[108]\n",
      "[109]\n",
      "[112]\n",
      "[112]\n",
      "[108]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[110]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[110]\n",
      "[111]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[109]\n",
      "[110]\n",
      "[109]\n",
      "[106]\n",
      "03/07 06:34:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][647/647]    acc/top1: 0.2736  acc/top5: 0.5889  acc/mean1: 0.3203  data_time: 0.0008  time: 0.0311\n",
      "03/07 06:34:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\videomae_anticipation_regular\\best_acc_top1_epoch_23.pth is removed\n",
      "03/07 06:34:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.2736 acc/top1 at 24 epoch is saved to best_acc_top1_epoch_24.pth.\n",
      "03/07 06:34:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 100/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:14:01  time: 0.1639  data_time: 0.0018  memory: 10434  loss: 1.3431  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3431\n",
      "03/07 06:35:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 200/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:13:45  time: 0.1661  data_time: 0.0019  memory: 10434  loss: 1.3848  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.3848\n",
      "03/07 06:35:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 300/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:13:28  time: 0.1643  data_time: 0.0019  memory: 10434  loss: 1.1384  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1384\n",
      "03/07 06:35:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 400/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:13:12  time: 0.1636  data_time: 0.0017  memory: 10434  loss: 1.3227  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3227\n",
      "03/07 06:36:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 500/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:12:55  time: 0.1638  data_time: 0.0020  memory: 10434  loss: 1.3209  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.3209\n",
      "03/07 06:36:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:36:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 600/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:12:39  time: 0.1635  data_time: 0.0020  memory: 10434  loss: 1.3346  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.3346\n",
      "03/07 06:36:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 700/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:12:22  time: 0.1636  data_time: 0.0018  memory: 10434  loss: 1.1978  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1978\n",
      "03/07 06:36:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 800/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:12:06  time: 0.1641  data_time: 0.0021  memory: 10434  loss: 1.1296  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1296\n",
      "03/07 06:37:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 900/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:11:50  time: 0.1651  data_time: 0.0018  memory: 10434  loss: 1.4592  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.4592\n",
      "03/07 06:37:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1000/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:11:33  time: 0.1636  data_time: 0.0017  memory: 10434  loss: 1.2761  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.2761\n",
      "03/07 06:37:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1100/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:11:17  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 1.8039  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8039\n",
      "03/07 06:37:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1200/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:11:00  time: 0.1647  data_time: 0.0017  memory: 10434  loss: 1.2336  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2336\n",
      "03/07 06:38:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1300/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:10:44  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 0.8506  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8506\n",
      "03/07 06:38:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1400/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:10:28  time: 0.1645  data_time: 0.0019  memory: 10434  loss: 0.9045  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9045\n",
      "03/07 06:38:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1500/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:10:11  time: 0.1650  data_time: 0.0018  memory: 10434  loss: 1.3280  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3280\n",
      "03/07 06:39:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:39:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1600/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:09:55  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 1.3735  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3735\n",
      "03/07 06:39:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1700/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:09:38  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 1.1728  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.1728\n",
      "03/07 06:39:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1800/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:09:22  time: 0.1639  data_time: 0.0020  memory: 10434  loss: 1.0701  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0701\n",
      "03/07 06:39:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1900/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:09:05  time: 0.1640  data_time: 0.0020  memory: 10434  loss: 1.1200  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1200\n",
      "03/07 06:40:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2000/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:08:49  time: 0.1634  data_time: 0.0019  memory: 10434  loss: 0.9993  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.9993\n",
      "03/07 06:40:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2100/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:08:33  time: 0.1631  data_time: 0.0018  memory: 10434  loss: 1.3191  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3191\n",
      "03/07 06:40:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2200/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:08:16  time: 0.1649  data_time: 0.0018  memory: 10434  loss: 0.9540  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9540\n",
      "03/07 06:40:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2300/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:08:00  time: 0.1653  data_time: 0.0017  memory: 10434  loss: 0.9518  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.9518\n",
      "03/07 06:41:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2400/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:07:43  time: 0.1652  data_time: 0.0018  memory: 10434  loss: 1.0576  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.0576\n",
      "03/07 06:41:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2500/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:07:27  time: 0.1631  data_time: 0.0017  memory: 10434  loss: 1.0279  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0279\n",
      "03/07 06:41:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:41:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2600/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:07:11  time: 0.1641  data_time: 0.0018  memory: 10434  loss: 1.0035  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0035\n",
      "03/07 06:42:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2700/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:06:54  time: 0.1633  data_time: 0.0020  memory: 10434  loss: 1.1765  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1765\n",
      "03/07 06:42:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2800/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:06:38  time: 0.1634  data_time: 0.0020  memory: 10434  loss: 1.3509  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.3509\n",
      "03/07 06:42:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2900/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:06:21  time: 0.1677  data_time: 0.0020  memory: 10434  loss: 0.9542  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9542\n",
      "03/07 06:42:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3000/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:06:05  time: 0.1636  data_time: 0.0017  memory: 10434  loss: 1.5990  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5990\n",
      "03/07 06:43:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3100/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:05:48  time: 0.1643  data_time: 0.0018  memory: 10434  loss: 1.5001  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5001\n",
      "03/07 06:43:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3200/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:05:32  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 1.6136  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6136\n",
      "03/07 06:43:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3300/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:05:16  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 1.2039  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.2039\n",
      "03/07 06:43:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3400/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:04:59  time: 0.1634  data_time: 0.0018  memory: 10434  loss: 1.3481  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3481\n",
      "03/07 06:44:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3500/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:04:43  time: 0.1637  data_time: 0.0019  memory: 10434  loss: 1.2118  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.2118\n",
      "03/07 06:44:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:44:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3600/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:04:26  time: 0.1634  data_time: 0.0020  memory: 10434  loss: 1.0510  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0510\n",
      "03/07 06:44:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3700/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:04:10  time: 0.1649  data_time: 0.0019  memory: 10434  loss: 0.9230  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.9230\n",
      "03/07 06:45:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3800/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:03:53  time: 0.1632  data_time: 0.0018  memory: 10434  loss: 1.0782  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.0782\n",
      "03/07 06:45:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3900/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:03:37  time: 0.1633  data_time: 0.0019  memory: 10434  loss: 1.3402  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3402\n",
      "03/07 06:45:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4000/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:03:21  time: 0.1645  data_time: 0.0020  memory: 10434  loss: 1.3126  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3126\n",
      "03/07 06:45:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4100/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:03:04  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 1.6169  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6169\n",
      "03/07 06:46:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4200/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:02:48  time: 0.1635  data_time: 0.0018  memory: 10434  loss: 1.3459  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3459\n",
      "03/07 06:46:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4300/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:02:31  time: 0.1629  data_time: 0.0019  memory: 10434  loss: 1.3965  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3965\n",
      "03/07 06:46:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4400/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:02:15  time: 0.1644  data_time: 0.0019  memory: 10434  loss: 1.2044  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2044\n",
      "03/07 06:46:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4500/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:01:59  time: 0.1647  data_time: 0.0019  memory: 10434  loss: 1.4810  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4810\n",
      "03/07 06:47:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:47:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4600/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:01:42  time: 0.1636  data_time: 0.0019  memory: 10434  loss: 1.1159  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1159\n",
      "03/07 06:47:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4700/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:01:26  time: 0.1642  data_time: 0.0019  memory: 10434  loss: 1.0529  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0529\n",
      "03/07 06:47:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4800/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:01:09  time: 0.1644  data_time: 0.0019  memory: 10434  loss: 1.2532  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2532\n",
      "03/07 06:48:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4900/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:00:53  time: 0.1631  data_time: 0.0019  memory: 10434  loss: 1.1453  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1453\n",
      "03/07 06:48:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][5000/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:00:36  time: 0.1640  data_time: 0.0019  memory: 10434  loss: 1.1812  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1812\n",
      "03/07 06:48:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][5100/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:00:20  time: 0.1641  data_time: 0.0019  memory: 10434  loss: 1.0917  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0917\n",
      "03/07 06:48:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][5200/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:00:04  time: 0.1662  data_time: 0.0023  memory: 10434  loss: 1.1707  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1707\n",
      "03/07 06:48:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: videomae_anticipation_regular_20250307_004221\n",
      "03/07 06:48:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][5225/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:00:00  time: 0.1621  data_time: 0.0024  memory: 10434  loss: 1.4764  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.4764\n",
      "03/07 06:48:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 25 epochs\n",
      "03/07 06:49:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][100/647]    eta: 0:00:17  time: 0.0311  data_time: 0.0008  memory: 861  \n",
      "03/07 06:49:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][200/647]    eta: 0:00:13  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "03/07 06:49:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][300/647]    eta: 0:00:10  time: 0.0311  data_time: 0.0008  memory: 861  \n",
      "03/07 06:49:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][400/647]    eta: 0:00:07  time: 0.0310  data_time: 0.0007  memory: 861  \n",
      "03/07 06:49:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][500/647]    eta: 0:00:04  time: 0.0311  data_time: 0.0008  memory: 861  \n",
      "03/07 06:49:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][600/647]    eta: 0:00:01  time: 0.0311  data_time: 0.0006  memory: 861  \n",
      "[0]\n",
      "[1]\n",
      "[17]\n",
      "[3]\n",
      "[3]\n",
      "[11]\n",
      "[4]\n",
      "[21]\n",
      "[17]\n",
      "[11]\n",
      "[12]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[1]\n",
      "[17]\n",
      "[18]\n",
      "[5]\n",
      "[20]\n",
      "[5]\n",
      "[14]\n",
      "[13]\n",
      "[11]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[5]\n",
      "[3]\n",
      "[3]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[3]\n",
      "[13]\n",
      "[11]\n",
      "[17]\n",
      "[13]\n",
      "[17]\n",
      "[20]\n",
      "[20]\n",
      "[21]\n",
      "[20]\n",
      "[0]\n",
      "[4]\n",
      "[11]\n",
      "[14]\n",
      "[1]\n",
      "[5]\n",
      "[5]\n",
      "[8]\n",
      "[17]\n",
      "[17]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[5]\n",
      "[13]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[5]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n",
      "[11]\n",
      "[26]\n",
      "[4]\n",
      "[5]\n",
      "[12]\n",
      "[21]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[11]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[21]\n",
      "[11]\n",
      "[3]\n",
      "[20]\n",
      "[5]\n",
      "[22]\n",
      "[15]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[16]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[11]\n",
      "[25]\n",
      "[25]\n",
      "[26]\n",
      "[41]\n",
      "[31]\n",
      "[4]\n",
      "[31]\n",
      "[27]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[4]\n",
      "[31]\n",
      "[5]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[93]\n",
      "[30]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[27]\n",
      "[27]\n",
      "[5]\n",
      "[41]\n",
      "[19]\n",
      "[19]\n",
      "[41]\n",
      "[4]\n",
      "[4]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[39]\n",
      "[34]\n",
      "[42]\n",
      "[19]\n",
      "[19]\n",
      "[3]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[34]\n",
      "[27]\n",
      "[41]\n",
      "[35]\n",
      "[38]\n",
      "[5]\n",
      "[5]\n",
      "[36]\n",
      "[41]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[19]\n",
      "[96]\n",
      "[12]\n",
      "[96]\n",
      "[15]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[8]\n",
      "[8]\n",
      "[96]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[105]\n",
      "[54]\n",
      "[54]\n",
      "[57]\n",
      "[89]\n",
      "[0]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[55]\n",
      "[57]\n",
      "[44]\n",
      "[44]\n",
      "[57]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[56]\n",
      "[55]\n",
      "[58]\n",
      "[46]\n",
      "[57]\n",
      "[55]\n",
      "[58]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[46]\n",
      "[58]\n",
      "[58]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[10]\n",
      "[56]\n",
      "[55]\n",
      "[55]\n",
      "[51]\n",
      "[55]\n",
      "[10]\n",
      "[54]\n",
      "[55]\n",
      "[55]\n",
      "[54]\n",
      "[15]\n",
      "[44]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[10]\n",
      "[59]\n",
      "[9]\n",
      "[55]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[0]\n",
      "[56]\n",
      "[12]\n",
      "[56]\n",
      "[44]\n",
      "[56]\n",
      "[16]\n",
      "[44]\n",
      "[55]\n",
      "[58]\n",
      "[57]\n",
      "[53]\n",
      "[44]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[12]\n",
      "[44]\n",
      "[7]\n",
      "[52]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[12]\n",
      "[56]\n",
      "[31]\n",
      "[31]\n",
      "[48]\n",
      "[30]\n",
      "[31]\n",
      "[29]\n",
      "[63]\n",
      "[29]\n",
      "[7]\n",
      "[29]\n",
      "[29]\n",
      "[7]\n",
      "[48]\n",
      "[69]\n",
      "[28]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[63]\n",
      "[65]\n",
      "[48]\n",
      "[48]\n",
      "[47]\n",
      "[48]\n",
      "[47]\n",
      "[47]\n",
      "[68]\n",
      "[68]\n",
      "[30]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[29]\n",
      "[29]\n",
      "[69]\n",
      "[48]\n",
      "[48]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[62]\n",
      "[48]\n",
      "[53]\n",
      "[70]\n",
      "[40]\n",
      "[40]\n",
      "[40]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[28]\n",
      "[98]\n",
      "[53]\n",
      "[110]\n",
      "[12]\n",
      "[122]\n",
      "[110]\n",
      "[111]\n",
      "[110]\n",
      "[110]\n",
      "[48]\n",
      "[110]\n",
      "[44]\n",
      "[44]\n",
      "[53]\n",
      "[122]\n",
      "[110]\n",
      "[15]\n",
      "[110]\n",
      "[110]\n",
      "[54]\n",
      "[15]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[53]\n",
      "[71]\n",
      "[52]\n",
      "[99]\n",
      "[52]\n",
      "[71]\n",
      "[99]\n",
      "[99]\n",
      "[48]\n",
      "[48]\n",
      "[52]\n",
      "[52]\n",
      "[48]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[52]\n",
      "[7]\n",
      "[48]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[72]\n",
      "[77]\n",
      "[73]\n",
      "[72]\n",
      "[79]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[75]\n",
      "[81]\n",
      "[7]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[85]\n",
      "[89]\n",
      "[76]\n",
      "[87]\n",
      "[90]\n",
      "[80]\n",
      "[74]\n",
      "[73]\n",
      "[80]\n",
      "[79]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[76]\n",
      "[76]\n",
      "[88]\n",
      "[73]\n",
      "[88]\n",
      "[90]\n",
      "[72]\n",
      "[75]\n",
      "[86]\n",
      "[72]\n",
      "[80]\n",
      "[80]\n",
      "[77]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[86]\n",
      "[86]\n",
      "[90]\n",
      "[72]\n",
      "[77]\n",
      "[73]\n",
      "[72]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[83]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[83]\n",
      "[83]\n",
      "[105]\n",
      "[31]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[112]\n",
      "[112]\n",
      "[91]\n",
      "[82]\n",
      "[91]\n",
      "[100]\n",
      "[100]\n",
      "[30]\n",
      "[91]\n",
      "[112]\n",
      "[30]\n",
      "[71]\n",
      "[112]\n",
      "[30]\n",
      "[71]\n",
      "[97]\n",
      "[99]\n",
      "[84]\n",
      "[96]\n",
      "[71]\n",
      "[71]\n",
      "[40]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[101]\n",
      "[101]\n",
      "[102]\n",
      "[101]\n",
      "[71]\n",
      "[71]\n",
      "[92]\n",
      "[101]\n",
      "[40]\n",
      "[62]\n",
      "[62]\n",
      "[102]\n",
      "[71]\n",
      "[101]\n",
      "[92]\n",
      "[71]\n",
      "[79]\n",
      "[101]\n",
      "[103]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[100]\n",
      "[71]\n",
      "[92]\n",
      "[101]\n",
      "[100]\n",
      "[62]\n",
      "[102]\n",
      "[99]\n",
      "[96]\n",
      "[96]\n",
      "[92]\n",
      "[0]\n",
      "[2]\n",
      "[0]\n",
      "[0]\n",
      "[92]\n",
      "[100]\n",
      "[104]\n",
      "[92]\n",
      "[0]\n",
      "[96]\n",
      "[92]\n",
      "[2]\n",
      "[96]\n",
      "[97]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[104]\n",
      "[92]\n",
      "[79]\n",
      "[79]\n",
      "[107]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[52]\n",
      "[100]\n",
      "[100]\n",
      "[97]\n",
      "[98]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[108]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[108]\n",
      "[109]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[110]\n",
      "[105]\n",
      "[109]\n",
      "[111]\n",
      "[109]\n",
      "[108]\n",
      "[109]\n",
      "[112]\n",
      "[112]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[107]\n",
      "[111]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[106]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[110]\n",
      "[111]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[107]\n",
      "[109]\n",
      "[110]\n",
      "[107]\n",
      "[106]\n",
      "03/07 06:49:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][647/647]    acc/top1: 0.2612  acc/top5: 0.5981  acc/mean1: 0.3087  data_time: 0.0008  time: 0.0311\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "\n",
    "import torch\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "from multiprocessing import Process\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    # Check MMAction2 installaation\n",
    "    import mmaction\n",
    "    print(mmaction.__version__)\n",
    "\n",
    "    import mmcv\n",
    "    print(mmcv.__version__)\n",
    "\n",
    "    # Check MMCV installation\n",
    "    from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "    print(get_compiling_cuda_version())\n",
    "    print(get_compiler_version())\n",
    "\n",
    "    # Check MMEngine installation\n",
    "    from mmengine.utils.dl_utils import collect_env\n",
    "    print(collect_env())\n",
    "\n",
    "    from mmaction.apis import inference_recognizer, init_recognizer\n",
    "    from mmengine import Config\n",
    "\n",
    "    from operator import itemgetter\n",
    "\n",
    "    import os.path as osp\n",
    "    import mmengine\n",
    "    from mmengine.runner import Runner\n",
    "\n",
    "    # Choose to use a config and initialize the recognizer\n",
    "    # cfg = './swin-small-p244-w877_in1k-pre_8xb8-amp-32x2x1-30e_kinetics400-rgb.py'\n",
    "    cfg = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/videomae_anticipation_regular.py'\n",
    "    cfg = Config.fromfile(cfg)\n",
    "\n",
    "    # Set up working dir to save files and logs.\n",
    "    cfg.work_dir = './exps/videomae_anticipation_regular'\n",
    "\n",
    "    # Create work_dir\n",
    "    mmengine.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "\n",
    "    # The original learning rate (LR) is set for 8-GPU training.\n",
    "    # We divide it by 8 since we only use one GPU.\n",
    "    cfg.train_dataloader.batch_size = cfg.train_dataloader.batch_size // 4\n",
    "    cfg.val_dataloader.batch_size = cfg.val_dataloader.batch_size // 4\n",
    "    cfg.test_dataloader.batch_size = 1\n",
    "    cfg.optim_wrapper.optimizer.lr = cfg.optim_wrapper.optimizer.lr / 8\n",
    "    cfg.train_cfg.max_epochs = 25\n",
    "\n",
    "\n",
    "    # We can initialize the logger for training and have a look\n",
    "    # at the final config used for training\n",
    "    print(f'Config:\\n{cfg.pretty_text}')\n",
    "\n",
    "    # Setup a checkpoint file to load\n",
    "    # checkpoint = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/videomaev2/best_acc_top1_epoch_23.pth'\n",
    "    # file = open('/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/uniformerv2_large/swin_last_checkpoint.pth', \"r\")\n",
    "    # checkpoint = file.read()\n",
    "    # file.close()\n",
    "\n",
    "    # Initialize the recognizer\n",
    "    model = init_recognizer(cfg, checkpoint=None, device='cuda:0')\n",
    "\n",
    "    # build the runner from config\n",
    "    runner = Runner.from_cfg(cfg)\n",
    "\n",
    "    # start training\n",
    "    runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu124 True\n",
      "1.2.0\n",
      "2.2.0\n",
      "12.4\n",
      "MSVC 194134120\n",
      "OrderedDict([('sys.platform', 'win32'), ('Python', '3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]'), ('CUDA available', True), ('MUSA available', False), ('numpy_random_seed', 1292769136), ('GPU 0', 'NVIDIA GeForce RTX 4080 SUPER'), ('CUDA_HOME', 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.4'), ('NVCC', 'Cuda compilation tools, release 12.4, V12.4.99'), ('MSVC', 'n/a, reason: fileno'), ('PyTorch', '2.4.1+cu124'), ('PyTorch compiling details', 'PyTorch built with:\\n  - C++ Version: 201703\\n  - MSVC 192930154\\n  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\\n  - OpenMP 2019\\n  - LAPACK is enabled (usually provided by MKL)\\n  - CPU capability usage: AVX2\\n  - CUDA Runtime 12.4\\n  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\\n  - CuDNN 90.1\\n  - Magma 2.5.4\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \\n'), ('TorchVision', '0.19.1+cu124'), ('OpenCV', '4.10.0'), ('MMEngine', '0.10.5')])\n",
      "Config:\n",
      "ann_file_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt'\n",
      "ann_file_train = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_train_balanced.txt'\n",
      "ann_file_val = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt'\n",
      "auto_scale_lr = dict(base_batch_size=8, enable=False)\n",
      "data_root = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train/'\n",
      "data_root_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "dataset_type = 'RawframeDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=3, max_keep_ckpts=5, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        arch='tiny',\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1,\n",
      "        drop_rate=0.0,\n",
      "        mlp_ratio=4.0,\n",
      "        patch_norm=True,\n",
      "        patch_size=(\n",
      "            2,\n",
      "            4,\n",
      "            4,\n",
      "        ),\n",
      "        pretrained=\n",
      "        'https://download.openmmlab.com/mmaction/v1.0/recognition/swin/swin_tiny_patch4_window7_224.pth',\n",
      "        pretrained2d=False,\n",
      "        qk_scale=None,\n",
      "        qkv_bias=True,\n",
      "        type='SwinTransformer3D',\n",
      "        window_size=(\n",
      "            8,\n",
      "            7,\n",
      "            7,\n",
      "        )),\n",
      "    cls_head=dict(\n",
      "        average_clips='prob',\n",
      "        dropout_ratio=0.5,\n",
      "        in_channels=768,\n",
      "        num_classes=160,\n",
      "        spatial_type='avg',\n",
      "        type='I3DHead'),\n",
      "    data_preprocessor=dict(\n",
      "        format_shape='NCTHW',\n",
      "        mean=[\n",
      "            113.8477,\n",
      "            104.25,\n",
      "            100.3492,\n",
      "        ],\n",
      "        std=[\n",
      "            60.7003,\n",
      "            56.8895,\n",
      "            57.735,\n",
      "        ],\n",
      "        type='ActionDataPreprocessor'),\n",
      "    type='Recognizer3D')\n",
      "optim_wrapper = dict(\n",
      "    constructor='SwinOptimWrapperConstructor',\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=0.000125, type='AdamW', weight_decay=0.02),\n",
      "    paramwise_cfg=dict(\n",
      "        absolute_pos_embed=dict(decay_mult=0.0),\n",
      "        backbone=dict(lr_mult=0.1),\n",
      "        norm=dict(decay_mult=0.0),\n",
      "        relative_position_bias_table=dict(decay_mult=0.0)),\n",
      "    type='AmpOptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=2.5,\n",
      "        start_factor=0.1,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        T_max=30,\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=30,\n",
      "        eta_min=0,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=4,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='ThreeCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(type='AccMetric')\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=4,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='ThreeCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=25, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_train_balanced.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                224,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(flip_ratio=0.5, type='Flip'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(clip_len=32, frame_interval=2, num_clips=1, type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        224,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(flip_ratio=0.5, type='Flip'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(type='AccMetric')\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='CenterCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './exps/swin_tiny_anticipation_regular'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddie\\anaconda3\\envs\\openmmlab\\Lib\\site-packages\\torch\\functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3610.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/07 06:49:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 2015798605\n",
      "    GPU 0: NVIDIA GeForce RTX 4080 SUPER\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.4\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.99\n",
      "    MSVC: n/a, reason: fileno\n",
      "    PyTorch: 2.4.1+cu124\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 201703\n",
      "  - MSVC 192930154\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.4\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 90.1\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.19.1+cu124\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 2015798605\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/07 06:49:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt'\n",
      "ann_file_train = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_train_balanced.txt'\n",
      "ann_file_val = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt'\n",
      "auto_scale_lr = dict(base_batch_size=8, enable=False)\n",
      "data_root = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train/'\n",
      "data_root_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "dataset_type = 'RawframeDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=3, max_keep_ckpts=5, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        arch='tiny',\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1,\n",
      "        drop_rate=0.0,\n",
      "        mlp_ratio=4.0,\n",
      "        patch_norm=True,\n",
      "        patch_size=(\n",
      "            2,\n",
      "            4,\n",
      "            4,\n",
      "        ),\n",
      "        pretrained=None,\n",
      "        pretrained2d=False,\n",
      "        qk_scale=None,\n",
      "        qkv_bias=True,\n",
      "        type='SwinTransformer3D',\n",
      "        window_size=(\n",
      "            8,\n",
      "            7,\n",
      "            7,\n",
      "        )),\n",
      "    cls_head=dict(\n",
      "        average_clips='prob',\n",
      "        dropout_ratio=0.5,\n",
      "        in_channels=768,\n",
      "        num_classes=160,\n",
      "        spatial_type='avg',\n",
      "        type='I3DHead'),\n",
      "    data_preprocessor=dict(\n",
      "        format_shape='NCTHW',\n",
      "        mean=[\n",
      "            113.8477,\n",
      "            104.25,\n",
      "            100.3492,\n",
      "        ],\n",
      "        std=[\n",
      "            60.7003,\n",
      "            56.8895,\n",
      "            57.735,\n",
      "        ],\n",
      "        type='ActionDataPreprocessor'),\n",
      "    type='Recognizer3D')\n",
      "optim_wrapper = dict(\n",
      "    constructor='SwinOptimWrapperConstructor',\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=0.000125, type='AdamW', weight_decay=0.02),\n",
      "    paramwise_cfg=dict(\n",
      "        absolute_pos_embed=dict(decay_mult=0.0),\n",
      "        backbone=dict(lr_mult=0.1),\n",
      "        norm=dict(decay_mult=0.0),\n",
      "        relative_position_bias_table=dict(decay_mult=0.0)),\n",
      "    type='AmpOptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=2.5,\n",
      "        start_factor=0.1,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        T_max=30,\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=30,\n",
      "        eta_min=0,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=4,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='ThreeCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(type='AccMetric')\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=4,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='ThreeCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=25, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_train_balanced.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                224,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(flip_ratio=0.5, type='Flip'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(clip_len=32, frame_interval=2, num_clips=1, type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        224,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(flip_ratio=0.5, type='Flip'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(type='AccMetric')\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='CenterCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './exps/swin_tiny_anticipation_regular'\n",
      "\n",
      "03/07 06:49:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/07 06:49:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.patch_embed.proj.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.patch_embed.proj.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.patch_embed.proj.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.patch_embed.proj.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.patch_embed.norm.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.patch_embed.norm.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.patch_embed.norm.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.patch_embed.norm.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.norm1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.norm1.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.norm1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.norm1.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.attn.relative_position_bias_table: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.attn.relative_position_bias_table: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.attn.qkv.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.attn.qkv.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.norm2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.norm2.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.norm2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.norm2.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.mlp.fc1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.mlp.fc1.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.mlp.fc1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.mlp.fc1.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.mlp.fc2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.mlp.fc2.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.mlp.fc2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.0.mlp.fc2.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.norm1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.norm1.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.norm1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.norm1.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.attn.relative_position_bias_table: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.attn.relative_position_bias_table: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.attn.qkv.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.attn.qkv.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.norm2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.norm2.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.norm2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.norm2.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.mlp.fc1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.mlp.fc1.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.mlp.fc1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.mlp.fc1.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.mlp.fc2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.mlp.fc2.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.mlp.fc2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.blocks.1.mlp.fc2.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.downsample.reduction.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.downsample.reduction.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.downsample.norm.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.downsample.norm.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.downsample.norm.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.0.downsample.norm.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.norm1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.norm1.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.norm1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.norm1.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.attn.relative_position_bias_table: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.attn.relative_position_bias_table: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.attn.qkv.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.attn.qkv.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.norm2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.norm2.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.norm2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.norm2.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.mlp.fc1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.mlp.fc1.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.mlp.fc1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.mlp.fc1.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.mlp.fc2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.mlp.fc2.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.mlp.fc2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.0.mlp.fc2.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.norm1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.norm1.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.norm1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.norm1.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.attn.relative_position_bias_table: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.attn.relative_position_bias_table: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.attn.qkv.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.attn.qkv.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.norm2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.norm2.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.norm2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.norm2.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.mlp.fc1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.mlp.fc1.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.mlp.fc1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.mlp.fc1.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.mlp.fc2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.mlp.fc2.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.mlp.fc2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.blocks.1.mlp.fc2.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.downsample.reduction.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.downsample.reduction.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.downsample.norm.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.downsample.norm.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.downsample.norm.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.1.downsample.norm.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.norm1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.norm1.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.norm1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.norm1.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.attn.relative_position_bias_table: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.attn.relative_position_bias_table: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.attn.qkv.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.attn.qkv.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.norm2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.norm2.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.norm2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.norm2.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.mlp.fc1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.mlp.fc1.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.mlp.fc1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.mlp.fc1.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.mlp.fc2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.mlp.fc2.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.mlp.fc2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.0.mlp.fc2.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.norm1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.norm1.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.norm1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.norm1.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.attn.relative_position_bias_table: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.attn.relative_position_bias_table: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.attn.qkv.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.attn.qkv.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.norm2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.norm2.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.norm2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.norm2.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.mlp.fc1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.mlp.fc1.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.mlp.fc1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.mlp.fc1.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.mlp.fc2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.mlp.fc2.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.mlp.fc2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.1.mlp.fc2.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.norm1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.norm1.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.norm1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.norm1.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.attn.relative_position_bias_table: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.attn.relative_position_bias_table: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.attn.qkv.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.attn.qkv.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.norm2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.norm2.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.norm2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.norm2.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.mlp.fc1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.mlp.fc1.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.mlp.fc1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.mlp.fc1.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.mlp.fc2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.mlp.fc2.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.mlp.fc2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.2.mlp.fc2.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.norm1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.norm1.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.norm1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.norm1.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.attn.relative_position_bias_table: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.attn.relative_position_bias_table: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.attn.qkv.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.attn.qkv.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.norm2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.norm2.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.norm2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.norm2.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.mlp.fc1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.mlp.fc1.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.mlp.fc1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.mlp.fc1.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.mlp.fc2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.mlp.fc2.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.mlp.fc2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.3.mlp.fc2.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.norm1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.norm1.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.norm1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.norm1.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.attn.relative_position_bias_table: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.attn.relative_position_bias_table: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.attn.qkv.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.attn.qkv.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.norm2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.norm2.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.norm2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.norm2.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.mlp.fc1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.mlp.fc1.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.mlp.fc1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.mlp.fc1.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.mlp.fc2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.mlp.fc2.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.mlp.fc2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.4.mlp.fc2.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.norm1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.norm1.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.norm1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.norm1.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.attn.relative_position_bias_table: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.attn.relative_position_bias_table: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.attn.qkv.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.attn.qkv.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.norm2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.norm2.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.norm2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.norm2.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.mlp.fc1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.mlp.fc1.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.mlp.fc1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.mlp.fc1.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.mlp.fc2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.mlp.fc2.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.mlp.fc2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.blocks.5.mlp.fc2.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.downsample.reduction.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.downsample.reduction.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.downsample.norm.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.downsample.norm.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.downsample.norm.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.2.downsample.norm.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.norm1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.norm1.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.norm1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.norm1.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.attn.relative_position_bias_table: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.attn.relative_position_bias_table: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.attn.qkv.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.attn.qkv.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.norm2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.norm2.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.norm2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.norm2.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.mlp.fc1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.mlp.fc1.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.mlp.fc1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.mlp.fc1.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.mlp.fc2.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.mlp.fc2.weight: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.mlp.fc2.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.0.mlp.fc2.bias: weight_decay = 0.02\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.norm1.weight: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.norm1.weight: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.norm1.bias: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.norm1.bias: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.attn.relative_position_bias_table: lr = 1.25e-05\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.attn.relative_position_bias_table: weight_decay = 0.0\n",
      "03/07 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.attn.qkv.weight: lr = 1.25e-05\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.attn.qkv.weight: weight_decay = 0.02\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.attn.qkv.bias: lr = 1.25e-05\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.attn.qkv.bias: weight_decay = 0.02\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.attn.proj.weight: lr = 1.25e-05\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.attn.proj.weight: weight_decay = 0.02\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.attn.proj.bias: lr = 1.25e-05\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.attn.proj.bias: weight_decay = 0.02\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.norm2.weight: lr = 1.25e-05\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.norm2.weight: weight_decay = 0.0\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.norm2.bias: lr = 1.25e-05\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.norm2.bias: weight_decay = 0.0\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.mlp.fc1.weight: lr = 1.25e-05\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.mlp.fc1.weight: weight_decay = 0.02\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.mlp.fc1.bias: lr = 1.25e-05\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.mlp.fc1.bias: weight_decay = 0.02\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.mlp.fc2.weight: lr = 1.25e-05\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.mlp.fc2.weight: weight_decay = 0.02\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.mlp.fc2.bias: lr = 1.25e-05\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.layers.3.blocks.1.mlp.fc2.bias: weight_decay = 0.02\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.norm3.weight: lr = 1.25e-05\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.norm3.weight: weight_decay = 0.0\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.norm3.bias: lr = 1.25e-05\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.backbone.norm3.bias: weight_decay = 0.0\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.cls_head.fc_cls.weight: lr = 0.000125\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.cls_head.fc_cls.weight: weight_decay = 0.02\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.cls_head.fc_cls.bias: lr = 0.000125\n",
      "03/07 06:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- base.cls_head.fc_cls.bias: weight_decay = 0.02\n",
      "03/07 06:50:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/07 06:50:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular.\n",
      "03/07 06:50:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 100/5225]  base_lr: 1.3353e-05 lr: 1.3353e-06  eta: 10:08:07  time: 0.1371  data_time: 0.0018  memory: 5847  loss: 5.1291  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 5.1291\n",
      "03/07 06:50:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 200/5225]  base_lr: 1.4214e-05 lr: 1.4214e-06  eta: 7:34:16  time: 0.1373  data_time: 0.0019  memory: 5847  loss: 5.0115  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 5.0115\n",
      "03/07 06:51:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 300/5225]  base_lr: 1.5075e-05 lr: 1.5075e-06  eta: 6:42:19  time: 0.1368  data_time: 0.0019  memory: 5847  loss: 4.9407  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.9407\n",
      "03/07 06:51:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 400/5225]  base_lr: 1.5937e-05 lr: 1.5937e-06  eta: 6:15:53  time: 0.1370  data_time: 0.0019  memory: 5847  loss: 4.9869  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.9869\n",
      "03/07 06:51:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 500/5225]  base_lr: 1.6798e-05 lr: 1.6798e-06  eta: 6:00:26  time: 0.1392  data_time: 0.0017  memory: 5847  loss: 4.8651  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.8651\n",
      "03/07 06:51:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 600/5225]  base_lr: 1.7659e-05 lr: 1.7659e-06  eta: 5:50:10  time: 0.1386  data_time: 0.0020  memory: 5847  loss: 4.8666  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.8666\n",
      "03/07 06:52:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 700/5225]  base_lr: 1.8521e-05 lr: 1.8521e-06  eta: 5:42:51  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 4.8189  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.8189\n",
      "03/07 06:52:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 800/5225]  base_lr: 1.9382e-05 lr: 1.9382e-06  eta: 5:37:25  time: 0.1397  data_time: 0.0020  memory: 5847  loss: 4.8752  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.8752\n",
      "03/07 06:52:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 900/5225]  base_lr: 2.0243e-05 lr: 2.0243e-06  eta: 5:33:01  time: 0.1374  data_time: 0.0018  memory: 5847  loss: 4.8224  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.8224\n",
      "03/07 06:52:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 06:52:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1000/5225]  base_lr: 2.1105e-05 lr: 2.1105e-06  eta: 5:29:32  time: 0.1396  data_time: 0.0017  memory: 5847  loss: 4.8121  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.8121\n",
      "03/07 06:52:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1100/5225]  base_lr: 2.1966e-05 lr: 2.1966e-06  eta: 5:26:28  time: 0.1383  data_time: 0.0018  memory: 5847  loss: 4.8187  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.8187\n",
      "03/07 06:53:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1200/5225]  base_lr: 2.2828e-05 lr: 2.2828e-06  eta: 5:23:56  time: 0.1393  data_time: 0.0019  memory: 5847  loss: 4.7678  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.7678\n",
      "03/07 06:53:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1300/5225]  base_lr: 2.3689e-05 lr: 2.3689e-06  eta: 5:21:51  time: 0.1388  data_time: 0.0019  memory: 5847  loss: 4.6803  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 4.6803\n",
      "03/07 06:53:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1400/5225]  base_lr: 2.4550e-05 lr: 2.4550e-06  eta: 5:19:47  time: 0.1371  data_time: 0.0017  memory: 5847  loss: 4.6476  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.6476\n",
      "03/07 06:53:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1500/5225]  base_lr: 2.5412e-05 lr: 2.5412e-06  eta: 5:18:01  time: 0.1370  data_time: 0.0017  memory: 5847  loss: 4.6167  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.6167\n",
      "03/07 06:54:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1600/5225]  base_lr: 2.6273e-05 lr: 2.6273e-06  eta: 5:16:26  time: 0.1391  data_time: 0.0019  memory: 5847  loss: 4.6869  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.6869\n",
      "03/07 06:54:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1700/5225]  base_lr: 2.7134e-05 lr: 2.7134e-06  eta: 5:15:03  time: 0.1377  data_time: 0.0018  memory: 5847  loss: 4.6893  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.6893\n",
      "03/07 06:54:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1800/5225]  base_lr: 2.7996e-05 lr: 2.7996e-06  eta: 5:13:49  time: 0.1398  data_time: 0.0019  memory: 5847  loss: 4.7344  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.7344\n",
      "03/07 06:54:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1900/5225]  base_lr: 2.8857e-05 lr: 2.8857e-06  eta: 5:12:44  time: 0.1388  data_time: 0.0018  memory: 5847  loss: 4.4683  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.4683\n",
      "03/07 06:55:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 06:55:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2000/5225]  base_lr: 2.9718e-05 lr: 2.9718e-06  eta: 5:11:39  time: 0.1368  data_time: 0.0018  memory: 5847  loss: 4.6383  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 4.6383\n",
      "03/07 06:55:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2100/5225]  base_lr: 3.0580e-05 lr: 3.0580e-06  eta: 5:10:37  time: 0.1368  data_time: 0.0018  memory: 5847  loss: 4.4147  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.4147\n",
      "03/07 06:55:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2200/5225]  base_lr: 3.1441e-05 lr: 3.1441e-06  eta: 5:09:38  time: 0.1378  data_time: 0.0018  memory: 5847  loss: 4.5420  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.5420\n",
      "03/07 06:55:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2300/5225]  base_lr: 3.2302e-05 lr: 3.2302e-06  eta: 5:08:46  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 4.4520  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.4520\n",
      "03/07 06:55:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2400/5225]  base_lr: 3.3164e-05 lr: 3.3164e-06  eta: 5:07:56  time: 0.1379  data_time: 0.0018  memory: 5847  loss: 4.3118  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.3118\n",
      "03/07 06:56:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2500/5225]  base_lr: 3.4025e-05 lr: 3.4025e-06  eta: 5:07:11  time: 0.1373  data_time: 0.0017  memory: 5847  loss: 4.4537  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 4.4537\n",
      "03/07 06:56:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2600/5225]  base_lr: 3.4886e-05 lr: 3.4886e-06  eta: 5:06:26  time: 0.1368  data_time: 0.0017  memory: 5847  loss: 4.5498  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.5498\n",
      "03/07 06:56:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2700/5225]  base_lr: 3.5748e-05 lr: 3.5748e-06  eta: 5:05:49  time: 0.1385  data_time: 0.0018  memory: 5847  loss: 4.4004  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.4004\n",
      "03/07 06:56:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2800/5225]  base_lr: 3.6609e-05 lr: 3.6609e-06  eta: 5:05:16  time: 0.1391  data_time: 0.0019  memory: 5847  loss: 4.4582  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.4582\n",
      "03/07 06:57:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][2900/5225]  base_lr: 3.7470e-05 lr: 3.7470e-06  eta: 5:04:39  time: 0.1365  data_time: 0.0019  memory: 5847  loss: 4.5362  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.5362\n",
      "03/07 06:57:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 06:57:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3000/5225]  base_lr: 3.8332e-05 lr: 3.8332e-06  eta: 5:03:59  time: 0.1368  data_time: 0.0017  memory: 5847  loss: 4.5084  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.5084\n",
      "03/07 06:57:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3100/5225]  base_lr: 3.9193e-05 lr: 3.9193e-06  eta: 5:03:26  time: 0.1395  data_time: 0.0019  memory: 5847  loss: 4.5980  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.5980\n",
      "03/07 06:57:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3200/5225]  base_lr: 4.0054e-05 lr: 4.0054e-06  eta: 5:02:56  time: 0.1386  data_time: 0.0018  memory: 5847  loss: 4.4441  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.4441\n",
      "03/07 06:58:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3300/5225]  base_lr: 4.0916e-05 lr: 4.0916e-06  eta: 5:02:25  time: 0.1368  data_time: 0.0017  memory: 5847  loss: 4.2419  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2419\n",
      "03/07 06:58:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3400/5225]  base_lr: 4.1777e-05 lr: 4.1777e-06  eta: 5:01:50  time: 0.1368  data_time: 0.0019  memory: 5847  loss: 4.4122  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.4122\n",
      "03/07 06:58:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3500/5225]  base_lr: 4.2638e-05 lr: 4.2638e-06  eta: 5:01:18  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 4.3924  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.3924\n",
      "03/07 06:58:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3600/5225]  base_lr: 4.3500e-05 lr: 4.3500e-06  eta: 5:00:49  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 4.3817  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.3817\n",
      "03/07 06:58:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3700/5225]  base_lr: 4.4361e-05 lr: 4.4361e-06  eta: 5:00:22  time: 0.1388  data_time: 0.0019  memory: 5847  loss: 4.4128  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.4128\n",
      "03/07 06:59:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3800/5225]  base_lr: 4.5222e-05 lr: 4.5222e-06  eta: 4:59:57  time: 0.1385  data_time: 0.0019  memory: 5847  loss: 4.4324  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.4324\n",
      "03/07 06:59:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][3900/5225]  base_lr: 4.6084e-05 lr: 4.6084e-06  eta: 4:59:33  time: 0.1395  data_time: 0.0020  memory: 5847  loss: 4.0143  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0143\n",
      "03/07 06:59:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 06:59:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4000/5225]  base_lr: 4.6945e-05 lr: 4.6945e-06  eta: 4:59:06  time: 0.1381  data_time: 0.0018  memory: 5847  loss: 4.3407  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.3407\n",
      "03/07 06:59:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4100/5225]  base_lr: 4.7806e-05 lr: 4.7806e-06  eta: 4:58:39  time: 0.1377  data_time: 0.0019  memory: 5847  loss: 4.2712  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 4.2712\n",
      "03/07 07:00:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4200/5225]  base_lr: 4.8668e-05 lr: 4.8668e-06  eta: 4:58:12  time: 0.1369  data_time: 0.0019  memory: 5847  loss: 4.3731  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.3731\n",
      "03/07 07:00:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4300/5225]  base_lr: 4.9529e-05 lr: 4.9529e-06  eta: 4:57:46  time: 0.1373  data_time: 0.0018  memory: 5847  loss: 4.2580  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.2580\n",
      "03/07 07:00:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4400/5225]  base_lr: 5.0390e-05 lr: 5.0390e-06  eta: 4:57:23  time: 0.1374  data_time: 0.0018  memory: 5847  loss: 4.0655  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.0655\n",
      "03/07 07:00:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4500/5225]  base_lr: 5.1252e-05 lr: 5.1252e-06  eta: 4:57:03  time: 0.1386  data_time: 0.0020  memory: 5847  loss: 4.2700  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.2700\n",
      "03/07 07:01:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4600/5225]  base_lr: 5.2113e-05 lr: 5.2113e-06  eta: 4:56:38  time: 0.1367  data_time: 0.0020  memory: 5847  loss: 4.2185  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2185\n",
      "03/07 07:01:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4700/5225]  base_lr: 5.2975e-05 lr: 5.2975e-06  eta: 4:56:15  time: 0.1370  data_time: 0.0019  memory: 5847  loss: 4.1398  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.1398\n",
      "03/07 07:01:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4800/5225]  base_lr: 5.3836e-05 lr: 5.3836e-06  eta: 4:55:52  time: 0.1368  data_time: 0.0019  memory: 5847  loss: 4.2473  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2473\n",
      "03/07 07:01:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4900/5225]  base_lr: 5.4697e-05 lr: 5.4697e-06  eta: 4:55:29  time: 0.1377  data_time: 0.0019  memory: 5847  loss: 4.1210  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 4.1210\n",
      "03/07 07:01:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:01:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][5000/5225]  base_lr: 5.5559e-05 lr: 5.5559e-06  eta: 4:55:08  time: 0.1378  data_time: 0.0018  memory: 5847  loss: 4.1408  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1408\n",
      "03/07 07:02:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][5100/5225]  base_lr: 5.6420e-05 lr: 5.6420e-06  eta: 4:54:47  time: 0.1387  data_time: 0.0019  memory: 5847  loss: 4.1224  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1224\n",
      "03/07 07:02:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][5200/5225]  base_lr: 5.7281e-05 lr: 5.7281e-06  eta: 4:54:26  time: 0.1371  data_time: 0.0017  memory: 5847  loss: 3.9206  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9206\n",
      "03/07 07:02:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:02:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][5225/5225]  base_lr: 5.7497e-05 lr: 5.7497e-06  eta: 4:54:19  time: 0.1340  data_time: 0.0021  memory: 5847  loss: 3.8010  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8010\n",
      "03/07 07:02:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][100/647]    eta: 0:00:36  time: 0.0292  data_time: 0.0007  memory: 1333  \n",
      "03/07 07:02:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][200/647]    eta: 0:00:21  time: 0.0293  data_time: 0.0009  memory: 1333  \n",
      "03/07 07:02:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][300/647]    eta: 0:00:14  time: 0.0293  data_time: 0.0007  memory: 1333  \n",
      "03/07 07:02:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][400/647]    eta: 0:00:09  time: 0.0293  data_time: 0.0008  memory: 1333  \n",
      "03/07 07:02:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][500/647]    eta: 0:00:05  time: 0.0293  data_time: 0.0008  memory: 1333  \n",
      "03/07 07:02:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][600/647]    eta: 0:00:01  time: 0.0293  data_time: 0.0007  memory: 1333  \n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[17]\n",
      "[102]\n",
      "[102]\n",
      "[14]\n",
      "[102]\n",
      "[102]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[104]\n",
      "[14]\n",
      "[11]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[17]\n",
      "[11]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[102]\n",
      "[102]\n",
      "[17]\n",
      "[11]\n",
      "[104]\n",
      "[25]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[25]\n",
      "[25]\n",
      "[25]\n",
      "[17]\n",
      "[17]\n",
      "[11]\n",
      "[17]\n",
      "[25]\n",
      "[25]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[17]\n",
      "[25]\n",
      "[97]\n",
      "[14]\n",
      "[14]\n",
      "[25]\n",
      "[11]\n",
      "[97]\n",
      "[17]\n",
      "[14]\n",
      "[25]\n",
      "[25]\n",
      "[97]\n",
      "[97]\n",
      "[25]\n",
      "[25]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[97]\n",
      "[38]\n",
      "[93]\n",
      "[27]\n",
      "[38]\n",
      "[27]\n",
      "[27]\n",
      "[29]\n",
      "[29]\n",
      "[38]\n",
      "[119]\n",
      "[38]\n",
      "[27]\n",
      "[27]\n",
      "[27]\n",
      "[27]\n",
      "[29]\n",
      "[29]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[93]\n",
      "[93]\n",
      "[27]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[27]\n",
      "[27]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[27]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[27]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[27]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[27]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[119]\n",
      "[53]\n",
      "[51]\n",
      "[115]\n",
      "[30]\n",
      "[44]\n",
      "[51]\n",
      "[119]\n",
      "[38]\n",
      "[119]\n",
      "[43]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[38]\n",
      "[102]\n",
      "[102]\n",
      "[11]\n",
      "[78]\n",
      "[11]\n",
      "[14]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[97]\n",
      "[38]\n",
      "[102]\n",
      "[96]\n",
      "[17]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[14]\n",
      "[14]\n",
      "[97]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[14]\n",
      "[10]\n",
      "[38]\n",
      "[38]\n",
      "[10]\n",
      "[10]\n",
      "[10]\n",
      "[10]\n",
      "[81]\n",
      "[10]\n",
      "[14]\n",
      "[81]\n",
      "[38]\n",
      "[10]\n",
      "[10]\n",
      "[10]\n",
      "[10]\n",
      "[53]\n",
      "[10]\n",
      "[10]\n",
      "[14]\n",
      "[102]\n",
      "[53]\n",
      "[14]\n",
      "[51]\n",
      "[119]\n",
      "[119]\n",
      "[119]\n",
      "[119]\n",
      "[119]\n",
      "[119]\n",
      "[119]\n",
      "[119]\n",
      "[119]\n",
      "[119]\n",
      "[44]\n",
      "[44]\n",
      "[119]\n",
      "[119]\n",
      "[53]\n",
      "[53]\n",
      "[119]\n",
      "[119]\n",
      "[53]\n",
      "[119]\n",
      "[115]\n",
      "[115]\n",
      "[119]\n",
      "[119]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[119]\n",
      "[38]\n",
      "[27]\n",
      "[27]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[27]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[62]\n",
      "[119]\n",
      "[62]\n",
      "[62]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[62]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[115]\n",
      "[66]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[122]\n",
      "[95]\n",
      "[95]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[121]\n",
      "[95]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[95]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[3]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[81]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[11]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[38]\n",
      "[115]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[29]\n",
      "[27]\n",
      "[38]\n",
      "[38]\n",
      "[30]\n",
      "[27]\n",
      "[38]\n",
      "[38]\n",
      "[27]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[38]\n",
      "[38]\n",
      "[44]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[25]\n",
      "[102]\n",
      "[97]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[97]\n",
      "[102]\n",
      "[97]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[115]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[95]\n",
      "[97]\n",
      "[95]\n",
      "[100]\n",
      "[119]\n",
      "[3]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[97]\n",
      "[38]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[38]\n",
      "[3]\n",
      "[16]\n",
      "[78]\n",
      "[97]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[95]\n",
      "[38]\n",
      "[117]\n",
      "[95]\n",
      "[95]\n",
      "[117]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[119]\n",
      "[119]\n",
      "[119]\n",
      "[119]\n",
      "[44]\n",
      "[119]\n",
      "[44]\n",
      "[44]\n",
      "[119]\n",
      "[44]\n",
      "03/07 07:02:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][647/647]    acc/top1: 0.0216  acc/top5: 0.1453  acc/mean1: 0.0409  data_time: 0.0063  time: 0.0351\n",
      "03/07 07:02:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.0216 acc/top1 at 1 epoch is saved to best_acc_top1_epoch_1.pth.\n",
      "03/07 07:03:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 100/5225]  base_lr: 5.8198e-05 lr: 5.8198e-06  eta: 4:54:03  time: 0.1369  data_time: 0.0018  memory: 5847  loss: 3.9670  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9670\n",
      "03/07 07:03:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 200/5225]  base_lr: 5.9057e-05 lr: 5.9057e-06  eta: 4:53:41  time: 0.1372  data_time: 0.0020  memory: 5847  loss: 3.8812  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8812\n",
      "03/07 07:03:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 300/5225]  base_lr: 5.9916e-05 lr: 5.9916e-06  eta: 4:53:21  time: 0.1393  data_time: 0.0019  memory: 5847  loss: 3.9570  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9570\n",
      "03/07 07:03:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 400/5225]  base_lr: 6.0775e-05 lr: 6.0775e-06  eta: 4:53:04  time: 0.1395  data_time: 0.0018  memory: 5847  loss: 3.9481  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.9481\n",
      "03/07 07:04:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 500/5225]  base_lr: 6.1634e-05 lr: 6.1634e-06  eta: 4:52:45  time: 0.1376  data_time: 0.0018  memory: 5847  loss: 4.0155  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 4.0155\n",
      "03/07 07:04:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 600/5225]  base_lr: 6.2493e-05 lr: 6.2493e-06  eta: 4:52:24  time: 0.1371  data_time: 0.0019  memory: 5847  loss: 3.9699  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9699\n",
      "03/07 07:04:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 700/5225]  base_lr: 6.3352e-05 lr: 6.3352e-06  eta: 4:52:02  time: 0.1368  data_time: 0.0019  memory: 5847  loss: 3.8690  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8690\n",
      "03/07 07:04:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:04:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 800/5225]  base_lr: 6.4211e-05 lr: 6.4211e-06  eta: 4:51:44  time: 0.1385  data_time: 0.0018  memory: 5847  loss: 3.8631  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 3.8631\n",
      "03/07 07:04:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 900/5225]  base_lr: 6.5070e-05 lr: 6.5070e-06  eta: 4:51:27  time: 0.1376  data_time: 0.0019  memory: 5847  loss: 4.1465  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1465\n",
      "03/07 07:05:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1000/5225]  base_lr: 6.5929e-05 lr: 6.5929e-06  eta: 4:51:08  time: 0.1370  data_time: 0.0020  memory: 5847  loss: 3.8651  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.8651\n",
      "03/07 07:05:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1100/5225]  base_lr: 6.6788e-05 lr: 6.6788e-06  eta: 4:50:51  time: 0.1386  data_time: 0.0017  memory: 5847  loss: 3.9208  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9208\n",
      "03/07 07:05:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1200/5225]  base_lr: 6.7647e-05 lr: 6.7647e-06  eta: 4:50:33  time: 0.1388  data_time: 0.0019  memory: 5847  loss: 3.8494  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8494\n",
      "03/07 07:05:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1300/5225]  base_lr: 6.8506e-05 lr: 6.8506e-06  eta: 4:50:14  time: 0.1370  data_time: 0.0019  memory: 5847  loss: 3.8684  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8684\n",
      "03/07 07:06:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1400/5225]  base_lr: 6.9365e-05 lr: 6.9365e-06  eta: 4:49:56  time: 0.1387  data_time: 0.0020  memory: 5847  loss: 3.8421  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8421\n",
      "03/07 07:06:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1500/5225]  base_lr: 7.0224e-05 lr: 7.0224e-06  eta: 4:49:38  time: 0.1368  data_time: 0.0019  memory: 5847  loss: 4.1597  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1597\n",
      "03/07 07:06:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1600/5225]  base_lr: 7.1083e-05 lr: 7.1083e-06  eta: 4:49:21  time: 0.1416  data_time: 0.0020  memory: 5847  loss: 4.1189  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.1189\n",
      "03/07 07:06:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1700/5225]  base_lr: 7.1942e-05 lr: 7.1942e-06  eta: 4:49:06  time: 0.1391  data_time: 0.0019  memory: 5847  loss: 3.9767  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.9767\n",
      "03/07 07:06:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:07:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1800/5225]  base_lr: 7.2801e-05 lr: 7.2801e-06  eta: 4:48:49  time: 0.1372  data_time: 0.0019  memory: 5847  loss: 4.2423  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2423\n",
      "03/07 07:07:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1900/5225]  base_lr: 7.3660e-05 lr: 7.3660e-06  eta: 4:48:32  time: 0.1372  data_time: 0.0018  memory: 5847  loss: 4.2313  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 4.2313\n",
      "03/07 07:07:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2000/5225]  base_lr: 7.4519e-05 lr: 7.4519e-06  eta: 4:48:14  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 3.7791  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.7791\n",
      "03/07 07:07:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2100/5225]  base_lr: 7.5378e-05 lr: 7.5378e-06  eta: 4:47:56  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 3.5455  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.5455\n",
      "03/07 07:07:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2200/5225]  base_lr: 7.6237e-05 lr: 7.6237e-06  eta: 4:47:38  time: 0.1386  data_time: 0.0018  memory: 5847  loss: 3.7925  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7925\n",
      "03/07 07:08:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2300/5225]  base_lr: 7.7096e-05 lr: 7.7096e-06  eta: 4:47:20  time: 0.1378  data_time: 0.0019  memory: 5847  loss: 3.8726  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8726\n",
      "03/07 07:08:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2400/5225]  base_lr: 7.7955e-05 lr: 7.7955e-06  eta: 4:47:03  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 3.8575  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8575\n",
      "03/07 07:08:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2500/5225]  base_lr: 7.8814e-05 lr: 7.8814e-06  eta: 4:46:47  time: 0.1385  data_time: 0.0019  memory: 5847  loss: 3.8286  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.8286\n",
      "03/07 07:08:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2600/5225]  base_lr: 7.9673e-05 lr: 7.9673e-06  eta: 4:46:32  time: 0.1373  data_time: 0.0019  memory: 5847  loss: 3.5946  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.5946\n",
      "03/07 07:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2700/5225]  base_lr: 8.0532e-05 lr: 8.0532e-06  eta: 4:46:17  time: 0.1374  data_time: 0.0018  memory: 5847  loss: 3.7700  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.7700\n",
      "03/07 07:09:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:09:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2800/5225]  base_lr: 8.1391e-05 lr: 8.1391e-06  eta: 4:46:01  time: 0.1381  data_time: 0.0018  memory: 5847  loss: 3.4726  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.4726\n",
      "03/07 07:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][2900/5225]  base_lr: 8.2250e-05 lr: 8.2250e-06  eta: 4:45:44  time: 0.1384  data_time: 0.0019  memory: 5847  loss: 3.8711  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8711\n",
      "03/07 07:09:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3000/5225]  base_lr: 8.3109e-05 lr: 8.3109e-06  eta: 4:45:28  time: 0.1393  data_time: 0.0019  memory: 5847  loss: 3.6772  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 3.6772\n",
      "03/07 07:10:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3100/5225]  base_lr: 8.3968e-05 lr: 8.3968e-06  eta: 4:45:13  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 3.6413  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.6413\n",
      "03/07 07:10:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3200/5225]  base_lr: 8.4827e-05 lr: 8.4827e-06  eta: 4:44:56  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 3.8940  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8940\n",
      "03/07 07:10:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3300/5225]  base_lr: 8.5686e-05 lr: 8.5686e-06  eta: 4:44:38  time: 0.1368  data_time: 0.0020  memory: 5847  loss: 3.6696  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 3.6696\n",
      "03/07 07:10:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3400/5225]  base_lr: 8.6545e-05 lr: 8.6545e-06  eta: 4:44:22  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 3.5585  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.5585\n",
      "03/07 07:10:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3500/5225]  base_lr: 8.7403e-05 lr: 8.7403e-06  eta: 4:44:07  time: 0.1405  data_time: 0.0019  memory: 5847  loss: 4.0132  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 4.0132\n",
      "03/07 07:11:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3600/5225]  base_lr: 8.8262e-05 lr: 8.8262e-06  eta: 4:43:52  time: 0.1390  data_time: 0.0020  memory: 5847  loss: 3.8555  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.8555\n",
      "03/07 07:11:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3700/5225]  base_lr: 8.9121e-05 lr: 8.9121e-06  eta: 4:43:36  time: 0.1376  data_time: 0.0019  memory: 5847  loss: 3.3746  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.3746\n",
      "03/07 07:11:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:11:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3800/5225]  base_lr: 8.9980e-05 lr: 8.9980e-06  eta: 4:43:20  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 3.7256  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7256\n",
      "03/07 07:11:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][3900/5225]  base_lr: 9.0839e-05 lr: 9.0839e-06  eta: 4:43:05  time: 0.1384  data_time: 0.0019  memory: 5847  loss: 3.2791  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.2791\n",
      "03/07 07:12:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4000/5225]  base_lr: 9.1698e-05 lr: 9.1698e-06  eta: 4:42:48  time: 0.1383  data_time: 0.0018  memory: 5847  loss: 3.6893  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.6893\n",
      "03/07 07:12:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4100/5225]  base_lr: 9.2557e-05 lr: 9.2557e-06  eta: 4:42:31  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 3.7589  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.7589\n",
      "03/07 07:12:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4200/5225]  base_lr: 9.3416e-05 lr: 9.3416e-06  eta: 4:42:15  time: 0.1410  data_time: 0.0018  memory: 5847  loss: 3.3937  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.3937\n",
      "03/07 07:12:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4300/5225]  base_lr: 9.4275e-05 lr: 9.4275e-06  eta: 4:42:01  time: 0.1393  data_time: 0.0020  memory: 5847  loss: 3.7228  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7228\n",
      "03/07 07:13:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4400/5225]  base_lr: 9.5134e-05 lr: 9.5134e-06  eta: 4:41:46  time: 0.1383  data_time: 0.0019  memory: 5847  loss: 3.5437  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.5437\n",
      "03/07 07:13:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4500/5225]  base_lr: 9.5993e-05 lr: 9.5993e-06  eta: 4:41:29  time: 0.1379  data_time: 0.0018  memory: 5847  loss: 3.4607  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.4607\n",
      "03/07 07:13:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4600/5225]  base_lr: 9.6852e-05 lr: 9.6852e-06  eta: 4:41:13  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 3.6729  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.6729\n",
      "03/07 07:13:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4700/5225]  base_lr: 9.7711e-05 lr: 9.7711e-06  eta: 4:40:56  time: 0.1373  data_time: 0.0019  memory: 5847  loss: 3.2665  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.2665\n",
      "03/07 07:13:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:13:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4800/5225]  base_lr: 9.8570e-05 lr: 9.8570e-06  eta: 4:40:41  time: 0.1390  data_time: 0.0019  memory: 5847  loss: 3.8886  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.8886\n",
      "03/07 07:14:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4900/5225]  base_lr: 9.9429e-05 lr: 9.9429e-06  eta: 4:40:25  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 3.4350  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.4350\n",
      "03/07 07:14:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][5000/5225]  base_lr: 1.0029e-04 lr: 1.0029e-05  eta: 4:40:09  time: 0.1378  data_time: 0.0019  memory: 5847  loss: 3.2172  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.2172\n",
      "03/07 07:14:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][5100/5225]  base_lr: 1.0115e-04 lr: 1.0115e-05  eta: 4:39:56  time: 0.1400  data_time: 0.0019  memory: 5847  loss: 3.2580  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.2580\n",
      "03/07 07:14:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][5200/5225]  base_lr: 1.0201e-04 lr: 1.0201e-05  eta: 4:39:41  time: 0.1396  data_time: 0.0019  memory: 5847  loss: 3.9838  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.9838\n",
      "03/07 07:14:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:14:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][5225/5225]  base_lr: 1.0222e-04 lr: 1.0222e-05  eta: 4:39:38  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 3.8266  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 3.8266\n",
      "03/07 07:14:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][100/647]    eta: 0:00:16  time: 0.0294  data_time: 0.0008  memory: 1333  \n",
      "03/07 07:15:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][200/647]    eta: 0:00:13  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "03/07 07:15:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][300/647]    eta: 0:00:10  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "03/07 07:15:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][400/647]    eta: 0:00:07  time: 0.0294  data_time: 0.0008  memory: 1333  \n",
      "03/07 07:15:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][500/647]    eta: 0:00:04  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "03/07 07:15:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][600/647]    eta: 0:00:01  time: 0.0293  data_time: 0.0005  memory: 1333  \n",
      "[21]\n",
      "[104]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[104]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[104]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[13]\n",
      "[104]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[22]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[22]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[104]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[104]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[24]\n",
      "[21]\n",
      "[24]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[24]\n",
      "[21]\n",
      "[21]\n",
      "[104]\n",
      "[22]\n",
      "[21]\n",
      "[24]\n",
      "[21]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[24]\n",
      "[96]\n",
      "[24]\n",
      "[21]\n",
      "[22]\n",
      "[21]\n",
      "[21]\n",
      "[24]\n",
      "[42]\n",
      "[93]\n",
      "[27]\n",
      "[42]\n",
      "[27]\n",
      "[27]\n",
      "[93]\n",
      "[27]\n",
      "[65]\n",
      "[40]\n",
      "[36]\n",
      "[27]\n",
      "[27]\n",
      "[27]\n",
      "[27]\n",
      "[27]\n",
      "[93]\n",
      "[39]\n",
      "[114]\n",
      "[114]\n",
      "[42]\n",
      "[93]\n",
      "[93]\n",
      "[27]\n",
      "[69]\n",
      "[39]\n",
      "[114]\n",
      "[114]\n",
      "[93]\n",
      "[93]\n",
      "[42]\n",
      "[42]\n",
      "[114]\n",
      "[27]\n",
      "[114]\n",
      "[114]\n",
      "[114]\n",
      "[114]\n",
      "[65]\n",
      "[114]\n",
      "[114]\n",
      "[114]\n",
      "[114]\n",
      "[114]\n",
      "[114]\n",
      "[114]\n",
      "[114]\n",
      "[114]\n",
      "[65]\n",
      "[114]\n",
      "[69]\n",
      "[39]\n",
      "[39]\n",
      "[39]\n",
      "[39]\n",
      "[65]\n",
      "[114]\n",
      "[114]\n",
      "[69]\n",
      "[113]\n",
      "[114]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[22]\n",
      "[0]\n",
      "[0]\n",
      "[114]\n",
      "[0]\n",
      "[9]\n",
      "[22]\n",
      "[77]\n",
      "[22]\n",
      "[27]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[89]\n",
      "[27]\n",
      "[0]\n",
      "[52]\n",
      "[21]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[10]\n",
      "[15]\n",
      "[54]\n",
      "[15]\n",
      "[15]\n",
      "[89]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[10]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[10]\n",
      "[22]\n",
      "[22]\n",
      "[39]\n",
      "[24]\n",
      "[22]\n",
      "[54]\n",
      "[22]\n",
      "[15]\n",
      "[21]\n",
      "[22]\n",
      "[22]\n",
      "[65]\n",
      "[83]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[0]\n",
      "[22]\n",
      "[54]\n",
      "[22]\n",
      "[22]\n",
      "[9]\n",
      "[22]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[100]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[65]\n",
      "[65]\n",
      "[63]\n",
      "[65]\n",
      "[65]\n",
      "[65]\n",
      "[65]\n",
      "[65]\n",
      "[65]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[65]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[68]\n",
      "[65]\n",
      "[65]\n",
      "[69]\n",
      "[69]\n",
      "[64]\n",
      "[40]\n",
      "[40]\n",
      "[40]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[65]\n",
      "[65]\n",
      "[65]\n",
      "[69]\n",
      "[64]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[65]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[68]\n",
      "[69]\n",
      "[68]\n",
      "[68]\n",
      "[69]\n",
      "[65]\n",
      "[95]\n",
      "[95]\n",
      "[122]\n",
      "[54]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[121]\n",
      "[122]\n",
      "[121]\n",
      "[122]\n",
      "[95]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[121]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[78]\n",
      "[78]\n",
      "[77]\n",
      "[89]\n",
      "[78]\n",
      "[89]\n",
      "[77]\n",
      "[78]\n",
      "[78]\n",
      "[89]\n",
      "[89]\n",
      "[77]\n",
      "[77]\n",
      "[77]\n",
      "[77]\n",
      "[77]\n",
      "[77]\n",
      "[77]\n",
      "[89]\n",
      "[89]\n",
      "[77]\n",
      "[77]\n",
      "[78]\n",
      "[78]\n",
      "[77]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[77]\n",
      "[77]\n",
      "[77]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[77]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[77]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[77]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[77]\n",
      "[77]\n",
      "[77]\n",
      "[77]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[77]\n",
      "[78]\n",
      "[77]\n",
      "[78]\n",
      "[22]\n",
      "[77]\n",
      "[77]\n",
      "[77]\n",
      "[77]\n",
      "[22]\n",
      "[3]\n",
      "[73]\n",
      "[73]\n",
      "[77]\n",
      "[77]\n",
      "[78]\n",
      "[78]\n",
      "[77]\n",
      "[77]\n",
      "[73]\n",
      "[77]\n",
      "[77]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[27]\n",
      "[27]\n",
      "[115]\n",
      "[93]\n",
      "[65]\n",
      "[93]\n",
      "[65]\n",
      "[65]\n",
      "[93]\n",
      "[27]\n",
      "[68]\n",
      "[68]\n",
      "[27]\n",
      "[27]\n",
      "[27]\n",
      "[114]\n",
      "[27]\n",
      "[27]\n",
      "[65]\n",
      "[27]\n",
      "[34]\n",
      "[95]\n",
      "[49]\n",
      "[68]\n",
      "[69]\n",
      "[68]\n",
      "[101]\n",
      "[102]\n",
      "[102]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[40]\n",
      "[40]\n",
      "[40]\n",
      "[101]\n",
      "[40]\n",
      "[62]\n",
      "[62]\n",
      "[62]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[101]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[101]\n",
      "[102]\n",
      "[103]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[101]\n",
      "[96]\n",
      "[104]\n",
      "[104]\n",
      "[96]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[96]\n",
      "[96]\n",
      "[104]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[122]\n",
      "[34]\n",
      "[34]\n",
      "[95]\n",
      "[34]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[39]\n",
      "[89]\n",
      "[39]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[89]\n",
      "[89]\n",
      "[39]\n",
      "[78]\n",
      "[84]\n",
      "[89]\n",
      "[89]\n",
      "[117]\n",
      "[84]\n",
      "[113]\n",
      "[114]\n",
      "[117]\n",
      "[117]\n",
      "[112]\n",
      "[112]\n",
      "[117]\n",
      "[117]\n",
      "[114]\n",
      "[114]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[95]\n",
      "[54]\n",
      "[54]\n",
      "[95]\n",
      "[54]\n",
      "[54]\n",
      "03/07 07:15:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][647/647]    acc/top1: 0.0371  acc/top5: 0.2009  acc/mean1: 0.0830  data_time: 0.0009  time: 0.0295\n",
      "03/07 07:15:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_1.pth is removed\n",
      "03/07 07:15:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.0371 acc/top1 at 2 epoch is saved to best_acc_top1_epoch_2.pth.\n",
      "03/07 07:15:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 100/5225]  base_lr: 1.0223e-04 lr: 1.0223e-05  eta: 4:39:22  time: 0.1367  data_time: 0.0020  memory: 5847  loss: 3.6761  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.6761\n",
      "03/07 07:15:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 200/5225]  base_lr: 1.0309e-04 lr: 1.0309e-05  eta: 4:39:07  time: 0.1400  data_time: 0.0020  memory: 5847  loss: 3.3435  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.3435\n",
      "03/07 07:15:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 300/5225]  base_lr: 1.0394e-04 lr: 1.0394e-05  eta: 4:38:52  time: 0.1377  data_time: 0.0019  memory: 5847  loss: 3.4674  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.4674\n",
      "03/07 07:16:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 400/5225]  base_lr: 1.0479e-04 lr: 1.0479e-05  eta: 4:38:35  time: 0.1373  data_time: 0.0019  memory: 5847  loss: 3.3218  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.3218\n",
      "03/07 07:16:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 500/5225]  base_lr: 1.0564e-04 lr: 1.0564e-05  eta: 4:38:19  time: 0.1378  data_time: 0.0019  memory: 5847  loss: 3.3196  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.3196\n",
      "03/07 07:16:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:16:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 600/5225]  base_lr: 1.0649e-04 lr: 1.0649e-05  eta: 4:38:04  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 3.6418  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.6418\n",
      "03/07 07:16:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 700/5225]  base_lr: 1.0735e-04 lr: 1.0735e-05  eta: 4:37:49  time: 0.1395  data_time: 0.0019  memory: 5847  loss: 3.2462  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.2462\n",
      "03/07 07:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 800/5225]  base_lr: 1.0820e-04 lr: 1.0820e-05  eta: 4:37:33  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 3.5244  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.5244\n",
      "03/07 07:17:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 900/5225]  base_lr: 1.0905e-04 lr: 1.0905e-05  eta: 4:37:19  time: 0.1392  data_time: 0.0020  memory: 5847  loss: 3.5611  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.5611\n",
      "03/07 07:17:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1000/5225]  base_lr: 1.0990e-04 lr: 1.0990e-05  eta: 4:37:04  time: 0.1375  data_time: 0.0018  memory: 5847  loss: 3.7845  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.7845\n",
      "03/07 07:17:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1100/5225]  base_lr: 1.1075e-04 lr: 1.1075e-05  eta: 4:36:48  time: 0.1378  data_time: 0.0018  memory: 5847  loss: 3.4229  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.4229\n",
      "03/07 07:18:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1200/5225]  base_lr: 1.1160e-04 lr: 1.1160e-05  eta: 4:36:32  time: 0.1385  data_time: 0.0018  memory: 5847  loss: 3.5985  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.5985\n",
      "03/07 07:18:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1300/5225]  base_lr: 1.1246e-04 lr: 1.1246e-05  eta: 4:36:17  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 3.4961  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.4961\n",
      "03/07 07:18:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1400/5225]  base_lr: 1.1331e-04 lr: 1.1331e-05  eta: 4:36:01  time: 0.1370  data_time: 0.0019  memory: 5847  loss: 3.4812  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.4812\n",
      "03/07 07:18:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1500/5225]  base_lr: 1.1416e-04 lr: 1.1416e-05  eta: 4:35:47  time: 0.1398  data_time: 0.0018  memory: 5847  loss: 3.3690  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.3690\n",
      "03/07 07:18:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:18:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1600/5225]  base_lr: 1.1501e-04 lr: 1.1501e-05  eta: 4:35:32  time: 0.1374  data_time: 0.0017  memory: 5847  loss: 3.3902  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.3902\n",
      "03/07 07:19:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1700/5225]  base_lr: 1.1586e-04 lr: 1.1586e-05  eta: 4:35:17  time: 0.1374  data_time: 0.0018  memory: 5847  loss: 3.5480  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.5480\n",
      "03/07 07:19:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1800/5225]  base_lr: 1.1672e-04 lr: 1.1672e-05  eta: 4:35:01  time: 0.1380  data_time: 0.0019  memory: 5847  loss: 3.4465  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.4465\n",
      "03/07 07:19:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1900/5225]  base_lr: 1.1757e-04 lr: 1.1757e-05  eta: 4:34:46  time: 0.1366  data_time: 0.0019  memory: 5847  loss: 3.1214  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.1214\n",
      "03/07 07:19:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2000/5225]  base_lr: 1.1842e-04 lr: 1.1842e-05  eta: 4:34:31  time: 0.1374  data_time: 0.0019  memory: 5847  loss: 3.2600  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.2600\n",
      "03/07 07:20:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2100/5225]  base_lr: 1.1927e-04 lr: 1.1927e-05  eta: 4:34:15  time: 0.1383  data_time: 0.0018  memory: 5847  loss: 3.6220  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.6220\n",
      "03/07 07:20:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2200/5225]  base_lr: 1.2012e-04 lr: 1.2012e-05  eta: 4:34:00  time: 0.1374  data_time: 0.0019  memory: 5847  loss: 3.6198  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.6198\n",
      "03/07 07:20:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2300/5225]  base_lr: 1.2098e-04 lr: 1.2098e-05  eta: 4:33:45  time: 0.1419  data_time: 0.0018  memory: 5847  loss: 3.6019  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.6019\n",
      "03/07 07:20:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2400/5225]  base_lr: 1.2183e-04 lr: 1.2183e-05  eta: 4:33:31  time: 0.1378  data_time: 0.0019  memory: 5847  loss: 3.5392  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.5392\n",
      "03/07 07:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2500/5225]  base_lr: 1.2268e-04 lr: 1.2268e-05  eta: 4:33:18  time: 0.1404  data_time: 0.0019  memory: 5847  loss: 3.1659  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.1659\n",
      "03/07 07:21:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:21:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2600/5225]  base_lr: 1.2353e-04 lr: 1.2353e-05  eta: 4:33:02  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 3.0265  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.0265\n",
      "03/07 07:21:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2700/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:32:46  time: 0.1370  data_time: 0.0018  memory: 5847  loss: 3.6729  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.6729\n",
      "03/07 07:21:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2800/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:32:32  time: 0.1410  data_time: 0.0018  memory: 5847  loss: 3.3649  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.3649\n",
      "03/07 07:21:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][2900/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:32:18  time: 0.1387  data_time: 0.0019  memory: 5847  loss: 3.2396  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.2396\n",
      "03/07 07:22:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3000/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:32:02  time: 0.1366  data_time: 0.0016  memory: 5847  loss: 3.4772  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.4772\n",
      "03/07 07:22:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3100/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:31:46  time: 0.1378  data_time: 0.0016  memory: 5847  loss: 3.3666  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.3666\n",
      "03/07 07:22:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3200/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:31:31  time: 0.1379  data_time: 0.0016  memory: 5847  loss: 3.4800  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.4800\n",
      "03/07 07:22:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3300/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:31:17  time: 0.1383  data_time: 0.0016  memory: 5847  loss: 3.2907  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.2907\n",
      "03/07 07:23:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3400/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:31:02  time: 0.1373  data_time: 0.0016  memory: 5847  loss: 3.5282  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.5282\n",
      "03/07 07:23:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3500/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:30:47  time: 0.1383  data_time: 0.0017  memory: 5847  loss: 3.3062  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.3062\n",
      "03/07 07:23:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:23:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3600/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:30:33  time: 0.1373  data_time: 0.0017  memory: 5847  loss: 3.5657  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.5657\n",
      "03/07 07:23:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3700/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:30:18  time: 0.1374  data_time: 0.0018  memory: 5847  loss: 3.6496  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.6496\n",
      "03/07 07:24:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3800/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:30:03  time: 0.1387  data_time: 0.0018  memory: 5847  loss: 3.1622  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.1622\n",
      "03/07 07:24:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][3900/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:29:48  time: 0.1378  data_time: 0.0019  memory: 5847  loss: 2.8877  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.8877\n",
      "03/07 07:24:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4000/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:29:33  time: 0.1370  data_time: 0.0016  memory: 5847  loss: 3.6716  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.6716\n",
      "03/07 07:24:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4100/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:29:18  time: 0.1380  data_time: 0.0017  memory: 5847  loss: 3.4309  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.4309\n",
      "03/07 07:24:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4200/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:29:03  time: 0.1377  data_time: 0.0017  memory: 5847  loss: 2.9716  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.9716\n",
      "03/07 07:25:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4300/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:28:49  time: 0.1395  data_time: 0.0017  memory: 5847  loss: 3.1917  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.1917\n",
      "03/07 07:25:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4400/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:28:34  time: 0.1381  data_time: 0.0017  memory: 5847  loss: 3.3200  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.3200\n",
      "03/07 07:25:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4500/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:28:19  time: 0.1382  data_time: 0.0018  memory: 5847  loss: 3.5645  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.5645\n",
      "03/07 07:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:25:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4600/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:28:04  time: 0.1371  data_time: 0.0017  memory: 5847  loss: 3.0058  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.0058\n",
      "03/07 07:26:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4700/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:27:49  time: 0.1392  data_time: 0.0018  memory: 5847  loss: 2.8514  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.8514\n",
      "03/07 07:26:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4800/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:27:34  time: 0.1383  data_time: 0.0017  memory: 5847  loss: 3.3874  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.3874\n",
      "03/07 07:26:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4900/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:27:19  time: 0.1396  data_time: 0.0017  memory: 5847  loss: 3.0586  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.0586\n",
      "03/07 07:26:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][5000/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:27:06  time: 0.1398  data_time: 0.0018  memory: 5847  loss: 3.2887  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.2887\n",
      "03/07 07:27:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][5100/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:26:52  time: 0.1387  data_time: 0.0017  memory: 5847  loss: 3.2462  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.2462\n",
      "03/07 07:27:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][5200/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:26:37  time: 0.1385  data_time: 0.0018  memory: 5847  loss: 3.1980  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.1980\n",
      "03/07 07:27:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:27:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][5225/5225]  base_lr: 1.2363e-04 lr: 1.2363e-05  eta: 4:26:35  time: 0.1480  data_time: 0.0014  memory: 5847  loss: 2.7856  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.7856\n",
      "03/07 07:27:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "03/07 07:27:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][100/647]    eta: 0:00:16  time: 0.0318  data_time: 0.0017  memory: 1333  \n",
      "03/07 07:27:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][200/647]    eta: 0:00:13  time: 0.0300  data_time: 0.0009  memory: 1333  \n",
      "03/07 07:27:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][300/647]    eta: 0:00:10  time: 0.0298  data_time: 0.0009  memory: 1333  \n",
      "03/07 07:27:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][400/647]    eta: 0:00:07  time: 0.0298  data_time: 0.0008  memory: 1333  \n",
      "03/07 07:27:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][500/647]    eta: 0:00:04  time: 0.0297  data_time: 0.0004  memory: 1333  \n",
      "03/07 07:27:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][600/647]    eta: 0:00:01  time: 0.0304  data_time: 0.0018  memory: 1333  \n",
      "[14]\n",
      "[28]\n",
      "[18]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[22]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[21]\n",
      "[18]\n",
      "[18]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[28]\n",
      "[11]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[9]\n",
      "[9]\n",
      "[28]\n",
      "[17]\n",
      "[17]\n",
      "[28]\n",
      "[9]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[21]\n",
      "[11]\n",
      "[18]\n",
      "[11]\n",
      "[21]\n",
      "[21]\n",
      "[0]\n",
      "[21]\n",
      "[11]\n",
      "[22]\n",
      "[21]\n",
      "[21]\n",
      "[22]\n",
      "[21]\n",
      "[11]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[0]\n",
      "[24]\n",
      "[24]\n",
      "[11]\n",
      "[25]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[0]\n",
      "[4]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[21]\n",
      "[0]\n",
      "[25]\n",
      "[0]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[11]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[24]\n",
      "[42]\n",
      "[27]\n",
      "[27]\n",
      "[41]\n",
      "[61]\n",
      "[61]\n",
      "[27]\n",
      "[27]\n",
      "[93]\n",
      "[52]\n",
      "[33]\n",
      "[27]\n",
      "[93]\n",
      "[27]\n",
      "[93]\n",
      "[93]\n",
      "[27]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[27]\n",
      "[27]\n",
      "[93]\n",
      "[42]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[91]\n",
      "[91]\n",
      "[42]\n",
      "[42]\n",
      "[33]\n",
      "[27]\n",
      "[33]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[33]\n",
      "[65]\n",
      "[41]\n",
      "[29]\n",
      "[38]\n",
      "[41]\n",
      "[38]\n",
      "[68]\n",
      "[67]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[110]\n",
      "[34]\n",
      "[110]\n",
      "[34]\n",
      "[34]\n",
      "[110]\n",
      "[33]\n",
      "[34]\n",
      "[33]\n",
      "[34]\n",
      "[52]\n",
      "[9]\n",
      "[52]\n",
      "[116]\n",
      "[9]\n",
      "[9]\n",
      "[0]\n",
      "[3]\n",
      "[22]\n",
      "[27]\n",
      "[9]\n",
      "[0]\n",
      "[9]\n",
      "[52]\n",
      "[53]\n",
      "[53]\n",
      "[0]\n",
      "[30]\n",
      "[52]\n",
      "[9]\n",
      "[9]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[9]\n",
      "[53]\n",
      "[53]\n",
      "[17]\n",
      "[17]\n",
      "[26]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[9]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[52]\n",
      "[9]\n",
      "[9]\n",
      "[3]\n",
      "[9]\n",
      "[9]\n",
      "[52]\n",
      "[52]\n",
      "[9]\n",
      "[3]\n",
      "[52]\n",
      "[22]\n",
      "[27]\n",
      "[3]\n",
      "[9]\n",
      "[9]\n",
      "[52]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[52]\n",
      "[9]\n",
      "[9]\n",
      "[52]\n",
      "[22]\n",
      "[54]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[51]\n",
      "[51]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[52]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[51]\n",
      "[51]\n",
      "[53]\n",
      "[52]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[65]\n",
      "[70]\n",
      "[67]\n",
      "[67]\n",
      "[65]\n",
      "[63]\n",
      "[65]\n",
      "[65]\n",
      "[65]\n",
      "[70]\n",
      "[70]\n",
      "[27]\n",
      "[67]\n",
      "[70]\n",
      "[69]\n",
      "[67]\n",
      "[67]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[68]\n",
      "[69]\n",
      "[70]\n",
      "[67]\n",
      "[65]\n",
      "[68]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[68]\n",
      "[68]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[65]\n",
      "[65]\n",
      "[65]\n",
      "[68]\n",
      "[70]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[65]\n",
      "[68]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[68]\n",
      "[68]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[70]\n",
      "[95]\n",
      "[121]\n",
      "[121]\n",
      "[95]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[72]\n",
      "[72]\n",
      "[78]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[78]\n",
      "[78]\n",
      "[72]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[78]\n",
      "[89]\n",
      "[76]\n",
      "[78]\n",
      "[89]\n",
      "[76]\n",
      "[78]\n",
      "[78]\n",
      "[76]\n",
      "[76]\n",
      "[78]\n",
      "[76]\n",
      "[76]\n",
      "[89]\n",
      "[89]\n",
      "[80]\n",
      "[76]\n",
      "[89]\n",
      "[76]\n",
      "[76]\n",
      "[76]\n",
      "[78]\n",
      "[76]\n",
      "[76]\n",
      "[78]\n",
      "[89]\n",
      "[80]\n",
      "[80]\n",
      "[78]\n",
      "[78]\n",
      "[76]\n",
      "[76]\n",
      "[76]\n",
      "[76]\n",
      "[84]\n",
      "[73]\n",
      "[78]\n",
      "[87]\n",
      "[89]\n",
      "[89]\n",
      "[78]\n",
      "[78]\n",
      "[78]\n",
      "[76]\n",
      "[72]\n",
      "[3]\n",
      "[79]\n",
      "[79]\n",
      "[79]\n",
      "[79]\n",
      "[3]\n",
      "[3]\n",
      "[87]\n",
      "[87]\n",
      "[3]\n",
      "[89]\n",
      "[72]\n",
      "[72]\n",
      "[79]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[91]\n",
      "[87]\n",
      "[91]\n",
      "[30]\n",
      "[93]\n",
      "[31]\n",
      "[31]\n",
      "[91]\n",
      "[93]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[93]\n",
      "[91]\n",
      "[68]\n",
      "[68]\n",
      "[68]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[93]\n",
      "[91]\n",
      "[34]\n",
      "[49]\n",
      "[49]\n",
      "[68]\n",
      "[116]\n",
      "[68]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[40]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[103]\n",
      "[103]\n",
      "[64]\n",
      "[103]\n",
      "[64]\n",
      "[103]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[92]\n",
      "[92]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[97]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[34]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[112]\n",
      "[3]\n",
      "[112]\n",
      "[112]\n",
      "[117]\n",
      "[112]\n",
      "[117]\n",
      "[112]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[74]\n",
      "[69]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[116]\n",
      "[42]\n",
      "[116]\n",
      "[116]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[117]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[110]\n",
      "[34]\n",
      "[110]\n",
      "[34]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[51]\n",
      "[110]\n",
      "03/07 07:27:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][647/647]    acc/top1: 0.0680  acc/top5: 0.2612  acc/mean1: 0.1306  data_time: 0.0010  time: 0.0301\n",
      "03/07 07:27:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_2.pth is removed\n",
      "03/07 07:27:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.0680 acc/top1 at 3 epoch is saved to best_acc_top1_epoch_3.pth.\n",
      "03/07 07:27:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 100/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:26:22  time: 0.1375  data_time: 0.0017  memory: 5847  loss: 3.2725  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.2725\n",
      "03/07 07:28:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 200/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:26:08  time: 0.1387  data_time: 0.0017  memory: 5847  loss: 3.7791  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.7791\n",
      "03/07 07:28:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 300/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:25:56  time: 0.1464  data_time: 0.0013  memory: 5847  loss: 3.4419  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.4419\n",
      "03/07 07:28:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:28:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 400/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:25:45  time: 0.1435  data_time: 0.0024  memory: 5847  loss: 2.8187  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.8187\n",
      "03/07 07:28:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 500/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:25:36  time: 0.1442  data_time: 0.0013  memory: 5847  loss: 3.1173  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.1173\n",
      "03/07 07:29:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 600/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:25:24  time: 0.1396  data_time: 0.0022  memory: 5847  loss: 2.7231  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.7231\n",
      "03/07 07:29:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 700/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:25:11  time: 0.1400  data_time: 0.0017  memory: 5847  loss: 3.3748  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.3748\n",
      "03/07 07:29:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 800/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:24:57  time: 0.1391  data_time: 0.0020  memory: 5847  loss: 3.4122  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 3.4122\n",
      "03/07 07:29:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 900/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:24:43  time: 0.1383  data_time: 0.0011  memory: 5847  loss: 3.3833  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.3833\n",
      "03/07 07:30:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1000/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:24:29  time: 0.1401  data_time: 0.0014  memory: 5847  loss: 2.9311  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.9311\n",
      "03/07 07:30:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1100/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:24:15  time: 0.1393  data_time: 0.0022  memory: 5847  loss: 3.4397  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.4397\n",
      "03/07 07:30:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1200/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:24:00  time: 0.1376  data_time: 0.0005  memory: 5847  loss: 3.0143  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.0143\n",
      "03/07 07:30:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1300/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:23:47  time: 0.1390  data_time: 0.0027  memory: 5847  loss: 3.3614  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.3614\n",
      "03/07 07:30:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:30:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1400/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:23:33  time: 0.1390  data_time: 0.0016  memory: 5847  loss: 3.4189  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.4189\n",
      "03/07 07:31:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1500/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:23:20  time: 0.1398  data_time: 0.0019  memory: 5847  loss: 3.4615  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.4615\n",
      "03/07 07:31:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1600/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:23:05  time: 0.1372  data_time: 0.0017  memory: 5847  loss: 3.2664  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.2664\n",
      "03/07 07:31:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1700/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:22:50  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 2.7294  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.7294\n",
      "03/07 07:31:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1800/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:22:35  time: 0.1377  data_time: 0.0018  memory: 5847  loss: 3.3550  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.3550\n",
      "03/07 07:32:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1900/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:22:21  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 3.2530  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.2530\n",
      "03/07 07:32:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2000/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:22:06  time: 0.1385  data_time: 0.0018  memory: 5847  loss: 3.0068  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.0068\n",
      "03/07 07:32:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2100/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:21:51  time: 0.1415  data_time: 0.0018  memory: 5847  loss: 3.4019  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.4019\n",
      "03/07 07:32:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2200/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:21:38  time: 0.1414  data_time: 0.0019  memory: 5847  loss: 3.2802  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.2802\n",
      "03/07 07:33:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2300/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:21:24  time: 0.1408  data_time: 0.0019  memory: 5847  loss: 3.3255  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 3.3255\n",
      "03/07 07:33:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:33:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2400/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:21:09  time: 0.1373  data_time: 0.0018  memory: 5847  loss: 3.3727  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.3727\n",
      "03/07 07:33:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2500/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:20:54  time: 0.1378  data_time: 0.0022  memory: 5847  loss: 2.5905  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.5905\n",
      "03/07 07:33:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2600/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:20:40  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 3.5916  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.5916\n",
      "03/07 07:33:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2700/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:20:26  time: 0.1395  data_time: 0.0019  memory: 5847  loss: 2.8876  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.8876\n",
      "03/07 07:34:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2800/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:20:12  time: 0.1381  data_time: 0.0019  memory: 5847  loss: 3.0002  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.0002\n",
      "03/07 07:34:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][2900/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:19:58  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 3.2778  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.2778\n",
      "03/07 07:34:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3000/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:19:43  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 3.1156  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.1156\n",
      "03/07 07:34:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3100/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:19:29  time: 0.1371  data_time: 0.0020  memory: 5847  loss: 3.6427  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.6427\n",
      "03/07 07:35:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3200/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:19:14  time: 0.1380  data_time: 0.0018  memory: 5847  loss: 3.0718  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.0718\n",
      "03/07 07:35:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3300/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:19:00  time: 0.1409  data_time: 0.0020  memory: 5847  loss: 3.2598  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.2598\n",
      "03/07 07:35:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:35:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3400/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:18:46  time: 0.1382  data_time: 0.0018  memory: 5847  loss: 2.5601  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.5601\n",
      "03/07 07:35:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3500/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:18:31  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 2.7295  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.7295\n",
      "03/07 07:36:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3600/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:18:16  time: 0.1372  data_time: 0.0019  memory: 5847  loss: 2.8701  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.8701\n",
      "03/07 07:36:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3700/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:18:02  time: 0.1378  data_time: 0.0018  memory: 5847  loss: 3.2040  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.2040\n",
      "03/07 07:36:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3800/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:17:48  time: 0.1389  data_time: 0.0020  memory: 5847  loss: 3.0949  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.0949\n",
      "03/07 07:36:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][3900/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:17:34  time: 0.1386  data_time: 0.0021  memory: 5847  loss: 2.5144  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.5144\n",
      "03/07 07:36:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4000/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:17:20  time: 0.1393  data_time: 0.0021  memory: 5847  loss: 3.2761  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.2761\n",
      "03/07 07:37:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4100/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:17:05  time: 0.1371  data_time: 0.0019  memory: 5847  loss: 2.7763  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.7763\n",
      "03/07 07:37:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4200/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:16:51  time: 0.1363  data_time: 0.0018  memory: 5847  loss: 2.9374  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.9374\n",
      "03/07 07:37:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4300/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:16:36  time: 0.1381  data_time: 0.0019  memory: 5847  loss: 2.8965  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.8965\n",
      "03/07 07:37:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:37:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4400/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:16:22  time: 0.1372  data_time: 0.0021  memory: 5847  loss: 3.0256  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.0256\n",
      "03/07 07:38:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4500/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:16:07  time: 0.1383  data_time: 0.0019  memory: 5847  loss: 2.9840  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.9840\n",
      "03/07 07:38:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4600/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:15:53  time: 0.1378  data_time: 0.0020  memory: 5847  loss: 2.9633  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.9633\n",
      "03/07 07:38:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4700/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:15:38  time: 0.1418  data_time: 0.0019  memory: 5847  loss: 3.2745  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.2745\n",
      "03/07 07:38:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4800/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:15:25  time: 0.1408  data_time: 0.0020  memory: 5847  loss: 3.0878  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.0878\n",
      "03/07 07:39:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4900/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:15:11  time: 0.1382  data_time: 0.0019  memory: 5847  loss: 2.9283  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.9283\n",
      "03/07 07:39:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][5000/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:14:57  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 3.1154  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.1154\n",
      "03/07 07:39:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][5100/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:14:42  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 3.2551  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.2551\n",
      "03/07 07:39:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][5200/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:14:29  time: 0.1394  data_time: 0.0019  memory: 5847  loss: 3.3189  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.3189\n",
      "03/07 07:39:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:39:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][5225/5225]  base_lr: 1.2194e-04 lr: 1.2194e-05  eta: 4:14:25  time: 0.1387  data_time: 0.0018  memory: 5847  loss: 3.3203  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.3203\n",
      "03/07 07:39:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][100/647]    eta: 0:00:16  time: 0.0296  data_time: 0.0010  memory: 1333  \n",
      "03/07 07:39:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][200/647]    eta: 0:00:13  time: 0.0293  data_time: 0.0008  memory: 1333  \n",
      "03/07 07:39:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][300/647]    eta: 0:00:10  time: 0.0298  data_time: 0.0009  memory: 1333  \n",
      "03/07 07:39:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][400/647]    eta: 0:00:07  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "03/07 07:40:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][500/647]    eta: 0:00:04  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 07:40:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][600/647]    eta: 0:00:01  time: 0.0293  data_time: 0.0009  memory: 1333  \n",
      "[17]\n",
      "[20]\n",
      "[17]\n",
      "[26]\n",
      "[26]\n",
      "[17]\n",
      "[20]\n",
      "[20]\n",
      "[17]\n",
      "[26]\n",
      "[25]\n",
      "[26]\n",
      "[26]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[20]\n",
      "[17]\n",
      "[26]\n",
      "[26]\n",
      "[20]\n",
      "[17]\n",
      "[17]\n",
      "[23]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[23]\n",
      "[26]\n",
      "[26]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[25]\n",
      "[23]\n",
      "[25]\n",
      "[23]\n",
      "[25]\n",
      "[25]\n",
      "[23]\n",
      "[23]\n",
      "[25]\n",
      "[25]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[25]\n",
      "[26]\n",
      "[25]\n",
      "[24]\n",
      "[26]\n",
      "[26]\n",
      "[26]\n",
      "[23]\n",
      "[23]\n",
      "[25]\n",
      "[23]\n",
      "[25]\n",
      "[26]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[25]\n",
      "[25]\n",
      "[25]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[26]\n",
      "[26]\n",
      "[23]\n",
      "[23]\n",
      "[26]\n",
      "[42]\n",
      "[27]\n",
      "[93]\n",
      "[42]\n",
      "[30]\n",
      "[30]\n",
      "[23]\n",
      "[29]\n",
      "[36]\n",
      "[8]\n",
      "[41]\n",
      "[27]\n",
      "[93]\n",
      "[93]\n",
      "[93]\n",
      "[93]\n",
      "[93]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[27]\n",
      "[27]\n",
      "[93]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[41]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[63]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[38]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[67]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[33]\n",
      "[34]\n",
      "[33]\n",
      "[34]\n",
      "[94]\n",
      "[9]\n",
      "[9]\n",
      "[114]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[84]\n",
      "[23]\n",
      "[26]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[53]\n",
      "[53]\n",
      "[113]\n",
      "[113]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[9]\n",
      "[53]\n",
      "[53]\n",
      "[26]\n",
      "[26]\n",
      "[113]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[9]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[9]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[80]\n",
      "[9]\n",
      "[9]\n",
      "[53]\n",
      "[12]\n",
      "[9]\n",
      "[105]\n",
      "[9]\n",
      "[12]\n",
      "[41]\n",
      "[105]\n",
      "[9]\n",
      "[23]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[12]\n",
      "[9]\n",
      "[30]\n",
      "[9]\n",
      "[9]\n",
      "[23]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[51]\n",
      "[53]\n",
      "[53]\n",
      "[47]\n",
      "[50]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[51]\n",
      "[51]\n",
      "[53]\n",
      "[53]\n",
      "[70]\n",
      "[67]\n",
      "[69]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[67]\n",
      "[67]\n",
      "[27]\n",
      "[29]\n",
      "[29]\n",
      "[65]\n",
      "[67]\n",
      "[69]\n",
      "[27]\n",
      "[27]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[70]\n",
      "[27]\n",
      "[65]\n",
      "[69]\n",
      "[67]\n",
      "[64]\n",
      "[29]\n",
      "[29]\n",
      "[64]\n",
      "[67]\n",
      "[67]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[65]\n",
      "[65]\n",
      "[29]\n",
      "[69]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[70]\n",
      "[70]\n",
      "[67]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[29]\n",
      "[98]\n",
      "[98]\n",
      "[121]\n",
      "[98]\n",
      "[121]\n",
      "[98]\n",
      "[98]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[98]\n",
      "[98]\n",
      "[121]\n",
      "[121]\n",
      "[98]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[98]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[95]\n",
      "[95]\n",
      "[98]\n",
      "[95]\n",
      "[116]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[116]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[82]\n",
      "[82]\n",
      "[84]\n",
      "[90]\n",
      "[74]\n",
      "[89]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[89]\n",
      "[89]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[89]\n",
      "[89]\n",
      "[84]\n",
      "[90]\n",
      "[82]\n",
      "[82]\n",
      "[84]\n",
      "[89]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[82]\n",
      "[82]\n",
      "[84]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[82]\n",
      "[82]\n",
      "[84]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[84]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[84]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[73]\n",
      "[84]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[73]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[105]\n",
      "[31]\n",
      "[31]\n",
      "[93]\n",
      "[93]\n",
      "[93]\n",
      "[93]\n",
      "[93]\n",
      "[93]\n",
      "[91]\n",
      "[68]\n",
      "[68]\n",
      "[30]\n",
      "[91]\n",
      "[93]\n",
      "[93]\n",
      "[93]\n",
      "[91]\n",
      "[93]\n",
      "[93]\n",
      "[34]\n",
      "[98]\n",
      "[49]\n",
      "[35]\n",
      "[116]\n",
      "[34]\n",
      "[101]\n",
      "[102]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[40]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[101]\n",
      "[103]\n",
      "[103]\n",
      "[101]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[101]\n",
      "[101]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[102]\n",
      "[100]\n",
      "[0]\n",
      "[100]\n",
      "[98]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[104]\n",
      "[104]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[98]\n",
      "[98]\n",
      "[97]\n",
      "[0]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[95]\n",
      "[118]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[98]\n",
      "[116]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[98]\n",
      "[98]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[36]\n",
      "[36]\n",
      "[105]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[108]\n",
      "[36]\n",
      "[105]\n",
      "[74]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[105]\n",
      "[112]\n",
      "[108]\n",
      "[117]\n",
      "[113]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[74]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[117]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[108]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[110]\n",
      "[110]\n",
      "[110]\n",
      "[33]\n",
      "[33]\n",
      "[33]\n",
      "03/07 07:40:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][647/647]    acc/top1: 0.0572  acc/top5: 0.2828  acc/mean1: 0.1022  data_time: 0.0009  time: 0.0296\n",
      "03/07 07:40:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:40:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 100/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:14:11  time: 0.1376  data_time: 0.0018  memory: 5847  loss: 2.7774  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.7774\n",
      "03/07 07:40:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 200/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:13:57  time: 0.1383  data_time: 0.0019  memory: 5847  loss: 3.3210  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.3210\n",
      "03/07 07:40:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 300/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:13:43  time: 0.1403  data_time: 0.0021  memory: 5847  loss: 2.7476  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.7476\n",
      "03/07 07:41:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 400/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:13:29  time: 0.1384  data_time: 0.0017  memory: 5847  loss: 2.7178  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.7178\n",
      "03/07 07:41:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 500/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:13:15  time: 0.1394  data_time: 0.0020  memory: 5847  loss: 2.5362  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5362\n",
      "03/07 07:41:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 600/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:13:01  time: 0.1378  data_time: 0.0019  memory: 5847  loss: 3.1050  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.1050\n",
      "03/07 07:41:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 700/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:12:47  time: 0.1377  data_time: 0.0018  memory: 5847  loss: 2.9188  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.9188\n",
      "03/07 07:41:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 800/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:12:33  time: 0.1374  data_time: 0.0018  memory: 5847  loss: 2.9922  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.9922\n",
      "03/07 07:42:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 900/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:12:18  time: 0.1379  data_time: 0.0022  memory: 5847  loss: 2.9506  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.9506\n",
      "03/07 07:42:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1000/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:12:04  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 3.0625  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.0625\n",
      "03/07 07:42:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:42:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1100/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:11:50  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 2.4807  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.4807\n",
      "03/07 07:42:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1200/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:11:36  time: 0.1388  data_time: 0.0021  memory: 5847  loss: 3.3230  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.3230\n",
      "03/07 07:43:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1300/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:11:22  time: 0.1381  data_time: 0.0019  memory: 5847  loss: 2.4561  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4561\n",
      "03/07 07:43:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1400/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:11:07  time: 0.1382  data_time: 0.0018  memory: 5847  loss: 3.3253  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.3253\n",
      "03/07 07:43:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1500/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:10:53  time: 0.1383  data_time: 0.0019  memory: 5847  loss: 2.8346  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.8346\n",
      "03/07 07:43:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1600/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:10:38  time: 0.1379  data_time: 0.0018  memory: 5847  loss: 2.7040  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.7040\n",
      "03/07 07:44:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1700/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:10:24  time: 0.1375  data_time: 0.0018  memory: 5847  loss: 2.7294  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.7294\n",
      "03/07 07:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1800/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:10:09  time: 0.1370  data_time: 0.0019  memory: 5847  loss: 2.8086  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.8086\n",
      "03/07 07:44:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1900/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:09:55  time: 0.1367  data_time: 0.0020  memory: 5847  loss: 2.9296  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.9296\n",
      "03/07 07:44:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2000/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:09:42  time: 0.1408  data_time: 0.0016  memory: 5847  loss: 2.4994  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4994\n",
      "03/07 07:44:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:44:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2100/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:09:28  time: 0.1387  data_time: 0.0017  memory: 5847  loss: 3.3988  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.3988\n",
      "03/07 07:45:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2200/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:09:14  time: 0.1373  data_time: 0.0018  memory: 5847  loss: 2.8395  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.8395\n",
      "03/07 07:45:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2300/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:08:59  time: 0.1384  data_time: 0.0018  memory: 5847  loss: 2.8318  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.8318\n",
      "03/07 07:45:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2400/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:08:45  time: 0.1384  data_time: 0.0019  memory: 5847  loss: 3.2139  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.2139\n",
      "03/07 07:45:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2500/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:08:31  time: 0.1386  data_time: 0.0020  memory: 5847  loss: 2.8101  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.8101\n",
      "03/07 07:46:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2600/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:08:17  time: 0.1389  data_time: 0.0020  memory: 5847  loss: 2.6879  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.6879\n",
      "03/07 07:46:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2700/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:08:03  time: 0.1369  data_time: 0.0020  memory: 5847  loss: 2.9747  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.9747\n",
      "03/07 07:46:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2800/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:07:48  time: 0.1401  data_time: 0.0019  memory: 5847  loss: 3.0574  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.0574\n",
      "03/07 07:46:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][2900/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:07:34  time: 0.1374  data_time: 0.0019  memory: 5847  loss: 2.5291  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.5291\n",
      "03/07 07:47:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3000/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:07:20  time: 0.1389  data_time: 0.0020  memory: 5847  loss: 2.7807  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.7807\n",
      "03/07 07:47:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:47:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3100/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:07:06  time: 0.1382  data_time: 0.0019  memory: 5847  loss: 2.6892  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.6892\n",
      "03/07 07:47:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3200/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:06:52  time: 0.1374  data_time: 0.0020  memory: 5847  loss: 3.2202  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.2202\n",
      "03/07 07:47:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3300/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:06:37  time: 0.1377  data_time: 0.0018  memory: 5847  loss: 3.0750  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 3.0750\n",
      "03/07 07:47:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3400/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:06:23  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 2.8590  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.8590\n",
      "03/07 07:48:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3500/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:06:09  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 2.4774  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.4774\n",
      "03/07 07:48:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3600/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:05:54  time: 0.1383  data_time: 0.0021  memory: 5847  loss: 3.1398  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.1398\n",
      "03/07 07:48:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3700/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:05:40  time: 0.1390  data_time: 0.0019  memory: 5847  loss: 2.8164  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.8164\n",
      "03/07 07:48:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3800/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:05:26  time: 0.1393  data_time: 0.0019  memory: 5847  loss: 2.5417  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5417\n",
      "03/07 07:49:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][3900/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:05:12  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 3.3288  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 3.3288\n",
      "03/07 07:49:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4000/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:04:57  time: 0.1393  data_time: 0.0020  memory: 5847  loss: 2.4727  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.4727\n",
      "03/07 07:49:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:49:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4100/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:04:43  time: 0.1372  data_time: 0.0018  memory: 5847  loss: 2.8217  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.8217\n",
      "03/07 07:49:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4200/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:04:28  time: 0.1373  data_time: 0.0019  memory: 5847  loss: 2.4762  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.4762\n",
      "03/07 07:50:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4300/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:04:14  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 2.6487  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.6487\n",
      "03/07 07:50:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4400/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:03:59  time: 0.1369  data_time: 0.0018  memory: 5847  loss: 3.1161  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.1161\n",
      "03/07 07:50:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4500/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:03:45  time: 0.1376  data_time: 0.0021  memory: 5847  loss: 2.6275  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.6275\n",
      "03/07 07:50:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4600/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:03:31  time: 0.1396  data_time: 0.0018  memory: 5847  loss: 2.8513  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.8513\n",
      "03/07 07:50:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4700/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:03:17  time: 0.1393  data_time: 0.0019  memory: 5847  loss: 3.0785  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.0785\n",
      "03/07 07:51:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4800/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:03:03  time: 0.1371  data_time: 0.0019  memory: 5847  loss: 2.8610  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.8610\n",
      "03/07 07:51:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4900/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:02:49  time: 0.1371  data_time: 0.0020  memory: 5847  loss: 2.4263  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4263\n",
      "03/07 07:51:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][5000/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:02:35  time: 0.1376  data_time: 0.0019  memory: 5847  loss: 2.9418  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.9418\n",
      "03/07 07:51:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:51:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][5100/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:02:21  time: 0.1386  data_time: 0.0018  memory: 5847  loss: 2.4307  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.4307\n",
      "03/07 07:52:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][5200/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:02:07  time: 0.1368  data_time: 0.0019  memory: 5847  loss: 2.5375  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5375\n",
      "03/07 07:52:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:52:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][5225/5225]  base_lr: 1.1960e-04 lr: 1.1960e-05  eta: 4:02:03  time: 0.1348  data_time: 0.0017  memory: 5847  loss: 2.7759  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.7759\n",
      "03/07 07:52:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][100/647]    eta: 0:00:16  time: 0.0293  data_time: 0.0009  memory: 1333  \n",
      "03/07 07:52:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][200/647]    eta: 0:00:13  time: 0.0296  data_time: 0.0008  memory: 1333  \n",
      "03/07 07:52:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][300/647]    eta: 0:00:10  time: 0.0294  data_time: 0.0007  memory: 1333  \n",
      "03/07 07:52:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][400/647]    eta: 0:00:07  time: 0.0295  data_time: 0.0006  memory: 1333  \n",
      "03/07 07:52:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][500/647]    eta: 0:00:04  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 07:52:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][600/647]    eta: 0:00:01  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "[17]\n",
      "[13]\n",
      "[17]\n",
      "[14]\n",
      "[20]\n",
      "[17]\n",
      "[20]\n",
      "[21]\n",
      "[17]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[25]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[13]\n",
      "[17]\n",
      "[14]\n",
      "[20]\n",
      "[20]\n",
      "[21]\n",
      "[14]\n",
      "[20]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[14]\n",
      "[14]\n",
      "[13]\n",
      "[13]\n",
      "[28]\n",
      "[17]\n",
      "[17]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[17]\n",
      "[20]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[21]\n",
      "[20]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[21]\n",
      "[20]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[14]\n",
      "[21]\n",
      "[4]\n",
      "[17]\n",
      "[22]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[25]\n",
      "[25]\n",
      "[24]\n",
      "[24]\n",
      "[25]\n",
      "[20]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[21]\n",
      "[17]\n",
      "[22]\n",
      "[22]\n",
      "[21]\n",
      "[22]\n",
      "[25]\n",
      "[11]\n",
      "[21]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[16]\n",
      "[24]\n",
      "[16]\n",
      "[16]\n",
      "[25]\n",
      "[22]\n",
      "[22]\n",
      "[16]\n",
      "[42]\n",
      "[29]\n",
      "[27]\n",
      "[41]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[31]\n",
      "[29]\n",
      "[115]\n",
      "[27]\n",
      "[31]\n",
      "[29]\n",
      "[31]\n",
      "[29]\n",
      "[27]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[30]\n",
      "[27]\n",
      "[31]\n",
      "[41]\n",
      "[38]\n",
      "[41]\n",
      "[117]\n",
      "[28]\n",
      "[28]\n",
      "[42]\n",
      "[42]\n",
      "[117]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[38]\n",
      "[41]\n",
      "[28]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[36]\n",
      "[28]\n",
      "[41]\n",
      "[42]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[105]\n",
      "[67]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[32]\n",
      "[34]\n",
      "[35]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[35]\n",
      "[34]\n",
      "[32]\n",
      "[81]\n",
      "[52]\n",
      "[59]\n",
      "[117]\n",
      "[10]\n",
      "[54]\n",
      "[52]\n",
      "[73]\n",
      "[22]\n",
      "[28]\n",
      "[52]\n",
      "[52]\n",
      "[55]\n",
      "[10]\n",
      "[46]\n",
      "[46]\n",
      "[9]\n",
      "[113]\n",
      "[52]\n",
      "[52]\n",
      "[55]\n",
      "[10]\n",
      "[46]\n",
      "[54]\n",
      "[10]\n",
      "[10]\n",
      "[10]\n",
      "[10]\n",
      "[10]\n",
      "[112]\n",
      "[54]\n",
      "[46]\n",
      "[10]\n",
      "[10]\n",
      "[46]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[57]\n",
      "[46]\n",
      "[46]\n",
      "[10]\n",
      "[52]\n",
      "[10]\n",
      "[28]\n",
      "[112]\n",
      "[55]\n",
      "[55]\n",
      "[10]\n",
      "[55]\n",
      "[28]\n",
      "[55]\n",
      "[12]\n",
      "[27]\n",
      "[28]\n",
      "[10]\n",
      "[10]\n",
      "[10]\n",
      "[55]\n",
      "[10]\n",
      "[10]\n",
      "[10]\n",
      "[52]\n",
      "[52]\n",
      "[10]\n",
      "[52]\n",
      "[55]\n",
      "[46]\n",
      "[46]\n",
      "[55]\n",
      "[55]\n",
      "[55]\n",
      "[55]\n",
      "[44]\n",
      "[46]\n",
      "[46]\n",
      "[57]\n",
      "[55]\n",
      "[44]\n",
      "[46]\n",
      "[46]\n",
      "[57]\n",
      "[55]\n",
      "[55]\n",
      "[55]\n",
      "[46]\n",
      "[46]\n",
      "[45]\n",
      "[55]\n",
      "[46]\n",
      "[55]\n",
      "[70]\n",
      "[67]\n",
      "[70]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[67]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[28]\n",
      "[67]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[66]\n",
      "[67]\n",
      "[28]\n",
      "[69]\n",
      "[67]\n",
      "[28]\n",
      "[28]\n",
      "[29]\n",
      "[29]\n",
      "[67]\n",
      "[67]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[68]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[28]\n",
      "[68]\n",
      "[70]\n",
      "[67]\n",
      "[67]\n",
      "[67]\n",
      "[68]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[28]\n",
      "[71]\n",
      "[44]\n",
      "[121]\n",
      "[71]\n",
      "[121]\n",
      "[121]\n",
      "[71]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[44]\n",
      "[71]\n",
      "[121]\n",
      "[121]\n",
      "[71]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[71]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[46]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[80]\n",
      "[90]\n",
      "[86]\n",
      "[89]\n",
      "[74]\n",
      "[89]\n",
      "[90]\n",
      "[81]\n",
      "[80]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[85]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[89]\n",
      "[86]\n",
      "[90]\n",
      "[89]\n",
      "[80]\n",
      "[86]\n",
      "[89]\n",
      "[89]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[89]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[86]\n",
      "[82]\n",
      "[90]\n",
      "[89]\n",
      "[81]\n",
      "[86]\n",
      "[89]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[90]\n",
      "[89]\n",
      "[89]\n",
      "[80]\n",
      "[81]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[89]\n",
      "[82]\n",
      "[86]\n",
      "[82]\n",
      "[89]\n",
      "[90]\n",
      "[86]\n",
      "[88]\n",
      "[81]\n",
      "[81]\n",
      "[81]\n",
      "[86]\n",
      "[83]\n",
      "[73]\n",
      "[86]\n",
      "[73]\n",
      "[89]\n",
      "[88]\n",
      "[81]\n",
      "[81]\n",
      "[73]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[112]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[91]\n",
      "[31]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[68]\n",
      "[17]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[91]\n",
      "[31]\n",
      "[31]\n",
      "[35]\n",
      "[71]\n",
      "[71]\n",
      "[43]\n",
      "[111]\n",
      "[50]\n",
      "[102]\n",
      "[62]\n",
      "[64]\n",
      "[102]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[71]\n",
      "[71]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[64]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[102]\n",
      "[64]\n",
      "[102]\n",
      "[102]\n",
      "[62]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[64]\n",
      "[102]\n",
      "[102]\n",
      "[79]\n",
      "[0]\n",
      "[104]\n",
      "[79]\n",
      "[79]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[79]\n",
      "[79]\n",
      "[79]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[79]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[109]\n",
      "[116]\n",
      "[116]\n",
      "[100]\n",
      "[34]\n",
      "[34]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[106]\n",
      "[106]\n",
      "[106]\n",
      "[106]\n",
      "[106]\n",
      "[106]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[117]\n",
      "[117]\n",
      "[105]\n",
      "[117]\n",
      "[105]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[74]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[117]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[106]\n",
      "[106]\n",
      "[35]\n",
      "[121]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[106]\n",
      "[109]\n",
      "03/07 07:52:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][647/647]    acc/top1: 0.0757  acc/top5: 0.3246  acc/mean1: 0.1458  data_time: 0.0009  time: 0.0295\n",
      "03/07 07:52:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_3.pth is removed\n",
      "03/07 07:52:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.0757 acc/top1 at 5 epoch is saved to best_acc_top1_epoch_5.pth.\n",
      "03/07 07:52:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 100/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:01:49  time: 0.1387  data_time: 0.0020  memory: 5847  loss: 2.6156  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6156\n",
      "03/07 07:52:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 200/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:01:35  time: 0.1391  data_time: 0.0020  memory: 5847  loss: 2.1341  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1341\n",
      "03/07 07:53:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 300/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:01:20  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 2.7086  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.7086\n",
      "03/07 07:53:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 400/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:01:06  time: 0.1370  data_time: 0.0020  memory: 5847  loss: 2.5788  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5788\n",
      "03/07 07:53:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 500/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:00:52  time: 0.1372  data_time: 0.0019  memory: 5847  loss: 2.7789  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.7789\n",
      "03/07 07:53:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 600/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:00:37  time: 0.1365  data_time: 0.0019  memory: 5847  loss: 2.9977  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.9977\n",
      "03/07 07:54:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 700/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:00:23  time: 0.1386  data_time: 0.0020  memory: 5847  loss: 2.7865  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.7865\n",
      "03/07 07:54:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 800/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 4:00:08  time: 0.1369  data_time: 0.0018  memory: 5847  loss: 2.8624  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.8624\n",
      "03/07 07:54:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:54:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 900/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:59:54  time: 0.1385  data_time: 0.0017  memory: 5847  loss: 2.5379  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.5379\n",
      "03/07 07:54:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1000/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:59:40  time: 0.1386  data_time: 0.0018  memory: 5847  loss: 2.6426  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6426\n",
      "03/07 07:55:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1100/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:59:26  time: 0.1381  data_time: 0.0019  memory: 5847  loss: 2.8128  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.8128\n",
      "03/07 07:55:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1200/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:59:12  time: 0.1383  data_time: 0.0019  memory: 5847  loss: 2.4200  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4200\n",
      "03/07 07:55:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1300/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:58:57  time: 0.1374  data_time: 0.0020  memory: 5847  loss: 2.4129  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4129\n",
      "03/07 07:55:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1400/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:58:43  time: 0.1372  data_time: 0.0018  memory: 5847  loss: 2.4976  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.4976\n",
      "03/07 07:55:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1500/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:58:29  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 2.4027  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.4027\n",
      "03/07 07:56:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1600/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:58:15  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 2.6729  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6729\n",
      "03/07 07:56:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1700/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:58:01  time: 0.1384  data_time: 0.0020  memory: 5847  loss: 2.6971  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.6971\n",
      "03/07 07:56:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1800/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:57:47  time: 0.1396  data_time: 0.0018  memory: 5847  loss: 2.8984  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.8984\n",
      "03/07 07:56:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:56:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1900/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:57:34  time: 0.1410  data_time: 0.0021  memory: 5847  loss: 2.4109  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.4109\n",
      "03/07 07:57:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2000/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:57:20  time: 0.1376  data_time: 0.0018  memory: 5847  loss: 2.6638  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6638\n",
      "03/07 07:57:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2100/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:57:05  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 2.8099  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.8099\n",
      "03/07 07:57:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2200/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:56:51  time: 0.1396  data_time: 0.0019  memory: 5847  loss: 2.3605  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3605\n",
      "03/07 07:57:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2300/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:56:37  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 2.4614  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.4614\n",
      "03/07 07:58:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2400/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:56:23  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 2.4469  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.4469\n",
      "03/07 07:58:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2500/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:56:09  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 2.2406  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.2406\n",
      "03/07 07:58:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2600/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:55:55  time: 0.1370  data_time: 0.0021  memory: 5847  loss: 2.3717  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.3717\n",
      "03/07 07:58:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2700/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:55:41  time: 0.1376  data_time: 0.0019  memory: 5847  loss: 2.4835  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.4835\n",
      "03/07 07:58:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2800/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:55:26  time: 0.1376  data_time: 0.0018  memory: 5847  loss: 2.4092  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.4092\n",
      "03/07 07:59:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 07:59:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][2900/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:55:12  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 2.6257  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6257\n",
      "03/07 07:59:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3000/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:54:58  time: 0.1376  data_time: 0.0021  memory: 5847  loss: 2.9456  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.9456\n",
      "03/07 07:59:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3100/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:54:44  time: 0.1374  data_time: 0.0020  memory: 5847  loss: 2.3734  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3734\n",
      "03/07 07:59:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3200/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:54:30  time: 0.1372  data_time: 0.0018  memory: 5847  loss: 2.3926  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.3926\n",
      "03/07 08:00:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3300/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:54:15  time: 0.1373  data_time: 0.0019  memory: 5847  loss: 2.5485  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5485\n",
      "03/07 08:00:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3400/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:54:01  time: 0.1371  data_time: 0.0018  memory: 5847  loss: 2.3907  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3907\n",
      "03/07 08:00:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3500/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:53:47  time: 0.1372  data_time: 0.0019  memory: 5847  loss: 2.3236  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.3236\n",
      "03/07 08:00:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3600/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:53:33  time: 0.1402  data_time: 0.0021  memory: 5847  loss: 2.7583  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.7583\n",
      "03/07 08:01:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3700/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:53:19  time: 0.1377  data_time: 0.0018  memory: 5847  loss: 2.4471  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.4471\n",
      "03/07 08:01:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3800/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:53:04  time: 0.1372  data_time: 0.0018  memory: 5847  loss: 2.3029  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.3029\n",
      "03/07 08:01:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:01:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][3900/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:52:50  time: 0.1371  data_time: 0.0018  memory: 5847  loss: 2.9443  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.9443\n",
      "03/07 08:01:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4000/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:52:36  time: 0.1369  data_time: 0.0018  memory: 5847  loss: 2.6586  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.6586\n",
      "03/07 08:01:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4100/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:52:21  time: 0.1371  data_time: 0.0019  memory: 5847  loss: 2.6416  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.6416\n",
      "03/07 08:02:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4200/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:52:07  time: 0.1376  data_time: 0.0021  memory: 5847  loss: 2.1146  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1146\n",
      "03/07 08:02:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4300/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:51:53  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 2.3342  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.3342\n",
      "03/07 08:02:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4400/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:51:39  time: 0.1398  data_time: 0.0020  memory: 5847  loss: 2.4102  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.4102\n",
      "03/07 08:02:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4500/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:51:25  time: 0.1374  data_time: 0.0020  memory: 5847  loss: 2.6243  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.6243\n",
      "03/07 08:03:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4600/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:51:11  time: 0.1386  data_time: 0.0020  memory: 5847  loss: 2.8889  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.8889\n",
      "03/07 08:03:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4700/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:50:57  time: 0.1377  data_time: 0.0019  memory: 5847  loss: 2.8456  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.8456\n",
      "03/07 08:03:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4800/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:50:43  time: 0.1388  data_time: 0.0020  memory: 5847  loss: 2.2236  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2236\n",
      "03/07 08:03:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:03:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4900/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:50:29  time: 0.1374  data_time: 0.0020  memory: 5847  loss: 2.5619  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.5619\n",
      "03/07 08:04:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][5000/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:50:15  time: 0.1383  data_time: 0.0019  memory: 5847  loss: 2.7700  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.7700\n",
      "03/07 08:04:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][5100/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:50:01  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 2.5070  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.5070\n",
      "03/07 08:04:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][5200/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:49:47  time: 0.1367  data_time: 0.0018  memory: 5847  loss: 2.7463  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.7463\n",
      "03/07 08:04:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:04:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][5225/5225]  base_lr: 1.1663e-04 lr: 1.1663e-05  eta: 3:49:43  time: 0.1354  data_time: 0.0019  memory: 5847  loss: 2.5699  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.5699\n",
      "03/07 08:04:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
      "03/07 08:04:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][100/647]    eta: 0:00:16  time: 0.0297  data_time: 0.0010  memory: 1333  \n",
      "03/07 08:04:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][200/647]    eta: 0:00:13  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "03/07 08:04:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][300/647]    eta: 0:00:10  time: 0.0296  data_time: 0.0009  memory: 1333  \n",
      "03/07 08:04:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][400/647]    eta: 0:00:07  time: 0.0294  data_time: 0.0008  memory: 1333  \n",
      "03/07 08:04:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][500/647]    eta: 0:00:04  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 08:04:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][600/647]    eta: 0:00:01  time: 0.0293  data_time: 0.0007  memory: 1333  \n",
      "[0]\n",
      "[0]\n",
      "[17]\n",
      "[26]\n",
      "[26]\n",
      "[11]\n",
      "[14]\n",
      "[0]\n",
      "[11]\n",
      "[11]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[14]\n",
      "[18]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[26]\n",
      "[14]\n",
      "[28]\n",
      "[18]\n",
      "[26]\n",
      "[26]\n",
      "[14]\n",
      "[11]\n",
      "[26]\n",
      "[22]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[17]\n",
      "[11]\n",
      "[11]\n",
      "[24]\n",
      "[22]\n",
      "[26]\n",
      "[13]\n",
      "[13]\n",
      "[28]\n",
      "[17]\n",
      "[30]\n",
      "[0]\n",
      "[5]\n",
      "[14]\n",
      "[0]\n",
      "[0]\n",
      "[18]\n",
      "[14]\n",
      "[14]\n",
      "[21]\n",
      "[0]\n",
      "[14]\n",
      "[18]\n",
      "[11]\n",
      "[11]\n",
      "[18]\n",
      "[11]\n",
      "[21]\n",
      "[0]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[0]\n",
      "[14]\n",
      "[22]\n",
      "[22]\n",
      "[11]\n",
      "[22]\n",
      "[22]\n",
      "[5]\n",
      "[22]\n",
      "[22]\n",
      "[11]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[25]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[26]\n",
      "[26]\n",
      "[5]\n",
      "[22]\n",
      "[11]\n",
      "[21]\n",
      "[11]\n",
      "[26]\n",
      "[23]\n",
      "[21]\n",
      "[22]\n",
      "[24]\n",
      "[11]\n",
      "[11]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[26]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[24]\n",
      "[42]\n",
      "[27]\n",
      "[87]\n",
      "[106]\n",
      "[87]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[36]\n",
      "[29]\n",
      "[36]\n",
      "[30]\n",
      "[19]\n",
      "[29]\n",
      "[31]\n",
      "[31]\n",
      "[27]\n",
      "[32]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[27]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[32]\n",
      "[41]\n",
      "[36]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[27]\n",
      "[36]\n",
      "[41]\n",
      "[37]\n",
      "[41]\n",
      "[28]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[36]\n",
      "[36]\n",
      "[33]\n",
      "[36]\n",
      "[42]\n",
      "[38]\n",
      "[32]\n",
      "[32]\n",
      "[36]\n",
      "[36]\n",
      "[36]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[42]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[110]\n",
      "[34]\n",
      "[34]\n",
      "[110]\n",
      "[36]\n",
      "[50]\n",
      "[35]\n",
      "[34]\n",
      "[94]\n",
      "[9]\n",
      "[59]\n",
      "[112]\n",
      "[51]\n",
      "[51]\n",
      "[57]\n",
      "[25]\n",
      "[26]\n",
      "[26]\n",
      "[59]\n",
      "[51]\n",
      "[51]\n",
      "[9]\n",
      "[46]\n",
      "[46]\n",
      "[9]\n",
      "[28]\n",
      "[51]\n",
      "[16]\n",
      "[15]\n",
      "[53]\n",
      "[46]\n",
      "[46]\n",
      "[56]\n",
      "[53]\n",
      "[46]\n",
      "[15]\n",
      "[15]\n",
      "[24]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[46]\n",
      "[57]\n",
      "[53]\n",
      "[56]\n",
      "[57]\n",
      "[46]\n",
      "[56]\n",
      "[53]\n",
      "[57]\n",
      "[55]\n",
      "[26]\n",
      "[24]\n",
      "[55]\n",
      "[53]\n",
      "[55]\n",
      "[51]\n",
      "[26]\n",
      "[55]\n",
      "[30]\n",
      "[20]\n",
      "[15]\n",
      "[57]\n",
      "[22]\n",
      "[57]\n",
      "[55]\n",
      "[53]\n",
      "[6]\n",
      "[45]\n",
      "[30]\n",
      "[52]\n",
      "[57]\n",
      "[52]\n",
      "[56]\n",
      "[46]\n",
      "[46]\n",
      "[44]\n",
      "[56]\n",
      "[46]\n",
      "[46]\n",
      "[44]\n",
      "[46]\n",
      "[46]\n",
      "[46]\n",
      "[44]\n",
      "[44]\n",
      "[56]\n",
      "[46]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[46]\n",
      "[46]\n",
      "[45]\n",
      "[44]\n",
      "[46]\n",
      "[44]\n",
      "[69]\n",
      "[67]\n",
      "[69]\n",
      "[66]\n",
      "[67]\n",
      "[29]\n",
      "[67]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[65]\n",
      "[48]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[66]\n",
      "[69]\n",
      "[67]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[66]\n",
      "[67]\n",
      "[65]\n",
      "[69]\n",
      "[65]\n",
      "[29]\n",
      "[29]\n",
      "[29]\n",
      "[48]\n",
      "[40]\n",
      "[40]\n",
      "[66]\n",
      "[40]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[65]\n",
      "[29]\n",
      "[69]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[36]\n",
      "[68]\n",
      "[69]\n",
      "[66]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[66]\n",
      "[67]\n",
      "[69]\n",
      "[28]\n",
      "[109]\n",
      "[44]\n",
      "[109]\n",
      "[98]\n",
      "[121]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[121]\n",
      "[121]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[121]\n",
      "[121]\n",
      "[122]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[44]\n",
      "[44]\n",
      "[7]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[51]\n",
      "[98]\n",
      "[51]\n",
      "[98]\n",
      "[98]\n",
      "[7]\n",
      "[109]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[109]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[72]\n",
      "[81]\n",
      "[86]\n",
      "[72]\n",
      "[72]\n",
      "[72]\n",
      "[77]\n",
      "[72]\n",
      "[72]\n",
      "[72]\n",
      "[89]\n",
      "[86]\n",
      "[90]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[72]\n",
      "[89]\n",
      "[86]\n",
      "[72]\n",
      "[72]\n",
      "[72]\n",
      "[86]\n",
      "[87]\n",
      "[72]\n",
      "[72]\n",
      "[81]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[72]\n",
      "[72]\n",
      "[82]\n",
      "[72]\n",
      "[86]\n",
      "[82]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[86]\n",
      "[72]\n",
      "[72]\n",
      "[72]\n",
      "[81]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[72]\n",
      "[82]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[72]\n",
      "[82]\n",
      "[90]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[87]\n",
      "[72]\n",
      "[72]\n",
      "[72]\n",
      "[72]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[72]\n",
      "[72]\n",
      "[77]\n",
      "[87]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[86]\n",
      "[87]\n",
      "[112]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[68]\n",
      "[83]\n",
      "[30]\n",
      "[87]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[87]\n",
      "[19]\n",
      "[93]\n",
      "[71]\n",
      "[49]\n",
      "[49]\n",
      "[71]\n",
      "[109]\n",
      "[50]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[100]\n",
      "[100]\n",
      "[40]\n",
      "[102]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[103]\n",
      "[102]\n",
      "[102]\n",
      "[100]\n",
      "[100]\n",
      "[102]\n",
      "[102]\n",
      "[100]\n",
      "[102]\n",
      "[103]\n",
      "[102]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[97]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[98]\n",
      "[97]\n",
      "[98]\n",
      "[0]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[71]\n",
      "[109]\n",
      "[97]\n",
      "[109]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[112]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[72]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[106]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[106]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "03/07 08:04:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [6][647/647]    acc/top1: 0.0989  acc/top5: 0.3957  acc/mean1: 0.1727  data_time: 0.0009  time: 0.0296\n",
      "03/07 08:04:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_5.pth is removed\n",
      "03/07 08:04:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.0989 acc/top1 at 6 epoch is saved to best_acc_top1_epoch_6.pth.\n",
      "03/07 08:05:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 100/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:49:29  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 2.6671  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.6671\n",
      "03/07 08:05:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 200/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:49:15  time: 0.1398  data_time: 0.0020  memory: 5847  loss: 2.5793  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5793\n",
      "03/07 08:05:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 300/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:49:01  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 2.4689  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4689\n",
      "03/07 08:05:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 400/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:48:47  time: 0.1376  data_time: 0.0019  memory: 5847  loss: 2.2445  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2445\n",
      "03/07 08:06:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 500/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:48:33  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 2.6362  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.6362\n",
      "03/07 08:06:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 600/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:48:18  time: 0.1375  data_time: 0.0020  memory: 5847  loss: 2.6350  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6350\n",
      "03/07 08:06:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:06:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 700/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:48:04  time: 0.1370  data_time: 0.0018  memory: 5847  loss: 2.3710  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3710\n",
      "03/07 08:06:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 800/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:47:50  time: 0.1392  data_time: 0.0019  memory: 5847  loss: 2.1451  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1451\n",
      "03/07 08:06:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 900/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:47:36  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 2.5734  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5734\n",
      "03/07 08:07:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1000/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:47:22  time: 0.1371  data_time: 0.0018  memory: 5847  loss: 2.4353  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.4353\n",
      "03/07 08:07:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1100/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:47:08  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 2.9589  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.9589\n",
      "03/07 08:07:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1200/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:46:54  time: 0.1375  data_time: 0.0020  memory: 5847  loss: 2.9005  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.9005\n",
      "03/07 08:07:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1300/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:46:40  time: 0.1376  data_time: 0.0019  memory: 5847  loss: 2.1402  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1402\n",
      "03/07 08:08:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1400/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:46:25  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 2.4867  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.4867\n",
      "03/07 08:08:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1500/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:46:11  time: 0.1376  data_time: 0.0019  memory: 5847  loss: 2.3225  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3225\n",
      "03/07 08:08:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1600/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:45:57  time: 0.1391  data_time: 0.0019  memory: 5847  loss: 2.3331  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3331\n",
      "03/07 08:08:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:08:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1700/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:45:44  time: 0.1409  data_time: 0.0018  memory: 5847  loss: 2.3708  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.3708\n",
      "03/07 08:09:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1800/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:45:31  time: 0.1418  data_time: 0.0019  memory: 5847  loss: 2.4238  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.4238\n",
      "03/07 08:09:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1900/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:45:16  time: 0.1371  data_time: 0.0018  memory: 5847  loss: 2.7515  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.7515\n",
      "03/07 08:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2000/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:45:02  time: 0.1373  data_time: 0.0019  memory: 5847  loss: 2.8287  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.8287\n",
      "03/07 08:09:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2100/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:44:48  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 2.3717  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3717\n",
      "03/07 08:09:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2200/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:44:34  time: 0.1391  data_time: 0.0019  memory: 5847  loss: 2.3055  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.3055\n",
      "03/07 08:10:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2300/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:44:20  time: 0.1370  data_time: 0.0020  memory: 5847  loss: 2.7017  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.7017\n",
      "03/07 08:10:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2400/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:44:06  time: 0.1366  data_time: 0.0018  memory: 5847  loss: 2.8265  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.8265\n",
      "03/07 08:10:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2500/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:43:51  time: 0.1379  data_time: 0.0017  memory: 5847  loss: 3.0047  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 3.0047\n",
      "03/07 08:10:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2600/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:43:37  time: 0.1379  data_time: 0.0018  memory: 5847  loss: 2.7433  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.7433\n",
      "03/07 08:10:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:11:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2700/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:43:24  time: 0.1378  data_time: 0.0020  memory: 5847  loss: 2.6899  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6899\n",
      "03/07 08:11:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2800/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:43:10  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 2.6483  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.6483\n",
      "03/07 08:11:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][2900/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:42:56  time: 0.1380  data_time: 0.0018  memory: 5847  loss: 2.5674  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.5674\n",
      "03/07 08:11:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3000/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:42:41  time: 0.1376  data_time: 0.0016  memory: 5847  loss: 2.8373  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.8373\n",
      "03/07 08:12:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3100/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:42:27  time: 0.1374  data_time: 0.0021  memory: 5847  loss: 2.5361  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.5361\n",
      "03/07 08:12:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3200/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:42:14  time: 0.1369  data_time: 0.0021  memory: 5847  loss: 2.6159  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6159\n",
      "03/07 08:12:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3300/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:41:59  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 2.3513  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3513\n",
      "03/07 08:12:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3400/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:41:45  time: 0.1388  data_time: 0.0021  memory: 5847  loss: 1.9460  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9460\n",
      "03/07 08:12:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3500/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:41:32  time: 0.1395  data_time: 0.0019  memory: 5847  loss: 2.3719  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.3719\n",
      "03/07 08:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3600/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:41:18  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 2.3302  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3302\n",
      "03/07 08:13:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:13:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3700/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:41:04  time: 0.1377  data_time: 0.0017  memory: 5847  loss: 2.9714  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.9714\n",
      "03/07 08:13:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3800/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:40:49  time: 0.1372  data_time: 0.0020  memory: 5847  loss: 2.4415  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4415\n",
      "03/07 08:13:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][3900/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:40:35  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 2.1522  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1522\n",
      "03/07 08:14:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4000/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:40:21  time: 0.1395  data_time: 0.0020  memory: 5847  loss: 2.7226  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.7226\n",
      "03/07 08:14:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4100/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:40:08  time: 0.1407  data_time: 0.0020  memory: 5847  loss: 2.2336  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2336\n",
      "03/07 08:14:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4200/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:39:54  time: 0.1407  data_time: 0.0019  memory: 5847  loss: 2.4647  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.4647\n",
      "03/07 08:14:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4300/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:39:41  time: 0.1394  data_time: 0.0018  memory: 5847  loss: 2.6797  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.6797\n",
      "03/07 08:15:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4400/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:39:27  time: 0.1386  data_time: 0.0019  memory: 5847  loss: 2.4875  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.4875\n",
      "03/07 08:15:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4500/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:39:13  time: 0.1372  data_time: 0.0020  memory: 5847  loss: 2.5946  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.5946\n",
      "03/07 08:15:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4600/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:38:59  time: 0.1368  data_time: 0.0017  memory: 5847  loss: 2.6357  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6357\n",
      "03/07 08:15:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:15:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4700/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:38:45  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 2.7846  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.7846\n",
      "03/07 08:15:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4800/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:38:31  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 1.9848  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.9848\n",
      "03/07 08:16:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4900/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:38:17  time: 0.1371  data_time: 0.0020  memory: 5847  loss: 2.2698  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.2698\n",
      "03/07 08:16:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][5000/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:38:03  time: 0.1369  data_time: 0.0017  memory: 5847  loss: 2.6504  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.6504\n",
      "03/07 08:16:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][5100/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:37:49  time: 0.1376  data_time: 0.0019  memory: 5847  loss: 2.3563  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.3563\n",
      "03/07 08:16:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][5200/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:37:35  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 2.0989  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0989\n",
      "03/07 08:16:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:16:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][5225/5225]  base_lr: 1.1306e-04 lr: 1.1306e-05  eta: 3:37:31  time: 0.1355  data_time: 0.0019  memory: 5847  loss: 2.9419  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.9419\n",
      "03/07 08:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][100/647]    eta: 0:00:16  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 08:17:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][200/647]    eta: 0:00:13  time: 0.0294  data_time: 0.0007  memory: 1333  \n",
      "03/07 08:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][300/647]    eta: 0:00:10  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "03/07 08:17:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][400/647]    eta: 0:00:07  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 08:17:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][500/647]    eta: 0:00:04  time: 0.0296  data_time: 0.0010  memory: 1333  \n",
      "03/07 08:17:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][600/647]    eta: 0:00:01  time: 0.0296  data_time: 0.0008  memory: 1333  \n",
      "[106]\n",
      "[18]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[18]\n",
      "[5]\n",
      "[17]\n",
      "[17]\n",
      "[11]\n",
      "[11]\n",
      "[6]\n",
      "[17]\n",
      "[18]\n",
      "[14]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[20]\n",
      "[14]\n",
      "[70]\n",
      "[18]\n",
      "[26]\n",
      "[4]\n",
      "[18]\n",
      "[17]\n",
      "[14]\n",
      "[18]\n",
      "[18]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[106]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[11]\n",
      "[18]\n",
      "[11]\n",
      "[20]\n",
      "[17]\n",
      "[18]\n",
      "[14]\n",
      "[5]\n",
      "[18]\n",
      "[18]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[18]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[18]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[0]\n",
      "[4]\n",
      "[17]\n",
      "[26]\n",
      "[4]\n",
      "[5]\n",
      "[11]\n",
      "[5]\n",
      "[11]\n",
      "[11]\n",
      "[4]\n",
      "[22]\n",
      "[4]\n",
      "[11]\n",
      "[26]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[18]\n",
      "[5]\n",
      "[5]\n",
      "[11]\n",
      "[11]\n",
      "[17]\n",
      "[26]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[20]\n",
      "[22]\n",
      "[23]\n",
      "[26]\n",
      "[16]\n",
      "[24]\n",
      "[16]\n",
      "[26]\n",
      "[20]\n",
      "[4]\n",
      "[4]\n",
      "[26]\n",
      "[41]\n",
      "[27]\n",
      "[30]\n",
      "[41]\n",
      "[27]\n",
      "[68]\n",
      "[29]\n",
      "[29]\n",
      "[31]\n",
      "[47]\n",
      "[115]\n",
      "[27]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[27]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[33]\n",
      "[33]\n",
      "[41]\n",
      "[41]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[38]\n",
      "[41]\n",
      "[19]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[36]\n",
      "[34]\n",
      "[35]\n",
      "[34]\n",
      "[57]\n",
      "[9]\n",
      "[58]\n",
      "[115]\n",
      "[51]\n",
      "[46]\n",
      "[9]\n",
      "[24]\n",
      "[23]\n",
      "[15]\n",
      "[56]\n",
      "[51]\n",
      "[15]\n",
      "[9]\n",
      "[46]\n",
      "[46]\n",
      "[9]\n",
      "[115]\n",
      "[52]\n",
      "[16]\n",
      "[55]\n",
      "[53]\n",
      "[9]\n",
      "[46]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[15]\n",
      "[15]\n",
      "[113]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[46]\n",
      "[9]\n",
      "[9]\n",
      "[46]\n",
      "[9]\n",
      "[46]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[51]\n",
      "[115]\n",
      "[113]\n",
      "[55]\n",
      "[53]\n",
      "[55]\n",
      "[55]\n",
      "[115]\n",
      "[46]\n",
      "[45]\n",
      "[41]\n",
      "[44]\n",
      "[53]\n",
      "[10]\n",
      "[53]\n",
      "[55]\n",
      "[53]\n",
      "[52]\n",
      "[46]\n",
      "[15]\n",
      "[52]\n",
      "[58]\n",
      "[15]\n",
      "[51]\n",
      "[47]\n",
      "[46]\n",
      "[44]\n",
      "[44]\n",
      "[46]\n",
      "[46]\n",
      "[44]\n",
      "[46]\n",
      "[53]\n",
      "[46]\n",
      "[44]\n",
      "[44]\n",
      "[7]\n",
      "[7]\n",
      "[53]\n",
      "[53]\n",
      "[58]\n",
      "[58]\n",
      "[47]\n",
      "[46]\n",
      "[45]\n",
      "[44]\n",
      "[7]\n",
      "[44]\n",
      "[70]\n",
      "[68]\n",
      "[70]\n",
      "[70]\n",
      "[67]\n",
      "[67]\n",
      "[67]\n",
      "[67]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[70]\n",
      "[70]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[68]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[68]\n",
      "[66]\n",
      "[67]\n",
      "[65]\n",
      "[68]\n",
      "[70]\n",
      "[29]\n",
      "[70]\n",
      "[29]\n",
      "[70]\n",
      "[68]\n",
      "[68]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[67]\n",
      "[67]\n",
      "[69]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[68]\n",
      "[70]\n",
      "[66]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[66]\n",
      "[68]\n",
      "[69]\n",
      "[70]\n",
      "[98]\n",
      "[44]\n",
      "[110]\n",
      "[98]\n",
      "[121]\n",
      "[44]\n",
      "[98]\n",
      "[99]\n",
      "[110]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[98]\n",
      "[98]\n",
      "[44]\n",
      "[121]\n",
      "[44]\n",
      "[98]\n",
      "[49]\n",
      "[99]\n",
      "[99]\n",
      "[98]\n",
      "[7]\n",
      "[53]\n",
      "[7]\n",
      "[51]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[7]\n",
      "[71]\n",
      "[99]\n",
      "[7]\n",
      "[7]\n",
      "[71]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[98]\n",
      "[7]\n",
      "[7]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[71]\n",
      "[7]\n",
      "[98]\n",
      "[74]\n",
      "[90]\n",
      "[88]\n",
      "[74]\n",
      "[74]\n",
      "[89]\n",
      "[90]\n",
      "[88]\n",
      "[74]\n",
      "[79]\n",
      "[88]\n",
      "[88]\n",
      "[90]\n",
      "[84]\n",
      "[84]\n",
      "[87]\n",
      "[88]\n",
      "[87]\n",
      "[74]\n",
      "[88]\n",
      "[88]\n",
      "[90]\n",
      "[74]\n",
      "[72]\n",
      "[84]\n",
      "[79]\n",
      "[80]\n",
      "[88]\n",
      "[90]\n",
      "[88]\n",
      "[84]\n",
      "[90]\n",
      "[84]\n",
      "[88]\n",
      "[87]\n",
      "[87]\n",
      "[72]\n",
      "[76]\n",
      "[90]\n",
      "[88]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[74]\n",
      "[90]\n",
      "[84]\n",
      "[74]\n",
      "[72]\n",
      "[72]\n",
      "[90]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[72]\n",
      "[88]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[87]\n",
      "[88]\n",
      "[90]\n",
      "[90]\n",
      "[90]\n",
      "[74]\n",
      "[74]\n",
      "[88]\n",
      "[74]\n",
      "[79]\n",
      "[88]\n",
      "[88]\n",
      "[84]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[88]\n",
      "[74]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[83]\n",
      "[88]\n",
      "[83]\n",
      "[30]\n",
      "[84]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[68]\n",
      "[68]\n",
      "[30]\n",
      "[91]\n",
      "[31]\n",
      "[31]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[84]\n",
      "[71]\n",
      "[49]\n",
      "[49]\n",
      "[7]\n",
      "[14]\n",
      "[50]\n",
      "[40]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[101]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[40]\n",
      "[100]\n",
      "[103]\n",
      "[103]\n",
      "[100]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[100]\n",
      "[40]\n",
      "[101]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[100]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[79]\n",
      "[79]\n",
      "[92]\n",
      "[79]\n",
      "[79]\n",
      "[92]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[96]\n",
      "[79]\n",
      "[79]\n",
      "[92]\n",
      "[79]\n",
      "[97]\n",
      "[96]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[110]\n",
      "[34]\n",
      "[34]\n",
      "[35]\n",
      "[34]\n",
      "[49]\n",
      "[14]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[97]\n",
      "[98]\n",
      "[97]\n",
      "[105]\n",
      "[105]\n",
      "[106]\n",
      "[106]\n",
      "[106]\n",
      "[106]\n",
      "[106]\n",
      "[106]\n",
      "[106]\n",
      "[105]\n",
      "[106]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[110]\n",
      "[112]\n",
      "[106]\n",
      "[111]\n",
      "[112]\n",
      "[117]\n",
      "[111]\n",
      "[117]\n",
      "[117]\n",
      "[74]\n",
      "[111]\n",
      "[115]\n",
      "[116]\n",
      "[117]\n",
      "[116]\n",
      "[112]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[111]\n",
      "[31]\n",
      "[106]\n",
      "[106]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[110]\n",
      "[110]\n",
      "[18]\n",
      "[18]\n",
      "[111]\n",
      "[110]\n",
      "[109]\n",
      "[110]\n",
      "[71]\n",
      "[110]\n",
      "03/07 08:17:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [7][647/647]    acc/top1: 0.1159  acc/top5: 0.4019  acc/mean1: 0.1870  data_time: 0.0009  time: 0.0296\n",
      "03/07 08:17:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_6.pth is removed\n",
      "03/07 08:17:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.1159 acc/top1 at 7 epoch is saved to best_acc_top1_epoch_7.pth.\n",
      "03/07 08:17:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 100/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:37:17  time: 0.1380  data_time: 0.0021  memory: 5847  loss: 2.1473  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1473\n",
      "03/07 08:17:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 200/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:37:03  time: 0.1376  data_time: 0.0022  memory: 5847  loss: 2.2241  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.2241\n",
      "03/07 08:17:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 300/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:36:49  time: 0.1370  data_time: 0.0018  memory: 5847  loss: 2.0484  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0484\n",
      "03/07 08:18:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 400/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:36:35  time: 0.1378  data_time: 0.0019  memory: 5847  loss: 2.5360  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.5360\n",
      "03/07 08:18:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:18:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 500/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:36:21  time: 0.1370  data_time: 0.0020  memory: 5847  loss: 2.0132  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0132\n",
      "03/07 08:18:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 600/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:36:07  time: 0.1400  data_time: 0.0021  memory: 5847  loss: 2.0174  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0174\n",
      "03/07 08:18:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 700/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:35:53  time: 0.1390  data_time: 0.0018  memory: 5847  loss: 3.0584  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 3.0584\n",
      "03/07 08:19:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 800/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:35:39  time: 0.1377  data_time: 0.0019  memory: 5847  loss: 2.1092  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1092\n",
      "03/07 08:19:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 900/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:35:25  time: 0.1373  data_time: 0.0020  memory: 5847  loss: 2.6806  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.6806\n",
      "03/07 08:19:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1000/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:35:11  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 2.4406  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.4406\n",
      "03/07 08:19:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1100/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:34:57  time: 0.1377  data_time: 0.0019  memory: 5847  loss: 1.9203  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9203\n",
      "03/07 08:20:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1200/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:34:43  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 2.1787  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1787\n",
      "03/07 08:20:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1300/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:34:29  time: 0.1370  data_time: 0.0019  memory: 5847  loss: 2.3198  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.3198\n",
      "03/07 08:20:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1400/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:34:14  time: 0.1369  data_time: 0.0018  memory: 5847  loss: 2.9514  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.9514\n",
      "03/07 08:20:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:20:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1500/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:34:01  time: 0.1423  data_time: 0.0022  memory: 5847  loss: 2.6386  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.6386\n",
      "03/07 08:20:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1600/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:33:47  time: 0.1389  data_time: 0.0018  memory: 5847  loss: 2.7681  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.7681\n",
      "03/07 08:21:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1700/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:33:33  time: 0.1373  data_time: 0.0020  memory: 5847  loss: 2.1961  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1961\n",
      "03/07 08:21:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1800/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:33:19  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 2.2557  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.2557\n",
      "03/07 08:21:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1900/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:33:05  time: 0.1375  data_time: 0.0018  memory: 5847  loss: 1.9622  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9622\n",
      "03/07 08:21:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2000/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:32:51  time: 0.1388  data_time: 0.0020  memory: 5847  loss: 2.5658  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.5658\n",
      "03/07 08:22:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2100/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:32:37  time: 0.1367  data_time: 0.0019  memory: 5847  loss: 2.2443  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.2443\n",
      "03/07 08:22:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2200/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:32:23  time: 0.1368  data_time: 0.0018  memory: 5847  loss: 3.0166  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 3.0166\n",
      "03/07 08:22:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2300/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:32:09  time: 0.1374  data_time: 0.0019  memory: 5847  loss: 2.6365  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.6365\n",
      "03/07 08:22:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2400/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:31:55  time: 0.1398  data_time: 0.0020  memory: 5847  loss: 2.1604  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1604\n",
      "03/07 08:22:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:23:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2500/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:31:41  time: 0.1382  data_time: 0.0019  memory: 5847  loss: 2.2895  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2895\n",
      "03/07 08:23:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2600/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:31:27  time: 0.1404  data_time: 0.0019  memory: 5847  loss: 3.0354  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 3.0354\n",
      "03/07 08:23:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2700/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:31:13  time: 0.1379  data_time: 0.0021  memory: 5847  loss: 2.4496  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.4496\n",
      "03/07 08:23:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2800/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:30:59  time: 0.1378  data_time: 0.0020  memory: 5847  loss: 2.1397  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1397\n",
      "03/07 08:23:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][2900/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:30:45  time: 0.1380  data_time: 0.0017  memory: 5847  loss: 2.2380  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2380\n",
      "03/07 08:24:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3000/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:30:31  time: 0.1384  data_time: 0.0020  memory: 5847  loss: 2.2225  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.2225\n",
      "03/07 08:24:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3100/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:30:17  time: 0.1375  data_time: 0.0018  memory: 5847  loss: 1.9706  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9706\n",
      "03/07 08:24:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3200/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:30:03  time: 0.1380  data_time: 0.0019  memory: 5847  loss: 2.3696  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3696\n",
      "03/07 08:24:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3300/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:29:49  time: 0.1394  data_time: 0.0018  memory: 5847  loss: 2.3758  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3758\n",
      "03/07 08:25:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3400/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:29:35  time: 0.1382  data_time: 0.0018  memory: 5847  loss: 2.2449  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2449\n",
      "03/07 08:25:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:25:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3500/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:29:21  time: 0.1371  data_time: 0.0019  memory: 5847  loss: 2.5054  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.5054\n",
      "03/07 08:25:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3600/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:29:07  time: 0.1380  data_time: 0.0019  memory: 5847  loss: 1.9965  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9965\n",
      "03/07 08:25:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3700/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:28:53  time: 0.1373  data_time: 0.0019  memory: 5847  loss: 2.2601  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2601\n",
      "03/07 08:26:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3800/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:28:39  time: 0.1376  data_time: 0.0019  memory: 5847  loss: 2.0857  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.0857\n",
      "03/07 08:26:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][3900/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:28:25  time: 0.1368  data_time: 0.0019  memory: 5847  loss: 2.4620  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.4620\n",
      "03/07 08:26:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4000/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:28:10  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 1.9267  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9267\n",
      "03/07 08:26:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4100/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:27:57  time: 0.1407  data_time: 0.0021  memory: 5847  loss: 2.0568  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0568\n",
      "03/07 08:26:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4200/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:27:43  time: 0.1388  data_time: 0.0020  memory: 5847  loss: 2.2688  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2688\n",
      "03/07 08:27:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4300/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:27:29  time: 0.1389  data_time: 0.0019  memory: 5847  loss: 2.6077  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.6077\n",
      "03/07 08:27:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4400/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:27:15  time: 0.1373  data_time: 0.0020  memory: 5847  loss: 2.3347  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3347\n",
      "03/07 08:27:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:27:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4500/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:27:01  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 2.8938  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.8938\n",
      "03/07 08:27:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4600/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:26:47  time: 0.1385  data_time: 0.0019  memory: 5847  loss: 1.9176  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9176\n",
      "03/07 08:28:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4700/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:26:33  time: 0.1371  data_time: 0.0020  memory: 5847  loss: 2.2341  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2341\n",
      "03/07 08:28:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4800/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:26:19  time: 0.1374  data_time: 0.0020  memory: 5847  loss: 2.4280  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.4280\n",
      "03/07 08:28:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4900/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:26:05  time: 0.1384  data_time: 0.0020  memory: 5847  loss: 1.9156  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9156\n",
      "03/07 08:28:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][5000/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:25:51  time: 0.1392  data_time: 0.0021  memory: 5847  loss: 2.3488  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.3488\n",
      "03/07 08:29:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][5100/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:25:37  time: 0.1388  data_time: 0.0020  memory: 5847  loss: 2.1058  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1058\n",
      "03/07 08:29:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][5200/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:25:23  time: 0.1374  data_time: 0.0020  memory: 5847  loss: 2.3989  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3989\n",
      "03/07 08:29:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:29:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][5225/5225]  base_lr: 1.0895e-04 lr: 1.0895e-05  eta: 3:25:20  time: 0.1356  data_time: 0.0019  memory: 5847  loss: 2.2795  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.2795\n",
      "03/07 08:29:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][100/647]    eta: 0:00:16  time: 0.0296  data_time: 0.0011  memory: 1333  \n",
      "03/07 08:29:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][200/647]    eta: 0:00:13  time: 0.0293  data_time: 0.0008  memory: 1333  \n",
      "03/07 08:29:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][300/647]    eta: 0:00:10  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 08:29:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][400/647]    eta: 0:00:07  time: 0.0294  data_time: 0.0008  memory: 1333  \n",
      "03/07 08:29:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][500/647]    eta: 0:00:04  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 08:29:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][600/647]    eta: 0:00:01  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "[0]\n",
      "[1]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[20]\n",
      "[4]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[13]\n",
      "[17]\n",
      "[18]\n",
      "[14]\n",
      "[20]\n",
      "[20]\n",
      "[14]\n",
      "[13]\n",
      "[17]\n",
      "[20]\n",
      "[23]\n",
      "[14]\n",
      "[21]\n",
      "[14]\n",
      "[20]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[23]\n",
      "[14]\n",
      "[17]\n",
      "[28]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[21]\n",
      "[20]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[13]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[17]\n",
      "[14]\n",
      "[22]\n",
      "[23]\n",
      "[2]\n",
      "[23]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[4]\n",
      "[11]\n",
      "[11]\n",
      "[23]\n",
      "[22]\n",
      "[22]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[5]\n",
      "[4]\n",
      "[11]\n",
      "[21]\n",
      "[17]\n",
      "[26]\n",
      "[23]\n",
      "[5]\n",
      "[22]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[23]\n",
      "[22]\n",
      "[23]\n",
      "[26]\n",
      "[24]\n",
      "[24]\n",
      "[16]\n",
      "[26]\n",
      "[20]\n",
      "[23]\n",
      "[23]\n",
      "[26]\n",
      "[42]\n",
      "[27]\n",
      "[27]\n",
      "[115]\n",
      "[63]\n",
      "[63]\n",
      "[29]\n",
      "[29]\n",
      "[31]\n",
      "[47]\n",
      "[115]\n",
      "[27]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[27]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[27]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[27]\n",
      "[36]\n",
      "[42]\n",
      "[37]\n",
      "[42]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[38]\n",
      "[42]\n",
      "[32]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[36]\n",
      "[34]\n",
      "[34]\n",
      "[32]\n",
      "[53]\n",
      "[9]\n",
      "[54]\n",
      "[55]\n",
      "[54]\n",
      "[54]\n",
      "[52]\n",
      "[26]\n",
      "[23]\n",
      "[55]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[57]\n",
      "[54]\n",
      "[54]\n",
      "[9]\n",
      "[55]\n",
      "[54]\n",
      "[55]\n",
      "[54]\n",
      "[53]\n",
      "[9]\n",
      "[54]\n",
      "[57]\n",
      "[10]\n",
      "[9]\n",
      "[54]\n",
      "[54]\n",
      "[26]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[57]\n",
      "[54]\n",
      "[57]\n",
      "[54]\n",
      "[52]\n",
      "[54]\n",
      "[28]\n",
      "[55]\n",
      "[55]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[54]\n",
      "[54]\n",
      "[16]\n",
      "[55]\n",
      "[10]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[53]\n",
      "[55]\n",
      "[54]\n",
      "[54]\n",
      "[52]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[57]\n",
      "[54]\n",
      "[55]\n",
      "[55]\n",
      "[55]\n",
      "[55]\n",
      "[55]\n",
      "[54]\n",
      "[53]\n",
      "[57]\n",
      "[44]\n",
      "[44]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[56]\n",
      "[44]\n",
      "[57]\n",
      "[55]\n",
      "[70]\n",
      "[67]\n",
      "[69]\n",
      "[70]\n",
      "[67]\n",
      "[29]\n",
      "[63]\n",
      "[67]\n",
      "[27]\n",
      "[29]\n",
      "[29]\n",
      "[27]\n",
      "[69]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[65]\n",
      "[69]\n",
      "[70]\n",
      "[29]\n",
      "[29]\n",
      "[29]\n",
      "[70]\n",
      "[67]\n",
      "[67]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[29]\n",
      "[29]\n",
      "[69]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[30]\n",
      "[69]\n",
      "[70]\n",
      "[66]\n",
      "[69]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[69]\n",
      "[28]\n",
      "[49]\n",
      "[44]\n",
      "[122]\n",
      "[99]\n",
      "[122]\n",
      "[49]\n",
      "[49]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[44]\n",
      "[49]\n",
      "[122]\n",
      "[122]\n",
      "[49]\n",
      "[122]\n",
      "[121]\n",
      "[122]\n",
      "[49]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[99]\n",
      "[49]\n",
      "[53]\n",
      "[44]\n",
      "[44]\n",
      "[99]\n",
      "[53]\n",
      "[53]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[71]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[97]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[97]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[99]\n",
      "[100]\n",
      "[80]\n",
      "[77]\n",
      "[86]\n",
      "[89]\n",
      "[80]\n",
      "[89]\n",
      "[77]\n",
      "[81]\n",
      "[80]\n",
      "[89]\n",
      "[89]\n",
      "[86]\n",
      "[82]\n",
      "[86]\n",
      "[86]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[80]\n",
      "[89]\n",
      "[86]\n",
      "[89]\n",
      "[80]\n",
      "[80]\n",
      "[86]\n",
      "[87]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[81]\n",
      "[86]\n",
      "[82]\n",
      "[78]\n",
      "[80]\n",
      "[80]\n",
      "[86]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[78]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[84]\n",
      "[87]\n",
      "[3]\n",
      "[86]\n",
      "[86]\n",
      "[82]\n",
      "[80]\n",
      "[77]\n",
      "[87]\n",
      "[72]\n",
      "[79]\n",
      "[81]\n",
      "[77]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[75]\n",
      "[77]\n",
      "[77]\n",
      "[77]\n",
      "[84]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[84]\n",
      "[112]\n",
      "[112]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[68]\n",
      "[68]\n",
      "[30]\n",
      "[91]\n",
      "[31]\n",
      "[31]\n",
      "[91]\n",
      "[31]\n",
      "[31]\n",
      "[84]\n",
      "[97]\n",
      "[49]\n",
      "[49]\n",
      "[68]\n",
      "[111]\n",
      "[7]\n",
      "[40]\n",
      "[62]\n",
      "[102]\n",
      "[101]\n",
      "[62]\n",
      "[62]\n",
      "[102]\n",
      "[102]\n",
      "[99]\n",
      "[40]\n",
      "[101]\n",
      "[40]\n",
      "[40]\n",
      "[64]\n",
      "[102]\n",
      "[102]\n",
      "[99]\n",
      "[103]\n",
      "[103]\n",
      "[40]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[99]\n",
      "[99]\n",
      "[92]\n",
      "[99]\n",
      "[99]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[40]\n",
      "[62]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[99]\n",
      "[99]\n",
      "[102]\n",
      "[102]\n",
      "[99]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[96]\n",
      "[96]\n",
      "[0]\n",
      "[96]\n",
      "[96]\n",
      "[99]\n",
      "[0]\n",
      "[99]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[99]\n",
      "[110]\n",
      "[107]\n",
      "[116]\n",
      "[116]\n",
      "[116]\n",
      "[32]\n",
      "[97]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[99]\n",
      "[99]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[122]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "03/07 08:29:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [8][647/647]    acc/top1: 0.1391  acc/top5: 0.4467  acc/mean1: 0.2028  data_time: 0.0009  time: 0.0296\n",
      "03/07 08:29:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_7.pth is removed\n",
      "03/07 08:29:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.1391 acc/top1 at 8 epoch is saved to best_acc_top1_epoch_8.pth.\n",
      "03/07 08:29:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 100/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:25:06  time: 0.1386  data_time: 0.0022  memory: 5847  loss: 2.2269  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2269\n",
      "03/07 08:30:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:30:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 200/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:24:52  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 2.3336  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.3336\n",
      "03/07 08:30:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 300/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:24:38  time: 0.1375  data_time: 0.0020  memory: 5847  loss: 1.8818  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.8818\n",
      "03/07 08:30:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 400/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:24:24  time: 0.1374  data_time: 0.0021  memory: 5847  loss: 2.3475  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.3475\n",
      "03/07 08:30:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 500/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:24:10  time: 0.1379  data_time: 0.0018  memory: 5847  loss: 2.6810  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.6810\n",
      "03/07 08:31:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 600/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:23:56  time: 0.1372  data_time: 0.0020  memory: 5847  loss: 2.1990  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1990\n",
      "03/07 08:31:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 700/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:23:42  time: 0.1377  data_time: 0.0022  memory: 5847  loss: 2.5023  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.5023\n",
      "03/07 08:31:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 800/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:23:28  time: 0.1372  data_time: 0.0020  memory: 5847  loss: 2.1083  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1083\n",
      "03/07 08:31:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 900/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:23:14  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 2.2493  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2493\n",
      "03/07 08:31:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1000/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:23:00  time: 0.1375  data_time: 0.0018  memory: 5847  loss: 2.0635  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0635\n",
      "03/07 08:32:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1100/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:22:46  time: 0.1374  data_time: 0.0019  memory: 5847  loss: 2.2482  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.2482\n",
      "03/07 08:32:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:32:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1200/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:22:32  time: 0.1372  data_time: 0.0019  memory: 5847  loss: 2.4484  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4484\n",
      "03/07 08:32:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1300/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:22:18  time: 0.1397  data_time: 0.0019  memory: 5847  loss: 2.0130  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0130\n",
      "03/07 08:32:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1400/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:22:04  time: 0.1398  data_time: 0.0020  memory: 5847  loss: 1.8422  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8422\n",
      "03/07 08:33:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1500/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:21:51  time: 0.1377  data_time: 0.0022  memory: 5847  loss: 2.5278  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.5278\n",
      "03/07 08:33:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1600/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:21:37  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 2.0486  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0486\n",
      "03/07 08:33:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1700/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:21:23  time: 0.1398  data_time: 0.0020  memory: 5847  loss: 2.2522  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.2522\n",
      "03/07 08:33:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1800/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:21:09  time: 0.1405  data_time: 0.0022  memory: 5847  loss: 1.7903  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7903\n",
      "03/07 08:34:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1900/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:20:55  time: 0.1376  data_time: 0.0019  memory: 5847  loss: 2.6740  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.6740\n",
      "03/07 08:34:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2000/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:20:41  time: 0.1375  data_time: 0.0020  memory: 5847  loss: 2.2535  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.2535\n",
      "03/07 08:34:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2100/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:20:27  time: 0.1373  data_time: 0.0020  memory: 5847  loss: 1.3994  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3994\n",
      "03/07 08:34:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:34:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2200/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:20:13  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 1.9532  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9532\n",
      "03/07 08:34:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2300/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:19:59  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 2.5366  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.5366\n",
      "03/07 08:35:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2400/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:19:45  time: 0.1395  data_time: 0.0020  memory: 5847  loss: 2.1342  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1342\n",
      "03/07 08:35:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2500/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:19:31  time: 0.1388  data_time: 0.0019  memory: 5847  loss: 2.2712  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2712\n",
      "03/07 08:35:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2600/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:19:17  time: 0.1378  data_time: 0.0020  memory: 5847  loss: 2.0072  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.0072\n",
      "03/07 08:35:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2700/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:19:03  time: 0.1374  data_time: 0.0019  memory: 5847  loss: 2.3080  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.3080\n",
      "03/07 08:36:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2800/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:18:49  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 2.5950  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.5950\n",
      "03/07 08:36:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][2900/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:18:35  time: 0.1370  data_time: 0.0020  memory: 5847  loss: 2.2356  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2356\n",
      "03/07 08:36:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3000/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:18:21  time: 0.1388  data_time: 0.0018  memory: 5847  loss: 2.1246  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1246\n",
      "03/07 08:36:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3100/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:18:07  time: 0.1390  data_time: 0.0018  memory: 5847  loss: 2.3878  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3878\n",
      "03/07 08:37:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:37:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3200/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:17:53  time: 0.1375  data_time: 0.0021  memory: 5847  loss: 2.0460  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0460\n",
      "03/07 08:37:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3300/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:17:39  time: 0.1373  data_time: 0.0019  memory: 5847  loss: 2.3143  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.3143\n",
      "03/07 08:37:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3400/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:17:25  time: 0.1383  data_time: 0.0022  memory: 5847  loss: 1.7715  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7715\n",
      "03/07 08:37:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3500/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:17:11  time: 0.1373  data_time: 0.0019  memory: 5847  loss: 2.3279  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.3279\n",
      "03/07 08:37:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3600/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:16:57  time: 0.1375  data_time: 0.0021  memory: 5847  loss: 2.1618  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1618\n",
      "03/07 08:38:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3700/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:16:43  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 2.0363  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0363\n",
      "03/07 08:38:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3800/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:16:29  time: 0.1381  data_time: 0.0018  memory: 5847  loss: 2.3893  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.3893\n",
      "03/07 08:38:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][3900/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:16:15  time: 0.1387  data_time: 0.0021  memory: 5847  loss: 1.9972  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9972\n",
      "03/07 08:38:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4000/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:16:01  time: 0.1386  data_time: 0.0022  memory: 5847  loss: 2.2008  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.2008\n",
      "03/07 08:39:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4100/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:15:48  time: 0.1370  data_time: 0.0019  memory: 5847  loss: 2.6543  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.6543\n",
      "03/07 08:39:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:39:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4200/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:15:34  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 2.0792  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0792\n",
      "03/07 08:39:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4300/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:15:20  time: 0.1380  data_time: 0.0019  memory: 5847  loss: 1.8398  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8398\n",
      "03/07 08:39:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4400/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:15:06  time: 0.1392  data_time: 0.0021  memory: 5847  loss: 2.2714  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2714\n",
      "03/07 08:40:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4500/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:14:52  time: 0.1384  data_time: 0.0019  memory: 5847  loss: 2.5401  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.5401\n",
      "03/07 08:40:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4600/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:14:38  time: 0.1370  data_time: 0.0019  memory: 5847  loss: 2.1298  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1298\n",
      "03/07 08:40:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4700/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:14:24  time: 0.1378  data_time: 0.0020  memory: 5847  loss: 2.3433  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3433\n",
      "03/07 08:40:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4800/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:14:10  time: 0.1388  data_time: 0.0019  memory: 5847  loss: 2.2193  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2193\n",
      "03/07 08:40:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4900/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:13:56  time: 0.1378  data_time: 0.0019  memory: 5847  loss: 2.4882  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.4882\n",
      "03/07 08:41:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][5000/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:13:42  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 1.9399  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9399\n",
      "03/07 08:41:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][5100/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:13:29  time: 0.1382  data_time: 0.0019  memory: 5847  loss: 2.2635  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2635\n",
      "03/07 08:41:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:41:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][5200/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:13:15  time: 0.1371  data_time: 0.0020  memory: 5847  loss: 2.0076  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0076\n",
      "03/07 08:41:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:41:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][5225/5225]  base_lr: 1.0432e-04 lr: 1.0432e-05  eta: 3:13:11  time: 0.1351  data_time: 0.0018  memory: 5847  loss: 2.0484  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.0484\n",
      "03/07 08:41:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
      "03/07 08:41:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][100/647]    eta: 0:00:16  time: 0.0294  data_time: 0.0010  memory: 1333  \n",
      "03/07 08:41:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][200/647]    eta: 0:00:13  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "03/07 08:41:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][300/647]    eta: 0:00:10  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 08:41:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][400/647]    eta: 0:00:07  time: 0.0294  data_time: 0.0008  memory: 1333  \n",
      "03/07 08:41:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][500/647]    eta: 0:00:04  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 08:42:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][600/647]    eta: 0:00:01  time: 0.0294  data_time: 0.0007  memory: 1333  \n",
      "[0]\n",
      "[70]\n",
      "[17]\n",
      "[14]\n",
      "[20]\n",
      "[17]\n",
      "[20]\n",
      "[4]\n",
      "[11]\n",
      "[14]\n",
      "[5]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[20]\n",
      "[20]\n",
      "[14]\n",
      "[28]\n",
      "[17]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[9]\n",
      "[4]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[28]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[9]\n",
      "[20]\n",
      "[9]\n",
      "[20]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[0]\n",
      "[4]\n",
      "[17]\n",
      "[26]\n",
      "[4]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[11]\n",
      "[11]\n",
      "[23]\n",
      "[23]\n",
      "[4]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[24]\n",
      "[26]\n",
      "[26]\n",
      "[20]\n",
      "[5]\n",
      "[5]\n",
      "[11]\n",
      "[21]\n",
      "[17]\n",
      "[26]\n",
      "[4]\n",
      "[5]\n",
      "[0]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[22]\n",
      "[23]\n",
      "[26]\n",
      "[26]\n",
      "[24]\n",
      "[16]\n",
      "[26]\n",
      "[20]\n",
      "[4]\n",
      "[4]\n",
      "[26]\n",
      "[42]\n",
      "[31]\n",
      "[19]\n",
      "[42]\n",
      "[87]\n",
      "[31]\n",
      "[29]\n",
      "[29]\n",
      "[31]\n",
      "[29]\n",
      "[33]\n",
      "[31]\n",
      "[19]\n",
      "[29]\n",
      "[31]\n",
      "[38]\n",
      "[27]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[30]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[33]\n",
      "[36]\n",
      "[42]\n",
      "[38]\n",
      "[42]\n",
      "[33]\n",
      "[19]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[33]\n",
      "[33]\n",
      "[36]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[38]\n",
      "[36]\n",
      "[36]\n",
      "[36]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[32]\n",
      "[59]\n",
      "[9]\n",
      "[59]\n",
      "[115]\n",
      "[59]\n",
      "[59]\n",
      "[58]\n",
      "[23]\n",
      "[26]\n",
      "[28]\n",
      "[59]\n",
      "[59]\n",
      "[59]\n",
      "[58]\n",
      "[45]\n",
      "[45]\n",
      "[9]\n",
      "[28]\n",
      "[59]\n",
      "[16]\n",
      "[55]\n",
      "[48]\n",
      "[57]\n",
      "[45]\n",
      "[59]\n",
      "[59]\n",
      "[9]\n",
      "[15]\n",
      "[15]\n",
      "[113]\n",
      "[58]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[48]\n",
      "[57]\n",
      "[57]\n",
      "[59]\n",
      "[57]\n",
      "[58]\n",
      "[57]\n",
      "[59]\n",
      "[52]\n",
      "[54]\n",
      "[105]\n",
      "[106]\n",
      "[54]\n",
      "[48]\n",
      "[59]\n",
      "[45]\n",
      "[27]\n",
      "[59]\n",
      "[30]\n",
      "[34]\n",
      "[106]\n",
      "[10]\n",
      "[10]\n",
      "[10]\n",
      "[55]\n",
      "[10]\n",
      "[10]\n",
      "[54]\n",
      "[15]\n",
      "[52]\n",
      "[59]\n",
      "[15]\n",
      "[56]\n",
      "[57]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[59]\n",
      "[46]\n",
      "[56]\n",
      "[46]\n",
      "[59]\n",
      "[45]\n",
      "[45]\n",
      "[57]\n",
      "[57]\n",
      "[59]\n",
      "[57]\n",
      "[59]\n",
      "[57]\n",
      "[48]\n",
      "[48]\n",
      "[56]\n",
      "[45]\n",
      "[57]\n",
      "[59]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[66]\n",
      "[67]\n",
      "[29]\n",
      "[67]\n",
      "[29]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[65]\n",
      "[70]\n",
      "[70]\n",
      "[33]\n",
      "[67]\n",
      "[70]\n",
      "[68]\n",
      "[62]\n",
      "[67]\n",
      "[66]\n",
      "[68]\n",
      "[68]\n",
      "[68]\n",
      "[68]\n",
      "[66]\n",
      "[67]\n",
      "[65]\n",
      "[68]\n",
      "[70]\n",
      "[29]\n",
      "[70]\n",
      "[29]\n",
      "[70]\n",
      "[48]\n",
      "[48]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[68]\n",
      "[68]\n",
      "[68]\n",
      "[36]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[68]\n",
      "[68]\n",
      "[68]\n",
      "[67]\n",
      "[68]\n",
      "[70]\n",
      "[116]\n",
      "[44]\n",
      "[109]\n",
      "[71]\n",
      "[121]\n",
      "[98]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[44]\n",
      "[44]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[71]\n",
      "[71]\n",
      "[53]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[97]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[80]\n",
      "[90]\n",
      "[73]\n",
      "[89]\n",
      "[80]\n",
      "[89]\n",
      "[77]\n",
      "[77]\n",
      "[80]\n",
      "[80]\n",
      "[89]\n",
      "[73]\n",
      "[90]\n",
      "[85]\n",
      "[84]\n",
      "[85]\n",
      "[73]\n",
      "[87]\n",
      "[80]\n",
      "[89]\n",
      "[85]\n",
      "[89]\n",
      "[80]\n",
      "[80]\n",
      "[85]\n",
      "[87]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[85]\n",
      "[85]\n",
      "[86]\n",
      "[85]\n",
      "[73]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[88]\n",
      "[81]\n",
      "[73]\n",
      "[88]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[85]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[84]\n",
      "[85]\n",
      "[84]\n",
      "[84]\n",
      "[87]\n",
      "[80]\n",
      "[73]\n",
      "[90]\n",
      "[90]\n",
      "[80]\n",
      "[74]\n",
      "[73]\n",
      "[72]\n",
      "[80]\n",
      "[76]\n",
      "[81]\n",
      "[84]\n",
      "[84]\n",
      "[73]\n",
      "[73]\n",
      "[73]\n",
      "[80]\n",
      "[74]\n",
      "[72]\n",
      "[77]\n",
      "[76]\n",
      "[83]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[83]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[68]\n",
      "[84]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[30]\n",
      "[71]\n",
      "[71]\n",
      "[49]\n",
      "[35]\n",
      "[14]\n",
      "[43]\n",
      "[71]\n",
      "[96]\n",
      "[102]\n",
      "[101]\n",
      "[97]\n",
      "[97]\n",
      "[102]\n",
      "[102]\n",
      "[100]\n",
      "[71]\n",
      "[101]\n",
      "[101]\n",
      "[71]\n",
      "[64]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[101]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[100]\n",
      "[71]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[96]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[100]\n",
      "[100]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[96]\n",
      "[96]\n",
      "[0]\n",
      "[96]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[0]\n",
      "[97]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[96]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[109]\n",
      "[107]\n",
      "[116]\n",
      "[71]\n",
      "[116]\n",
      "[95]\n",
      "[116]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[106]\n",
      "[111]\n",
      "[105]\n",
      "[111]\n",
      "[106]\n",
      "[105]\n",
      "[105]\n",
      "[106]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[105]\n",
      "[117]\n",
      "[106]\n",
      "[111]\n",
      "[106]\n",
      "[106]\n",
      "[111]\n",
      "[117]\n",
      "[117]\n",
      "[105]\n",
      "[117]\n",
      "[105]\n",
      "[111]\n",
      "[117]\n",
      "[111]\n",
      "[117]\n",
      "[31]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[30]\n",
      "[111]\n",
      "[111]\n",
      "[106]\n",
      "[106]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "03/07 08:42:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [9][647/647]    acc/top1: 0.1345  acc/top5: 0.4575  acc/mean1: 0.2255  data_time: 0.0009  time: 0.0297\n",
      "03/07 08:42:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 100/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:12:57  time: 0.1370  data_time: 0.0018  memory: 5847  loss: 2.1372  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1372\n",
      "03/07 08:42:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 200/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:12:43  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 1.9827  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9827\n",
      "03/07 08:42:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 300/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:12:29  time: 0.1403  data_time: 0.0021  memory: 5847  loss: 2.1004  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1004\n",
      "03/07 08:42:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 400/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:12:16  time: 0.1381  data_time: 0.0022  memory: 5847  loss: 2.4323  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.4323\n",
      "03/07 08:43:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 500/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:12:02  time: 0.1376  data_time: 0.0021  memory: 5847  loss: 2.1344  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1344\n",
      "03/07 08:43:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 600/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:11:48  time: 0.1382  data_time: 0.0019  memory: 5847  loss: 2.3387  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3387\n",
      "03/07 08:43:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 700/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:11:34  time: 0.1377  data_time: 0.0018  memory: 5847  loss: 1.9681  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.9681\n",
      "03/07 08:43:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 800/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:11:20  time: 0.1375  data_time: 0.0020  memory: 5847  loss: 2.2574  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2574\n",
      "03/07 08:44:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 900/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:11:06  time: 0.1397  data_time: 0.0020  memory: 5847  loss: 2.5008  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.5008\n",
      "03/07 08:44:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:44:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1000/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:10:52  time: 0.1367  data_time: 0.0020  memory: 5847  loss: 2.0735  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0735\n",
      "03/07 08:44:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1100/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:10:38  time: 0.1395  data_time: 0.0019  memory: 5847  loss: 2.0628  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0628\n",
      "03/07 08:44:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1200/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:10:24  time: 0.1396  data_time: 0.0021  memory: 5847  loss: 2.2338  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2338\n",
      "03/07 08:45:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1300/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:10:11  time: 0.1393  data_time: 0.0019  memory: 5847  loss: 1.8286  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8286\n",
      "03/07 08:45:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1400/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:09:57  time: 0.1373  data_time: 0.0020  memory: 5847  loss: 2.4219  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.4219\n",
      "03/07 08:45:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1500/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:09:43  time: 0.1371  data_time: 0.0021  memory: 5847  loss: 2.2913  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.2913\n",
      "03/07 08:45:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1600/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:09:29  time: 0.1390  data_time: 0.0020  memory: 5847  loss: 2.1256  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1256\n",
      "03/07 08:45:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1700/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:09:15  time: 0.1388  data_time: 0.0020  memory: 5847  loss: 2.0320  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0320\n",
      "03/07 08:46:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1800/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:09:01  time: 0.1375  data_time: 0.0021  memory: 5847  loss: 2.3070  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3070\n",
      "03/07 08:46:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1900/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:08:47  time: 0.1371  data_time: 0.0019  memory: 5847  loss: 1.6791  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6791\n",
      "03/07 08:46:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:46:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2000/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:08:33  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 1.8299  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8299\n",
      "03/07 08:46:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2100/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:08:19  time: 0.1399  data_time: 0.0019  memory: 5847  loss: 2.9649  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.9649\n",
      "03/07 08:47:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2200/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:08:05  time: 0.1375  data_time: 0.0020  memory: 5847  loss: 2.0623  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0623\n",
      "03/07 08:47:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2300/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:07:51  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 2.5364  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.5364\n",
      "03/07 08:47:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2400/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:07:37  time: 0.1382  data_time: 0.0019  memory: 5847  loss: 2.1966  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1966\n",
      "03/07 08:47:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2500/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:07:23  time: 0.1376  data_time: 0.0019  memory: 5847  loss: 1.8874  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.8874\n",
      "03/07 08:48:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2600/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:07:09  time: 0.1373  data_time: 0.0020  memory: 5847  loss: 2.1572  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1572\n",
      "03/07 08:48:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2700/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:06:55  time: 0.1370  data_time: 0.0020  memory: 5847  loss: 2.4798  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4798\n",
      "03/07 08:48:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2800/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:06:41  time: 0.1384  data_time: 0.0019  memory: 5847  loss: 2.1717  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1717\n",
      "03/07 08:48:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][2900/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:06:28  time: 0.1389  data_time: 0.0021  memory: 5847  loss: 1.7669  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7669\n",
      "03/07 08:48:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:48:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3000/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:06:14  time: 0.1391  data_time: 0.0019  memory: 5847  loss: 2.0537  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0537\n",
      "03/07 08:49:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3100/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:06:00  time: 0.1381  data_time: 0.0021  memory: 5847  loss: 2.1528  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1528\n",
      "03/07 08:49:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3200/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:05:46  time: 0.1366  data_time: 0.0018  memory: 5847  loss: 2.0879  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0879\n",
      "03/07 08:49:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3300/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:05:32  time: 0.1374  data_time: 0.0021  memory: 5847  loss: 2.2349  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.2349\n",
      "03/07 08:49:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3400/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:05:18  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 1.7719  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7719\n",
      "03/07 08:50:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3500/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:05:04  time: 0.1371  data_time: 0.0020  memory: 5847  loss: 2.1732  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1732\n",
      "03/07 08:50:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3600/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:04:50  time: 0.1385  data_time: 0.0018  memory: 5847  loss: 2.1922  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1922\n",
      "03/07 08:50:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3700/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:04:36  time: 0.1381  data_time: 0.0019  memory: 5847  loss: 2.0290  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0290\n",
      "03/07 08:50:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3800/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:04:22  time: 0.1427  data_time: 0.0019  memory: 5847  loss: 2.3846  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3846\n",
      "03/07 08:51:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][3900/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:04:08  time: 0.1387  data_time: 0.0019  memory: 5847  loss: 1.9647  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9647\n",
      "03/07 08:51:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:51:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4000/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:03:55  time: 0.1390  data_time: 0.0019  memory: 5847  loss: 2.1565  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1565\n",
      "03/07 08:51:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4100/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:03:41  time: 0.1371  data_time: 0.0018  memory: 5847  loss: 1.9414  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9414\n",
      "03/07 08:51:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4200/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:03:27  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 2.3676  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.3676\n",
      "03/07 08:51:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4300/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:03:13  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 1.8647  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8647\n",
      "03/07 08:52:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4400/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:02:59  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 2.2955  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2955\n",
      "03/07 08:52:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4500/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:02:45  time: 0.1379  data_time: 0.0022  memory: 5847  loss: 1.9324  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9324\n",
      "03/07 08:52:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4600/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:02:31  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 1.9672  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9672\n",
      "03/07 08:52:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4700/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:02:17  time: 0.1382  data_time: 0.0018  memory: 5847  loss: 1.9329  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9329\n",
      "03/07 08:53:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4800/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:02:03  time: 0.1386  data_time: 0.0023  memory: 5847  loss: 1.8396  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8396\n",
      "03/07 08:53:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4900/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:01:49  time: 0.1373  data_time: 0.0021  memory: 5847  loss: 2.2620  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2620\n",
      "03/07 08:53:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:53:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][5000/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:01:36  time: 0.1394  data_time: 0.0020  memory: 5847  loss: 1.6699  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.6699\n",
      "03/07 08:53:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][5100/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:01:22  time: 0.1387  data_time: 0.0020  memory: 5847  loss: 2.0445  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0445\n",
      "03/07 08:54:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][5200/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:01:08  time: 0.1386  data_time: 0.0019  memory: 5847  loss: 2.0114  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0114\n",
      "03/07 08:54:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:54:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][5225/5225]  base_lr: 9.9237e-05 lr: 9.9237e-06  eta: 3:01:04  time: 0.1346  data_time: 0.0019  memory: 5847  loss: 1.9891  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.9891\n",
      "03/07 08:54:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][100/647]    eta: 0:00:16  time: 0.0296  data_time: 0.0008  memory: 1333  \n",
      "03/07 08:54:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][200/647]    eta: 0:00:13  time: 0.0294  data_time: 0.0010  memory: 1333  \n",
      "03/07 08:54:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][300/647]    eta: 0:00:10  time: 0.0295  data_time: 0.0010  memory: 1333  \n",
      "03/07 08:54:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][400/647]    eta: 0:00:07  time: 0.0294  data_time: 0.0008  memory: 1333  \n",
      "03/07 08:54:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][500/647]    eta: 0:00:04  time: 0.0296  data_time: 0.0008  memory: 1333  \n",
      "03/07 08:54:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][600/647]    eta: 0:00:01  time: 0.0294  data_time: 0.0008  memory: 1333  \n",
      "[0]\n",
      "[1]\n",
      "[17]\n",
      "[14]\n",
      "[3]\n",
      "[9]\n",
      "[3]\n",
      "[4]\n",
      "[11]\n",
      "[11]\n",
      "[22]\n",
      "[22]\n",
      "[23]\n",
      "[14]\n",
      "[17]\n",
      "[3]\n",
      "[17]\n",
      "[18]\n",
      "[14]\n",
      "[20]\n",
      "[20]\n",
      "[3]\n",
      "[4]\n",
      "[17]\n",
      "[23]\n",
      "[3]\n",
      "[20]\n",
      "[9]\n",
      "[3]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[11]\n",
      "[9]\n",
      "[3]\n",
      "[23]\n",
      "[23]\n",
      "[14]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[9]\n",
      "[20]\n",
      "[21]\n",
      "[4]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[14]\n",
      "[20]\n",
      "[17]\n",
      "[9]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[13]\n",
      "[14]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[20]\n",
      "[14]\n",
      "[0]\n",
      "[4]\n",
      "[25]\n",
      "[23]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[4]\n",
      "[11]\n",
      "[11]\n",
      "[23]\n",
      "[22]\n",
      "[22]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[4]\n",
      "[11]\n",
      "[21]\n",
      "[25]\n",
      "[23]\n",
      "[23]\n",
      "[5]\n",
      "[22]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[23]\n",
      "[22]\n",
      "[23]\n",
      "[23]\n",
      "[25]\n",
      "[24]\n",
      "[26]\n",
      "[25]\n",
      "[25]\n",
      "[23]\n",
      "[23]\n",
      "[26]\n",
      "[42]\n",
      "[31]\n",
      "[30]\n",
      "[41]\n",
      "[30]\n",
      "[30]\n",
      "[29]\n",
      "[29]\n",
      "[31]\n",
      "[29]\n",
      "[115]\n",
      "[27]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[27]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[27]\n",
      "[36]\n",
      "[42]\n",
      "[42]\n",
      "[41]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[36]\n",
      "[65]\n",
      "[36]\n",
      "[42]\n",
      "[38]\n",
      "[38]\n",
      "[31]\n",
      "[36]\n",
      "[62]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[35]\n",
      "[35]\n",
      "[97]\n",
      "[34]\n",
      "[34]\n",
      "[97]\n",
      "[43]\n",
      "[43]\n",
      "[43]\n",
      "[32]\n",
      "[94]\n",
      "[9]\n",
      "[52]\n",
      "[113]\n",
      "[59]\n",
      "[45]\n",
      "[58]\n",
      "[52]\n",
      "[52]\n",
      "[51]\n",
      "[52]\n",
      "[58]\n",
      "[52]\n",
      "[58]\n",
      "[45]\n",
      "[45]\n",
      "[9]\n",
      "[51]\n",
      "[52]\n",
      "[59]\n",
      "[54]\n",
      "[53]\n",
      "[47]\n",
      "[46]\n",
      "[52]\n",
      "[53]\n",
      "[47]\n",
      "[54]\n",
      "[54]\n",
      "[26]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[46]\n",
      "[47]\n",
      "[47]\n",
      "[53]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[53]\n",
      "[52]\n",
      "[52]\n",
      "[105]\n",
      "[106]\n",
      "[46]\n",
      "[53]\n",
      "[52]\n",
      "[46]\n",
      "[27]\n",
      "[46]\n",
      "[52]\n",
      "[16]\n",
      "[51]\n",
      "[52]\n",
      "[53]\n",
      "[53]\n",
      "[45]\n",
      "[52]\n",
      "[52]\n",
      "[46]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[45]\n",
      "[47]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[45]\n",
      "[47]\n",
      "[47]\n",
      "[45]\n",
      "[45]\n",
      "[7]\n",
      "[47]\n",
      "[58]\n",
      "[47]\n",
      "[52]\n",
      "[52]\n",
      "[47]\n",
      "[46]\n",
      "[31]\n",
      "[44]\n",
      "[47]\n",
      "[45]\n",
      "[30]\n",
      "[67]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[62]\n",
      "[62]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[27]\n",
      "[70]\n",
      "[70]\n",
      "[27]\n",
      "[67]\n",
      "[70]\n",
      "[68]\n",
      "[62]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[40]\n",
      "[67]\n",
      "[27]\n",
      "[68]\n",
      "[70]\n",
      "[29]\n",
      "[29]\n",
      "[29]\n",
      "[47]\n",
      "[67]\n",
      "[67]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[70]\n",
      "[29]\n",
      "[70]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[62]\n",
      "[70]\n",
      "[70]\n",
      "[66]\n",
      "[67]\n",
      "[62]\n",
      "[68]\n",
      "[40]\n",
      "[67]\n",
      "[69]\n",
      "[43]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[122]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[98]\n",
      "[98]\n",
      "[122]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[121]\n",
      "[122]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[99]\n",
      "[98]\n",
      "[98]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[99]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[74]\n",
      "[90]\n",
      "[73]\n",
      "[74]\n",
      "[74]\n",
      "[75]\n",
      "[77]\n",
      "[76]\n",
      "[74]\n",
      "[74]\n",
      "[82]\n",
      "[88]\n",
      "[90]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[73]\n",
      "[74]\n",
      "[89]\n",
      "[86]\n",
      "[76]\n",
      "[74]\n",
      "[74]\n",
      "[73]\n",
      "[75]\n",
      "[74]\n",
      "[81]\n",
      "[81]\n",
      "[88]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[73]\n",
      "[87]\n",
      "[87]\n",
      "[75]\n",
      "[75]\n",
      "[82]\n",
      "[82]\n",
      "[73]\n",
      "[88]\n",
      "[90]\n",
      "[74]\n",
      "[74]\n",
      "[73]\n",
      "[74]\n",
      "[74]\n",
      "[74]\n",
      "[82]\n",
      "[90]\n",
      "[75]\n",
      "[75]\n",
      "[75]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[87]\n",
      "[75]\n",
      "[73]\n",
      "[88]\n",
      "[90]\n",
      "[74]\n",
      "[74]\n",
      "[73]\n",
      "[74]\n",
      "[79]\n",
      "[74]\n",
      "[74]\n",
      "[84]\n",
      "[84]\n",
      "[73]\n",
      "[73]\n",
      "[73]\n",
      "[74]\n",
      "[74]\n",
      "[74]\n",
      "[77]\n",
      "[73]\n",
      "[83]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[75]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[30]\n",
      "[97]\n",
      "[49]\n",
      "[49]\n",
      "[43]\n",
      "[109]\n",
      "[97]\n",
      "[40]\n",
      "[62]\n",
      "[102]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[71]\n",
      "[101]\n",
      "[40]\n",
      "[40]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[40]\n",
      "[103]\n",
      "[103]\n",
      "[92]\n",
      "[102]\n",
      "[71]\n",
      "[100]\n",
      "[100]\n",
      "[99]\n",
      "[71]\n",
      "[102]\n",
      "[62]\n",
      "[102]\n",
      "[40]\n",
      "[62]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[40]\n",
      "[99]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[96]\n",
      "[96]\n",
      "[79]\n",
      "[96]\n",
      "[96]\n",
      "[0]\n",
      "[96]\n",
      "[99]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[98]\n",
      "[96]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[99]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[97]\n",
      "[98]\n",
      "[98]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[105]\n",
      "[105]\n",
      "[106]\n",
      "[109]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[106]\n",
      "[105]\n",
      "[74]\n",
      "[111]\n",
      "[111]\n",
      "[108]\n",
      "[110]\n",
      "[108]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[108]\n",
      "[74]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[109]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "03/07 08:54:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][647/647]    acc/top1: 0.1577  acc/top5: 0.4884  acc/mean1: 0.2247  data_time: 0.0010  time: 0.0296\n",
      "03/07 08:54:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_8.pth is removed\n",
      "03/07 08:54:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.1577 acc/top1 at 10 epoch is saved to best_acc_top1_epoch_10.pth.\n",
      "03/07 08:54:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 100/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:00:50  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 2.4259  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.4259\n",
      "03/07 08:54:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 200/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:00:37  time: 0.1393  data_time: 0.0018  memory: 5847  loss: 2.0365  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.0365\n",
      "03/07 08:55:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 300/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:00:23  time: 0.1394  data_time: 0.0020  memory: 5847  loss: 1.6642  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.6642\n",
      "03/07 08:55:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 400/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 3:00:09  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 1.5065  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5065\n",
      "03/07 08:55:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 500/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:59:55  time: 0.1392  data_time: 0.0019  memory: 5847  loss: 1.7260  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.7260\n",
      "03/07 08:55:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 600/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:59:41  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 1.6659  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6659\n",
      "03/07 08:56:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 700/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:59:27  time: 0.1372  data_time: 0.0020  memory: 5847  loss: 2.1739  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.1739\n",
      "03/07 08:56:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:56:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 800/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:59:13  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 1.8100  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8100\n",
      "03/07 08:56:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 900/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:58:59  time: 0.1399  data_time: 0.0019  memory: 5847  loss: 2.1590  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.1590\n",
      "03/07 08:56:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1000/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:58:45  time: 0.1403  data_time: 0.0021  memory: 5847  loss: 1.7272  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7272\n",
      "03/07 08:56:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1100/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:58:32  time: 0.1401  data_time: 0.0020  memory: 5847  loss: 1.9757  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9757\n",
      "03/07 08:57:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1200/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:58:18  time: 0.1379  data_time: 0.0021  memory: 5847  loss: 2.2986  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2986\n",
      "03/07 08:57:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1300/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:58:04  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 1.9159  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9159\n",
      "03/07 08:57:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1400/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:57:50  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 2.5926  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.5926\n",
      "03/07 08:57:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1500/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:57:36  time: 0.1404  data_time: 0.0020  memory: 5847  loss: 2.3343  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.3343\n",
      "03/07 08:58:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1600/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:57:22  time: 0.1372  data_time: 0.0019  memory: 5847  loss: 1.8961  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8961\n",
      "03/07 08:58:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1700/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:57:08  time: 0.1372  data_time: 0.0021  memory: 5847  loss: 1.9918  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9918\n",
      "03/07 08:58:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 08:58:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1800/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:56:54  time: 0.1389  data_time: 0.0019  memory: 5847  loss: 1.9237  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9237\n",
      "03/07 08:58:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1900/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:56:40  time: 0.1388  data_time: 0.0021  memory: 5847  loss: 2.1748  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1748\n",
      "03/07 08:59:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2000/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:56:27  time: 0.1399  data_time: 0.0020  memory: 5847  loss: 2.3664  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.3664\n",
      "03/07 08:59:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2100/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:56:13  time: 0.1376  data_time: 0.0021  memory: 5847  loss: 2.2282  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.2282\n",
      "03/07 08:59:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2200/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:55:59  time: 0.1384  data_time: 0.0020  memory: 5847  loss: 1.8703  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8703\n",
      "03/07 08:59:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2300/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:55:45  time: 0.1375  data_time: 0.0020  memory: 5847  loss: 1.9867  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9867\n",
      "03/07 08:59:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2400/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:55:31  time: 0.1375  data_time: 0.0018  memory: 5847  loss: 2.1694  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1694\n",
      "03/07 09:00:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2500/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:55:17  time: 0.1377  data_time: 0.0019  memory: 5847  loss: 2.0337  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0337\n",
      "03/07 09:00:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2600/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:55:03  time: 0.1368  data_time: 0.0020  memory: 5847  loss: 2.1464  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1464\n",
      "03/07 09:00:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2700/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:54:49  time: 0.1391  data_time: 0.0022  memory: 5847  loss: 2.0830  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0830\n",
      "03/07 09:00:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:00:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2800/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:54:36  time: 0.1397  data_time: 0.0019  memory: 5847  loss: 1.7317  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.7317\n",
      "03/07 09:01:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][2900/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:54:22  time: 0.1380  data_time: 0.0021  memory: 5847  loss: 1.9023  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9023\n",
      "03/07 09:01:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3000/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:54:08  time: 0.1372  data_time: 0.0018  memory: 5847  loss: 2.1110  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1110\n",
      "03/07 09:01:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3100/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:53:54  time: 0.1383  data_time: 0.0018  memory: 5847  loss: 2.1838  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1838\n",
      "03/07 09:01:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3200/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:53:40  time: 0.1384  data_time: 0.0021  memory: 5847  loss: 1.9170  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9170\n",
      "03/07 09:02:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3300/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:53:26  time: 0.1380  data_time: 0.0018  memory: 5847  loss: 1.9598  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9598\n",
      "03/07 09:02:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3400/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:53:12  time: 0.1390  data_time: 0.0020  memory: 5847  loss: 1.9783  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.9783\n",
      "03/07 09:02:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3500/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:52:58  time: 0.1388  data_time: 0.0020  memory: 5847  loss: 1.7706  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7706\n",
      "03/07 09:02:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3600/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:52:44  time: 0.1416  data_time: 0.0020  memory: 5847  loss: 2.2170  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2170\n",
      "03/07 09:02:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3700/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:52:31  time: 0.1391  data_time: 0.0020  memory: 5847  loss: 1.8947  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8947\n",
      "03/07 09:03:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:03:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3800/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:52:17  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 2.0343  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0343\n",
      "03/07 09:03:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][3900/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:52:03  time: 0.1382  data_time: 0.0019  memory: 5847  loss: 2.2657  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2657\n",
      "03/07 09:03:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4000/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:51:49  time: 0.1394  data_time: 0.0019  memory: 5847  loss: 2.0466  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0466\n",
      "03/07 09:03:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4100/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:51:35  time: 0.1387  data_time: 0.0018  memory: 5847  loss: 2.3984  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3984\n",
      "03/07 09:04:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4200/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:51:21  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 1.8435  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8435\n",
      "03/07 09:04:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4300/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:51:07  time: 0.1374  data_time: 0.0020  memory: 5847  loss: 1.9959  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9959\n",
      "03/07 09:04:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4400/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:50:53  time: 0.1381  data_time: 0.0021  memory: 5847  loss: 2.2516  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.2516\n",
      "03/07 09:04:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4500/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:50:39  time: 0.1387  data_time: 0.0018  memory: 5847  loss: 1.9372  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9372\n",
      "03/07 09:05:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4600/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:50:26  time: 0.1390  data_time: 0.0019  memory: 5847  loss: 2.0747  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.0747\n",
      "03/07 09:05:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4700/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:50:12  time: 0.1374  data_time: 0.0020  memory: 5847  loss: 2.1452  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1452\n",
      "03/07 09:05:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:05:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4800/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:49:58  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 2.5691  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.5691\n",
      "03/07 09:05:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][4900/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:49:44  time: 0.1374  data_time: 0.0020  memory: 5847  loss: 2.4558  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.4558\n",
      "03/07 09:05:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][5000/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:49:30  time: 0.1367  data_time: 0.0020  memory: 5847  loss: 1.5009  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5009\n",
      "03/07 09:06:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][5100/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:49:16  time: 0.1381  data_time: 0.0021  memory: 5847  loss: 1.8694  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8694\n",
      "03/07 09:06:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][5200/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:49:02  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 1.9293  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9293\n",
      "03/07 09:06:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:06:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][5225/5225]  base_lr: 9.3750e-05 lr: 9.3750e-06  eta: 2:48:59  time: 0.1355  data_time: 0.0020  memory: 5847  loss: 1.3939  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3939\n",
      "03/07 09:06:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][100/647]    eta: 0:00:16  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 09:06:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][200/647]    eta: 0:00:13  time: 0.0294  data_time: 0.0008  memory: 1333  \n",
      "03/07 09:06:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][300/647]    eta: 0:00:10  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 09:06:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][400/647]    eta: 0:00:07  time: 0.0295  data_time: 0.0010  memory: 1333  \n",
      "03/07 09:06:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][500/647]    eta: 0:00:04  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 09:06:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][600/647]    eta: 0:00:01  time: 0.0293  data_time: 0.0007  memory: 1333  \n",
      "[0]\n",
      "[1]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[3]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[21]\n",
      "[22]\n",
      "[14]\n",
      "[11]\n",
      "[18]\n",
      "[14]\n",
      "[17]\n",
      "[18]\n",
      "[14]\n",
      "[20]\n",
      "[20]\n",
      "[14]\n",
      "[13]\n",
      "[17]\n",
      "[3]\n",
      "[3]\n",
      "[20]\n",
      "[21]\n",
      "[3]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[22]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[5]\n",
      "[20]\n",
      "[21]\n",
      "[20]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[13]\n",
      "[14]\n",
      "[17]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[21]\n",
      "[13]\n",
      "[13]\n",
      "[11]\n",
      "[17]\n",
      "[14]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[14]\n",
      "[0]\n",
      "[3]\n",
      "[25]\n",
      "[23]\n",
      "[4]\n",
      "[5]\n",
      "[5]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[25]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[21]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[5]\n",
      "[22]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[20]\n",
      "[22]\n",
      "[23]\n",
      "[26]\n",
      "[25]\n",
      "[24]\n",
      "[26]\n",
      "[25]\n",
      "[25]\n",
      "[22]\n",
      "[22]\n",
      "[26]\n",
      "[42]\n",
      "[27]\n",
      "[30]\n",
      "[31]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[29]\n",
      "[115]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[30]\n",
      "[30]\n",
      "[27]\n",
      "[42]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[41]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[27]\n",
      "[19]\n",
      "[31]\n",
      "[38]\n",
      "[20]\n",
      "[31]\n",
      "[31]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[42]\n",
      "[18]\n",
      "[35]\n",
      "[18]\n",
      "[35]\n",
      "[34]\n",
      "[35]\n",
      "[97]\n",
      "[43]\n",
      "[35]\n",
      "[18]\n",
      "[32]\n",
      "[59]\n",
      "[9]\n",
      "[59]\n",
      "[55]\n",
      "[54]\n",
      "[54]\n",
      "[9]\n",
      "[23]\n",
      "[23]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[48]\n",
      "[54]\n",
      "[54]\n",
      "[9]\n",
      "[56]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[48]\n",
      "[54]\n",
      "[48]\n",
      "[54]\n",
      "[9]\n",
      "[54]\n",
      "[54]\n",
      "[3]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[57]\n",
      "[54]\n",
      "[57]\n",
      "[54]\n",
      "[52]\n",
      "[54]\n",
      "[105]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[105]\n",
      "[54]\n",
      "[54]\n",
      "[27]\n",
      "[55]\n",
      "[59]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[52]\n",
      "[54]\n",
      "[54]\n",
      "[56]\n",
      "[57]\n",
      "[56]\n",
      "[55]\n",
      "[56]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[55]\n",
      "[57]\n",
      "[57]\n",
      "[45]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[57]\n",
      "[48]\n",
      "[54]\n",
      "[54]\n",
      "[56]\n",
      "[57]\n",
      "[55]\n",
      "[30]\n",
      "[68]\n",
      "[68]\n",
      "[30]\n",
      "[28]\n",
      "[28]\n",
      "[63]\n",
      "[63]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[28]\n",
      "[48]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[70]\n",
      "[69]\n",
      "[63]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[68]\n",
      "[67]\n",
      "[27]\n",
      "[68]\n",
      "[70]\n",
      "[29]\n",
      "[7]\n",
      "[29]\n",
      "[47]\n",
      "[67]\n",
      "[67]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[68]\n",
      "[29]\n",
      "[29]\n",
      "[68]\n",
      "[7]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[68]\n",
      "[68]\n",
      "[70]\n",
      "[68]\n",
      "[68]\n",
      "[68]\n",
      "[68]\n",
      "[68]\n",
      "[63]\n",
      "[69]\n",
      "[43]\n",
      "[71]\n",
      "[44]\n",
      "[122]\n",
      "[71]\n",
      "[122]\n",
      "[122]\n",
      "[71]\n",
      "[122]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[122]\n",
      "[44]\n",
      "[54]\n",
      "[121]\n",
      "[122]\n",
      "[71]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[122]\n",
      "[122]\n",
      "[99]\n",
      "[99]\n",
      "[100]\n",
      "[71]\n",
      "[48]\n",
      "[44]\n",
      "[51]\n",
      "[100]\n",
      "[48]\n",
      "[48]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[100]\n",
      "[80]\n",
      "[90]\n",
      "[86]\n",
      "[89]\n",
      "[80]\n",
      "[89]\n",
      "[77]\n",
      "[77]\n",
      "[72]\n",
      "[80]\n",
      "[89]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[89]\n",
      "[86]\n",
      "[77]\n",
      "[72]\n",
      "[80]\n",
      "[86]\n",
      "[87]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[88]\n",
      "[81]\n",
      "[86]\n",
      "[88]\n",
      "[90]\n",
      "[80]\n",
      "[77]\n",
      "[86]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[84]\n",
      "[86]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[86]\n",
      "[84]\n",
      "[90]\n",
      "[75]\n",
      "[74]\n",
      "[73]\n",
      "[72]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[73]\n",
      "[86]\n",
      "[86]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[30]\n",
      "[71]\n",
      "[49]\n",
      "[49]\n",
      "[35]\n",
      "[49]\n",
      "[97]\n",
      "[40]\n",
      "[96]\n",
      "[102]\n",
      "[101]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[40]\n",
      "[101]\n",
      "[40]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[100]\n",
      "[103]\n",
      "[103]\n",
      "[40]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[102]\n",
      "[97]\n",
      "[102]\n",
      "[40]\n",
      "[96]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[100]\n",
      "[100]\n",
      "[102]\n",
      "[92]\n",
      "[100]\n",
      "[102]\n",
      "[102]\n",
      "[92]\n",
      "[96]\n",
      "[97]\n",
      "[92]\n",
      "[96]\n",
      "[96]\n",
      "[92]\n",
      "[97]\n",
      "[104]\n",
      "[100]\n",
      "[104]\n",
      "[92]\n",
      "[96]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[96]\n",
      "[104]\n",
      "[104]\n",
      "[100]\n",
      "[100]\n",
      "[109]\n",
      "[116]\n",
      "[116]\n",
      "[71]\n",
      "[116]\n",
      "[32]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[97]\n",
      "[100]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[106]\n",
      "[106]\n",
      "[111]\n",
      "[106]\n",
      "[111]\n",
      "[106]\n",
      "[106]\n",
      "[105]\n",
      "[74]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[105]\n",
      "[112]\n",
      "[108]\n",
      "[111]\n",
      "[109]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[31]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[18]\n",
      "[111]\n",
      "[100]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[100]\n",
      "[109]\n",
      "03/07 09:06:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][647/647]    acc/top1: 0.1437  acc/top5: 0.4961  acc/mean1: 0.1974  data_time: 0.0009  time: 0.0296\n",
      "03/07 09:07:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 100/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:48:45  time: 0.1377  data_time: 0.0021  memory: 5847  loss: 2.1104  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1104\n",
      "03/07 09:07:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 200/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:48:31  time: 0.1380  data_time: 0.0018  memory: 5847  loss: 1.8682  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8682\n",
      "03/07 09:07:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 300/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:48:17  time: 0.1382  data_time: 0.0019  memory: 5847  loss: 2.0484  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0484\n",
      "03/07 09:07:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 400/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:48:03  time: 0.1376  data_time: 0.0021  memory: 5847  loss: 1.7119  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7119\n",
      "03/07 09:07:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 500/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:47:49  time: 0.1376  data_time: 0.0019  memory: 5847  loss: 1.4952  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4952\n",
      "03/07 09:08:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:08:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 600/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:47:35  time: 0.1375  data_time: 0.0020  memory: 5847  loss: 2.0150  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0150\n",
      "03/07 09:08:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 700/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:47:21  time: 0.1389  data_time: 0.0022  memory: 5847  loss: 2.3294  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.3294\n",
      "03/07 09:08:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 800/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:47:07  time: 0.1396  data_time: 0.0017  memory: 5847  loss: 2.2120  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2120\n",
      "03/07 09:08:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 900/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:46:54  time: 0.1397  data_time: 0.0019  memory: 5847  loss: 2.1708  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1708\n",
      "03/07 09:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1000/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:46:40  time: 0.1378  data_time: 0.0022  memory: 5847  loss: 2.0220  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0220\n",
      "03/07 09:09:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1100/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:46:26  time: 0.1377  data_time: 0.0019  memory: 5847  loss: 2.2065  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.2065\n",
      "03/07 09:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1200/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:46:12  time: 0.1400  data_time: 0.0019  memory: 5847  loss: 1.8726  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8726\n",
      "03/07 09:09:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1300/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:45:58  time: 0.1400  data_time: 0.0020  memory: 5847  loss: 1.7724  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7724\n",
      "03/07 09:10:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1400/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:45:45  time: 0.1375  data_time: 0.0020  memory: 5847  loss: 2.0080  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0080\n",
      "03/07 09:10:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1500/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:45:31  time: 0.1377  data_time: 0.0019  memory: 5847  loss: 2.1607  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1607\n",
      "03/07 09:10:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:10:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1600/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:45:17  time: 0.1371  data_time: 0.0020  memory: 5847  loss: 2.0299  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0299\n",
      "03/07 09:10:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1700/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:45:03  time: 0.1376  data_time: 0.0019  memory: 5847  loss: 1.6550  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6550\n",
      "03/07 09:10:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1800/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:44:49  time: 0.1389  data_time: 0.0020  memory: 5847  loss: 1.6010  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.6010\n",
      "03/07 09:11:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1900/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:44:35  time: 0.1389  data_time: 0.0018  memory: 5847  loss: 1.6766  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.6766\n",
      "03/07 09:11:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2000/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:44:21  time: 0.1388  data_time: 0.0019  memory: 5847  loss: 2.0347  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0347\n",
      "03/07 09:11:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2100/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:44:07  time: 0.1392  data_time: 0.0020  memory: 5847  loss: 2.1590  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1590\n",
      "03/07 09:11:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2200/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:43:53  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 1.6200  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6200\n",
      "03/07 09:12:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2300/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:43:40  time: 0.1374  data_time: 0.0020  memory: 5847  loss: 1.5385  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5385\n",
      "03/07 09:12:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2400/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:43:26  time: 0.1372  data_time: 0.0020  memory: 5847  loss: 2.2450  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2450\n",
      "03/07 09:12:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2500/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:43:12  time: 0.1387  data_time: 0.0019  memory: 5847  loss: 1.5779  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5779\n",
      "03/07 09:12:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:12:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2600/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:42:58  time: 0.1395  data_time: 0.0021  memory: 5847  loss: 1.9590  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9590\n",
      "03/07 09:13:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2700/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:42:44  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 2.3098  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.3098\n",
      "03/07 09:13:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2800/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:42:30  time: 0.1382  data_time: 0.0019  memory: 5847  loss: 2.1859  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1859\n",
      "03/07 09:13:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][2900/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:42:16  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 2.5193  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.5193\n",
      "03/07 09:13:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3000/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:42:02  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 2.0342  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0342\n",
      "03/07 09:13:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3100/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:41:49  time: 0.1388  data_time: 0.0019  memory: 5847  loss: 2.1533  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1533\n",
      "03/07 09:14:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3200/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:41:35  time: 0.1390  data_time: 0.0020  memory: 5847  loss: 2.0843  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0843\n",
      "03/07 09:14:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3300/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:41:21  time: 0.1377  data_time: 0.0018  memory: 5847  loss: 1.7406  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7406\n",
      "03/07 09:14:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3400/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:41:07  time: 0.1385  data_time: 0.0019  memory: 5847  loss: 1.7768  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7768\n",
      "03/07 09:14:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3500/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:40:53  time: 0.1397  data_time: 0.0021  memory: 5847  loss: 1.4122  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4122\n",
      "03/07 09:14:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:15:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3600/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:40:40  time: 0.1389  data_time: 0.0021  memory: 5847  loss: 1.8383  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8383\n",
      "03/07 09:15:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3700/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:40:26  time: 0.1370  data_time: 0.0019  memory: 5847  loss: 1.9990  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9990\n",
      "03/07 09:15:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3800/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:40:12  time: 0.1406  data_time: 0.0020  memory: 5847  loss: 2.7054  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.7054\n",
      "03/07 09:15:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][3900/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:39:58  time: 0.1390  data_time: 0.0020  memory: 5847  loss: 1.9553  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9553\n",
      "03/07 09:16:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4000/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:39:44  time: 0.1378  data_time: 0.0019  memory: 5847  loss: 1.2751  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2751\n",
      "03/07 09:16:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4100/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:39:30  time: 0.1382  data_time: 0.0021  memory: 5847  loss: 1.5829  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5829\n",
      "03/07 09:16:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4200/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:39:16  time: 0.1378  data_time: 0.0020  memory: 5847  loss: 1.7005  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7005\n",
      "03/07 09:16:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4300/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:39:02  time: 0.1381  data_time: 0.0018  memory: 5847  loss: 1.8126  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8126\n",
      "03/07 09:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4400/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:38:48  time: 0.1377  data_time: 0.0017  memory: 5847  loss: 1.9184  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9184\n",
      "03/07 09:17:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4500/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:38:35  time: 0.1389  data_time: 0.0019  memory: 5847  loss: 1.6215  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6215\n",
      "03/07 09:17:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:17:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4600/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:38:21  time: 0.1372  data_time: 0.0019  memory: 5847  loss: 1.8507  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8507\n",
      "03/07 09:17:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4700/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:38:07  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.9811  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9811\n",
      "03/07 09:17:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4800/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:37:53  time: 0.1399  data_time: 0.0020  memory: 5847  loss: 2.2124  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2124\n",
      "03/07 09:18:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][4900/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:37:39  time: 0.1386  data_time: 0.0020  memory: 5847  loss: 1.9948  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9948\n",
      "03/07 09:18:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][5000/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:37:25  time: 0.1375  data_time: 0.0021  memory: 5847  loss: 2.3601  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3601\n",
      "03/07 09:18:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][5100/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:37:11  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 1.6794  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6794\n",
      "03/07 09:18:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][5200/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:36:57  time: 0.1396  data_time: 0.0021  memory: 5847  loss: 2.0480  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0480\n",
      "03/07 09:18:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:18:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][5225/5225]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 2:36:54  time: 0.1365  data_time: 0.0020  memory: 5847  loss: 1.5321  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.5321\n",
      "03/07 09:18:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 12 epochs\n",
      "03/07 09:18:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][100/647]    eta: 0:00:16  time: 0.0296  data_time: 0.0010  memory: 1333  \n",
      "03/07 09:18:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][200/647]    eta: 0:00:13  time: 0.0296  data_time: 0.0009  memory: 1333  \n",
      "03/07 09:19:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][300/647]    eta: 0:00:10  time: 0.0295  data_time: 0.0010  memory: 1333  \n",
      "03/07 09:19:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][400/647]    eta: 0:00:07  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 09:19:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][500/647]    eta: 0:00:04  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 09:19:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][600/647]    eta: 0:00:01  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "[0]\n",
      "[1]\n",
      "[17]\n",
      "[14]\n",
      "[3]\n",
      "[17]\n",
      "[3]\n",
      "[5]\n",
      "[11]\n",
      "[11]\n",
      "[5]\n",
      "[22]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[3]\n",
      "[17]\n",
      "[17]\n",
      "[5]\n",
      "[5]\n",
      "[3]\n",
      "[14]\n",
      "[4]\n",
      "[17]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[5]\n",
      "[3]\n",
      "[13]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[6]\n",
      "[22]\n",
      "[22]\n",
      "[13]\n",
      "[17]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[5]\n",
      "[4]\n",
      "[5]\n",
      "[3]\n",
      "[17]\n",
      "[14]\n",
      "[3]\n",
      "[5]\n",
      "[5]\n",
      "[20]\n",
      "[17]\n",
      "[11]\n",
      "[17]\n",
      "[11]\n",
      "[11]\n",
      "[5]\n",
      "[13]\n",
      "[13]\n",
      "[11]\n",
      "[17]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[17]\n",
      "[5]\n",
      "[3]\n",
      "[0]\n",
      "[4]\n",
      "[11]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[5]\n",
      "[5]\n",
      "[11]\n",
      "[11]\n",
      "[4]\n",
      "[22]\n",
      "[4]\n",
      "[11]\n",
      "[24]\n",
      "[24]\n",
      "[24]\n",
      "[20]\n",
      "[26]\n",
      "[20]\n",
      "[5]\n",
      "[5]\n",
      "[11]\n",
      "[21]\n",
      "[11]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[6]\n",
      "[22]\n",
      "[22]\n",
      "[20]\n",
      "[24]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[20]\n",
      "[6]\n",
      "[6]\n",
      "[16]\n",
      "[43]\n",
      "[29]\n",
      "[16]\n",
      "[31]\n",
      "[27]\n",
      "[27]\n",
      "[29]\n",
      "[29]\n",
      "[31]\n",
      "[29]\n",
      "[33]\n",
      "[27]\n",
      "[31]\n",
      "[29]\n",
      "[31]\n",
      "[31]\n",
      "[13]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[43]\n",
      "[27]\n",
      "[13]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[41]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[65]\n",
      "[41]\n",
      "[41]\n",
      "[111]\n",
      "[41]\n",
      "[33]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[29]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[33]\n",
      "[65]\n",
      "[19]\n",
      "[19]\n",
      "[38]\n",
      "[19]\n",
      "[19]\n",
      "[37]\n",
      "[63]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[35]\n",
      "[34]\n",
      "[32]\n",
      "[57]\n",
      "[57]\n",
      "[59]\n",
      "[55]\n",
      "[59]\n",
      "[54]\n",
      "[58]\n",
      "[16]\n",
      "[23]\n",
      "[51]\n",
      "[59]\n",
      "[54]\n",
      "[51]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[9]\n",
      "[55]\n",
      "[59]\n",
      "[59]\n",
      "[54]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[54]\n",
      "[54]\n",
      "[3]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[54]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[52]\n",
      "[54]\n",
      "[55]\n",
      "[51]\n",
      "[54]\n",
      "[48]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[54]\n",
      "[45]\n",
      "[16]\n",
      "[55]\n",
      "[12]\n",
      "[54]\n",
      "[58]\n",
      "[54]\n",
      "[12]\n",
      "[48]\n",
      "[54]\n",
      "[15]\n",
      "[52]\n",
      "[58]\n",
      "[54]\n",
      "[56]\n",
      "[7]\n",
      "[56]\n",
      "[56]\n",
      "[44]\n",
      "[48]\n",
      "[45]\n",
      "[44]\n",
      "[56]\n",
      "[48]\n",
      "[57]\n",
      "[45]\n",
      "[44]\n",
      "[7]\n",
      "[7]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[48]\n",
      "[48]\n",
      "[56]\n",
      "[44]\n",
      "[57]\n",
      "[44]\n",
      "[30]\n",
      "[67]\n",
      "[69]\n",
      "[30]\n",
      "[31]\n",
      "[29]\n",
      "[63]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[65]\n",
      "[70]\n",
      "[69]\n",
      "[65]\n",
      "[67]\n",
      "[70]\n",
      "[69]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[66]\n",
      "[67]\n",
      "[65]\n",
      "[68]\n",
      "[70]\n",
      "[29]\n",
      "[7]\n",
      "[29]\n",
      "[48]\n",
      "[67]\n",
      "[67]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[29]\n",
      "[29]\n",
      "[69]\n",
      "[70]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[68]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[67]\n",
      "[68]\n",
      "[70]\n",
      "[67]\n",
      "[69]\n",
      "[70]\n",
      "[98]\n",
      "[44]\n",
      "[122]\n",
      "[98]\n",
      "[122]\n",
      "[122]\n",
      "[98]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[44]\n",
      "[44]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[98]\n",
      "[98]\n",
      "[48]\n",
      "[44]\n",
      "[44]\n",
      "[100]\n",
      "[48]\n",
      "[44]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[71]\n",
      "[71]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[71]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[71]\n",
      "[98]\n",
      "[98]\n",
      "[80]\n",
      "[90]\n",
      "[73]\n",
      "[89]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[77]\n",
      "[72]\n",
      "[79]\n",
      "[82]\n",
      "[77]\n",
      "[82]\n",
      "[86]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[80]\n",
      "[76]\n",
      "[86]\n",
      "[77]\n",
      "[75]\n",
      "[80]\n",
      "[73]\n",
      "[87]\n",
      "[75]\n",
      "[81]\n",
      "[81]\n",
      "[85]\n",
      "[85]\n",
      "[86]\n",
      "[85]\n",
      "[73]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[77]\n",
      "[77]\n",
      "[86]\n",
      "[88]\n",
      "[90]\n",
      "[79]\n",
      "[80]\n",
      "[73]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[77]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[83]\n",
      "[85]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[80]\n",
      "[73]\n",
      "[73]\n",
      "[88]\n",
      "[79]\n",
      "[74]\n",
      "[73]\n",
      "[79]\n",
      "[79]\n",
      "[79]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[73]\n",
      "[83]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[71]\n",
      "[71]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[30]\n",
      "[71]\n",
      "[49]\n",
      "[49]\n",
      "[71]\n",
      "[49]\n",
      "[7]\n",
      "[40]\n",
      "[62]\n",
      "[62]\n",
      "[101]\n",
      "[62]\n",
      "[62]\n",
      "[102]\n",
      "[101]\n",
      "[71]\n",
      "[71]\n",
      "[101]\n",
      "[101]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[71]\n",
      "[101]\n",
      "[103]\n",
      "[101]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[71]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[71]\n",
      "[102]\n",
      "[62]\n",
      "[102]\n",
      "[40]\n",
      "[62]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[92]\n",
      "[92]\n",
      "[102]\n",
      "[101]\n",
      "[92]\n",
      "[62]\n",
      "[102]\n",
      "[92]\n",
      "[96]\n",
      "[97]\n",
      "[92]\n",
      "[79]\n",
      "[96]\n",
      "[92]\n",
      "[0]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[96]\n",
      "[97]\n",
      "[96]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[96]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[109]\n",
      "[107]\n",
      "[109]\n",
      "[71]\n",
      "[116]\n",
      "[100]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[105]\n",
      "[105]\n",
      "[108]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[108]\n",
      "[105]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[108]\n",
      "[112]\n",
      "[109]\n",
      "[111]\n",
      "[109]\n",
      "[108]\n",
      "[111]\n",
      "[111]\n",
      "[108]\n",
      "[109]\n",
      "[111]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[30]\n",
      "[111]\n",
      "[111]\n",
      "[106]\n",
      "[107]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[111]\n",
      "[100]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[100]\n",
      "[109]\n",
      "03/07 09:19:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][647/647]    acc/top1: 0.1777  acc/top5: 0.5116  acc/mean1: 0.2436  data_time: 0.0010  time: 0.0296\n",
      "03/07 09:19:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_10.pth is removed\n",
      "03/07 09:19:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.1777 acc/top1 at 12 epoch is saved to best_acc_top1_epoch_12.pth.\n",
      "03/07 09:19:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 100/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:36:40  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.7452  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7452\n",
      "03/07 09:19:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 200/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:36:26  time: 0.1374  data_time: 0.0017  memory: 5847  loss: 2.4711  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.4711\n",
      "03/07 09:19:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:19:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 300/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:36:12  time: 0.1370  data_time: 0.0019  memory: 5847  loss: 1.6685  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6685\n",
      "03/07 09:20:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 400/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:35:58  time: 0.1386  data_time: 0.0021  memory: 5847  loss: 1.6075  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6075\n",
      "03/07 09:20:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 500/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:35:44  time: 0.1375  data_time: 0.0020  memory: 5847  loss: 2.2306  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2306\n",
      "03/07 09:20:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 600/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:35:31  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 1.7374  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7374\n",
      "03/07 09:20:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 700/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:35:17  time: 0.1406  data_time: 0.0020  memory: 5847  loss: 1.7164  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7164\n",
      "03/07 09:21:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 800/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:35:03  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 2.1007  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.1007\n",
      "03/07 09:21:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 900/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:34:49  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 2.1647  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1647\n",
      "03/07 09:21:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1000/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:34:35  time: 0.1390  data_time: 0.0020  memory: 5847  loss: 1.5956  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5956\n",
      "03/07 09:21:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1100/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:34:21  time: 0.1386  data_time: 0.0021  memory: 5847  loss: 2.0445  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0445\n",
      "03/07 09:22:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1200/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:34:07  time: 0.1384  data_time: 0.0020  memory: 5847  loss: 1.6113  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6113\n",
      "03/07 09:22:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:22:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1300/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:33:53  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 2.0334  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0334\n",
      "03/07 09:22:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1400/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:33:39  time: 0.1386  data_time: 0.0020  memory: 5847  loss: 2.1035  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1035\n",
      "03/07 09:22:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1500/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:33:26  time: 0.1380  data_time: 0.0018  memory: 5847  loss: 1.5250  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5250\n",
      "03/07 09:22:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1600/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:33:12  time: 0.1383  data_time: 0.0021  memory: 5847  loss: 1.5367  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5367\n",
      "03/07 09:23:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1700/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:32:58  time: 0.1389  data_time: 0.0021  memory: 5847  loss: 1.6260  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6260\n",
      "03/07 09:23:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1800/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:32:44  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 1.7220  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7220\n",
      "03/07 09:23:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1900/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:32:30  time: 0.1388  data_time: 0.0020  memory: 5847  loss: 1.4897  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4897\n",
      "03/07 09:23:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2000/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:32:16  time: 0.1389  data_time: 0.0020  memory: 5847  loss: 1.6963  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6963\n",
      "03/07 09:24:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2100/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:32:02  time: 0.1375  data_time: 0.0021  memory: 5847  loss: 1.8769  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8769\n",
      "03/07 09:24:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2200/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:31:48  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 1.4976  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4976\n",
      "03/07 09:24:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:24:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2300/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:31:35  time: 0.1405  data_time: 0.0023  memory: 5847  loss: 1.7965  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7965\n",
      "03/07 09:24:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2400/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:31:21  time: 0.1396  data_time: 0.0020  memory: 5847  loss: 1.9112  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9112\n",
      "03/07 09:25:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2500/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:31:07  time: 0.1391  data_time: 0.0021  memory: 5847  loss: 1.6051  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6051\n",
      "03/07 09:25:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2600/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:30:53  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 1.8310  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8310\n",
      "03/07 09:25:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2700/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:30:39  time: 0.1378  data_time: 0.0018  memory: 5847  loss: 1.9901  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.9901\n",
      "03/07 09:25:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2800/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:30:25  time: 0.1375  data_time: 0.0021  memory: 5847  loss: 1.4538  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4538\n",
      "03/07 09:25:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][2900/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:30:11  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 1.2131  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2131\n",
      "03/07 09:26:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3000/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:29:57  time: 0.1389  data_time: 0.0018  memory: 5847  loss: 1.6977  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6977\n",
      "03/07 09:26:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3100/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:29:44  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.7803  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7803\n",
      "03/07 09:26:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3200/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:29:30  time: 0.1406  data_time: 0.0020  memory: 5847  loss: 1.8000  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.8000\n",
      "03/07 09:26:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:26:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3300/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:29:16  time: 0.1402  data_time: 0.0022  memory: 5847  loss: 1.9400  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9400\n",
      "03/07 09:27:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3400/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:29:02  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 2.1277  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1277\n",
      "03/07 09:27:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3500/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:28:48  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 2.4162  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4162\n",
      "03/07 09:27:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3600/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:28:35  time: 0.1391  data_time: 0.0019  memory: 5847  loss: 1.9544  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9544\n",
      "03/07 09:27:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3700/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:28:21  time: 0.1387  data_time: 0.0021  memory: 5847  loss: 1.7553  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7553\n",
      "03/07 09:28:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3800/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:28:07  time: 0.1386  data_time: 0.0021  memory: 5847  loss: 1.9210  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9210\n",
      "03/07 09:28:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][3900/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:27:53  time: 0.1373  data_time: 0.0020  memory: 5847  loss: 1.9889  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9889\n",
      "03/07 09:28:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4000/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:27:39  time: 0.1371  data_time: 0.0020  memory: 5847  loss: 1.7702  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7702\n",
      "03/07 09:28:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4100/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:27:25  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 1.6880  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6880\n",
      "03/07 09:28:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4200/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:27:11  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 1.7922  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7922\n",
      "03/07 09:29:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:29:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4300/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:26:57  time: 0.1377  data_time: 0.0019  memory: 5847  loss: 1.9965  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9965\n",
      "03/07 09:29:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4400/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:26:44  time: 0.1374  data_time: 0.0019  memory: 5847  loss: 1.7282  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7282\n",
      "03/07 09:29:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4500/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:26:30  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 2.3084  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3084\n",
      "03/07 09:29:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4600/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:26:16  time: 0.1371  data_time: 0.0019  memory: 5847  loss: 2.0333  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.0333\n",
      "03/07 09:30:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4700/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:26:02  time: 0.1383  data_time: 0.0021  memory: 5847  loss: 2.1695  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.1695\n",
      "03/07 09:30:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4800/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:25:48  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 2.0780  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0780\n",
      "03/07 09:30:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][4900/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:25:34  time: 0.1384  data_time: 0.0020  memory: 5847  loss: 2.1553  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1553\n",
      "03/07 09:30:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][5000/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:25:20  time: 0.1397  data_time: 0.0022  memory: 5847  loss: 1.7712  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.7712\n",
      "03/07 09:31:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][5100/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:25:06  time: 0.1390  data_time: 0.0021  memory: 5847  loss: 2.1928  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1928\n",
      "03/07 09:31:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][5200/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:24:53  time: 0.1375  data_time: 0.0018  memory: 5847  loss: 2.2903  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.2903\n",
      "03/07 09:31:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:31:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][5225/5225]  base_lr: 8.1814e-05 lr: 8.1814e-06  eta: 2:24:49  time: 0.1358  data_time: 0.0018  memory: 5847  loss: 2.0646  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0646\n",
      "03/07 09:31:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][100/647]    eta: 0:00:16  time: 0.0295  data_time: 0.0010  memory: 1333  \n",
      "03/07 09:31:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][200/647]    eta: 0:00:13  time: 0.0294  data_time: 0.0010  memory: 1333  \n",
      "03/07 09:31:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][300/647]    eta: 0:00:10  time: 0.0295  data_time: 0.0010  memory: 1333  \n",
      "03/07 09:31:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][400/647]    eta: 0:00:07  time: 0.0294  data_time: 0.0007  memory: 1333  \n",
      "03/07 09:31:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][500/647]    eta: 0:00:04  time: 0.0296  data_time: 0.0009  memory: 1333  \n",
      "03/07 09:31:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][600/647]    eta: 0:00:01  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "[0]\n",
      "[7]\n",
      "[2]\n",
      "[14]\n",
      "[20]\n",
      "[2]\n",
      "[4]\n",
      "[4]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[3]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[14]\n",
      "[4]\n",
      "[17]\n",
      "[20]\n",
      "[3]\n",
      "[20]\n",
      "[21]\n",
      "[4]\n",
      "[13]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[9]\n",
      "[13]\n",
      "[22]\n",
      "[23]\n",
      "[13]\n",
      "[17]\n",
      "[28]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[21]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n",
      "[17]\n",
      "[14]\n",
      "[4]\n",
      "[5]\n",
      "[13]\n",
      "[20]\n",
      "[17]\n",
      "[9]\n",
      "[17]\n",
      "[17]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[20]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[20]\n",
      "[4]\n",
      "[5]\n",
      "[5]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[4]\n",
      "[22]\n",
      "[4]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[21]\n",
      "[25]\n",
      "[20]\n",
      "[4]\n",
      "[21]\n",
      "[22]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[20]\n",
      "[22]\n",
      "[23]\n",
      "[25]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[25]\n",
      "[4]\n",
      "[4]\n",
      "[26]\n",
      "[42]\n",
      "[31]\n",
      "[31]\n",
      "[19]\n",
      "[31]\n",
      "[30]\n",
      "[30]\n",
      "[29]\n",
      "[31]\n",
      "[42]\n",
      "[19]\n",
      "[30]\n",
      "[31]\n",
      "[93]\n",
      "[31]\n",
      "[31]\n",
      "[13]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[19]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[27]\n",
      "[19]\n",
      "[42]\n",
      "[38]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[28]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[32]\n",
      "[32]\n",
      "[32]\n",
      "[34]\n",
      "[19]\n",
      "[35]\n",
      "[34]\n",
      "[34]\n",
      "[43]\n",
      "[32]\n",
      "[32]\n",
      "[57]\n",
      "[57]\n",
      "[52]\n",
      "[55]\n",
      "[59]\n",
      "[45]\n",
      "[9]\n",
      "[10]\n",
      "[10]\n",
      "[55]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[55]\n",
      "[52]\n",
      "[52]\n",
      "[55]\n",
      "[52]\n",
      "[9]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[9]\n",
      "[54]\n",
      "[54]\n",
      "[15]\n",
      "[9]\n",
      "[9]\n",
      "[57]\n",
      "[9]\n",
      "[48]\n",
      "[57]\n",
      "[57]\n",
      "[55]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[10]\n",
      "[52]\n",
      "[52]\n",
      "[55]\n",
      "[55]\n",
      "[59]\n",
      "[45]\n",
      "[59]\n",
      "[45]\n",
      "[55]\n",
      "[59]\n",
      "[52]\n",
      "[16]\n",
      "[55]\n",
      "[52]\n",
      "[10]\n",
      "[10]\n",
      "[45]\n",
      "[52]\n",
      "[10]\n",
      "[45]\n",
      "[15]\n",
      "[52]\n",
      "[52]\n",
      "[45]\n",
      "[56]\n",
      "[57]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[45]\n",
      "[56]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[45]\n",
      "[44]\n",
      "[57]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[56]\n",
      "[57]\n",
      "[57]\n",
      "[48]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[63]\n",
      "[67]\n",
      "[63]\n",
      "[29]\n",
      "[29]\n",
      "[28]\n",
      "[70]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[63]\n",
      "[27]\n",
      "[69]\n",
      "[70]\n",
      "[29]\n",
      "[29]\n",
      "[29]\n",
      "[47]\n",
      "[47]\n",
      "[67]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[29]\n",
      "[29]\n",
      "[69]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[68]\n",
      "[70]\n",
      "[40]\n",
      "[69]\n",
      "[40]\n",
      "[69]\n",
      "[40]\n",
      "[40]\n",
      "[69]\n",
      "[70]\n",
      "[98]\n",
      "[44]\n",
      "[122]\n",
      "[71]\n",
      "[122]\n",
      "[44]\n",
      "[71]\n",
      "[121]\n",
      "[121]\n",
      "[122]\n",
      "[121]\n",
      "[44]\n",
      "[44]\n",
      "[51]\n",
      "[121]\n",
      "[98]\n",
      "[71]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[122]\n",
      "[111]\n",
      "[110]\n",
      "[110]\n",
      "[98]\n",
      "[49]\n",
      "[51]\n",
      "[51]\n",
      "[51]\n",
      "[71]\n",
      "[51]\n",
      "[51]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[98]\n",
      "[71]\n",
      "[71]\n",
      "[98]\n",
      "[98]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[80]\n",
      "[90]\n",
      "[73]\n",
      "[89]\n",
      "[80]\n",
      "[89]\n",
      "[77]\n",
      "[77]\n",
      "[72]\n",
      "[80]\n",
      "[82]\n",
      "[3]\n",
      "[82]\n",
      "[86]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[80]\n",
      "[89]\n",
      "[86]\n",
      "[89]\n",
      "[80]\n",
      "[80]\n",
      "[84]\n",
      "[87]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[3]\n",
      "[3]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[81]\n",
      "[84]\n",
      "[88]\n",
      "[78]\n",
      "[80]\n",
      "[80]\n",
      "[3]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[78]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[87]\n",
      "[80]\n",
      "[3]\n",
      "[84]\n",
      "[88]\n",
      "[79]\n",
      "[74]\n",
      "[73]\n",
      "[79]\n",
      "[79]\n",
      "[79]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[73]\n",
      "[84]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[87]\n",
      "[31]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[30]\n",
      "[71]\n",
      "[49]\n",
      "[49]\n",
      "[43]\n",
      "[14]\n",
      "[43]\n",
      "[40]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[101]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[100]\n",
      "[101]\n",
      "[103]\n",
      "[71]\n",
      "[103]\n",
      "[101]\n",
      "[103]\n",
      "[103]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[40]\n",
      "[101]\n",
      "[101]\n",
      "[102]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[101]\n",
      "[100]\n",
      "[101]\n",
      "[101]\n",
      "[92]\n",
      "[96]\n",
      "[96]\n",
      "[0]\n",
      "[79]\n",
      "[79]\n",
      "[0]\n",
      "[0]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[0]\n",
      "[96]\n",
      "[96]\n",
      "[0]\n",
      "[96]\n",
      "[97]\n",
      "[96]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[109]\n",
      "[71]\n",
      "[111]\n",
      "[71]\n",
      "[19]\n",
      "[95]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[98]\n",
      "[97]\n",
      "[98]\n",
      "[71]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[106]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[110]\n",
      "[106]\n",
      "[106]\n",
      "[111]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[111]\n",
      "[108]\n",
      "[80]\n",
      "[111]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[30]\n",
      "[111]\n",
      "[112]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[111]\n",
      "[109]\n",
      "[111]\n",
      "[109]\n",
      "03/07 09:31:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][647/647]    acc/top1: 0.1855  acc/top5: 0.5332  acc/mean1: 0.2366  data_time: 0.0009  time: 0.0295\n",
      "03/07 09:31:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_12.pth is removed\n",
      "03/07 09:31:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.1855 acc/top1 at 13 epoch is saved to best_acc_top1_epoch_13.pth.\n",
      "03/07 09:31:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:31:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 100/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:24:35  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 1.7503  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7503\n",
      "03/07 09:32:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 200/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:24:21  time: 0.1385  data_time: 0.0019  memory: 5847  loss: 1.5125  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5125\n",
      "03/07 09:32:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 300/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:24:07  time: 0.1382  data_time: 0.0019  memory: 5847  loss: 1.9431  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.9431\n",
      "03/07 09:32:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 400/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:23:54  time: 0.1386  data_time: 0.0022  memory: 5847  loss: 1.9006  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9006\n",
      "03/07 09:32:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 500/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:23:40  time: 0.1403  data_time: 0.0019  memory: 5847  loss: 1.9646  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9646\n",
      "03/07 09:33:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 600/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:23:26  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 1.8514  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8514\n",
      "03/07 09:33:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 700/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:23:12  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 2.3288  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3288\n",
      "03/07 09:33:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 800/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:22:58  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 2.0687  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0687\n",
      "03/07 09:33:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 900/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:22:44  time: 0.1386  data_time: 0.0021  memory: 5847  loss: 1.8948  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8948\n",
      "03/07 09:33:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1000/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:22:31  time: 0.1401  data_time: 0.0021  memory: 5847  loss: 1.3818  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3818\n",
      "03/07 09:34:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:34:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1100/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:22:17  time: 0.1393  data_time: 0.0019  memory: 5847  loss: 1.7689  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7689\n",
      "03/07 09:34:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1200/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:22:03  time: 0.1391  data_time: 0.0019  memory: 5847  loss: 2.5272  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.5272\n",
      "03/07 09:34:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1300/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:21:49  time: 0.1388  data_time: 0.0020  memory: 5847  loss: 2.0243  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0243\n",
      "03/07 09:34:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1400/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:21:35  time: 0.1372  data_time: 0.0020  memory: 5847  loss: 1.8300  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8300\n",
      "03/07 09:35:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1500/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:21:22  time: 0.1396  data_time: 0.0020  memory: 5847  loss: 2.2304  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2304\n",
      "03/07 09:35:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1600/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:21:08  time: 0.1391  data_time: 0.0020  memory: 5847  loss: 2.1051  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1051\n",
      "03/07 09:35:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1700/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:20:54  time: 0.1386  data_time: 0.0019  memory: 5847  loss: 1.9056  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9056\n",
      "03/07 09:35:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1800/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:20:40  time: 0.1394  data_time: 0.0018  memory: 5847  loss: 2.0271  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0271\n",
      "03/07 09:36:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1900/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:20:26  time: 0.1380  data_time: 0.0021  memory: 5847  loss: 1.7382  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7382\n",
      "03/07 09:36:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2000/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:20:12  time: 0.1393  data_time: 0.0020  memory: 5847  loss: 1.7888  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7888\n",
      "03/07 09:36:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:36:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2100/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:19:58  time: 0.1383  data_time: 0.0019  memory: 5847  loss: 1.7866  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7866\n",
      "03/07 09:36:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2200/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:19:45  time: 0.1397  data_time: 0.0019  memory: 5847  loss: 2.1472  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.1472\n",
      "03/07 09:36:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2300/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:19:31  time: 0.1405  data_time: 0.0020  memory: 5847  loss: 1.8675  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8675\n",
      "03/07 09:37:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2400/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:19:17  time: 0.1375  data_time: 0.0021  memory: 5847  loss: 1.7859  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7859\n",
      "03/07 09:37:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2500/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:19:03  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 1.6513  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6513\n",
      "03/07 09:37:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2600/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:18:49  time: 0.1378  data_time: 0.0020  memory: 5847  loss: 1.5433  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5433\n",
      "03/07 09:37:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2700/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:18:35  time: 0.1370  data_time: 0.0018  memory: 5847  loss: 2.1559  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1559\n",
      "03/07 09:38:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2800/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:18:21  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 1.4840  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4840\n",
      "03/07 09:38:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][2900/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:18:08  time: 0.1377  data_time: 0.0019  memory: 5847  loss: 1.7276  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7276\n",
      "03/07 09:38:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3000/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:17:54  time: 0.1400  data_time: 0.0020  memory: 5847  loss: 1.3730  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3730\n",
      "03/07 09:38:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:38:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3100/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:17:40  time: 0.1420  data_time: 0.0021  memory: 5847  loss: 1.8892  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8892\n",
      "03/07 09:39:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3200/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:17:26  time: 0.1382  data_time: 0.0022  memory: 5847  loss: 1.6477  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6477\n",
      "03/07 09:39:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3300/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:17:12  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 2.3511  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.3511\n",
      "03/07 09:39:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3400/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:16:58  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 1.8274  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8274\n",
      "03/07 09:39:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3500/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:16:45  time: 0.1405  data_time: 0.0021  memory: 5847  loss: 1.8834  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8834\n",
      "03/07 09:39:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3600/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:16:31  time: 0.1392  data_time: 0.0018  memory: 5847  loss: 1.8840  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8840\n",
      "03/07 09:40:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3700/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:16:17  time: 0.1377  data_time: 0.0019  memory: 5847  loss: 2.0607  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0607\n",
      "03/07 09:40:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3800/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:16:03  time: 0.1387  data_time: 0.0022  memory: 5847  loss: 1.4943  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.4943\n",
      "03/07 09:40:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][3900/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:15:49  time: 0.1386  data_time: 0.0022  memory: 5847  loss: 1.5397  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5397\n",
      "03/07 09:40:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4000/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:15:35  time: 0.1390  data_time: 0.0021  memory: 5847  loss: 1.8066  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8066\n",
      "03/07 09:41:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:41:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4100/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:15:22  time: 0.1390  data_time: 0.0020  memory: 5847  loss: 1.8966  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8966\n",
      "03/07 09:41:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4200/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:15:08  time: 0.1389  data_time: 0.0023  memory: 5847  loss: 1.6888  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6888\n",
      "03/07 09:41:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4300/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:14:54  time: 0.1373  data_time: 0.0019  memory: 5847  loss: 1.6868  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6868\n",
      "03/07 09:41:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4400/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:14:40  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 2.1755  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1755\n",
      "03/07 09:42:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4500/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:14:26  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 1.5873  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5873\n",
      "03/07 09:42:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4600/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:14:12  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 1.4803  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4803\n",
      "03/07 09:42:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4700/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:13:58  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 1.7286  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7286\n",
      "03/07 09:42:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4800/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:13:44  time: 0.1402  data_time: 0.0021  memory: 5847  loss: 1.9550  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9550\n",
      "03/07 09:42:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][4900/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:13:31  time: 0.1395  data_time: 0.0019  memory: 5847  loss: 1.6418  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6418\n",
      "03/07 09:43:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][5000/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:13:17  time: 0.1387  data_time: 0.0020  memory: 5847  loss: 2.2928  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.2928\n",
      "03/07 09:43:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:43:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][5100/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:13:03  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 1.6223  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6223\n",
      "03/07 09:43:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][5200/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:12:49  time: 0.1381  data_time: 0.0021  memory: 5847  loss: 1.5783  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5783\n",
      "03/07 09:43:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:43:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][5225/5225]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 2:12:46  time: 0.1356  data_time: 0.0020  memory: 5847  loss: 1.6731  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6731\n",
      "03/07 09:43:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][100/647]    eta: 0:00:16  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "03/07 09:43:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][200/647]    eta: 0:00:13  time: 0.0294  data_time: 0.0008  memory: 1333  \n",
      "03/07 09:43:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][300/647]    eta: 0:00:10  time: 0.0295  data_time: 0.0006  memory: 1333  \n",
      "03/07 09:43:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][400/647]    eta: 0:00:07  time: 0.0296  data_time: 0.0007  memory: 1333  \n",
      "03/07 09:43:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][500/647]    eta: 0:00:04  time: 0.0296  data_time: 0.0006  memory: 1333  \n",
      "03/07 09:44:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][600/647]    eta: 0:00:01  time: 0.0294  data_time: 0.0007  memory: 1333  \n",
      "[0]\n",
      "[1]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[17]\n",
      "[4]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[21]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[13]\n",
      "[17]\n",
      "[18]\n",
      "[14]\n",
      "[20]\n",
      "[20]\n",
      "[14]\n",
      "[1]\n",
      "[17]\n",
      "[3]\n",
      "[1]\n",
      "[20]\n",
      "[5]\n",
      "[1]\n",
      "[13]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[13]\n",
      "[17]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[7]\n",
      "[5]\n",
      "[1]\n",
      "[5]\n",
      "[1]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[13]\n",
      "[8]\n",
      "[17]\n",
      "[5]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[5]\n",
      "[13]\n",
      "[13]\n",
      "[11]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[5]\n",
      "[14]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[20]\n",
      "[4]\n",
      "[5]\n",
      "[5]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[5]\n",
      "[11]\n",
      "[21]\n",
      "[25]\n",
      "[20]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[22]\n",
      "[22]\n",
      "[25]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[25]\n",
      "[1]\n",
      "[1]\n",
      "[26]\n",
      "[42]\n",
      "[31]\n",
      "[63]\n",
      "[31]\n",
      "[63]\n",
      "[30]\n",
      "[30]\n",
      "[29]\n",
      "[31]\n",
      "[29]\n",
      "[115]\n",
      "[27]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[67]\n",
      "[13]\n",
      "[43]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[30]\n",
      "[30]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[33]\n",
      "[19]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[33]\n",
      "[19]\n",
      "[42]\n",
      "[38]\n",
      "[31]\n",
      "[31]\n",
      "[37]\n",
      "[62]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[16]\n",
      "[21]\n",
      "[21]\n",
      "[35]\n",
      "[19]\n",
      "[35]\n",
      "[97]\n",
      "[43]\n",
      "[35]\n",
      "[21]\n",
      "[32]\n",
      "[57]\n",
      "[57]\n",
      "[52]\n",
      "[44]\n",
      "[54]\n",
      "[54]\n",
      "[58]\n",
      "[52]\n",
      "[52]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[51]\n",
      "[57]\n",
      "[54]\n",
      "[54]\n",
      "[57]\n",
      "[51]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[54]\n",
      "[15]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[58]\n",
      "[52]\n",
      "[54]\n",
      "[44]\n",
      "[51]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[105]\n",
      "[54]\n",
      "[47]\n",
      "[16]\n",
      "[44]\n",
      "[52]\n",
      "[52]\n",
      "[58]\n",
      "[54]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[15]\n",
      "[52]\n",
      "[52]\n",
      "[47]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[44]\n",
      "[44]\n",
      "[59]\n",
      "[59]\n",
      "[44]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[44]\n",
      "[44]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[52]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[47]\n",
      "[44]\n",
      "[57]\n",
      "[44]\n",
      "[30]\n",
      "[67]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[63]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[28]\n",
      "[70]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[66]\n",
      "[67]\n",
      "[66]\n",
      "[53]\n",
      "[70]\n",
      "[29]\n",
      "[51]\n",
      "[29]\n",
      "[47]\n",
      "[47]\n",
      "[67]\n",
      "[70]\n",
      "[40]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[69]\n",
      "[70]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[53]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[40]\n",
      "[68]\n",
      "[40]\n",
      "[64]\n",
      "[69]\n",
      "[70]\n",
      "[98]\n",
      "[44]\n",
      "[98]\n",
      "[100]\n",
      "[122]\n",
      "[98]\n",
      "[100]\n",
      "[98]\n",
      "[110]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[121]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[121]\n",
      "[44]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[100]\n",
      "[98]\n",
      "[100]\n",
      "[44]\n",
      "[51]\n",
      "[100]\n",
      "[100]\n",
      "[51]\n",
      "[71]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[71]\n",
      "[71]\n",
      "[7]\n",
      "[97]\n",
      "[71]\n",
      "[98]\n",
      "[100]\n",
      "[52]\n",
      "[98]\n",
      "[98]\n",
      "[100]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[100]\n",
      "[72]\n",
      "[90]\n",
      "[73]\n",
      "[89]\n",
      "[80]\n",
      "[76]\n",
      "[77]\n",
      "[88]\n",
      "[76]\n",
      "[80]\n",
      "[82]\n",
      "[86]\n",
      "[90]\n",
      "[86]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[89]\n",
      "[76]\n",
      "[86]\n",
      "[88]\n",
      "[80]\n",
      "[80]\n",
      "[86]\n",
      "[87]\n",
      "[76]\n",
      "[82]\n",
      "[81]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[90]\n",
      "[81]\n",
      "[86]\n",
      "[88]\n",
      "[90]\n",
      "[80]\n",
      "[81]\n",
      "[73]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[80]\n",
      "[73]\n",
      "[90]\n",
      "[90]\n",
      "[72]\n",
      "[74]\n",
      "[73]\n",
      "[72]\n",
      "[79]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[73]\n",
      "[84]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[30]\n",
      "[87]\n",
      "[31]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[71]\n",
      "[100]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[71]\n",
      "[71]\n",
      "[49]\n",
      "[43]\n",
      "[15]\n",
      "[43]\n",
      "[40]\n",
      "[64]\n",
      "[101]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[101]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[100]\n",
      "[101]\n",
      "[103]\n",
      "[71]\n",
      "[103]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[40]\n",
      "[62]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[100]\n",
      "[100]\n",
      "[102]\n",
      "[101]\n",
      "[100]\n",
      "[102]\n",
      "[102]\n",
      "[100]\n",
      "[96]\n",
      "[96]\n",
      "[92]\n",
      "[96]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[104]\n",
      "[104]\n",
      "[104]\n",
      "[92]\n",
      "[96]\n",
      "[96]\n",
      "[1]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[1]\n",
      "[104]\n",
      "[104]\n",
      "[92]\n",
      "[92]\n",
      "[109]\n",
      "[107]\n",
      "[109]\n",
      "[71]\n",
      "[116]\n",
      "[100]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[97]\n",
      "[98]\n",
      "[97]\n",
      "[98]\n",
      "[97]\n",
      "[98]\n",
      "[98]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[74]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[110]\n",
      "[112]\n",
      "[108]\n",
      "[111]\n",
      "[109]\n",
      "[108]\n",
      "[111]\n",
      "[117]\n",
      "[117]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[117]\n",
      "[112]\n",
      "[111]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[111]\n",
      "[108]\n",
      "[109]\n",
      "[109]\n",
      "[107]\n",
      "[106]\n",
      "[107]\n",
      "03/07 09:44:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][647/647]    acc/top1: 0.1870  acc/top5: 0.5224  acc/mean1: 0.2499  data_time: 0.0009  time: 0.0295\n",
      "03/07 09:44:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_13.pth is removed\n",
      "03/07 09:44:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.1870 acc/top1 at 14 epoch is saved to best_acc_top1_epoch_14.pth.\n",
      "03/07 09:44:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 100/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:12:32  time: 0.1377  data_time: 0.0021  memory: 5847  loss: 1.8242  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.8242\n",
      "03/07 09:44:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 200/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:12:18  time: 0.1405  data_time: 0.0021  memory: 5847  loss: 2.1089  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1089\n",
      "03/07 09:44:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 300/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:12:04  time: 0.1409  data_time: 0.0019  memory: 5847  loss: 1.6665  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6665\n",
      "03/07 09:45:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 400/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:11:50  time: 0.1408  data_time: 0.0019  memory: 5847  loss: 1.8385  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8385\n",
      "03/07 09:45:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 500/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:11:36  time: 0.1375  data_time: 0.0021  memory: 5847  loss: 2.3030  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.3030\n",
      "03/07 09:45:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 600/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:11:23  time: 0.1376  data_time: 0.0021  memory: 5847  loss: 2.1617  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.1617\n",
      "03/07 09:45:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 700/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:11:09  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 1.5367  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5367\n",
      "03/07 09:45:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 800/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:10:55  time: 0.1392  data_time: 0.0020  memory: 5847  loss: 1.6572  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6572\n",
      "03/07 09:46:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:46:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 900/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:10:41  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 2.1839  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.1839\n",
      "03/07 09:46:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1000/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:10:27  time: 0.1370  data_time: 0.0019  memory: 5847  loss: 2.4921  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.4921\n",
      "03/07 09:46:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1100/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:10:13  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 1.4330  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4330\n",
      "03/07 09:46:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1200/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:09:59  time: 0.1392  data_time: 0.0021  memory: 5847  loss: 1.5550  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5550\n",
      "03/07 09:47:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1300/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:09:45  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 1.7134  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7134\n",
      "03/07 09:47:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1400/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:09:32  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 1.8497  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8497\n",
      "03/07 09:47:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1500/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:09:18  time: 0.1370  data_time: 0.0020  memory: 5847  loss: 2.0793  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.0793\n",
      "03/07 09:47:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1600/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:09:04  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 1.8084  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8084\n",
      "03/07 09:48:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1700/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:08:50  time: 0.1372  data_time: 0.0020  memory: 5847  loss: 1.9839  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9839\n",
      "03/07 09:48:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1800/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:08:36  time: 0.1373  data_time: 0.0021  memory: 5847  loss: 1.6425  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6425\n",
      "03/07 09:48:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:48:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1900/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:08:22  time: 0.1383  data_time: 0.0022  memory: 5847  loss: 1.6924  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6924\n",
      "03/07 09:48:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2000/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:08:08  time: 0.1396  data_time: 0.0020  memory: 5847  loss: 1.4789  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4789\n",
      "03/07 09:48:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2100/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:07:55  time: 0.1386  data_time: 0.0020  memory: 5847  loss: 1.5800  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5800\n",
      "03/07 09:49:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2200/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:07:41  time: 0.1372  data_time: 0.0020  memory: 5847  loss: 1.6917  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6917\n",
      "03/07 09:49:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2300/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:07:27  time: 0.1383  data_time: 0.0022  memory: 5847  loss: 1.7932  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7932\n",
      "03/07 09:49:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2400/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:07:13  time: 0.1383  data_time: 0.0019  memory: 5847  loss: 1.6202  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6202\n",
      "03/07 09:49:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2500/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:06:59  time: 0.1384  data_time: 0.0021  memory: 5847  loss: 1.7553  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7553\n",
      "03/07 09:50:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2600/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:06:45  time: 0.1382  data_time: 0.0019  memory: 5847  loss: 1.9043  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9043\n",
      "03/07 09:50:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2700/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:06:31  time: 0.1391  data_time: 0.0019  memory: 5847  loss: 1.7481  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7481\n",
      "03/07 09:50:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2800/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:06:17  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 1.5278  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5278\n",
      "03/07 09:50:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:50:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][2900/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:06:04  time: 0.1393  data_time: 0.0018  memory: 5847  loss: 1.4821  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4821\n",
      "03/07 09:51:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3000/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:05:50  time: 0.1399  data_time: 0.0020  memory: 5847  loss: 1.9895  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.9895\n",
      "03/07 09:51:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3100/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:05:36  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.5234  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5234\n",
      "03/07 09:51:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3200/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:05:22  time: 0.1387  data_time: 0.0020  memory: 5847  loss: 2.0077  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0077\n",
      "03/07 09:51:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3300/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:05:08  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 1.7386  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7386\n",
      "03/07 09:51:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3400/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:04:54  time: 0.1376  data_time: 0.0018  memory: 5847  loss: 1.6992  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6992\n",
      "03/07 09:52:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3500/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:04:41  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 2.3643  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.3643\n",
      "03/07 09:52:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3600/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:04:27  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 1.8296  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8296\n",
      "03/07 09:52:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3700/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:04:13  time: 0.1380  data_time: 0.0019  memory: 5847  loss: 1.3392  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.3392\n",
      "03/07 09:52:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3800/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:03:59  time: 0.1405  data_time: 0.0021  memory: 5847  loss: 1.5739  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5739\n",
      "03/07 09:52:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:53:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][3900/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:03:45  time: 0.1384  data_time: 0.0021  memory: 5847  loss: 1.6248  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6248\n",
      "03/07 09:53:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4000/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:03:31  time: 0.1384  data_time: 0.0021  memory: 5847  loss: 1.6815  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6815\n",
      "03/07 09:53:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4100/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:03:17  time: 0.1387  data_time: 0.0021  memory: 5847  loss: 1.7530  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7530\n",
      "03/07 09:53:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4200/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:03:03  time: 0.1386  data_time: 0.0021  memory: 5847  loss: 1.7806  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.7806\n",
      "03/07 09:54:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4300/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:02:50  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 1.4499  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4499\n",
      "03/07 09:54:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4400/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:02:36  time: 0.1389  data_time: 0.0018  memory: 5847  loss: 1.4919  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4919\n",
      "03/07 09:54:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4500/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:02:22  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 1.4585  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4585\n",
      "03/07 09:54:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4600/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:02:08  time: 0.1388  data_time: 0.0019  memory: 5847  loss: 1.8951  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8951\n",
      "03/07 09:54:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4700/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:01:54  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 1.4764  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4764\n",
      "03/07 09:55:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4800/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:01:40  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 1.8462  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.8462\n",
      "03/07 09:55:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:55:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][4900/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:01:26  time: 0.1394  data_time: 0.0020  memory: 5847  loss: 1.7450  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7450\n",
      "03/07 09:55:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][5000/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:01:12  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 2.2149  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.2149\n",
      "03/07 09:55:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][5100/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:00:59  time: 0.1375  data_time: 0.0020  memory: 5847  loss: 1.8101  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8101\n",
      "03/07 09:56:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][5200/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:00:45  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 1.5762  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5762\n",
      "03/07 09:56:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:56:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][5225/5225]  base_lr: 6.9033e-05 lr: 6.9033e-06  eta: 2:00:41  time: 0.1352  data_time: 0.0021  memory: 5847  loss: 1.7458  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7458\n",
      "03/07 09:56:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 15 epochs\n",
      "03/07 09:56:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][100/647]    eta: 0:00:16  time: 0.0294  data_time: 0.0008  memory: 1333  \n",
      "03/07 09:56:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][200/647]    eta: 0:00:13  time: 0.0293  data_time: 0.0008  memory: 1333  \n",
      "03/07 09:56:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][300/647]    eta: 0:00:10  time: 0.0294  data_time: 0.0008  memory: 1333  \n",
      "03/07 09:56:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][400/647]    eta: 0:00:07  time: 0.0295  data_time: 0.0006  memory: 1333  \n",
      "03/07 09:56:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][500/647]    eta: 0:00:04  time: 0.0296  data_time: 0.0009  memory: 1333  \n",
      "03/07 09:56:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][600/647]    eta: 0:00:01  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[3]\n",
      "[4]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[22]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[13]\n",
      "[17]\n",
      "[18]\n",
      "[14]\n",
      "[14]\n",
      "[3]\n",
      "[14]\n",
      "[3]\n",
      "[14]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[21]\n",
      "[3]\n",
      "[13]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[22]\n",
      "[23]\n",
      "[13]\n",
      "[11]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[20]\n",
      "[21]\n",
      "[4]\n",
      "[21]\n",
      "[3]\n",
      "[11]\n",
      "[14]\n",
      "[13]\n",
      "[21]\n",
      "[13]\n",
      "[3]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[11]\n",
      "[18]\n",
      "[20]\n",
      "[13]\n",
      "[14]\n",
      "[0]\n",
      "[3]\n",
      "[2]\n",
      "[23]\n",
      "[4]\n",
      "[21]\n",
      "[22]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[23]\n",
      "[22]\n",
      "[22]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[21]\n",
      "[11]\n",
      "[23]\n",
      "[4]\n",
      "[21]\n",
      "[22]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[22]\n",
      "[23]\n",
      "[23]\n",
      "[24]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[25]\n",
      "[23]\n",
      "[23]\n",
      "[16]\n",
      "[42]\n",
      "[27]\n",
      "[27]\n",
      "[116]\n",
      "[27]\n",
      "[27]\n",
      "[13]\n",
      "[13]\n",
      "[5]\n",
      "[29]\n",
      "[115]\n",
      "[27]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[63]\n",
      "[13]\n",
      "[32]\n",
      "[32]\n",
      "[41]\n",
      "[43]\n",
      "[27]\n",
      "[13]\n",
      "[41]\n",
      "[41]\n",
      "[35]\n",
      "[19]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[41]\n",
      "[43]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[111]\n",
      "[41]\n",
      "[27]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[27]\n",
      "[41]\n",
      "[35]\n",
      "[38]\n",
      "[35]\n",
      "[35]\n",
      "[36]\n",
      "[27]\n",
      "[19]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[12]\n",
      "[11]\n",
      "[11]\n",
      "[34]\n",
      "[12]\n",
      "[11]\n",
      "[16]\n",
      "[34]\n",
      "[35]\n",
      "[12]\n",
      "[12]\n",
      "[57]\n",
      "[52]\n",
      "[52]\n",
      "[55]\n",
      "[59]\n",
      "[59]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[55]\n",
      "[52]\n",
      "[52]\n",
      "[51]\n",
      "[58]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[56]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[10]\n",
      "[10]\n",
      "[52]\n",
      "[10]\n",
      "[10]\n",
      "[10]\n",
      "[54]\n",
      "[54]\n",
      "[51]\n",
      "[58]\n",
      "[10]\n",
      "[10]\n",
      "[10]\n",
      "[59]\n",
      "[10]\n",
      "[10]\n",
      "[54]\n",
      "[10]\n",
      "[57]\n",
      "[10]\n",
      "[47]\n",
      "[52]\n",
      "[52]\n",
      "[105]\n",
      "[108]\n",
      "[54]\n",
      "[59]\n",
      "[59]\n",
      "[54]\n",
      "[55]\n",
      "[59]\n",
      "[52]\n",
      "[15]\n",
      "[55]\n",
      "[52]\n",
      "[59]\n",
      "[58]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[10]\n",
      "[52]\n",
      "[52]\n",
      "[47]\n",
      "[56]\n",
      "[57]\n",
      "[56]\n",
      "[45]\n",
      "[45]\n",
      "[59]\n",
      "[59]\n",
      "[45]\n",
      "[56]\n",
      "[59]\n",
      "[59]\n",
      "[45]\n",
      "[45]\n",
      "[57]\n",
      "[56]\n",
      "[58]\n",
      "[12]\n",
      "[59]\n",
      "[52]\n",
      "[58]\n",
      "[53]\n",
      "[47]\n",
      "[45]\n",
      "[57]\n",
      "[45]\n",
      "[30]\n",
      "[67]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[63]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[28]\n",
      "[70]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[66]\n",
      "[67]\n",
      "[27]\n",
      "[68]\n",
      "[70]\n",
      "[29]\n",
      "[28]\n",
      "[29]\n",
      "[47]\n",
      "[67]\n",
      "[67]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[67]\n",
      "[29]\n",
      "[69]\n",
      "[28]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[68]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[68]\n",
      "[68]\n",
      "[40]\n",
      "[67]\n",
      "[69]\n",
      "[28]\n",
      "[98]\n",
      "[44]\n",
      "[122]\n",
      "[100]\n",
      "[122]\n",
      "[122]\n",
      "[99]\n",
      "[99]\n",
      "[110]\n",
      "[15]\n",
      "[122]\n",
      "[122]\n",
      "[44]\n",
      "[53]\n",
      "[121]\n",
      "[98]\n",
      "[99]\n",
      "[121]\n",
      "[121]\n",
      "[51]\n",
      "[122]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[100]\n",
      "[99]\n",
      "[48]\n",
      "[44]\n",
      "[51]\n",
      "[100]\n",
      "[52]\n",
      "[52]\n",
      "[53]\n",
      "[98]\n",
      "[98]\n",
      "[52]\n",
      "[71]\n",
      "[100]\n",
      "[52]\n",
      "[97]\n",
      "[100]\n",
      "[98]\n",
      "[99]\n",
      "[52]\n",
      "[98]\n",
      "[98]\n",
      "[12]\n",
      "[52]\n",
      "[52]\n",
      "[53]\n",
      "[98]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[100]\n",
      "[75]\n",
      "[90]\n",
      "[73]\n",
      "[89]\n",
      "[75]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[89]\n",
      "[76]\n",
      "[86]\n",
      "[88]\n",
      "[80]\n",
      "[80]\n",
      "[83]\n",
      "[87]\n",
      "[75]\n",
      "[81]\n",
      "[81]\n",
      "[88]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[88]\n",
      "[81]\n",
      "[86]\n",
      "[88]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[73]\n",
      "[75]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[80]\n",
      "[73]\n",
      "[83]\n",
      "[90]\n",
      "[75]\n",
      "[74]\n",
      "[73]\n",
      "[75]\n",
      "[79]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[73]\n",
      "[87]\n",
      "[74]\n",
      "[75]\n",
      "[76]\n",
      "[73]\n",
      "[83]\n",
      "[88]\n",
      "[78]\n",
      "[91]\n",
      "[30]\n",
      "[91]\n",
      "[30]\n",
      "[87]\n",
      "[31]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[71]\n",
      "[30]\n",
      "[30]\n",
      "[83]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[71]\n",
      "[49]\n",
      "[49]\n",
      "[83]\n",
      "[14]\n",
      "[84]\n",
      "[40]\n",
      "[101]\n",
      "[102]\n",
      "[102]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[71]\n",
      "[102]\n",
      "[40]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[99]\n",
      "[71]\n",
      "[102]\n",
      "[62]\n",
      "[102]\n",
      "[40]\n",
      "[62]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[100]\n",
      "[92]\n",
      "[102]\n",
      "[92]\n",
      "[92]\n",
      "[102]\n",
      "[102]\n",
      "[92]\n",
      "[96]\n",
      "[97]\n",
      "[1]\n",
      "[79]\n",
      "[96]\n",
      "[1]\n",
      "[1]\n",
      "[92]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[0]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[96]\n",
      "[104]\n",
      "[104]\n",
      "[92]\n",
      "[92]\n",
      "[109]\n",
      "[97]\n",
      "[109]\n",
      "[71]\n",
      "[71]\n",
      "[83]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[95]\n",
      "[95]\n",
      "[97]\n",
      "[95]\n",
      "[95]\n",
      "[106]\n",
      "[105]\n",
      "[108]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[106]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[110]\n",
      "[112]\n",
      "[108]\n",
      "[111]\n",
      "[109]\n",
      "[108]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[111]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[111]\n",
      "[106]\n",
      "[107]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[111]\n",
      "[107]\n",
      "[100]\n",
      "[109]\n",
      "03/07 09:56:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][647/647]    acc/top1: 0.1808  acc/top5: 0.5564  acc/mean1: 0.2285  data_time: 0.0009  time: 0.0296\n",
      "03/07 09:56:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 100/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:00:27  time: 0.1394  data_time: 0.0020  memory: 5847  loss: 1.5077  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5077\n",
      "03/07 09:56:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 200/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:00:14  time: 0.1393  data_time: 0.0021  memory: 5847  loss: 1.9840  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9840\n",
      "03/07 09:57:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 300/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 2:00:00  time: 0.1373  data_time: 0.0020  memory: 5847  loss: 1.4516  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4516\n",
      "03/07 09:57:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 400/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:59:46  time: 0.1367  data_time: 0.0020  memory: 5847  loss: 2.0554  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0554\n",
      "03/07 09:57:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 500/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:59:32  time: 0.1392  data_time: 0.0019  memory: 5847  loss: 1.6067  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6067\n",
      "03/07 09:57:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 600/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:59:18  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 1.8725  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8725\n",
      "03/07 09:57:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 09:58:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 700/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:59:05  time: 0.1395  data_time: 0.0020  memory: 5847  loss: 1.6235  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6235\n",
      "03/07 09:58:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 800/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:58:51  time: 0.1374  data_time: 0.0018  memory: 5847  loss: 1.3832  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3832\n",
      "03/07 09:58:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 900/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:58:37  time: 0.1392  data_time: 0.0020  memory: 5847  loss: 1.4940  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4940\n",
      "03/07 09:58:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1000/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:58:23  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 1.9797  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9797\n",
      "03/07 09:59:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1100/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:58:09  time: 0.1376  data_time: 0.0021  memory: 5847  loss: 1.7614  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7614\n",
      "03/07 09:59:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1200/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:57:55  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 1.7797  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7797\n",
      "03/07 09:59:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1300/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:57:41  time: 0.1397  data_time: 0.0021  memory: 5847  loss: 1.3119  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3119\n",
      "03/07 09:59:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1400/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:57:28  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 1.6237  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6237\n",
      "03/07 09:59:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1500/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:57:14  time: 0.1399  data_time: 0.0020  memory: 5847  loss: 1.9148  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9148\n",
      "03/07 10:00:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1600/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:57:00  time: 0.1374  data_time: 0.0021  memory: 5847  loss: 2.0414  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0414\n",
      "03/07 10:00:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:00:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1700/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:56:46  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 1.7818  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7818\n",
      "03/07 10:00:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1800/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:56:32  time: 0.1384  data_time: 0.0020  memory: 5847  loss: 2.0505  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0505\n",
      "03/07 10:00:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1900/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:56:18  time: 0.1389  data_time: 0.0019  memory: 5847  loss: 1.8077  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8077\n",
      "03/07 10:01:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2000/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:56:04  time: 0.1386  data_time: 0.0019  memory: 5847  loss: 2.0361  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0361\n",
      "03/07 10:01:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2100/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:55:51  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.7179  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.7179\n",
      "03/07 10:01:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2200/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:55:37  time: 0.1383  data_time: 0.0019  memory: 5847  loss: 1.9513  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.9513\n",
      "03/07 10:01:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2300/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:55:23  time: 0.1377  data_time: 0.0022  memory: 5847  loss: 1.6190  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6190\n",
      "03/07 10:02:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2400/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:55:09  time: 0.1379  data_time: 0.0021  memory: 5847  loss: 1.7364  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7364\n",
      "03/07 10:02:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2500/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:54:55  time: 0.1385  data_time: 0.0019  memory: 5847  loss: 1.9443  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9443\n",
      "03/07 10:02:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2600/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:54:41  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 1.9394  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9394\n",
      "03/07 10:02:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:02:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2700/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:54:27  time: 0.1393  data_time: 0.0018  memory: 5847  loss: 2.0545  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.0545\n",
      "03/07 10:02:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2800/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:54:14  time: 0.1387  data_time: 0.0020  memory: 5847  loss: 1.7430  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7430\n",
      "03/07 10:03:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][2900/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:54:00  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.9356  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9356\n",
      "03/07 10:03:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3000/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:53:46  time: 0.1386  data_time: 0.0021  memory: 5847  loss: 1.6931  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6931\n",
      "03/07 10:03:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3100/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:53:32  time: 0.1377  data_time: 0.0021  memory: 5847  loss: 1.6314  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6314\n",
      "03/07 10:03:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3200/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:53:18  time: 0.1397  data_time: 0.0018  memory: 5847  loss: 1.5304  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5304\n",
      "03/07 10:04:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3300/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:53:04  time: 0.1372  data_time: 0.0020  memory: 5847  loss: 1.4597  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4597\n",
      "03/07 10:04:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3400/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:52:50  time: 0.1377  data_time: 0.0022  memory: 5847  loss: 1.7611  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7611\n",
      "03/07 10:04:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3500/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:52:37  time: 0.1400  data_time: 0.0020  memory: 5847  loss: 1.5870  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5870\n",
      "03/07 10:04:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3600/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:52:23  time: 0.1389  data_time: 0.0019  memory: 5847  loss: 1.8597  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8597\n",
      "03/07 10:04:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:05:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3700/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:52:09  time: 0.1395  data_time: 0.0020  memory: 5847  loss: 1.5543  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5543\n",
      "03/07 10:05:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3800/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:51:55  time: 0.1386  data_time: 0.0020  memory: 5847  loss: 1.6365  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6365\n",
      "03/07 10:05:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][3900/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:51:41  time: 0.1398  data_time: 0.0021  memory: 5847  loss: 1.8371  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.8371\n",
      "03/07 10:05:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4000/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:51:27  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 1.5050  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5050\n",
      "03/07 10:05:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4100/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:51:13  time: 0.1381  data_time: 0.0023  memory: 5847  loss: 1.1812  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1812\n",
      "03/07 10:06:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4200/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:51:00  time: 0.1371  data_time: 0.0019  memory: 5847  loss: 1.6126  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.6126\n",
      "03/07 10:06:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4300/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:50:46  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 1.2769  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2769\n",
      "03/07 10:06:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4400/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:50:32  time: 0.1378  data_time: 0.0020  memory: 5847  loss: 1.5282  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5282\n",
      "03/07 10:06:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4500/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:50:18  time: 0.1386  data_time: 0.0020  memory: 5847  loss: 1.7282  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.7282\n",
      "03/07 10:07:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4600/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:50:04  time: 0.1384  data_time: 0.0020  memory: 5847  loss: 1.8536  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8536\n",
      "03/07 10:07:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:07:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4700/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:49:50  time: 0.1395  data_time: 0.0021  memory: 5847  loss: 1.6803  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6803\n",
      "03/07 10:07:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4800/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:49:36  time: 0.1386  data_time: 0.0022  memory: 5847  loss: 1.3922  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3922\n",
      "03/07 10:07:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][4900/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:49:23  time: 0.1375  data_time: 0.0020  memory: 5847  loss: 1.1126  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1126\n",
      "03/07 10:08:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][5000/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:49:09  time: 0.1374  data_time: 0.0019  memory: 5847  loss: 1.8951  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8951\n",
      "03/07 10:08:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][5100/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:48:55  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 1.3245  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3245\n",
      "03/07 10:08:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][5200/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:48:41  time: 0.1382  data_time: 0.0022  memory: 5847  loss: 1.3786  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3786\n",
      "03/07 10:08:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:08:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][5225/5225]  base_lr: 6.2500e-05 lr: 6.2500e-06  eta: 1:48:37  time: 0.1365  data_time: 0.0021  memory: 5847  loss: 2.3410  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.3410\n",
      "03/07 10:08:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][100/647]    eta: 0:00:16  time: 0.0296  data_time: 0.0010  memory: 1333  \n",
      "03/07 10:08:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][200/647]    eta: 0:00:13  time: 0.0295  data_time: 0.0007  memory: 1333  \n",
      "03/07 10:08:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][300/647]    eta: 0:00:10  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 10:08:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][400/647]    eta: 0:00:07  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "03/07 10:08:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][500/647]    eta: 0:00:04  time: 0.0296  data_time: 0.0010  memory: 1333  \n",
      "03/07 10:08:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][600/647]    eta: 0:00:01  time: 0.0295  data_time: 0.0008  memory: 1333  \n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[14]\n",
      "[14]\n",
      "[2]\n",
      "[20]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[14]\n",
      "[11]\n",
      "[2]\n",
      "[6]\n",
      "[17]\n",
      "[18]\n",
      "[11]\n",
      "[2]\n",
      "[20]\n",
      "[0]\n",
      "[0]\n",
      "[2]\n",
      "[3]\n",
      "[3]\n",
      "[20]\n",
      "[5]\n",
      "[3]\n",
      "[12]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[9]\n",
      "[9]\n",
      "[14]\n",
      "[22]\n",
      "[14]\n",
      "[9]\n",
      "[9]\n",
      "[14]\n",
      "[2]\n",
      "[17]\n",
      "[2]\n",
      "[5]\n",
      "[20]\n",
      "[9]\n",
      "[20]\n",
      "[2]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[12]\n",
      "[20]\n",
      "[9]\n",
      "[9]\n",
      "[11]\n",
      "[11]\n",
      "[9]\n",
      "[12]\n",
      "[13]\n",
      "[13]\n",
      "[11]\n",
      "[2]\n",
      "[14]\n",
      "[2]\n",
      "[18]\n",
      "[18]\n",
      "[2]\n",
      "[20]\n",
      "[0]\n",
      "[3]\n",
      "[2]\n",
      "[26]\n",
      "[20]\n",
      "[5]\n",
      "[22]\n",
      "[5]\n",
      "[9]\n",
      "[11]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[25]\n",
      "[5]\n",
      "[5]\n",
      "[2]\n",
      "[100]\n",
      "[2]\n",
      "[26]\n",
      "[20]\n",
      "[5]\n",
      "[22]\n",
      "[25]\n",
      "[11]\n",
      "[11]\n",
      "[6]\n",
      "[22]\n",
      "[22]\n",
      "[26]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[25]\n",
      "[22]\n",
      "[22]\n",
      "[26]\n",
      "[42]\n",
      "[31]\n",
      "[63]\n",
      "[19]\n",
      "[63]\n",
      "[30]\n",
      "[30]\n",
      "[29]\n",
      "[31]\n",
      "[29]\n",
      "[115]\n",
      "[27]\n",
      "[31]\n",
      "[93]\n",
      "[31]\n",
      "[67]\n",
      "[13]\n",
      "[17]\n",
      "[42]\n",
      "[42]\n",
      "[43]\n",
      "[30]\n",
      "[30]\n",
      "[67]\n",
      "[42]\n",
      "[17]\n",
      "[19]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[65]\n",
      "[41]\n",
      "[42]\n",
      "[37]\n",
      "[19]\n",
      "[40]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[19]\n",
      "[41]\n",
      "[33]\n",
      "[65]\n",
      "[19]\n",
      "[35]\n",
      "[38]\n",
      "[35]\n",
      "[35]\n",
      "[37]\n",
      "[62]\n",
      "[19]\n",
      "[42]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[99]\n",
      "[34]\n",
      "[97]\n",
      "[34]\n",
      "[35]\n",
      "[20]\n",
      "[100]\n",
      "[57]\n",
      "[9]\n",
      "[52]\n",
      "[55]\n",
      "[59]\n",
      "[45]\n",
      "[47]\n",
      "[52]\n",
      "[52]\n",
      "[51]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[45]\n",
      "[45]\n",
      "[52]\n",
      "[56]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[52]\n",
      "[9]\n",
      "[45]\n",
      "[52]\n",
      "[52]\n",
      "[9]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[9]\n",
      "[45]\n",
      "[9]\n",
      "[48]\n",
      "[59]\n",
      "[9]\n",
      "[56]\n",
      "[48]\n",
      "[59]\n",
      "[52]\n",
      "[45]\n",
      "[105]\n",
      "[51]\n",
      "[46]\n",
      "[45]\n",
      "[59]\n",
      "[45]\n",
      "[55]\n",
      "[59]\n",
      "[46]\n",
      "[15]\n",
      "[55]\n",
      "[52]\n",
      "[59]\n",
      "[47]\n",
      "[45]\n",
      "[52]\n",
      "[52]\n",
      "[46]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[47]\n",
      "[45]\n",
      "[57]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[45]\n",
      "[56]\n",
      "[56]\n",
      "[45]\n",
      "[59]\n",
      "[45]\n",
      "[56]\n",
      "[57]\n",
      "[56]\n",
      "[48]\n",
      "[52]\n",
      "[45]\n",
      "[52]\n",
      "[48]\n",
      "[46]\n",
      "[45]\n",
      "[45]\n",
      "[56]\n",
      "[44]\n",
      "[30]\n",
      "[67]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[62]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[45]\n",
      "[70]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[67]\n",
      "[66]\n",
      "[68]\n",
      "[70]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[67]\n",
      "[67]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[67]\n",
      "[29]\n",
      "[69]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[68]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[68]\n",
      "[69]\n",
      "[68]\n",
      "[68]\n",
      "[69]\n",
      "[70]\n",
      "[99]\n",
      "[44]\n",
      "[15]\n",
      "[100]\n",
      "[122]\n",
      "[44]\n",
      "[99]\n",
      "[98]\n",
      "[110]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[98]\n",
      "[99]\n",
      "[98]\n",
      "[121]\n",
      "[44]\n",
      "[98]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[100]\n",
      "[99]\n",
      "[48]\n",
      "[52]\n",
      "[46]\n",
      "[100]\n",
      "[52]\n",
      "[52]\n",
      "[100]\n",
      "[98]\n",
      "[98]\n",
      "[52]\n",
      "[100]\n",
      "[100]\n",
      "[52]\n",
      "[97]\n",
      "[100]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[100]\n",
      "[97]\n",
      "[48]\n",
      "[52]\n",
      "[52]\n",
      "[48]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[100]\n",
      "[89]\n",
      "[90]\n",
      "[73]\n",
      "[89]\n",
      "[89]\n",
      "[89]\n",
      "[77]\n",
      "[77]\n",
      "[89]\n",
      "[89]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[89]\n",
      "[73]\n",
      "[89]\n",
      "[89]\n",
      "[72]\n",
      "[86]\n",
      "[87]\n",
      "[89]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[72]\n",
      "[80]\n",
      "[82]\n",
      "[77]\n",
      "[86]\n",
      "[88]\n",
      "[90]\n",
      "[74]\n",
      "[72]\n",
      "[73]\n",
      "[80]\n",
      "[72]\n",
      "[72]\n",
      "[82]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[80]\n",
      "[73]\n",
      "[78]\n",
      "[90]\n",
      "[75]\n",
      "[72]\n",
      "[73]\n",
      "[74]\n",
      "[79]\n",
      "[79]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[74]\n",
      "[77]\n",
      "[77]\n",
      "[73]\n",
      "[86]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[100]\n",
      "[100]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[30]\n",
      "[71]\n",
      "[99]\n",
      "[84]\n",
      "[97]\n",
      "[15]\n",
      "[97]\n",
      "[100]\n",
      "[96]\n",
      "[101]\n",
      "[101]\n",
      "[96]\n",
      "[96]\n",
      "[101]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[100]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[100]\n",
      "[103]\n",
      "[103]\n",
      "[100]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[102]\n",
      "[62]\n",
      "[102]\n",
      "[100]\n",
      "[96]\n",
      "[102]\n",
      "[102]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[100]\n",
      "[102]\n",
      "[92]\n",
      "[100]\n",
      "[96]\n",
      "[2]\n",
      "[2]\n",
      "[79]\n",
      "[79]\n",
      "[2]\n",
      "[2]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[79]\n",
      "[97]\n",
      "[96]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[109]\n",
      "[107]\n",
      "[107]\n",
      "[71]\n",
      "[97]\n",
      "[100]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[97]\n",
      "[100]\n",
      "[97]\n",
      "[96]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[112]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[112]\n",
      "[108]\n",
      "[111]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[37]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[106]\n",
      "[107]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[100]\n",
      "[110]\n",
      "[109]\n",
      "[107]\n",
      "[100]\n",
      "[107]\n",
      "03/07 10:08:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][647/647]    acc/top1: 0.1963  acc/top5: 0.5410  acc/mean1: 0.2478  data_time: 0.0009  time: 0.0296\n",
      "03/07 10:08:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_14.pth is removed\n",
      "03/07 10:08:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.1963 acc/top1 at 16 epoch is saved to best_acc_top1_epoch_16.pth.\n",
      "03/07 10:09:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 100/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:48:24  time: 0.1370  data_time: 0.0021  memory: 5847  loss: 1.9770  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.9770\n",
      "03/07 10:09:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 200/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:48:10  time: 0.1391  data_time: 0.0021  memory: 5847  loss: 1.8530  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8530\n",
      "03/07 10:09:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 300/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:47:56  time: 0.1381  data_time: 0.0021  memory: 5847  loss: 1.4827  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4827\n",
      "03/07 10:09:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:09:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 400/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:47:42  time: 0.1400  data_time: 0.0020  memory: 5847  loss: 1.8151  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8151\n",
      "03/07 10:10:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 500/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:47:28  time: 0.1372  data_time: 0.0020  memory: 5847  loss: 1.8771  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8771\n",
      "03/07 10:10:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 600/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:47:14  time: 0.1371  data_time: 0.0017  memory: 5847  loss: 2.0064  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 2.0064\n",
      "03/07 10:10:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 700/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:47:00  time: 0.1380  data_time: 0.0019  memory: 5847  loss: 2.0577  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0577\n",
      "03/07 10:10:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 800/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:46:47  time: 0.1381  data_time: 0.0019  memory: 5847  loss: 1.8020  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8020\n",
      "03/07 10:10:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 900/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:46:33  time: 0.1400  data_time: 0.0020  memory: 5847  loss: 1.8712  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8712\n",
      "03/07 10:11:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1000/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:46:19  time: 0.1415  data_time: 0.0021  memory: 5847  loss: 1.5287  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5287\n",
      "03/07 10:11:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1100/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:46:05  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 1.6570  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6570\n",
      "03/07 10:11:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1200/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:45:51  time: 0.1380  data_time: 0.0021  memory: 5847  loss: 1.5121  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5121\n",
      "03/07 10:11:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1300/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:45:37  time: 0.1377  data_time: 0.0021  memory: 5847  loss: 1.2103  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2103\n",
      "03/07 10:12:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:12:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1400/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:45:23  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.3276  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.3276\n",
      "03/07 10:12:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1500/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:45:10  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.9479  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9479\n",
      "03/07 10:12:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1600/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:44:56  time: 0.1389  data_time: 0.0020  memory: 5847  loss: 1.4612  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4612\n",
      "03/07 10:12:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1700/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:44:42  time: 0.1398  data_time: 0.0021  memory: 5847  loss: 1.6438  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6438\n",
      "03/07 10:13:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1800/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:44:28  time: 0.1388  data_time: 0.0022  memory: 5847  loss: 1.7252  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7252\n",
      "03/07 10:13:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1900/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:44:14  time: 0.1391  data_time: 0.0022  memory: 5847  loss: 1.0238  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.0238\n",
      "03/07 10:13:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2000/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:44:00  time: 0.1384  data_time: 0.0021  memory: 5847  loss: 1.6625  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6625\n",
      "03/07 10:13:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2100/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:43:46  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 1.4033  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4033\n",
      "03/07 10:13:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2200/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:43:32  time: 0.1388  data_time: 0.0020  memory: 5847  loss: 1.5550  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5550\n",
      "03/07 10:14:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2300/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:43:19  time: 0.1379  data_time: 0.0021  memory: 5847  loss: 1.6148  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6148\n",
      "03/07 10:14:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:14:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2400/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:43:05  time: 0.1381  data_time: 0.0021  memory: 5847  loss: 1.7354  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.7354\n",
      "03/07 10:14:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2500/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:42:51  time: 0.1409  data_time: 0.0021  memory: 5847  loss: 1.4790  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4790\n",
      "03/07 10:14:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2600/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:42:37  time: 0.1407  data_time: 0.0021  memory: 5847  loss: 1.1305  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.1305\n",
      "03/07 10:15:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2700/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:42:23  time: 0.1380  data_time: 0.0021  memory: 5847  loss: 1.9921  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9921\n",
      "03/07 10:15:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2800/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:42:09  time: 0.1374  data_time: 0.0021  memory: 5847  loss: 1.4944  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4944\n",
      "03/07 10:15:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][2900/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:41:56  time: 0.1392  data_time: 0.0021  memory: 5847  loss: 1.7558  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7558\n",
      "03/07 10:15:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3000/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:41:42  time: 0.1384  data_time: 0.0021  memory: 5847  loss: 1.7769  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7769\n",
      "03/07 10:16:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3100/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:41:28  time: 0.1398  data_time: 0.0019  memory: 5847  loss: 1.5376  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5376\n",
      "03/07 10:16:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3200/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:41:14  time: 0.1391  data_time: 0.0018  memory: 5847  loss: 1.5204  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5204\n",
      "03/07 10:16:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3300/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:41:00  time: 0.1385  data_time: 0.0019  memory: 5847  loss: 1.8451  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8451\n",
      "03/07 10:16:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:16:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3400/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:40:46  time: 0.1392  data_time: 0.0020  memory: 5847  loss: 1.6926  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6926\n",
      "03/07 10:17:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3500/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:40:33  time: 0.1389  data_time: 0.0021  memory: 5847  loss: 1.9337  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9337\n",
      "03/07 10:17:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3600/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:40:19  time: 0.1395  data_time: 0.0021  memory: 5847  loss: 1.3882  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3882\n",
      "03/07 10:17:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3700/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:40:05  time: 0.1400  data_time: 0.0021  memory: 5847  loss: 1.8306  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.8306\n",
      "03/07 10:17:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3800/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:39:51  time: 0.1385  data_time: 0.0022  memory: 5847  loss: 1.2911  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2911\n",
      "03/07 10:17:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][3900/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:39:37  time: 0.1383  data_time: 0.0021  memory: 5847  loss: 1.6984  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6984\n",
      "03/07 10:18:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4000/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:39:23  time: 0.1382  data_time: 0.0019  memory: 5847  loss: 1.7343  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7343\n",
      "03/07 10:18:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4100/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:39:09  time: 0.1375  data_time: 0.0022  memory: 5847  loss: 1.3945  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.3945\n",
      "03/07 10:18:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4200/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:38:56  time: 0.1390  data_time: 0.0021  memory: 5847  loss: 1.3446  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3446\n",
      "03/07 10:18:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4300/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:38:42  time: 0.1403  data_time: 0.0021  memory: 5847  loss: 1.7758  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7758\n",
      "03/07 10:19:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:19:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4400/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:38:28  time: 0.1379  data_time: 0.0021  memory: 5847  loss: 2.0866  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 2.0866\n",
      "03/07 10:19:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4500/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:38:14  time: 0.1393  data_time: 0.0021  memory: 5847  loss: 1.7908  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7908\n",
      "03/07 10:19:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4600/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:38:00  time: 0.1379  data_time: 0.0021  memory: 5847  loss: 1.7356  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7356\n",
      "03/07 10:19:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4700/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:37:46  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 1.5408  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5408\n",
      "03/07 10:20:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4800/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:37:33  time: 0.1381  data_time: 0.0022  memory: 5847  loss: 1.2491  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2491\n",
      "03/07 10:20:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][4900/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:37:19  time: 0.1375  data_time: 0.0020  memory: 5847  loss: 1.7824  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7824\n",
      "03/07 10:20:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][5000/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:37:05  time: 0.1389  data_time: 0.0021  memory: 5847  loss: 2.0480  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 2.0480\n",
      "03/07 10:20:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][5100/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:36:51  time: 0.1392  data_time: 0.0019  memory: 5847  loss: 1.9927  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.9927\n",
      "03/07 10:20:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][5200/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:36:37  time: 0.1409  data_time: 0.0020  memory: 5847  loss: 1.8907  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8907\n",
      "03/07 10:21:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:21:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][5225/5225]  base_lr: 5.5967e-05 lr: 5.5967e-06  eta: 1:36:34  time: 0.1369  data_time: 0.0019  memory: 5847  loss: 1.6494  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6494\n",
      "03/07 10:21:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][100/647]    eta: 0:00:16  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 10:21:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][200/647]    eta: 0:00:13  time: 0.0294  data_time: 0.0008  memory: 1333  \n",
      "03/07 10:21:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][300/647]    eta: 0:00:10  time: 0.0295  data_time: 0.0008  memory: 1333  \n",
      "03/07 10:21:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][400/647]    eta: 0:00:07  time: 0.0294  data_time: 0.0008  memory: 1333  \n",
      "03/07 10:21:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][500/647]    eta: 0:00:04  time: 0.0296  data_time: 0.0009  memory: 1333  \n",
      "03/07 10:21:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][600/647]    eta: 0:00:01  time: 0.0294  data_time: 0.0008  memory: 1333  \n",
      "[0]\n",
      "[1]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[11]\n",
      "[4]\n",
      "[5]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[22]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[17]\n",
      "[20]\n",
      "[13]\n",
      "[5]\n",
      "[4]\n",
      "[6]\n",
      "[4]\n",
      "[17]\n",
      "[3]\n",
      "[6]\n",
      "[4]\n",
      "[5]\n",
      "[3]\n",
      "[13]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[22]\n",
      "[23]\n",
      "[13]\n",
      "[9]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[5]\n",
      "[4]\n",
      "[9]\n",
      "[8]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[5]\n",
      "[13]\n",
      "[8]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[5]\n",
      "[13]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[23]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[5]\n",
      "[11]\n",
      "[11]\n",
      "[22]\n",
      "[22]\n",
      "[22]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[5]\n",
      "[5]\n",
      "[11]\n",
      "[21]\n",
      "[2]\n",
      "[26]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[6]\n",
      "[22]\n",
      "[22]\n",
      "[26]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[25]\n",
      "[6]\n",
      "[6]\n",
      "[16]\n",
      "[42]\n",
      "[27]\n",
      "[63]\n",
      "[31]\n",
      "[27]\n",
      "[27]\n",
      "[47]\n",
      "[29]\n",
      "[31]\n",
      "[8]\n",
      "[115]\n",
      "[27]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[35]\n",
      "[13]\n",
      "[35]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[27]\n",
      "[13]\n",
      "[41]\n",
      "[42]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[17]\n",
      "[19]\n",
      "[27]\n",
      "[19]\n",
      "[19]\n",
      "[41]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[41]\n",
      "[34]\n",
      "[27]\n",
      "[19]\n",
      "[35]\n",
      "[38]\n",
      "[35]\n",
      "[31]\n",
      "[37]\n",
      "[27]\n",
      "[19]\n",
      "[42]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[32]\n",
      "[32]\n",
      "[34]\n",
      "[34]\n",
      "[19]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[35]\n",
      "[43]\n",
      "[32]\n",
      "[57]\n",
      "[9]\n",
      "[52]\n",
      "[115]\n",
      "[52]\n",
      "[54]\n",
      "[58]\n",
      "[52]\n",
      "[52]\n",
      "[51]\n",
      "[52]\n",
      "[52]\n",
      "[51]\n",
      "[57]\n",
      "[54]\n",
      "[54]\n",
      "[9]\n",
      "[51]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[53]\n",
      "[9]\n",
      "[54]\n",
      "[53]\n",
      "[53]\n",
      "[9]\n",
      "[54]\n",
      "[54]\n",
      "[6]\n",
      "[48]\n",
      "[57]\n",
      "[57]\n",
      "[9]\n",
      "[54]\n",
      "[53]\n",
      "[57]\n",
      "[54]\n",
      "[9]\n",
      "[57]\n",
      "[57]\n",
      "[53]\n",
      "[52]\n",
      "[54]\n",
      "[105]\n",
      "[51]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[51]\n",
      "[54]\n",
      "[47]\n",
      "[15]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[53]\n",
      "[54]\n",
      "[52]\n",
      "[53]\n",
      "[54]\n",
      "[54]\n",
      "[52]\n",
      "[52]\n",
      "[47]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[54]\n",
      "[44]\n",
      "[56]\n",
      "[53]\n",
      "[53]\n",
      "[44]\n",
      "[44]\n",
      "[51]\n",
      "[56]\n",
      "[53]\n",
      "[54]\n",
      "[54]\n",
      "[52]\n",
      "[53]\n",
      "[53]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[30]\n",
      "[67]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[27]\n",
      "[70]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[40]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[69]\n",
      "[40]\n",
      "[67]\n",
      "[27]\n",
      "[40]\n",
      "[70]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[67]\n",
      "[67]\n",
      "[70]\n",
      "[40]\n",
      "[69]\n",
      "[69]\n",
      "[28]\n",
      "[51]\n",
      "[29]\n",
      "[69]\n",
      "[70]\n",
      "[70]\n",
      "[40]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[53]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[40]\n",
      "[40]\n",
      "[40]\n",
      "[67]\n",
      "[69]\n",
      "[70]\n",
      "[98]\n",
      "[44]\n",
      "[98]\n",
      "[100]\n",
      "[122]\n",
      "[98]\n",
      "[99]\n",
      "[99]\n",
      "[98]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[53]\n",
      "[98]\n",
      "[98]\n",
      "[99]\n",
      "[98]\n",
      "[121]\n",
      "[51]\n",
      "[98]\n",
      "[99]\n",
      "[98]\n",
      "[98]\n",
      "[100]\n",
      "[99]\n",
      "[48]\n",
      "[51]\n",
      "[51]\n",
      "[100]\n",
      "[51]\n",
      "[51]\n",
      "[100]\n",
      "[98]\n",
      "[98]\n",
      "[52]\n",
      "[100]\n",
      "[100]\n",
      "[8]\n",
      "[97]\n",
      "[100]\n",
      "[52]\n",
      "[8]\n",
      "[52]\n",
      "[98]\n",
      "[51]\n",
      "[8]\n",
      "[52]\n",
      "[51]\n",
      "[48]\n",
      "[98]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[72]\n",
      "[90]\n",
      "[73]\n",
      "[89]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[77]\n",
      "[72]\n",
      "[81]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[76]\n",
      "[86]\n",
      "[77]\n",
      "[74]\n",
      "[72]\n",
      "[86]\n",
      "[87]\n",
      "[75]\n",
      "[81]\n",
      "[81]\n",
      "[83]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[74]\n",
      "[80]\n",
      "[77]\n",
      "[77]\n",
      "[78]\n",
      "[78]\n",
      "[90]\n",
      "[74]\n",
      "[60]\n",
      "[73]\n",
      "[75]\n",
      "[72]\n",
      "[72]\n",
      "[82]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[87]\n",
      "[76]\n",
      "[73]\n",
      "[83]\n",
      "[90]\n",
      "[75]\n",
      "[74]\n",
      "[73]\n",
      "[75]\n",
      "[79]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[83]\n",
      "[78]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[87]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[30]\n",
      "[97]\n",
      "[99]\n",
      "[49]\n",
      "[96]\n",
      "[14]\n",
      "[97]\n",
      "[40]\n",
      "[96]\n",
      "[101]\n",
      "[101]\n",
      "[96]\n",
      "[96]\n",
      "[101]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[40]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[92]\n",
      "[101]\n",
      "[103]\n",
      "[40]\n",
      "[79]\n",
      "[79]\n",
      "[92]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[100]\n",
      "[102]\n",
      "[62]\n",
      "[102]\n",
      "[40]\n",
      "[96]\n",
      "[102]\n",
      "[102]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[62]\n",
      "[92]\n",
      "[92]\n",
      "[96]\n",
      "[97]\n",
      "[92]\n",
      "[79]\n",
      "[96]\n",
      "[99]\n",
      "[0]\n",
      "[92]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[0]\n",
      "[97]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[96]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[109]\n",
      "[97]\n",
      "[109]\n",
      "[99]\n",
      "[19]\n",
      "[100]\n",
      "[98]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[96]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[111]\n",
      "[105]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[74]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[108]\n",
      "[111]\n",
      "[109]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[108]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[30]\n",
      "[111]\n",
      "[112]\n",
      "[106]\n",
      "[106]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[112]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[100]\n",
      "[109]\n",
      "[111]\n",
      "[110]\n",
      "[100]\n",
      "[107]\n",
      "03/07 10:21:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][647/647]    acc/top1: 0.2133  acc/top5: 0.5595  acc/mean1: 0.2654  data_time: 0.0009  time: 0.0296\n",
      "03/07 10:21:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_16.pth is removed\n",
      "03/07 10:21:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.2133 acc/top1 at 17 epoch is saved to best_acc_top1_epoch_17.pth.\n",
      "03/07 10:21:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 100/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:36:20  time: 0.1392  data_time: 0.0021  memory: 5847  loss: 1.6401  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6401\n",
      "03/07 10:21:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:21:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 200/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:36:06  time: 0.1379  data_time: 0.0018  memory: 5847  loss: 1.9498  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9498\n",
      "03/07 10:22:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 300/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:35:52  time: 0.1395  data_time: 0.0021  memory: 5847  loss: 1.7693  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7693\n",
      "03/07 10:22:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 400/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:35:38  time: 0.1395  data_time: 0.0021  memory: 5847  loss: 1.3610  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3610\n",
      "03/07 10:22:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 500/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:35:25  time: 0.1396  data_time: 0.0020  memory: 5847  loss: 1.7234  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7234\n",
      "03/07 10:22:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 600/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:35:11  time: 0.1373  data_time: 0.0021  memory: 5847  loss: 1.2365  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2365\n",
      "03/07 10:22:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 700/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:34:57  time: 0.1384  data_time: 0.0020  memory: 5847  loss: 1.8680  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8680\n",
      "03/07 10:23:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 800/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:34:43  time: 0.1388  data_time: 0.0021  memory: 5847  loss: 1.7090  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7090\n",
      "03/07 10:23:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 900/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:34:29  time: 0.1405  data_time: 0.0021  memory: 5847  loss: 1.4192  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.4192\n",
      "03/07 10:23:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1000/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:34:15  time: 0.1373  data_time: 0.0020  memory: 5847  loss: 1.5592  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.5592\n",
      "03/07 10:23:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1100/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:34:01  time: 0.1378  data_time: 0.0019  memory: 5847  loss: 1.9125  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.9125\n",
      "03/07 10:24:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:24:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1200/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:33:48  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 1.2286  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2286\n",
      "03/07 10:24:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1300/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:33:34  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 2.0833  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.0833\n",
      "03/07 10:24:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1400/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:33:20  time: 0.1420  data_time: 0.0020  memory: 5847  loss: 1.7036  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7036\n",
      "03/07 10:24:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1500/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:33:06  time: 0.1379  data_time: 0.0021  memory: 5847  loss: 1.2723  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2723\n",
      "03/07 10:25:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1600/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:32:52  time: 0.1372  data_time: 0.0019  memory: 5847  loss: 1.7027  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7027\n",
      "03/07 10:25:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1700/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:32:38  time: 0.1370  data_time: 0.0021  memory: 5847  loss: 1.6392  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6392\n",
      "03/07 10:25:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1800/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:32:24  time: 0.1378  data_time: 0.0020  memory: 5847  loss: 1.6470  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6470\n",
      "03/07 10:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1900/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:32:10  time: 0.1386  data_time: 0.0022  memory: 5847  loss: 1.1404  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.1404\n",
      "03/07 10:25:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2000/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:31:57  time: 0.1387  data_time: 0.0021  memory: 5847  loss: 1.9023  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9023\n",
      "03/07 10:26:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2100/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:31:43  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 1.6568  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6568\n",
      "03/07 10:26:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:26:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2200/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:31:29  time: 0.1376  data_time: 0.0021  memory: 5847  loss: 1.5827  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5827\n",
      "03/07 10:26:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2300/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:31:15  time: 0.1393  data_time: 0.0021  memory: 5847  loss: 1.6217  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6217\n",
      "03/07 10:26:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2400/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:31:01  time: 0.1411  data_time: 0.0022  memory: 5847  loss: 1.4666  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4666\n",
      "03/07 10:27:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2500/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:30:47  time: 0.1389  data_time: 0.0020  memory: 5847  loss: 1.8021  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8021\n",
      "03/07 10:27:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2600/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:30:34  time: 0.1375  data_time: 0.0021  memory: 5847  loss: 1.0338  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0338\n",
      "03/07 10:27:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2700/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:30:20  time: 0.1400  data_time: 0.0021  memory: 5847  loss: 1.4567  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4567\n",
      "03/07 10:27:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2800/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:30:06  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 1.9269  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.9269\n",
      "03/07 10:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][2900/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:29:52  time: 0.1375  data_time: 0.0021  memory: 5847  loss: 1.4426  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4426\n",
      "03/07 10:28:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3000/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:29:38  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 1.7150  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7150\n",
      "03/07 10:28:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3100/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:29:24  time: 0.1391  data_time: 0.0020  memory: 5847  loss: 1.6421  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6421\n",
      "03/07 10:28:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:28:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3200/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:29:10  time: 0.1380  data_time: 0.0021  memory: 5847  loss: 1.8715  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8715\n",
      "03/07 10:28:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3300/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:28:57  time: 0.1392  data_time: 0.0021  memory: 5847  loss: 1.2279  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2279\n",
      "03/07 10:29:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3400/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:28:43  time: 0.1387  data_time: 0.0021  memory: 5847  loss: 1.7232  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7232\n",
      "03/07 10:29:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3500/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:28:29  time: 0.1391  data_time: 0.0019  memory: 5847  loss: 1.7278  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7278\n",
      "03/07 10:29:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3600/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:28:15  time: 0.1388  data_time: 0.0019  memory: 5847  loss: 1.9217  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.9217\n",
      "03/07 10:29:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3700/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:28:01  time: 0.1378  data_time: 0.0020  memory: 5847  loss: 1.4044  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4044\n",
      "03/07 10:30:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3800/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:27:47  time: 0.1392  data_time: 0.0019  memory: 5847  loss: 1.3869  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.3869\n",
      "03/07 10:30:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][3900/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:27:33  time: 0.1381  data_time: 0.0019  memory: 5847  loss: 1.7666  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7666\n",
      "03/07 10:30:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4000/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:27:20  time: 0.1394  data_time: 0.0019  memory: 5847  loss: 1.3648  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3648\n",
      "03/07 10:30:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4100/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:27:06  time: 0.1386  data_time: 0.0021  memory: 5847  loss: 1.3066  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3066\n",
      "03/07 10:31:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:31:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4200/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:26:52  time: 0.1395  data_time: 0.0022  memory: 5847  loss: 1.3467  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3467\n",
      "03/07 10:31:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4300/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:26:38  time: 0.1369  data_time: 0.0019  memory: 5847  loss: 1.7294  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.7294\n",
      "03/07 10:31:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4400/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:26:24  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 1.4680  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4680\n",
      "03/07 10:31:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4500/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:26:10  time: 0.1384  data_time: 0.0021  memory: 5847  loss: 1.7591  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7591\n",
      "03/07 10:31:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4600/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:25:56  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.7894  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7894\n",
      "03/07 10:32:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4700/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:25:43  time: 0.1392  data_time: 0.0019  memory: 5847  loss: 1.2942  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2942\n",
      "03/07 10:32:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4800/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:25:29  time: 0.1380  data_time: 0.0019  memory: 5847  loss: 1.5204  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5204\n",
      "03/07 10:32:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][4900/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:25:15  time: 0.1403  data_time: 0.0021  memory: 5847  loss: 1.3630  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3630\n",
      "03/07 10:32:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][5000/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:25:01  time: 0.1406  data_time: 0.0020  memory: 5847  loss: 1.8040  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8040\n",
      "03/07 10:33:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][5100/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:24:47  time: 0.1381  data_time: 0.0021  memory: 5847  loss: 1.3022  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3022\n",
      "03/07 10:33:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:33:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][5200/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:24:33  time: 0.1372  data_time: 0.0020  memory: 5847  loss: 1.5847  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5847\n",
      "03/07 10:33:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:33:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][5225/5225]  base_lr: 4.9506e-05 lr: 4.9506e-06  eta: 1:24:30  time: 0.1356  data_time: 0.0020  memory: 5847  loss: 1.3404  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.3404\n",
      "03/07 10:33:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 18 epochs\n",
      "03/07 10:33:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][100/647]    eta: 0:00:16  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "03/07 10:33:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][200/647]    eta: 0:00:13  time: 0.0297  data_time: 0.0009  memory: 1333  \n",
      "03/07 10:33:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][300/647]    eta: 0:00:10  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 10:33:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][400/647]    eta: 0:00:07  time: 0.0296  data_time: 0.0009  memory: 1333  \n",
      "03/07 10:33:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][500/647]    eta: 0:00:04  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 10:33:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][600/647]    eta: 0:00:01  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[9]\n",
      "[4]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[21]\n",
      "[22]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[4]\n",
      "[17]\n",
      "[18]\n",
      "[21]\n",
      "[20]\n",
      "[4]\n",
      "[6]\n",
      "[4]\n",
      "[17]\n",
      "[3]\n",
      "[3]\n",
      "[4]\n",
      "[21]\n",
      "[3]\n",
      "[13]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[6]\n",
      "[22]\n",
      "[23]\n",
      "[11]\n",
      "[9]\n",
      "[6]\n",
      "[17]\n",
      "[17]\n",
      "[7]\n",
      "[21]\n",
      "[4]\n",
      "[9]\n",
      "[8]\n",
      "[11]\n",
      "[14]\n",
      "[13]\n",
      "[5]\n",
      "[12]\n",
      "[8]\n",
      "[11]\n",
      "[9]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[21]\n",
      "[13]\n",
      "[13]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[5]\n",
      "[8]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[23]\n",
      "[4]\n",
      "[5]\n",
      "[21]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[23]\n",
      "[22]\n",
      "[22]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[0]\n",
      "[21]\n",
      "[2]\n",
      "[26]\n",
      "[4]\n",
      "[21]\n",
      "[22]\n",
      "[25]\n",
      "[11]\n",
      "[11]\n",
      "[20]\n",
      "[22]\n",
      "[23]\n",
      "[26]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[25]\n",
      "[22]\n",
      "[22]\n",
      "[26]\n",
      "[42]\n",
      "[31]\n",
      "[63]\n",
      "[31]\n",
      "[27]\n",
      "[31]\n",
      "[30]\n",
      "[29]\n",
      "[31]\n",
      "[8]\n",
      "[115]\n",
      "[27]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[93]\n",
      "[13]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[27]\n",
      "[13]\n",
      "[31]\n",
      "[42]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[17]\n",
      "[19]\n",
      "[33]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[31]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[33]\n",
      "[19]\n",
      "[19]\n",
      "[38]\n",
      "[31]\n",
      "[31]\n",
      "[19]\n",
      "[63]\n",
      "[19]\n",
      "[42]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[32]\n",
      "[21]\n",
      "[21]\n",
      "[34]\n",
      "[99]\n",
      "[34]\n",
      "[34]\n",
      "[34]\n",
      "[96]\n",
      "[21]\n",
      "[32]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[55]\n",
      "[51]\n",
      "[46]\n",
      "[58]\n",
      "[52]\n",
      "[51]\n",
      "[51]\n",
      "[52]\n",
      "[52]\n",
      "[51]\n",
      "[57]\n",
      "[45]\n",
      "[45]\n",
      "[58]\n",
      "[51]\n",
      "[52]\n",
      "[52]\n",
      "[51]\n",
      "[48]\n",
      "[9]\n",
      "[54]\n",
      "[58]\n",
      "[10]\n",
      "[9]\n",
      "[54]\n",
      "[54]\n",
      "[15]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[58]\n",
      "[44]\n",
      "[58]\n",
      "[58]\n",
      "[54]\n",
      "[57]\n",
      "[56]\n",
      "[58]\n",
      "[48]\n",
      "[52]\n",
      "[54]\n",
      "[55]\n",
      "[51]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[51]\n",
      "[51]\n",
      "[54]\n",
      "[46]\n",
      "[15]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[58]\n",
      "[54]\n",
      "[52]\n",
      "[52]\n",
      "[46]\n",
      "[15]\n",
      "[52]\n",
      "[52]\n",
      "[47]\n",
      "[56]\n",
      "[51]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[45]\n",
      "[44]\n",
      "[56]\n",
      "[46]\n",
      "[53]\n",
      "[44]\n",
      "[56]\n",
      "[51]\n",
      "[56]\n",
      "[53]\n",
      "[12]\n",
      "[51]\n",
      "[51]\n",
      "[48]\n",
      "[48]\n",
      "[56]\n",
      "[44]\n",
      "[56]\n",
      "[56]\n",
      "[31]\n",
      "[67]\n",
      "[31]\n",
      "[27]\n",
      "[31]\n",
      "[31]\n",
      "[63]\n",
      "[67]\n",
      "[63]\n",
      "[29]\n",
      "[29]\n",
      "[28]\n",
      "[70]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[70]\n",
      "[40]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[40]\n",
      "[40]\n",
      "[40]\n",
      "[67]\n",
      "[40]\n",
      "[63]\n",
      "[27]\n",
      "[68]\n",
      "[70]\n",
      "[29]\n",
      "[29]\n",
      "[29]\n",
      "[47]\n",
      "[67]\n",
      "[67]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[51]\n",
      "[29]\n",
      "[40]\n",
      "[67]\n",
      "[70]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[53]\n",
      "[70]\n",
      "[68]\n",
      "[40]\n",
      "[67]\n",
      "[68]\n",
      "[40]\n",
      "[67]\n",
      "[69]\n",
      "[51]\n",
      "[99]\n",
      "[44]\n",
      "[122]\n",
      "[99]\n",
      "[122]\n",
      "[122]\n",
      "[99]\n",
      "[99]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[122]\n",
      "[44]\n",
      "[44]\n",
      "[122]\n",
      "[122]\n",
      "[99]\n",
      "[122]\n",
      "[121]\n",
      "[122]\n",
      "[122]\n",
      "[121]\n",
      "[121]\n",
      "[121]\n",
      "[100]\n",
      "[99]\n",
      "[48]\n",
      "[44]\n",
      "[51]\n",
      "[100]\n",
      "[51]\n",
      "[51]\n",
      "[71]\n",
      "[71]\n",
      "[98]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[97]\n",
      "[71]\n",
      "[51]\n",
      "[100]\n",
      "[51]\n",
      "[98]\n",
      "[98]\n",
      "[48]\n",
      "[98]\n",
      "[98]\n",
      "[53]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[71]\n",
      "[80]\n",
      "[90]\n",
      "[73]\n",
      "[89]\n",
      "[80]\n",
      "[76]\n",
      "[77]\n",
      "[82]\n",
      "[72]\n",
      "[81]\n",
      "[82]\n",
      "[7]\n",
      "[82]\n",
      "[86]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[76]\n",
      "[86]\n",
      "[77]\n",
      "[80]\n",
      "[80]\n",
      "[86]\n",
      "[87]\n",
      "[80]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[77]\n",
      "[86]\n",
      "[88]\n",
      "[90]\n",
      "[80]\n",
      "[76]\n",
      "[73]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[73]\n",
      "[86]\n",
      "[90]\n",
      "[75]\n",
      "[74]\n",
      "[73]\n",
      "[75]\n",
      "[81]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[84]\n",
      "[82]\n",
      "[78]\n",
      "[87]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[87]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[30]\n",
      "[71]\n",
      "[99]\n",
      "[49]\n",
      "[71]\n",
      "[14]\n",
      "[96]\n",
      "[71]\n",
      "[96]\n",
      "[97]\n",
      "[101]\n",
      "[96]\n",
      "[96]\n",
      "[101]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[71]\n",
      "[71]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[92]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[102]\n",
      "[97]\n",
      "[102]\n",
      "[71]\n",
      "[96]\n",
      "[102]\n",
      "[102]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[92]\n",
      "[100]\n",
      "[97]\n",
      "[92]\n",
      "[92]\n",
      "[96]\n",
      "[97]\n",
      "[92]\n",
      "[96]\n",
      "[96]\n",
      "[1]\n",
      "[1]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[0]\n",
      "[97]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[96]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[71]\n",
      "[99]\n",
      "[100]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[97]\n",
      "[100]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[108]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[106]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[110]\n",
      "[112]\n",
      "[108]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[113]\n",
      "[107]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[111]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[100]\n",
      "[110]\n",
      "[111]\n",
      "[110]\n",
      "[100]\n",
      "[107]\n",
      "03/07 10:33:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][647/647]    acc/top1: 0.2025  acc/top5: 0.5811  acc/mean1: 0.2522  data_time: 0.0009  time: 0.0295\n",
      "03/07 10:34:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 100/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:24:16  time: 0.1398  data_time: 0.0022  memory: 5847  loss: 1.5426  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5426\n",
      "03/07 10:34:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 200/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:24:02  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 1.7905  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7905\n",
      "03/07 10:34:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 300/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:23:48  time: 0.1386  data_time: 0.0022  memory: 5847  loss: 1.6863  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6863\n",
      "03/07 10:34:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 400/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:23:34  time: 0.1401  data_time: 0.0021  memory: 5847  loss: 1.4541  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.4541\n",
      "03/07 10:34:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 500/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:23:21  time: 0.1398  data_time: 0.0022  memory: 5847  loss: 1.5997  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5997\n",
      "03/07 10:35:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 600/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:23:07  time: 0.1402  data_time: 0.0022  memory: 5847  loss: 1.8205  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8205\n",
      "03/07 10:35:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 700/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:22:53  time: 0.1401  data_time: 0.0021  memory: 5847  loss: 1.4565  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4565\n",
      "03/07 10:35:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 800/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:22:39  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 1.7225  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7225\n",
      "03/07 10:35:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 900/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:22:25  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 1.4371  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.4371\n",
      "03/07 10:35:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:36:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1000/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:22:11  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 1.4848  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4848\n",
      "03/07 10:36:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1100/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:21:57  time: 0.1375  data_time: 0.0019  memory: 5847  loss: 1.9032  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9032\n",
      "03/07 10:36:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1200/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:21:44  time: 0.1401  data_time: 0.0020  memory: 5847  loss: 1.1856  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.1856\n",
      "03/07 10:36:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1300/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:21:30  time: 0.1375  data_time: 0.0022  memory: 5847  loss: 1.3454  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3454\n",
      "03/07 10:37:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1400/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:21:16  time: 0.1397  data_time: 0.0020  memory: 5847  loss: 1.8694  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8694\n",
      "03/07 10:37:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1500/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:21:02  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 1.5691  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5691\n",
      "03/07 10:37:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1600/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:20:48  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 1.6830  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6830\n",
      "03/07 10:37:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1700/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:20:34  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 1.2748  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2748\n",
      "03/07 10:37:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1800/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:20:20  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 1.5969  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5969\n",
      "03/07 10:38:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][1900/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:20:07  time: 0.1378  data_time: 0.0019  memory: 5847  loss: 1.3574  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.3574\n",
      "03/07 10:38:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:38:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2000/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:19:53  time: 0.1386  data_time: 0.0020  memory: 5847  loss: 2.1367  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 2.1367\n",
      "03/07 10:38:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2100/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:19:39  time: 0.1382  data_time: 0.0022  memory: 5847  loss: 1.6871  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6871\n",
      "03/07 10:38:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2200/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:19:25  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 1.6282  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6282\n",
      "03/07 10:39:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2300/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:19:11  time: 0.1375  data_time: 0.0020  memory: 5847  loss: 1.2786  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2786\n",
      "03/07 10:39:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2400/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:18:57  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 0.7915  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7915\n",
      "03/07 10:39:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2500/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:18:43  time: 0.1395  data_time: 0.0019  memory: 5847  loss: 1.2575  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2575\n",
      "03/07 10:39:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2600/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:18:30  time: 0.1400  data_time: 0.0021  memory: 5847  loss: 1.4765  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4765\n",
      "03/07 10:40:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2700/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:18:16  time: 0.1406  data_time: 0.0020  memory: 5847  loss: 1.3684  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3684\n",
      "03/07 10:40:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2800/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:18:02  time: 0.1394  data_time: 0.0021  memory: 5847  loss: 1.0726  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0726\n",
      "03/07 10:40:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][2900/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:17:48  time: 0.1391  data_time: 0.0020  memory: 5847  loss: 1.5623  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5623\n",
      "03/07 10:40:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:40:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3000/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:17:34  time: 0.1393  data_time: 0.0020  memory: 5847  loss: 1.1116  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1116\n",
      "03/07 10:40:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3100/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:17:20  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 1.5401  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5401\n",
      "03/07 10:41:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3200/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:17:07  time: 0.1405  data_time: 0.0021  memory: 5847  loss: 1.8569  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8569\n",
      "03/07 10:41:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3300/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:16:53  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 1.5430  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5430\n",
      "03/07 10:41:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3400/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:16:39  time: 0.1384  data_time: 0.0021  memory: 5847  loss: 1.2519  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2519\n",
      "03/07 10:41:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3500/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:16:25  time: 0.1392  data_time: 0.0018  memory: 5847  loss: 1.2946  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2946\n",
      "03/07 10:42:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3600/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:16:11  time: 0.1390  data_time: 0.0022  memory: 5847  loss: 1.7066  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7066\n",
      "03/07 10:42:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3700/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:15:57  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 1.0891  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0891\n",
      "03/07 10:42:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3800/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:15:43  time: 0.1388  data_time: 0.0019  memory: 5847  loss: 1.8503  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.8503\n",
      "03/07 10:42:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][3900/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:15:30  time: 0.1381  data_time: 0.0019  memory: 5847  loss: 1.4849  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4849\n",
      "03/07 10:42:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:43:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4000/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:15:16  time: 0.1383  data_time: 0.0021  memory: 5847  loss: 1.0792  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0792\n",
      "03/07 10:43:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4100/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:15:02  time: 0.1383  data_time: 0.0019  memory: 5847  loss: 1.6167  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6167\n",
      "03/07 10:43:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4200/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:14:48  time: 0.1384  data_time: 0.0019  memory: 5847  loss: 1.2598  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2598\n",
      "03/07 10:43:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4300/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:14:34  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 1.6588  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6588\n",
      "03/07 10:43:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4400/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:14:20  time: 0.1377  data_time: 0.0022  memory: 5847  loss: 1.5785  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5785\n",
      "03/07 10:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4500/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:14:06  time: 0.1375  data_time: 0.0020  memory: 5847  loss: 1.3040  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3040\n",
      "03/07 10:44:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4600/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:13:53  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 1.3838  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3838\n",
      "03/07 10:44:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4700/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:13:39  time: 0.1401  data_time: 0.0021  memory: 5847  loss: 1.5714  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5714\n",
      "03/07 10:44:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4800/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:13:25  time: 0.1396  data_time: 0.0021  memory: 5847  loss: 1.7015  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7015\n",
      "03/07 10:45:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][4900/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:13:11  time: 0.1378  data_time: 0.0020  memory: 5847  loss: 1.4617  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4617\n",
      "03/07 10:45:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:45:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][5000/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:12:57  time: 0.1380  data_time: 0.0018  memory: 5847  loss: 1.4252  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4252\n",
      "03/07 10:45:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][5100/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:12:43  time: 0.1398  data_time: 0.0018  memory: 5847  loss: 1.7460  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7460\n",
      "03/07 10:45:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][5200/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:12:29  time: 0.1398  data_time: 0.0021  memory: 5847  loss: 1.3374  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3374\n",
      "03/07 10:45:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:45:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][5225/5225]  base_lr: 4.3186e-05 lr: 4.3186e-06  eta: 1:12:26  time: 0.1362  data_time: 0.0018  memory: 5847  loss: 1.2058  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2058\n",
      "03/07 10:45:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][100/647]    eta: 0:00:16  time: 0.0294  data_time: 0.0008  memory: 1333  \n",
      "03/07 10:45:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][200/647]    eta: 0:00:13  time: 0.0295  data_time: 0.0010  memory: 1333  \n",
      "03/07 10:46:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][300/647]    eta: 0:00:10  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 10:46:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][400/647]    eta: 0:00:07  time: 0.0294  data_time: 0.0007  memory: 1333  \n",
      "03/07 10:46:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][500/647]    eta: 0:00:04  time: 0.0295  data_time: 0.0007  memory: 1333  \n",
      "03/07 10:46:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][600/647]    eta: 0:00:01  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[14]\n",
      "[3]\n",
      "[9]\n",
      "[8]\n",
      "[7]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[6]\n",
      "[17]\n",
      "[18]\n",
      "[12]\n",
      "[20]\n",
      "[3]\n",
      "[14]\n",
      "[1]\n",
      "[17]\n",
      "[3]\n",
      "[3]\n",
      "[20]\n",
      "[5]\n",
      "[3]\n",
      "[13]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[9]\n",
      "[9]\n",
      "[13]\n",
      "[22]\n",
      "[14]\n",
      "[12]\n",
      "[9]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[5]\n",
      "[8]\n",
      "[9]\n",
      "[8]\n",
      "[11]\n",
      "[14]\n",
      "[13]\n",
      "[5]\n",
      "[12]\n",
      "[8]\n",
      "[9]\n",
      "[9]\n",
      "[11]\n",
      "[11]\n",
      "[9]\n",
      "[12]\n",
      "[13]\n",
      "[13]\n",
      "[9]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[20]\n",
      "[0]\n",
      "[3]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[12]\n",
      "[21]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[5]\n",
      "[2]\n",
      "[21]\n",
      "[2]\n",
      "[20]\n",
      "[20]\n",
      "[5]\n",
      "[22]\n",
      "[20]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[26]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[25]\n",
      "[6]\n",
      "[6]\n",
      "[16]\n",
      "[42]\n",
      "[31]\n",
      "[97]\n",
      "[31]\n",
      "[63]\n",
      "[30]\n",
      "[30]\n",
      "[29]\n",
      "[31]\n",
      "[8]\n",
      "[115]\n",
      "[30]\n",
      "[31]\n",
      "[93]\n",
      "[31]\n",
      "[93]\n",
      "[13]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[30]\n",
      "[13]\n",
      "[41]\n",
      "[42]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[17]\n",
      "[19]\n",
      "[3]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[31]\n",
      "[41]\n",
      "[41]\n",
      "[19]\n",
      "[41]\n",
      "[34]\n",
      "[41]\n",
      "[19]\n",
      "[19]\n",
      "[38]\n",
      "[19]\n",
      "[5]\n",
      "[19]\n",
      "[62]\n",
      "[19]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[32]\n",
      "[11]\n",
      "[21]\n",
      "[34]\n",
      "[100]\n",
      "[34]\n",
      "[97]\n",
      "[34]\n",
      "[96]\n",
      "[21]\n",
      "[32]\n",
      "[57]\n",
      "[52]\n",
      "[52]\n",
      "[55]\n",
      "[52]\n",
      "[54]\n",
      "[58]\n",
      "[52]\n",
      "[52]\n",
      "[51]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[45]\n",
      "[45]\n",
      "[52]\n",
      "[51]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[53]\n",
      "[9]\n",
      "[54]\n",
      "[52]\n",
      "[52]\n",
      "[9]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[58]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[45]\n",
      "[57]\n",
      "[58]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[53]\n",
      "[52]\n",
      "[54]\n",
      "[44]\n",
      "[51]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[54]\n",
      "[47]\n",
      "[15]\n",
      "[44]\n",
      "[52]\n",
      "[54]\n",
      "[58]\n",
      "[54]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[47]\n",
      "[56]\n",
      "[57]\n",
      "[45]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[45]\n",
      "[44]\n",
      "[56]\n",
      "[52]\n",
      "[57]\n",
      "[45]\n",
      "[45]\n",
      "[57]\n",
      "[56]\n",
      "[54]\n",
      "[12]\n",
      "[52]\n",
      "[52]\n",
      "[58]\n",
      "[48]\n",
      "[47]\n",
      "[45]\n",
      "[56]\n",
      "[56]\n",
      "[30]\n",
      "[67]\n",
      "[67]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[63]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[28]\n",
      "[70]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[69]\n",
      "[40]\n",
      "[63]\n",
      "[27]\n",
      "[68]\n",
      "[70]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[67]\n",
      "[67]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[44]\n",
      "[67]\n",
      "[29]\n",
      "[69]\n",
      "[67]\n",
      "[69]\n",
      "[40]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[68]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[40]\n",
      "[68]\n",
      "[40]\n",
      "[67]\n",
      "[69]\n",
      "[28]\n",
      "[71]\n",
      "[44]\n",
      "[122]\n",
      "[100]\n",
      "[122]\n",
      "[98]\n",
      "[100]\n",
      "[99]\n",
      "[110]\n",
      "[44]\n",
      "[122]\n",
      "[122]\n",
      "[44]\n",
      "[44]\n",
      "[122]\n",
      "[99]\n",
      "[99]\n",
      "[98]\n",
      "[121]\n",
      "[122]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[99]\n",
      "[100]\n",
      "[99]\n",
      "[100]\n",
      "[44]\n",
      "[52]\n",
      "[100]\n",
      "[9]\n",
      "[9]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[98]\n",
      "[100]\n",
      "[98]\n",
      "[98]\n",
      "[71]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[100]\n",
      "[80]\n",
      "[90]\n",
      "[73]\n",
      "[89]\n",
      "[80]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[76]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[76]\n",
      "[86]\n",
      "[82]\n",
      "[75]\n",
      "[80]\n",
      "[86]\n",
      "[87]\n",
      "[76]\n",
      "[81]\n",
      "[81]\n",
      "[83]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[76]\n",
      "[76]\n",
      "[82]\n",
      "[76]\n",
      "[83]\n",
      "[82]\n",
      "[90]\n",
      "[80]\n",
      "[81]\n",
      "[73]\n",
      "[75]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[76]\n",
      "[73]\n",
      "[83]\n",
      "[83]\n",
      "[75]\n",
      "[76]\n",
      "[73]\n",
      "[76]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[83]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[79]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[71]\n",
      "[99]\n",
      "[49]\n",
      "[71]\n",
      "[71]\n",
      "[97]\n",
      "[40]\n",
      "[96]\n",
      "[101]\n",
      "[101]\n",
      "[96]\n",
      "[96]\n",
      "[101]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[71]\n",
      "[71]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[71]\n",
      "[79]\n",
      "[103]\n",
      "[71]\n",
      "[79]\n",
      "[79]\n",
      "[92]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[102]\n",
      "[97]\n",
      "[102]\n",
      "[71]\n",
      "[96]\n",
      "[102]\n",
      "[102]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[100]\n",
      "[97]\n",
      "[102]\n",
      "[92]\n",
      "[96]\n",
      "[97]\n",
      "[2]\n",
      "[79]\n",
      "[96]\n",
      "[98]\n",
      "[98]\n",
      "[92]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[96]\n",
      "[97]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[96]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[109]\n",
      "[107]\n",
      "[107]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[97]\n",
      "[100]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[74]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[109]\n",
      "[111]\n",
      "[109]\n",
      "[112]\n",
      "[111]\n",
      "[109]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[106]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[100]\n",
      "[109]\n",
      "[111]\n",
      "[107]\n",
      "[100]\n",
      "[109]\n",
      "03/07 10:46:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][647/647]    acc/top1: 0.2226  acc/top5: 0.5703  acc/mean1: 0.2533  data_time: 0.0009  time: 0.0295\n",
      "03/07 10:46:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_17.pth is removed\n",
      "03/07 10:46:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.2226 acc/top1 at 19 epoch is saved to best_acc_top1_epoch_19.pth.\n",
      "03/07 10:46:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 100/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:12:12  time: 0.1380  data_time: 0.0021  memory: 5847  loss: 1.3772  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3772\n",
      "03/07 10:46:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 200/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:11:58  time: 0.1392  data_time: 0.0021  memory: 5847  loss: 1.5107  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5107\n",
      "03/07 10:46:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 300/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:11:44  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 1.9064  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.9064\n",
      "03/07 10:47:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 400/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:11:31  time: 0.1413  data_time: 0.0021  memory: 5847  loss: 1.8592  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8592\n",
      "03/07 10:47:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 500/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:11:17  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.4571  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4571\n",
      "03/07 10:47:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 600/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:11:03  time: 0.1380  data_time: 0.0021  memory: 5847  loss: 1.8130  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8130\n",
      "03/07 10:47:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 700/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:10:49  time: 0.1377  data_time: 0.0022  memory: 5847  loss: 1.1902  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1902\n",
      "03/07 10:47:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:48:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 800/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:10:35  time: 0.1389  data_time: 0.0021  memory: 5847  loss: 1.3696  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3696\n",
      "03/07 10:48:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 900/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:10:21  time: 0.1394  data_time: 0.0021  memory: 5847  loss: 1.4345  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4345\n",
      "03/07 10:48:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1000/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:10:07  time: 0.1388  data_time: 0.0020  memory: 5847  loss: 1.3221  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.3221\n",
      "03/07 10:48:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1100/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:09:54  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 1.5252  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5252\n",
      "03/07 10:49:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1200/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:09:40  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 1.9484  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.9484\n",
      "03/07 10:49:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1300/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:09:26  time: 0.1388  data_time: 0.0020  memory: 5847  loss: 1.3092  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.3092\n",
      "03/07 10:49:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1400/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:09:12  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 1.7892  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7892\n",
      "03/07 10:49:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1500/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:08:58  time: 0.1379  data_time: 0.0021  memory: 5847  loss: 1.5249  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5249\n",
      "03/07 10:49:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1600/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:08:44  time: 0.1390  data_time: 0.0021  memory: 5847  loss: 1.1809  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.1809\n",
      "03/07 10:50:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1700/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:08:30  time: 0.1378  data_time: 0.0020  memory: 5847  loss: 1.6203  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6203\n",
      "03/07 10:50:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:50:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1800/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:08:17  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 1.4388  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4388\n",
      "03/07 10:50:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][1900/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:08:03  time: 0.1389  data_time: 0.0020  memory: 5847  loss: 1.6427  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6427\n",
      "03/07 10:50:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2000/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:07:49  time: 0.1390  data_time: 0.0021  memory: 5847  loss: 1.6293  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6293\n",
      "03/07 10:51:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2100/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:07:35  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 1.4600  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4600\n",
      "03/07 10:51:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2200/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:07:21  time: 0.1374  data_time: 0.0020  memory: 5847  loss: 1.1714  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1714\n",
      "03/07 10:51:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2300/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:07:07  time: 0.1378  data_time: 0.0019  memory: 5847  loss: 1.7372  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.7372\n",
      "03/07 10:51:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2400/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:06:53  time: 0.1401  data_time: 0.0020  memory: 5847  loss: 1.7228  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.7228\n",
      "03/07 10:52:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2500/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:06:40  time: 0.1386  data_time: 0.0020  memory: 5847  loss: 1.2386  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.2386\n",
      "03/07 10:52:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2600/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:06:26  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 1.3751  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3751\n",
      "03/07 10:52:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2700/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:06:12  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 1.6492  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6492\n",
      "03/07 10:52:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:52:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2800/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:05:58  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 1.6185  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6185\n",
      "03/07 10:52:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][2900/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:05:44  time: 0.1416  data_time: 0.0019  memory: 5847  loss: 1.3552  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3552\n",
      "03/07 10:53:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3000/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:05:30  time: 0.1400  data_time: 0.0021  memory: 5847  loss: 1.5277  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5277\n",
      "03/07 10:53:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3100/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:05:16  time: 0.1381  data_time: 0.0021  memory: 5847  loss: 1.6412  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6412\n",
      "03/07 10:53:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3200/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:05:03  time: 0.1388  data_time: 0.0019  memory: 5847  loss: 1.4050  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4050\n",
      "03/07 10:53:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3300/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:04:49  time: 0.1381  data_time: 0.0022  memory: 5847  loss: 1.2231  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2231\n",
      "03/07 10:54:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3400/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:04:35  time: 0.1383  data_time: 0.0021  memory: 5847  loss: 1.4064  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4064\n",
      "03/07 10:54:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3500/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:04:21  time: 0.1372  data_time: 0.0019  memory: 5847  loss: 1.1307  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.1307\n",
      "03/07 10:54:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3600/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:04:07  time: 0.1386  data_time: 0.0019  memory: 5847  loss: 1.2999  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2999\n",
      "03/07 10:54:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3700/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:03:53  time: 0.1389  data_time: 0.0019  memory: 5847  loss: 1.7162  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7162\n",
      "03/07 10:54:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:55:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3800/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:03:39  time: 0.1399  data_time: 0.0021  memory: 5847  loss: 1.5657  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5657\n",
      "03/07 10:55:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][3900/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:03:26  time: 0.1383  data_time: 0.0019  memory: 5847  loss: 1.7645  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.7645\n",
      "03/07 10:55:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4000/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:03:12  time: 0.1384  data_time: 0.0020  memory: 5847  loss: 1.6186  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6186\n",
      "03/07 10:55:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4100/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:02:58  time: 0.1382  data_time: 0.0021  memory: 5847  loss: 1.4437  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.4437\n",
      "03/07 10:55:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4200/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:02:44  time: 0.1396  data_time: 0.0023  memory: 5847  loss: 1.0459  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0459\n",
      "03/07 10:56:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4300/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:02:30  time: 0.1386  data_time: 0.0021  memory: 5847  loss: 1.8203  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8203\n",
      "03/07 10:56:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4400/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:02:16  time: 0.1386  data_time: 0.0019  memory: 5847  loss: 1.6915  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6915\n",
      "03/07 10:56:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4500/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:02:02  time: 0.1397  data_time: 0.0019  memory: 5847  loss: 1.4589  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.4589\n",
      "03/07 10:56:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4600/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:01:48  time: 0.1407  data_time: 0.0020  memory: 5847  loss: 1.6831  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6831\n",
      "03/07 10:57:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4700/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:01:35  time: 0.1388  data_time: 0.0021  memory: 5847  loss: 1.5219  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5219\n",
      "03/07 10:57:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:57:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4800/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:01:21  time: 0.1377  data_time: 0.0021  memory: 5847  loss: 1.3541  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.3541\n",
      "03/07 10:57:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][4900/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:01:07  time: 0.1392  data_time: 0.0021  memory: 5847  loss: 1.2563  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2563\n",
      "03/07 10:57:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][5000/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:00:53  time: 0.1400  data_time: 0.0022  memory: 5847  loss: 1.6004  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6004\n",
      "03/07 10:58:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][5100/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:00:39  time: 0.1383  data_time: 0.0021  memory: 5847  loss: 1.2401  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.2401\n",
      "03/07 10:58:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][5200/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:00:25  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 1.2525  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2525\n",
      "03/07 10:58:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:58:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][5225/5225]  base_lr: 3.7079e-05 lr: 3.7079e-06  eta: 1:00:22  time: 0.1364  data_time: 0.0017  memory: 5847  loss: 1.6458  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6458\n",
      "03/07 10:58:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][100/647]    eta: 0:00:16  time: 0.0296  data_time: 0.0008  memory: 1333  \n",
      "03/07 10:58:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][200/647]    eta: 0:00:13  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "03/07 10:58:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][300/647]    eta: 0:00:10  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 10:58:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][400/647]    eta: 0:00:07  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 10:58:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][500/647]    eta: 0:00:04  time: 0.0296  data_time: 0.0009  memory: 1333  \n",
      "03/07 10:58:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][600/647]    eta: 0:00:01  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[14]\n",
      "[6]\n",
      "[11]\n",
      "[4]\n",
      "[7]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[6]\n",
      "[17]\n",
      "[18]\n",
      "[14]\n",
      "[20]\n",
      "[6]\n",
      "[14]\n",
      "[4]\n",
      "[17]\n",
      "[6]\n",
      "[6]\n",
      "[20]\n",
      "[5]\n",
      "[6]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[6]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[6]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[5]\n",
      "[4]\n",
      "[11]\n",
      "[8]\n",
      "[11]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[12]\n",
      "[8]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[20]\n",
      "[8]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[6]\n",
      "[22]\n",
      "[22]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[2]\n",
      "[21]\n",
      "[2]\n",
      "[20]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[22]\n",
      "[23]\n",
      "[14]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[25]\n",
      "[6]\n",
      "[6]\n",
      "[16]\n",
      "[42]\n",
      "[31]\n",
      "[27]\n",
      "[31]\n",
      "[27]\n",
      "[27]\n",
      "[29]\n",
      "[29]\n",
      "[31]\n",
      "[29]\n",
      "[115]\n",
      "[27]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[93]\n",
      "[13]\n",
      "[14]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[30]\n",
      "[13]\n",
      "[41]\n",
      "[42]\n",
      "[14]\n",
      "[42]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[17]\n",
      "[19]\n",
      "[3]\n",
      "[19]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[41]\n",
      "[14]\n",
      "[41]\n",
      "[34]\n",
      "[15]\n",
      "[19]\n",
      "[35]\n",
      "[38]\n",
      "[31]\n",
      "[31]\n",
      "[36]\n",
      "[62]\n",
      "[19]\n",
      "[42]\n",
      "[14]\n",
      "[42]\n",
      "[42]\n",
      "[16]\n",
      "[11]\n",
      "[11]\n",
      "[34]\n",
      "[20]\n",
      "[34]\n",
      "[97]\n",
      "[43]\n",
      "[96]\n",
      "[20]\n",
      "[32]\n",
      "[57]\n",
      "[52]\n",
      "[52]\n",
      "[55]\n",
      "[46]\n",
      "[46]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[51]\n",
      "[52]\n",
      "[52]\n",
      "[51]\n",
      "[57]\n",
      "[46]\n",
      "[46]\n",
      "[52]\n",
      "[51]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[46]\n",
      "[10]\n",
      "[10]\n",
      "[57]\n",
      "[54]\n",
      "[54]\n",
      "[44]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[59]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[59]\n",
      "[52]\n",
      "[54]\n",
      "[44]\n",
      "[51]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[54]\n",
      "[47]\n",
      "[44]\n",
      "[55]\n",
      "[52]\n",
      "[52]\n",
      "[59]\n",
      "[54]\n",
      "[52]\n",
      "[52]\n",
      "[46]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[47]\n",
      "[56]\n",
      "[57]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[56]\n",
      "[44]\n",
      "[56]\n",
      "[46]\n",
      "[57]\n",
      "[45]\n",
      "[56]\n",
      "[51]\n",
      "[56]\n",
      "[57]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[47]\n",
      "[46]\n",
      "[47]\n",
      "[56]\n",
      "[56]\n",
      "[44]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[63]\n",
      "[64]\n",
      "[63]\n",
      "[29]\n",
      "[29]\n",
      "[27]\n",
      "[70]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[31]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[63]\n",
      "[27]\n",
      "[68]\n",
      "[70]\n",
      "[29]\n",
      "[29]\n",
      "[29]\n",
      "[47]\n",
      "[67]\n",
      "[29]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[44]\n",
      "[29]\n",
      "[29]\n",
      "[69]\n",
      "[70]\n",
      "[70]\n",
      "[40]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[68]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[40]\n",
      "[68]\n",
      "[40]\n",
      "[67]\n",
      "[69]\n",
      "[70]\n",
      "[71]\n",
      "[44]\n",
      "[98]\n",
      "[100]\n",
      "[122]\n",
      "[98]\n",
      "[100]\n",
      "[99]\n",
      "[110]\n",
      "[44]\n",
      "[122]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[121]\n",
      "[98]\n",
      "[71]\n",
      "[98]\n",
      "[121]\n",
      "[44]\n",
      "[99]\n",
      "[99]\n",
      "[98]\n",
      "[98]\n",
      "[100]\n",
      "[99]\n",
      "[8]\n",
      "[7]\n",
      "[52]\n",
      "[100]\n",
      "[100]\n",
      "[8]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[97]\n",
      "[100]\n",
      "[71]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[97]\n",
      "[100]\n",
      "[98]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[71]\n",
      "[80]\n",
      "[90]\n",
      "[73]\n",
      "[89]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[72]\n",
      "[81]\n",
      "[82]\n",
      "[7]\n",
      "[88]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[76]\n",
      "[86]\n",
      "[89]\n",
      "[75]\n",
      "[80]\n",
      "[86]\n",
      "[87]\n",
      "[75]\n",
      "[81]\n",
      "[81]\n",
      "[83]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[88]\n",
      "[77]\n",
      "[86]\n",
      "[88]\n",
      "[90]\n",
      "[80]\n",
      "[76]\n",
      "[73]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[77]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[73]\n",
      "[3]\n",
      "[90]\n",
      "[75]\n",
      "[74]\n",
      "[73]\n",
      "[75]\n",
      "[81]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[73]\n",
      "[84]\n",
      "[88]\n",
      "[78]\n",
      "[31]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[71]\n",
      "[30]\n",
      "[30]\n",
      "[87]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[30]\n",
      "[71]\n",
      "[71]\n",
      "[84]\n",
      "[71]\n",
      "[15]\n",
      "[7]\n",
      "[40]\n",
      "[96]\n",
      "[101]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[100]\n",
      "[101]\n",
      "[40]\n",
      "[40]\n",
      "[64]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[103]\n",
      "[99]\n",
      "[100]\n",
      "[99]\n",
      "[99]\n",
      "[71]\n",
      "[102]\n",
      "[62]\n",
      "[102]\n",
      "[40]\n",
      "[96]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[100]\n",
      "[71]\n",
      "[102]\n",
      "[101]\n",
      "[100]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[96]\n",
      "[97]\n",
      "[2]\n",
      "[96]\n",
      "[96]\n",
      "[0]\n",
      "[0]\n",
      "[99]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[0]\n",
      "[97]\n",
      "[0]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[0]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[109]\n",
      "[107]\n",
      "[107]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[100]\n",
      "[97]\n",
      "[71]\n",
      "[100]\n",
      "[105]\n",
      "[106]\n",
      "[106]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[105]\n",
      "[106]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[110]\n",
      "[106]\n",
      "[108]\n",
      "[111]\n",
      "[109]\n",
      "[106]\n",
      "[111]\n",
      "[112]\n",
      "[108]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[106]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[106]\n",
      "[109]\n",
      "[111]\n",
      "[107]\n",
      "[111]\n",
      "[107]\n",
      "03/07 10:58:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][647/647]    acc/top1: 0.2025  acc/top5: 0.5827  acc/mean1: 0.2617  data_time: 0.0009  time: 0.0296\n",
      "03/07 10:58:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 100/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 1:00:08  time: 0.1386  data_time: 0.0022  memory: 5847  loss: 1.4795  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4795\n",
      "03/07 10:59:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 200/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:59:54  time: 0.1381  data_time: 0.0021  memory: 5847  loss: 1.2748  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2748\n",
      "03/07 10:59:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 300/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:59:40  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 1.2248  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2248\n",
      "03/07 10:59:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 400/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:59:26  time: 0.1376  data_time: 0.0020  memory: 5847  loss: 1.3321  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.3321\n",
      "03/07 10:59:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 10:59:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 500/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:59:13  time: 0.1393  data_time: 0.0020  memory: 5847  loss: 1.2760  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2760\n",
      "03/07 11:00:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 600/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:58:59  time: 0.1393  data_time: 0.0022  memory: 5847  loss: 1.5031  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5031\n",
      "03/07 11:00:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 700/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:58:45  time: 0.1375  data_time: 0.0020  memory: 5847  loss: 1.0907  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0907\n",
      "03/07 11:00:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 800/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:58:31  time: 0.1383  data_time: 0.0021  memory: 5847  loss: 1.6452  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6452\n",
      "03/07 11:00:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 900/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:58:17  time: 0.1393  data_time: 0.0021  memory: 5847  loss: 1.6705  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6705\n",
      "03/07 11:00:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1000/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:58:03  time: 0.1397  data_time: 0.0021  memory: 5847  loss: 2.0247  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 2.0247\n",
      "03/07 11:01:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1100/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:57:49  time: 0.1390  data_time: 0.0022  memory: 5847  loss: 1.1772  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1772\n",
      "03/07 11:01:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1200/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:57:36  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 1.6683  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6683\n",
      "03/07 11:01:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1300/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:57:22  time: 0.1381  data_time: 0.0019  memory: 5847  loss: 1.2575  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2575\n",
      "03/07 11:01:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1400/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:57:08  time: 0.1390  data_time: 0.0019  memory: 5847  loss: 1.3588  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3588\n",
      "03/07 11:02:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:02:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1500/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:56:54  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 1.3954  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3954\n",
      "03/07 11:02:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1600/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:56:40  time: 0.1384  data_time: 0.0021  memory: 5847  loss: 1.6311  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6311\n",
      "03/07 11:02:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1700/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:56:26  time: 0.1392  data_time: 0.0020  memory: 5847  loss: 1.3379  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3379\n",
      "03/07 11:02:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1800/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:56:12  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 1.1149  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1149\n",
      "03/07 11:03:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][1900/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:55:59  time: 0.1381  data_time: 0.0021  memory: 5847  loss: 1.3980  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3980\n",
      "03/07 11:03:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2000/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:55:45  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 1.6161  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6161\n",
      "03/07 11:03:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2100/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:55:31  time: 0.1389  data_time: 0.0021  memory: 5847  loss: 1.3061  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3061\n",
      "03/07 11:03:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2200/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:55:17  time: 0.1396  data_time: 0.0021  memory: 5847  loss: 1.6635  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6635\n",
      "03/07 11:03:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2300/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:55:03  time: 0.1388  data_time: 0.0020  memory: 5847  loss: 1.2905  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2905\n",
      "03/07 11:04:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2400/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:54:49  time: 0.1383  data_time: 0.0021  memory: 5847  loss: 1.5741  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5741\n",
      "03/07 11:04:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:04:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2500/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:54:35  time: 0.1371  data_time: 0.0020  memory: 5847  loss: 1.5097  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5097\n",
      "03/07 11:04:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2600/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:54:22  time: 0.1401  data_time: 0.0021  memory: 5847  loss: 1.3204  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.3204\n",
      "03/07 11:04:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2700/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:54:08  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 1.4256  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4256\n",
      "03/07 11:05:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2800/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:53:54  time: 0.1399  data_time: 0.0021  memory: 5847  loss: 1.3783  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3783\n",
      "03/07 11:05:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][2900/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:53:40  time: 0.1397  data_time: 0.0022  memory: 5847  loss: 1.4417  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4417\n",
      "03/07 11:05:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3000/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:53:26  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 1.4756  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4756\n",
      "03/07 11:05:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3100/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:53:12  time: 0.1382  data_time: 0.0019  memory: 5847  loss: 1.5033  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5033\n",
      "03/07 11:06:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3200/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:52:58  time: 0.1379  data_time: 0.0021  memory: 5847  loss: 1.3328  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3328\n",
      "03/07 11:06:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3300/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:52:44  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 1.3235  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3235\n",
      "03/07 11:06:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3400/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:52:31  time: 0.1384  data_time: 0.0019  memory: 5847  loss: 1.1785  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1785\n",
      "03/07 11:06:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:06:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3500/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:52:17  time: 0.1384  data_time: 0.0021  memory: 5847  loss: 1.4346  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4346\n",
      "03/07 11:06:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3600/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:52:03  time: 0.1408  data_time: 0.0022  memory: 5847  loss: 1.7044  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7044\n",
      "03/07 11:07:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3700/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:51:49  time: 0.1377  data_time: 0.0022  memory: 5847  loss: 1.3758  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.3758\n",
      "03/07 11:07:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3800/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:51:35  time: 0.1388  data_time: 0.0019  memory: 5847  loss: 1.3074  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3074\n",
      "03/07 11:07:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][3900/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:51:21  time: 0.1383  data_time: 0.0021  memory: 5847  loss: 1.7165  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7165\n",
      "03/07 11:07:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4000/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:51:07  time: 0.1382  data_time: 0.0021  memory: 5847  loss: 1.6536  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6536\n",
      "03/07 11:08:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4100/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:50:54  time: 0.1392  data_time: 0.0021  memory: 5847  loss: 2.0389  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.0389\n",
      "03/07 11:08:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4200/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:50:40  time: 0.1384  data_time: 0.0019  memory: 5847  loss: 1.8458  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8458\n",
      "03/07 11:08:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4300/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:50:26  time: 0.1396  data_time: 0.0021  memory: 5847  loss: 1.5503  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5503\n",
      "03/07 11:08:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4400/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:50:12  time: 0.1406  data_time: 0.0021  memory: 5847  loss: 1.5877  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5877\n",
      "03/07 11:09:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:09:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4500/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:49:58  time: 0.1389  data_time: 0.0021  memory: 5847  loss: 1.4452  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.4452\n",
      "03/07 11:09:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4600/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:49:44  time: 0.1386  data_time: 0.0021  memory: 5847  loss: 1.2736  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2736\n",
      "03/07 11:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4700/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:49:30  time: 0.1395  data_time: 0.0021  memory: 5847  loss: 1.8319  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.8319\n",
      "03/07 11:09:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4800/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:49:17  time: 0.1388  data_time: 0.0020  memory: 5847  loss: 1.5705  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5705\n",
      "03/07 11:10:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][4900/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:49:03  time: 0.1399  data_time: 0.0020  memory: 5847  loss: 1.4876  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4876\n",
      "03/07 11:10:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][5000/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:48:49  time: 0.1379  data_time: 0.0021  memory: 5847  loss: 1.5449  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5449\n",
      "03/07 11:10:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][5100/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:48:35  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 1.4159  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.4159\n",
      "03/07 11:10:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][5200/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:48:21  time: 0.1384  data_time: 0.0022  memory: 5847  loss: 1.5385  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5385\n",
      "03/07 11:10:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:10:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][5225/5225]  base_lr: 3.1250e-05 lr: 3.1250e-06  eta: 0:48:18  time: 0.1358  data_time: 0.0020  memory: 5847  loss: 1.2054  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.2054\n",
      "03/07 11:10:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 21 epochs\n",
      "03/07 11:10:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][100/647]    eta: 0:00:16  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 11:10:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][200/647]    eta: 0:00:13  time: 0.0295  data_time: 0.0008  memory: 1333  \n",
      "03/07 11:10:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][300/647]    eta: 0:00:10  time: 0.0295  data_time: 0.0008  memory: 1333  \n",
      "03/07 11:10:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][400/647]    eta: 0:00:07  time: 0.0295  data_time: 0.0010  memory: 1333  \n",
      "03/07 11:11:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][500/647]    eta: 0:00:04  time: 0.0296  data_time: 0.0010  memory: 1333  \n",
      "03/07 11:11:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][600/647]    eta: 0:00:01  time: 0.0293  data_time: 0.0009  memory: 1333  \n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[3]\n",
      "[11]\n",
      "[3]\n",
      "[7]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[3]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[0]\n",
      "[3]\n",
      "[17]\n",
      "[3]\n",
      "[3]\n",
      "[20]\n",
      "[5]\n",
      "[3]\n",
      "[13]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[22]\n",
      "[14]\n",
      "[0]\n",
      "[17]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[5]\n",
      "[3]\n",
      "[0]\n",
      "[3]\n",
      "[17]\n",
      "[3]\n",
      "[3]\n",
      "[5]\n",
      "[13]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[11]\n",
      "[17]\n",
      "[13]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[20]\n",
      "[20]\n",
      "[0]\n",
      "[3]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[4]\n",
      "[11]\n",
      "[11]\n",
      "[3]\n",
      "[22]\n",
      "[22]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[5]\n",
      "[2]\n",
      "[13]\n",
      "[2]\n",
      "[20]\n",
      "[20]\n",
      "[5]\n",
      "[22]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[3]\n",
      "[22]\n",
      "[22]\n",
      "[26]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[25]\n",
      "[6]\n",
      "[6]\n",
      "[26]\n",
      "[42]\n",
      "[31]\n",
      "[63]\n",
      "[31]\n",
      "[27]\n",
      "[27]\n",
      "[30]\n",
      "[29]\n",
      "[5]\n",
      "[29]\n",
      "[115]\n",
      "[27]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[67]\n",
      "[13]\n",
      "[17]\n",
      "[42]\n",
      "[42]\n",
      "[43]\n",
      "[27]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[17]\n",
      "[42]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[112]\n",
      "[41]\n",
      "[63]\n",
      "[19]\n",
      "[41]\n",
      "[41]\n",
      "[31]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[34]\n",
      "[65]\n",
      "[41]\n",
      "[35]\n",
      "[38]\n",
      "[31]\n",
      "[31]\n",
      "[40]\n",
      "[62]\n",
      "[19]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[16]\n",
      "[32]\n",
      "[21]\n",
      "[34]\n",
      "[19]\n",
      "[34]\n",
      "[107]\n",
      "[43]\n",
      "[96]\n",
      "[20]\n",
      "[32]\n",
      "[57]\n",
      "[52]\n",
      "[52]\n",
      "[56]\n",
      "[54]\n",
      "[54]\n",
      "[45]\n",
      "[52]\n",
      "[51]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[51]\n",
      "[57]\n",
      "[46]\n",
      "[46]\n",
      "[57]\n",
      "[51]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[53]\n",
      "[9]\n",
      "[54]\n",
      "[53]\n",
      "[53]\n",
      "[9]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[53]\n",
      "[10]\n",
      "[54]\n",
      "[57]\n",
      "[56]\n",
      "[57]\n",
      "[53]\n",
      "[52]\n",
      "[54]\n",
      "[44]\n",
      "[51]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[54]\n",
      "[47]\n",
      "[15]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[47]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[56]\n",
      "[51]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[45]\n",
      "[44]\n",
      "[56]\n",
      "[46]\n",
      "[47]\n",
      "[9]\n",
      "[56]\n",
      "[51]\n",
      "[56]\n",
      "[53]\n",
      "[47]\n",
      "[52]\n",
      "[51]\n",
      "[47]\n",
      "[53]\n",
      "[47]\n",
      "[56]\n",
      "[56]\n",
      "[44]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[63]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[27]\n",
      "[70]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[69]\n",
      "[40]\n",
      "[67]\n",
      "[27]\n",
      "[40]\n",
      "[70]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[67]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[67]\n",
      "[29]\n",
      "[69]\n",
      "[70]\n",
      "[70]\n",
      "[40]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[53]\n",
      "[70]\n",
      "[68]\n",
      "[40]\n",
      "[40]\n",
      "[68]\n",
      "[40]\n",
      "[67]\n",
      "[69]\n",
      "[70]\n",
      "[107]\n",
      "[44]\n",
      "[110]\n",
      "[100]\n",
      "[122]\n",
      "[98]\n",
      "[99]\n",
      "[99]\n",
      "[110]\n",
      "[44]\n",
      "[122]\n",
      "[44]\n",
      "[44]\n",
      "[53]\n",
      "[122]\n",
      "[98]\n",
      "[98]\n",
      "[110]\n",
      "[121]\n",
      "[53]\n",
      "[98]\n",
      "[98]\n",
      "[110]\n",
      "[110]\n",
      "[51]\n",
      "[51]\n",
      "[48]\n",
      "[44]\n",
      "[51]\n",
      "[100]\n",
      "[51]\n",
      "[45]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[51]\n",
      "[71]\n",
      "[71]\n",
      "[7]\n",
      "[97]\n",
      "[71]\n",
      "[52]\n",
      "[8]\n",
      "[51]\n",
      "[98]\n",
      "[51]\n",
      "[8]\n",
      "[46]\n",
      "[51]\n",
      "[53]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[75]\n",
      "[78]\n",
      "[73]\n",
      "[89]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[88]\n",
      "[74]\n",
      "[79]\n",
      "[82]\n",
      "[83]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[89]\n",
      "[89]\n",
      "[87]\n",
      "[89]\n",
      "[75]\n",
      "[80]\n",
      "[86]\n",
      "[87]\n",
      "[75]\n",
      "[81]\n",
      "[81]\n",
      "[88]\n",
      "[83]\n",
      "[84]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[87]\n",
      "[75]\n",
      "[75]\n",
      "[82]\n",
      "[77]\n",
      "[86]\n",
      "[88]\n",
      "[90]\n",
      "[74]\n",
      "[80]\n",
      "[73]\n",
      "[75]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[78]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[87]\n",
      "[75]\n",
      "[73]\n",
      "[84]\n",
      "[78]\n",
      "[75]\n",
      "[72]\n",
      "[73]\n",
      "[75]\n",
      "[79]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[73]\n",
      "[84]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[79]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[71]\n",
      "[7]\n",
      "[84]\n",
      "[71]\n",
      "[15]\n",
      "[71]\n",
      "[40]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[96]\n",
      "[96]\n",
      "[101]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[101]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[92]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[40]\n",
      "[101]\n",
      "[102]\n",
      "[102]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[100]\n",
      "[101]\n",
      "[92]\n",
      "[92]\n",
      "[96]\n",
      "[96]\n",
      "[92]\n",
      "[96]\n",
      "[96]\n",
      "[0]\n",
      "[96]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[0]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[96]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[109]\n",
      "[107]\n",
      "[107]\n",
      "[71]\n",
      "[107]\n",
      "[100]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[96]\n",
      "[71]\n",
      "[97]\n",
      "[96]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[74]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[109]\n",
      "[111]\n",
      "[109]\n",
      "[112]\n",
      "[111]\n",
      "[109]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[107]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[112]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[109]\n",
      "[107]\n",
      "[111]\n",
      "[107]\n",
      "03/07 11:11:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][647/647]    acc/top1: 0.2164  acc/top5: 0.5935  acc/mean1: 0.2715  data_time: 0.0009  time: 0.0296\n",
      "03/07 11:11:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 100/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:48:04  time: 0.1394  data_time: 0.0021  memory: 5847  loss: 1.4226  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4226\n",
      "03/07 11:11:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 200/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:47:50  time: 0.1380  data_time: 0.0021  memory: 5847  loss: 1.4608  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4608\n",
      "03/07 11:11:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:11:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 300/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:47:36  time: 0.1383  data_time: 0.0019  memory: 5847  loss: 1.6298  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6298\n",
      "03/07 11:12:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 400/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:47:22  time: 0.1392  data_time: 0.0020  memory: 5847  loss: 1.3351  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3351\n",
      "03/07 11:12:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 500/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:47:08  time: 0.1382  data_time: 0.0021  memory: 5847  loss: 1.2545  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2545\n",
      "03/07 11:12:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 600/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:46:54  time: 0.1372  data_time: 0.0022  memory: 5847  loss: 1.7206  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7206\n",
      "03/07 11:12:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 700/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:46:41  time: 0.1401  data_time: 0.0021  memory: 5847  loss: 1.4431  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4431\n",
      "03/07 11:12:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 800/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:46:27  time: 0.1395  data_time: 0.0020  memory: 5847  loss: 1.3457  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3457\n",
      "03/07 11:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 900/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:46:13  time: 0.1373  data_time: 0.0020  memory: 5847  loss: 1.2978  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2978\n",
      "03/07 11:13:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1000/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:45:59  time: 0.1378  data_time: 0.0020  memory: 5847  loss: 1.3545  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3545\n",
      "03/07 11:13:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1100/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:45:45  time: 0.1377  data_time: 0.0019  memory: 5847  loss: 1.6389  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6389\n",
      "03/07 11:13:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1200/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:45:31  time: 0.1378  data_time: 0.0020  memory: 5847  loss: 1.0018  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0018\n",
      "03/07 11:14:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:14:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1300/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:45:17  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 1.0262  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0262\n",
      "03/07 11:14:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1400/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:45:04  time: 0.1374  data_time: 0.0021  memory: 5847  loss: 1.9693  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9693\n",
      "03/07 11:14:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1500/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:44:50  time: 0.1398  data_time: 0.0022  memory: 5847  loss: 1.4920  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4920\n",
      "03/07 11:14:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1600/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:44:36  time: 0.1410  data_time: 0.0020  memory: 5847  loss: 1.1695  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1695\n",
      "03/07 11:15:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1700/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:44:22  time: 0.1400  data_time: 0.0021  memory: 5847  loss: 1.3469  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3469\n",
      "03/07 11:15:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1800/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:44:08  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 1.5636  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5636\n",
      "03/07 11:15:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][1900/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:43:54  time: 0.1376  data_time: 0.0022  memory: 5847  loss: 1.2755  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.2755\n",
      "03/07 11:15:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2000/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:43:40  time: 0.1387  data_time: 0.0022  memory: 5847  loss: 1.3510  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3510\n",
      "03/07 11:15:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2100/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:43:27  time: 0.1405  data_time: 0.0020  memory: 5847  loss: 1.6890  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6890\n",
      "03/07 11:16:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2200/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:43:13  time: 0.1373  data_time: 0.0021  memory: 5847  loss: 1.5710  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5710\n",
      "03/07 11:16:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:16:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2300/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:42:59  time: 0.1387  data_time: 0.0019  memory: 5847  loss: 1.4609  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4609\n",
      "03/07 11:16:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2400/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:42:45  time: 0.1386  data_time: 0.0021  memory: 5847  loss: 1.5782  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5782\n",
      "03/07 11:16:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2500/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:42:31  time: 0.1388  data_time: 0.0022  memory: 5847  loss: 1.5612  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5612\n",
      "03/07 11:17:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2600/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:42:17  time: 0.1386  data_time: 0.0021  memory: 5847  loss: 1.4496  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4496\n",
      "03/07 11:17:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2700/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:42:03  time: 0.1393  data_time: 0.0022  memory: 5847  loss: 1.7796  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7796\n",
      "03/07 11:17:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2800/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:41:50  time: 0.1391  data_time: 0.0020  memory: 5847  loss: 1.0559  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0559\n",
      "03/07 11:17:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][2900/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:41:36  time: 0.1378  data_time: 0.0020  memory: 5847  loss: 1.5208  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5208\n",
      "03/07 11:18:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3000/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:41:22  time: 0.1384  data_time: 0.0020  memory: 5847  loss: 1.2532  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2532\n",
      "03/07 11:18:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3100/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:41:08  time: 0.1388  data_time: 0.0022  memory: 5847  loss: 1.6237  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6237\n",
      "03/07 11:18:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3200/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:40:54  time: 0.1377  data_time: 0.0021  memory: 5847  loss: 1.4012  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4012\n",
      "03/07 11:18:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:18:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3300/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:40:40  time: 0.1398  data_time: 0.0021  memory: 5847  loss: 2.0464  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.0464\n",
      "03/07 11:18:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3400/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:40:26  time: 0.1399  data_time: 0.0021  memory: 5847  loss: 1.7546  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7546\n",
      "03/07 11:19:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3500/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:40:12  time: 0.1385  data_time: 0.0022  memory: 5847  loss: 1.4622  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.4622\n",
      "03/07 11:19:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3600/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:39:59  time: 0.1378  data_time: 0.0022  memory: 5847  loss: 1.4936  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4936\n",
      "03/07 11:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3700/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:39:45  time: 0.1377  data_time: 0.0021  memory: 5847  loss: 1.4476  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4476\n",
      "03/07 11:19:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3800/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:39:31  time: 0.1390  data_time: 0.0019  memory: 5847  loss: 1.4218  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4218\n",
      "03/07 11:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][3900/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:39:17  time: 0.1391  data_time: 0.0020  memory: 5847  loss: 1.5180  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.5180\n",
      "03/07 11:20:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4000/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:39:03  time: 0.1389  data_time: 0.0021  memory: 5847  loss: 1.5074  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5074\n",
      "03/07 11:20:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4100/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:38:49  time: 0.1403  data_time: 0.0021  memory: 5847  loss: 1.4467  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4467\n",
      "03/07 11:20:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4200/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:38:35  time: 0.1407  data_time: 0.0021  memory: 5847  loss: 1.7185  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.7185\n",
      "03/07 11:20:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:21:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4300/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:38:22  time: 0.1392  data_time: 0.0021  memory: 5847  loss: 1.6960  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6960\n",
      "03/07 11:21:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4400/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:38:08  time: 0.1382  data_time: 0.0019  memory: 5847  loss: 1.7112  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7112\n",
      "03/07 11:21:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4500/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:37:54  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 1.4637  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4637\n",
      "03/07 11:21:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4600/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:37:40  time: 0.1411  data_time: 0.0020  memory: 5847  loss: 1.4793  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4793\n",
      "03/07 11:21:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4700/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:37:26  time: 0.1392  data_time: 0.0022  memory: 5847  loss: 1.5767  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5767\n",
      "03/07 11:22:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4800/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:37:12  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.3383  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3383\n",
      "03/07 11:22:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][4900/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:36:58  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 1.4057  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.4057\n",
      "03/07 11:22:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][5000/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:36:45  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 1.3682  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3682\n",
      "03/07 11:22:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][5100/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:36:31  time: 0.1400  data_time: 0.0020  memory: 5847  loss: 1.1826  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1826\n",
      "03/07 11:23:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][5200/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:36:17  time: 0.1390  data_time: 0.0021  memory: 5847  loss: 1.7839  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.7839\n",
      "03/07 11:23:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:23:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][5225/5225]  base_lr: 2.5763e-05 lr: 2.5763e-06  eta: 0:36:13  time: 0.1369  data_time: 0.0020  memory: 5847  loss: 1.0965  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0965\n",
      "03/07 11:23:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][100/647]    eta: 0:00:16  time: 0.0295  data_time: 0.0008  memory: 1333  \n",
      "03/07 11:23:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][200/647]    eta: 0:00:13  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "03/07 11:23:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][300/647]    eta: 0:00:10  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "03/07 11:23:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][400/647]    eta: 0:00:07  time: 0.0295  data_time: 0.0008  memory: 1333  \n",
      "03/07 11:23:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][500/647]    eta: 0:00:04  time: 0.0294  data_time: 0.0009  memory: 1333  \n",
      "03/07 11:23:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][600/647]    eta: 0:00:01  time: 0.0293  data_time: 0.0008  memory: 1333  \n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[3]\n",
      "[11]\n",
      "[4]\n",
      "[7]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[6]\n",
      "[17]\n",
      "[18]\n",
      "[11]\n",
      "[11]\n",
      "[4]\n",
      "[6]\n",
      "[1]\n",
      "[17]\n",
      "[3]\n",
      "[6]\n",
      "[20]\n",
      "[5]\n",
      "[3]\n",
      "[13]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[5]\n",
      "[4]\n",
      "[9]\n",
      "[8]\n",
      "[11]\n",
      "[3]\n",
      "[13]\n",
      "[5]\n",
      "[13]\n",
      "[8]\n",
      "[11]\n",
      "[9]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[13]\n",
      "[11]\n",
      "[17]\n",
      "[14]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[5]\n",
      "[20]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[5]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[11]\n",
      "[26]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[2]\n",
      "[21]\n",
      "[2]\n",
      "[20]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[25]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[25]\n",
      "[6]\n",
      "[6]\n",
      "[16]\n",
      "[42]\n",
      "[31]\n",
      "[63]\n",
      "[31]\n",
      "[27]\n",
      "[27]\n",
      "[47]\n",
      "[29]\n",
      "[5]\n",
      "[29]\n",
      "[115]\n",
      "[27]\n",
      "[31]\n",
      "[93]\n",
      "[31]\n",
      "[93]\n",
      "[13]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[30]\n",
      "[13]\n",
      "[41]\n",
      "[42]\n",
      "[14]\n",
      "[42]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[17]\n",
      "[19]\n",
      "[3]\n",
      "[19]\n",
      "[14]\n",
      "[41]\n",
      "[14]\n",
      "[14]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[34]\n",
      "[41]\n",
      "[41]\n",
      "[35]\n",
      "[38]\n",
      "[31]\n",
      "[31]\n",
      "[37]\n",
      "[39]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[42]\n",
      "[42]\n",
      "[32]\n",
      "[32]\n",
      "[21]\n",
      "[34]\n",
      "[19]\n",
      "[34]\n",
      "[16]\n",
      "[43]\n",
      "[96]\n",
      "[21]\n",
      "[32]\n",
      "[57]\n",
      "[56]\n",
      "[52]\n",
      "[55]\n",
      "[54]\n",
      "[54]\n",
      "[58]\n",
      "[52]\n",
      "[54]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[51]\n",
      "[58]\n",
      "[46]\n",
      "[46]\n",
      "[56]\n",
      "[56]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[53]\n",
      "[9]\n",
      "[53]\n",
      "[53]\n",
      "[53]\n",
      "[9]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[58]\n",
      "[48]\n",
      "[58]\n",
      "[58]\n",
      "[48]\n",
      "[48]\n",
      "[58]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[58]\n",
      "[53]\n",
      "[52]\n",
      "[54]\n",
      "[55]\n",
      "[51]\n",
      "[54]\n",
      "[53]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[54]\n",
      "[47]\n",
      "[44]\n",
      "[55]\n",
      "[52]\n",
      "[54]\n",
      "[53]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[59]\n",
      "[44]\n",
      "[56]\n",
      "[47]\n",
      "[47]\n",
      "[45]\n",
      "[56]\n",
      "[7]\n",
      "[56]\n",
      "[53]\n",
      "[48]\n",
      "[52]\n",
      "[52]\n",
      "[48]\n",
      "[48]\n",
      "[47]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[31]\n",
      "[67]\n",
      "[31]\n",
      "[70]\n",
      "[31]\n",
      "[31]\n",
      "[63]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[28]\n",
      "[70]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[40]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[69]\n",
      "[40]\n",
      "[67]\n",
      "[27]\n",
      "[68]\n",
      "[70]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[67]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[28]\n",
      "[67]\n",
      "[29]\n",
      "[69]\n",
      "[70]\n",
      "[70]\n",
      "[40]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[53]\n",
      "[70]\n",
      "[68]\n",
      "[70]\n",
      "[68]\n",
      "[68]\n",
      "[40]\n",
      "[67]\n",
      "[69]\n",
      "[70]\n",
      "[71]\n",
      "[44]\n",
      "[122]\n",
      "[71]\n",
      "[122]\n",
      "[122]\n",
      "[100]\n",
      "[98]\n",
      "[110]\n",
      "[44]\n",
      "[122]\n",
      "[122]\n",
      "[44]\n",
      "[53]\n",
      "[122]\n",
      "[98]\n",
      "[71]\n",
      "[110]\n",
      "[121]\n",
      "[53]\n",
      "[122]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[100]\n",
      "[99]\n",
      "[48]\n",
      "[44]\n",
      "[54]\n",
      "[100]\n",
      "[48]\n",
      "[48]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[8]\n",
      "[71]\n",
      "[71]\n",
      "[8]\n",
      "[98]\n",
      "[98]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[72]\n",
      "[90]\n",
      "[73]\n",
      "[89]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[88]\n",
      "[72]\n",
      "[81]\n",
      "[82]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[76]\n",
      "[86]\n",
      "[89]\n",
      "[80]\n",
      "[80]\n",
      "[86]\n",
      "[87]\n",
      "[75]\n",
      "[81]\n",
      "[81]\n",
      "[83]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[72]\n",
      "[76]\n",
      "[82]\n",
      "[77]\n",
      "[86]\n",
      "[88]\n",
      "[90]\n",
      "[80]\n",
      "[76]\n",
      "[73]\n",
      "[75]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[73]\n",
      "[3]\n",
      "[78]\n",
      "[72]\n",
      "[72]\n",
      "[73]\n",
      "[72]\n",
      "[81]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[85]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[83]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[79]\n",
      "[112]\n",
      "[87]\n",
      "[31]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[71]\n",
      "[71]\n",
      "[84]\n",
      "[71]\n",
      "[14]\n",
      "[71]\n",
      "[40]\n",
      "[101]\n",
      "[101]\n",
      "[101]\n",
      "[96]\n",
      "[96]\n",
      "[101]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[101]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[71]\n",
      "[101]\n",
      "[103]\n",
      "[71]\n",
      "[101]\n",
      "[101]\n",
      "[103]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[40]\n",
      "[101]\n",
      "[101]\n",
      "[102]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[101]\n",
      "[100]\n",
      "[101]\n",
      "[92]\n",
      "[40]\n",
      "[96]\n",
      "[97]\n",
      "[0]\n",
      "[96]\n",
      "[96]\n",
      "[0]\n",
      "[0]\n",
      "[92]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[0]\n",
      "[97]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[0]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[109]\n",
      "[97]\n",
      "[107]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[71]\n",
      "[97]\n",
      "[71]\n",
      "[100]\n",
      "[105]\n",
      "[106]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[108]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[110]\n",
      "[112]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[111]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[109]\n",
      "[107]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[112]\n",
      "[109]\n",
      "[111]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[111]\n",
      "[107]\n",
      "[111]\n",
      "[107]\n",
      "03/07 11:23:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][647/647]    acc/top1: 0.2303  acc/top5: 0.6028  acc/mean1: 0.2890  data_time: 0.0009  time: 0.0296\n",
      "03/07 11:23:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_19.pth is removed\n",
      "03/07 11:23:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.2303 acc/top1 at 22 epoch is saved to best_acc_top1_epoch_22.pth.\n",
      "03/07 11:23:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:23:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 100/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:35:59  time: 0.1383  data_time: 0.0022  memory: 5847  loss: 1.5729  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5729\n",
      "03/07 11:24:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 200/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:35:46  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.5445  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5445\n",
      "03/07 11:24:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 300/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:35:32  time: 0.1378  data_time: 0.0022  memory: 5847  loss: 1.5300  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5300\n",
      "03/07 11:24:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 400/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:35:18  time: 0.1382  data_time: 0.0021  memory: 5847  loss: 1.4609  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4609\n",
      "03/07 11:24:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 500/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:35:04  time: 0.1399  data_time: 0.0021  memory: 5847  loss: 1.2335  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.2335\n",
      "03/07 11:24:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 600/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:34:50  time: 0.1396  data_time: 0.0021  memory: 5847  loss: 1.1719  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.1719\n",
      "03/07 11:25:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 700/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:34:36  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.6561  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6561\n",
      "03/07 11:25:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 800/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:34:22  time: 0.1393  data_time: 0.0021  memory: 5847  loss: 1.2413  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.2413\n",
      "03/07 11:25:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 900/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:34:09  time: 0.1387  data_time: 0.0021  memory: 5847  loss: 1.3059  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3059\n",
      "03/07 11:25:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1000/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:33:55  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 1.1540  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1540\n",
      "03/07 11:25:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:26:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1100/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:33:41  time: 0.1383  data_time: 0.0022  memory: 5847  loss: 0.9866  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9866\n",
      "03/07 11:26:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1200/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:33:27  time: 0.1377  data_time: 0.0022  memory: 5847  loss: 1.5812  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5812\n",
      "03/07 11:26:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1300/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:33:13  time: 0.1399  data_time: 0.0022  memory: 5847  loss: 1.5719  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5719\n",
      "03/07 11:26:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1400/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:32:59  time: 0.1404  data_time: 0.0021  memory: 5847  loss: 1.4712  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4712\n",
      "03/07 11:27:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1500/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:32:45  time: 0.1399  data_time: 0.0022  memory: 5847  loss: 1.4014  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4014\n",
      "03/07 11:27:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1600/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:32:31  time: 0.1383  data_time: 0.0021  memory: 5847  loss: 1.4288  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4288\n",
      "03/07 11:27:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1700/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:32:18  time: 0.1375  data_time: 0.0021  memory: 5847  loss: 1.1925  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.1925\n",
      "03/07 11:27:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1800/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:32:04  time: 0.1393  data_time: 0.0021  memory: 5847  loss: 1.3471  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3471\n",
      "03/07 11:27:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][1900/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:31:50  time: 0.1398  data_time: 0.0021  memory: 5847  loss: 1.3416  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3416\n",
      "03/07 11:28:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2000/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:31:36  time: 0.1382  data_time: 0.0022  memory: 5847  loss: 1.3506  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3506\n",
      "03/07 11:28:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:28:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2100/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:31:22  time: 0.1389  data_time: 0.0022  memory: 5847  loss: 1.6405  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6405\n",
      "03/07 11:28:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2200/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:31:08  time: 0.1397  data_time: 0.0021  memory: 5847  loss: 1.3373  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3373\n",
      "03/07 11:28:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2300/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:30:54  time: 0.1382  data_time: 0.0022  memory: 5847  loss: 1.2460  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2460\n",
      "03/07 11:29:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2400/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:30:41  time: 0.1403  data_time: 0.0023  memory: 5847  loss: 1.2993  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2993\n",
      "03/07 11:29:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2500/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:30:27  time: 0.1389  data_time: 0.0019  memory: 5847  loss: 1.5559  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5559\n",
      "03/07 11:29:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2600/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:30:13  time: 0.1386  data_time: 0.0020  memory: 5847  loss: 1.1216  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1216\n",
      "03/07 11:29:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2700/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:29:59  time: 0.1392  data_time: 0.0022  memory: 5847  loss: 1.2130  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2130\n",
      "03/07 11:30:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2800/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:29:45  time: 0.1387  data_time: 0.0022  memory: 5847  loss: 1.6503  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6503\n",
      "03/07 11:30:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][2900/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:29:31  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.2542  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2542\n",
      "03/07 11:30:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3000/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:29:17  time: 0.1382  data_time: 0.0021  memory: 5847  loss: 1.4470  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4470\n",
      "03/07 11:30:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:30:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3100/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:29:03  time: 0.1379  data_time: 0.0020  memory: 5847  loss: 1.3424  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3424\n",
      "03/07 11:30:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3200/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:28:50  time: 0.1397  data_time: 0.0021  memory: 5847  loss: 1.6765  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6765\n",
      "03/07 11:31:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3300/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:28:36  time: 0.1384  data_time: 0.0022  memory: 5847  loss: 1.1909  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1909\n",
      "03/07 11:31:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3400/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:28:22  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 1.3058  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3058\n",
      "03/07 11:31:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3500/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:28:08  time: 0.1386  data_time: 0.0021  memory: 5847  loss: 1.2709  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2709\n",
      "03/07 11:31:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3600/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:27:54  time: 0.1377  data_time: 0.0021  memory: 5847  loss: 1.3974  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3974\n",
      "03/07 11:32:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3700/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:27:40  time: 0.1379  data_time: 0.0022  memory: 5847  loss: 1.3650  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3650\n",
      "03/07 11:32:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3800/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:27:26  time: 0.1384  data_time: 0.0021  memory: 5847  loss: 1.5577  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5577\n",
      "03/07 11:32:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][3900/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:27:13  time: 0.1390  data_time: 0.0020  memory: 5847  loss: 1.4043  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4043\n",
      "03/07 11:32:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4000/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:26:59  time: 0.1410  data_time: 0.0022  memory: 5847  loss: 1.6646  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6646\n",
      "03/07 11:32:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:33:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4100/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:26:45  time: 0.1383  data_time: 0.0024  memory: 5847  loss: 1.8055  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.8055\n",
      "03/07 11:33:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4200/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:26:31  time: 0.1394  data_time: 0.0021  memory: 5847  loss: 1.3333  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3333\n",
      "03/07 11:33:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4300/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:26:17  time: 0.1395  data_time: 0.0020  memory: 5847  loss: 1.2852  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2852\n",
      "03/07 11:33:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4400/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:26:03  time: 0.1391  data_time: 0.0021  memory: 5847  loss: 1.1469  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1469\n",
      "03/07 11:33:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4500/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:25:49  time: 0.1404  data_time: 0.0020  memory: 5847  loss: 1.1827  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1827\n",
      "03/07 11:34:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4600/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:25:36  time: 0.1378  data_time: 0.0023  memory: 5847  loss: 1.1525  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1525\n",
      "03/07 11:34:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4700/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:25:22  time: 0.1384  data_time: 0.0022  memory: 5847  loss: 1.2236  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2236\n",
      "03/07 11:34:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4800/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:25:08  time: 0.1381  data_time: 0.0019  memory: 5847  loss: 1.4231  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4231\n",
      "03/07 11:34:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][4900/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:24:54  time: 0.1388  data_time: 0.0022  memory: 5847  loss: 1.5506  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5506\n",
      "03/07 11:35:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][5000/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:24:40  time: 0.1395  data_time: 0.0019  memory: 5847  loss: 1.2847  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2847\n",
      "03/07 11:35:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:35:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][5100/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:24:26  time: 0.1395  data_time: 0.0020  memory: 5847  loss: 1.0834  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0834\n",
      "03/07 11:35:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][5200/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:24:12  time: 0.1383  data_time: 0.0022  memory: 5847  loss: 1.2945  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2945\n",
      "03/07 11:35:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:35:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][5225/5225]  base_lr: 2.0679e-05 lr: 2.0679e-06  eta: 0:24:09  time: 0.1367  data_time: 0.0020  memory: 5847  loss: 1.5679  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.5679\n",
      "03/07 11:35:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][100/647]    eta: 0:00:16  time: 0.0295  data_time: 0.0008  memory: 1333  \n",
      "03/07 11:35:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][200/647]    eta: 0:00:13  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 11:35:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][300/647]    eta: 0:00:10  time: 0.0295  data_time: 0.0008  memory: 1333  \n",
      "03/07 11:35:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][400/647]    eta: 0:00:07  time: 0.0295  data_time: 0.0010  memory: 1333  \n",
      "03/07 11:35:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][500/647]    eta: 0:00:04  time: 0.0296  data_time: 0.0009  memory: 1333  \n",
      "03/07 11:35:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][600/647]    eta: 0:00:01  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[9]\n",
      "[4]\n",
      "[4]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[6]\n",
      "[17]\n",
      "[18]\n",
      "[4]\n",
      "[20]\n",
      "[4]\n",
      "[6]\n",
      "[4]\n",
      "[17]\n",
      "[3]\n",
      "[3]\n",
      "[20]\n",
      "[5]\n",
      "[3]\n",
      "[13]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[23]\n",
      "[23]\n",
      "[12]\n",
      "[17]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[5]\n",
      "[4]\n",
      "[0]\n",
      "[8]\n",
      "[11]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[13]\n",
      "[8]\n",
      "[11]\n",
      "[9]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[11]\n",
      "[17]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[5]\n",
      "[8]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[5]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[23]\n",
      "[23]\n",
      "[23]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[2]\n",
      "[21]\n",
      "[2]\n",
      "[26]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[23]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[25]\n",
      "[25]\n",
      "[25]\n",
      "[26]\n",
      "[42]\n",
      "[31]\n",
      "[63]\n",
      "[31]\n",
      "[27]\n",
      "[27]\n",
      "[29]\n",
      "[29]\n",
      "[31]\n",
      "[29]\n",
      "[115]\n",
      "[27]\n",
      "[31]\n",
      "[93]\n",
      "[31]\n",
      "[93]\n",
      "[13]\n",
      "[20]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[30]\n",
      "[13]\n",
      "[41]\n",
      "[42]\n",
      "[19]\n",
      "[31]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[5]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[17]\n",
      "[19]\n",
      "[3]\n",
      "[19]\n",
      "[14]\n",
      "[41]\n",
      "[31]\n",
      "[14]\n",
      "[41]\n",
      "[14]\n",
      "[41]\n",
      "[34]\n",
      "[33]\n",
      "[41]\n",
      "[35]\n",
      "[38]\n",
      "[31]\n",
      "[21]\n",
      "[19]\n",
      "[62]\n",
      "[19]\n",
      "[42]\n",
      "[41]\n",
      "[41]\n",
      "[42]\n",
      "[8]\n",
      "[21]\n",
      "[21]\n",
      "[34]\n",
      "[96]\n",
      "[34]\n",
      "[97]\n",
      "[43]\n",
      "[96]\n",
      "[21]\n",
      "[32]\n",
      "[57]\n",
      "[9]\n",
      "[57]\n",
      "[55]\n",
      "[46]\n",
      "[46]\n",
      "[58]\n",
      "[52]\n",
      "[54]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[51]\n",
      "[57]\n",
      "[46]\n",
      "[46]\n",
      "[56]\n",
      "[56]\n",
      "[52]\n",
      "[56]\n",
      "[54]\n",
      "[53]\n",
      "[9]\n",
      "[54]\n",
      "[53]\n",
      "[53]\n",
      "[9]\n",
      "[54]\n",
      "[54]\n",
      "[15]\n",
      "[48]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[46]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[53]\n",
      "[56]\n",
      "[54]\n",
      "[55]\n",
      "[51]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[54]\n",
      "[47]\n",
      "[44]\n",
      "[55]\n",
      "[52]\n",
      "[54]\n",
      "[59]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[56]\n",
      "[57]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[45]\n",
      "[44]\n",
      "[56]\n",
      "[46]\n",
      "[47]\n",
      "[44]\n",
      "[44]\n",
      "[51]\n",
      "[56]\n",
      "[54]\n",
      "[54]\n",
      "[52]\n",
      "[52]\n",
      "[48]\n",
      "[53]\n",
      "[47]\n",
      "[44]\n",
      "[56]\n",
      "[56]\n",
      "[31]\n",
      "[67]\n",
      "[31]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[63]\n",
      "[67]\n",
      "[63]\n",
      "[29]\n",
      "[29]\n",
      "[28]\n",
      "[70]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[70]\n",
      "[69]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[69]\n",
      "[68]\n",
      "[63]\n",
      "[27]\n",
      "[68]\n",
      "[70]\n",
      "[47]\n",
      "[7]\n",
      "[29]\n",
      "[47]\n",
      "[67]\n",
      "[67]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[51]\n",
      "[29]\n",
      "[29]\n",
      "[70]\n",
      "[67]\n",
      "[70]\n",
      "[40]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[53]\n",
      "[70]\n",
      "[68]\n",
      "[70]\n",
      "[68]\n",
      "[68]\n",
      "[68]\n",
      "[67]\n",
      "[69]\n",
      "[52]\n",
      "[71]\n",
      "[44]\n",
      "[98]\n",
      "[100]\n",
      "[122]\n",
      "[98]\n",
      "[99]\n",
      "[98]\n",
      "[98]\n",
      "[44]\n",
      "[121]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[121]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[121]\n",
      "[44]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[100]\n",
      "[99]\n",
      "[100]\n",
      "[44]\n",
      "[51]\n",
      "[100]\n",
      "[100]\n",
      "[52]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[97]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[98]\n",
      "[97]\n",
      "[100]\n",
      "[97]\n",
      "[98]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[80]\n",
      "[90]\n",
      "[73]\n",
      "[89]\n",
      "[80]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[72]\n",
      "[81]\n",
      "[82]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[76]\n",
      "[86]\n",
      "[89]\n",
      "[80]\n",
      "[80]\n",
      "[86]\n",
      "[87]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[88]\n",
      "[83]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[77]\n",
      "[86]\n",
      "[88]\n",
      "[90]\n",
      "[80]\n",
      "[81]\n",
      "[73]\n",
      "[75]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[76]\n",
      "[73]\n",
      "[3]\n",
      "[90]\n",
      "[72]\n",
      "[72]\n",
      "[73]\n",
      "[72]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[86]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[79]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[30]\n",
      "[71]\n",
      "[71]\n",
      "[84]\n",
      "[83]\n",
      "[14]\n",
      "[97]\n",
      "[40]\n",
      "[0]\n",
      "[101]\n",
      "[101]\n",
      "[96]\n",
      "[96]\n",
      "[101]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[101]\n",
      "[40]\n",
      "[64]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[71]\n",
      "[103]\n",
      "[103]\n",
      "[92]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[102]\n",
      "[101]\n",
      "[102]\n",
      "[40]\n",
      "[101]\n",
      "[102]\n",
      "[102]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[102]\n",
      "[92]\n",
      "[100]\n",
      "[101]\n",
      "[92]\n",
      "[92]\n",
      "[96]\n",
      "[97]\n",
      "[0]\n",
      "[79]\n",
      "[96]\n",
      "[97]\n",
      "[98]\n",
      "[92]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[0]\n",
      "[97]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[0]\n",
      "[99]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[109]\n",
      "[97]\n",
      "[97]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[96]\n",
      "[98]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[97]\n",
      "[98]\n",
      "[105]\n",
      "[105]\n",
      "[106]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[106]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[110]\n",
      "[105]\n",
      "[108]\n",
      "[111]\n",
      "[111]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[108]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[111]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[107]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[108]\n",
      "[109]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[111]\n",
      "[107]\n",
      "[111]\n",
      "[107]\n",
      "03/07 11:35:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][647/647]    acc/top1: 0.2365  acc/top5: 0.6043  acc/mean1: 0.2917  data_time: 0.0009  time: 0.0296\n",
      "03/07 11:35:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_22.pth is removed\n",
      "03/07 11:35:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.2365 acc/top1 at 23 epoch is saved to best_acc_top1_epoch_23.pth.\n",
      "03/07 11:36:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 100/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:23:55  time: 0.1385  data_time: 0.0022  memory: 5847  loss: 1.6970  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6970\n",
      "03/07 11:36:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 200/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:23:41  time: 0.1386  data_time: 0.0022  memory: 5847  loss: 0.9787  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9787\n",
      "03/07 11:36:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 300/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:23:27  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 1.5390  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5390\n",
      "03/07 11:36:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 400/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:23:13  time: 0.1392  data_time: 0.0020  memory: 5847  loss: 1.7507  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7507\n",
      "03/07 11:37:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 500/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:23:00  time: 0.1390  data_time: 0.0022  memory: 5847  loss: 1.1012  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1012\n",
      "03/07 11:37:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 600/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:22:46  time: 0.1382  data_time: 0.0021  memory: 5847  loss: 1.4225  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4225\n",
      "03/07 11:37:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 700/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:22:32  time: 0.1386  data_time: 0.0021  memory: 5847  loss: 1.6098  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6098\n",
      "03/07 11:37:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 800/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:22:18  time: 0.1388  data_time: 0.0022  memory: 5847  loss: 1.3915  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3915\n",
      "03/07 11:37:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:38:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 900/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:22:04  time: 0.1372  data_time: 0.0020  memory: 5847  loss: 1.7285  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.7285\n",
      "03/07 11:38:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1000/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:21:50  time: 0.1390  data_time: 0.0021  memory: 5847  loss: 1.2865  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2865\n",
      "03/07 11:38:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1100/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:21:36  time: 0.1394  data_time: 0.0021  memory: 5847  loss: 1.4825  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4825\n",
      "03/07 11:38:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1200/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:21:22  time: 0.1397  data_time: 0.0021  memory: 5847  loss: 1.4042  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4042\n",
      "03/07 11:39:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1300/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:21:09  time: 0.1396  data_time: 0.0019  memory: 5847  loss: 1.2890  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2890\n",
      "03/07 11:39:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1400/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:20:55  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 1.3427  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3427\n",
      "03/07 11:39:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1500/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:20:41  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 1.3236  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.3236\n",
      "03/07 11:39:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1600/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:20:27  time: 0.1380  data_time: 0.0020  memory: 5847  loss: 1.3851  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3851\n",
      "03/07 11:39:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1700/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:20:13  time: 0.1395  data_time: 0.0021  memory: 5847  loss: 1.5104  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.5104\n",
      "03/07 11:40:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1800/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:19:59  time: 0.1389  data_time: 0.0019  memory: 5847  loss: 1.6132  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6132\n",
      "03/07 11:40:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:40:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][1900/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:19:45  time: 0.1405  data_time: 0.0021  memory: 5847  loss: 1.4614  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4614\n",
      "03/07 11:40:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2000/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:19:32  time: 0.1388  data_time: 0.0019  memory: 5847  loss: 1.5584  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5584\n",
      "03/07 11:40:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2100/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:19:18  time: 0.1382  data_time: 0.0019  memory: 5847  loss: 1.1155  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1155\n",
      "03/07 11:41:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2200/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:19:04  time: 0.1387  data_time: 0.0020  memory: 5847  loss: 1.3306  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3306\n",
      "03/07 11:41:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2300/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:18:50  time: 0.1409  data_time: 0.0021  memory: 5847  loss: 1.2410  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2410\n",
      "03/07 11:41:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2400/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:18:36  time: 0.1380  data_time: 0.0021  memory: 5847  loss: 1.4903  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4903\n",
      "03/07 11:41:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2500/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:18:22  time: 0.1384  data_time: 0.0020  memory: 5847  loss: 0.8878  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8878\n",
      "03/07 11:42:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2600/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:18:08  time: 0.1383  data_time: 0.0021  memory: 5847  loss: 1.4170  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4170\n",
      "03/07 11:42:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2700/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:17:54  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.2515  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2515\n",
      "03/07 11:42:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2800/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:17:41  time: 0.1386  data_time: 0.0020  memory: 5847  loss: 1.6467  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6467\n",
      "03/07 11:42:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:42:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][2900/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:17:27  time: 0.1395  data_time: 0.0020  memory: 5847  loss: 1.3939  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3939\n",
      "03/07 11:42:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3000/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:17:13  time: 0.1391  data_time: 0.0021  memory: 5847  loss: 1.6438  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6438\n",
      "03/07 11:43:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3100/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:16:59  time: 0.1386  data_time: 0.0020  memory: 5847  loss: 1.4818  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4818\n",
      "03/07 11:43:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3200/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:16:45  time: 0.1383  data_time: 0.0021  memory: 5847  loss: 1.2715  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2715\n",
      "03/07 11:43:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3300/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:16:31  time: 0.1393  data_time: 0.0021  memory: 5847  loss: 1.1666  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1666\n",
      "03/07 11:43:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3400/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:16:17  time: 0.1398  data_time: 0.0022  memory: 5847  loss: 1.1773  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.1773\n",
      "03/07 11:44:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3500/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:16:04  time: 0.1376  data_time: 0.0022  memory: 5847  loss: 1.2384  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2384\n",
      "03/07 11:44:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3600/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:15:50  time: 0.1389  data_time: 0.0020  memory: 5847  loss: 1.4297  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4297\n",
      "03/07 11:44:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3700/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:15:36  time: 0.1418  data_time: 0.0021  memory: 5847  loss: 1.2467  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2467\n",
      "03/07 11:44:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3800/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:15:22  time: 0.1383  data_time: 0.0021  memory: 5847  loss: 1.3597  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3597\n",
      "03/07 11:44:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:45:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][3900/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:15:08  time: 0.1374  data_time: 0.0021  memory: 5847  loss: 1.6881  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.6881\n",
      "03/07 11:45:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4000/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:14:54  time: 0.1380  data_time: 0.0022  memory: 5847  loss: 1.5232  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5232\n",
      "03/07 11:45:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4100/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:14:40  time: 0.1387  data_time: 0.0020  memory: 5847  loss: 1.2430  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2430\n",
      "03/07 11:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4200/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:14:27  time: 0.1395  data_time: 0.0021  memory: 5847  loss: 1.6564  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.6564\n",
      "03/07 11:46:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4300/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:14:13  time: 0.1390  data_time: 0.0021  memory: 5847  loss: 1.3142  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3142\n",
      "03/07 11:46:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4400/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:13:59  time: 0.1373  data_time: 0.0021  memory: 5847  loss: 1.4983  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4983\n",
      "03/07 11:46:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4500/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:13:45  time: 0.1382  data_time: 0.0021  memory: 5847  loss: 1.1426  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.1426\n",
      "03/07 11:46:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4600/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:13:31  time: 0.1404  data_time: 0.0022  memory: 5847  loss: 1.1210  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1210\n",
      "03/07 11:46:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4700/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:13:17  time: 0.1379  data_time: 0.0021  memory: 5847  loss: 1.1263  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1263\n",
      "03/07 11:47:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4800/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:13:03  time: 0.1387  data_time: 0.0020  memory: 5847  loss: 1.5501  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5501\n",
      "03/07 11:47:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:47:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][4900/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:12:49  time: 0.1391  data_time: 0.0020  memory: 5847  loss: 0.7422  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7422\n",
      "03/07 11:47:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][5000/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:12:36  time: 0.1381  data_time: 0.0021  memory: 5847  loss: 1.1420  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1420\n",
      "03/07 11:47:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][5100/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:12:22  time: 0.1374  data_time: 0.0021  memory: 5847  loss: 1.0122  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0122\n",
      "03/07 11:48:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][5200/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:12:08  time: 0.1372  data_time: 0.0020  memory: 5847  loss: 1.4346  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4346\n",
      "03/07 11:48:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:48:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][5225/5225]  base_lr: 1.6053e-05 lr: 1.6053e-06  eta: 0:12:04  time: 0.1354  data_time: 0.0021  memory: 5847  loss: 1.2449  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2449\n",
      "03/07 11:48:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 24 epochs\n",
      "03/07 11:48:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][100/647]    eta: 0:00:16  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 11:48:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][200/647]    eta: 0:00:13  time: 0.0295  data_time: 0.0008  memory: 1333  \n",
      "03/07 11:48:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][300/647]    eta: 0:00:10  time: 0.0295  data_time: 0.0009  memory: 1333  \n",
      "03/07 11:48:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][400/647]    eta: 0:00:07  time: 0.0293  data_time: 0.0008  memory: 1333  \n",
      "03/07 11:48:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][500/647]    eta: 0:00:04  time: 0.0296  data_time: 0.0009  memory: 1333  \n",
      "03/07 11:48:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][600/647]    eta: 0:00:01  time: 0.0293  data_time: 0.0008  memory: 1333  \n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[14]\n",
      "[3]\n",
      "[11]\n",
      "[8]\n",
      "[7]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[6]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[20]\n",
      "[20]\n",
      "[14]\n",
      "[1]\n",
      "[17]\n",
      "[3]\n",
      "[6]\n",
      "[20]\n",
      "[5]\n",
      "[3]\n",
      "[13]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[13]\n",
      "[17]\n",
      "[16]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[5]\n",
      "[20]\n",
      "[0]\n",
      "[8]\n",
      "[17]\n",
      "[14]\n",
      "[14]\n",
      "[5]\n",
      "[13]\n",
      "[8]\n",
      "[11]\n",
      "[9]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[13]\n",
      "[11]\n",
      "[17]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[18]\n",
      "[20]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[21]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[22]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[5]\n",
      "[2]\n",
      "[21]\n",
      "[2]\n",
      "[20]\n",
      "[20]\n",
      "[5]\n",
      "[22]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[14]\n",
      "[22]\n",
      "[23]\n",
      "[14]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[25]\n",
      "[6]\n",
      "[6]\n",
      "[16]\n",
      "[42]\n",
      "[31]\n",
      "[63]\n",
      "[31]\n",
      "[27]\n",
      "[27]\n",
      "[29]\n",
      "[29]\n",
      "[31]\n",
      "[29]\n",
      "[115]\n",
      "[27]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[93]\n",
      "[13]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[30]\n",
      "[13]\n",
      "[41]\n",
      "[42]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[111]\n",
      "[19]\n",
      "[3]\n",
      "[19]\n",
      "[19]\n",
      "[41]\n",
      "[31]\n",
      "[14]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[27]\n",
      "[41]\n",
      "[35]\n",
      "[38]\n",
      "[31]\n",
      "[31]\n",
      "[19]\n",
      "[62]\n",
      "[19]\n",
      "[42]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[16]\n",
      "[12]\n",
      "[5]\n",
      "[34]\n",
      "[97]\n",
      "[34]\n",
      "[97]\n",
      "[43]\n",
      "[96]\n",
      "[21]\n",
      "[100]\n",
      "[57]\n",
      "[57]\n",
      "[52]\n",
      "[55]\n",
      "[46]\n",
      "[46]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[51]\n",
      "[52]\n",
      "[52]\n",
      "[51]\n",
      "[57]\n",
      "[46]\n",
      "[46]\n",
      "[52]\n",
      "[56]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[53]\n",
      "[57]\n",
      "[54]\n",
      "[53]\n",
      "[53]\n",
      "[9]\n",
      "[54]\n",
      "[54]\n",
      "[15]\n",
      "[58]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[53]\n",
      "[52]\n",
      "[54]\n",
      "[55]\n",
      "[51]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[54]\n",
      "[47]\n",
      "[44]\n",
      "[55]\n",
      "[52]\n",
      "[54]\n",
      "[53]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[56]\n",
      "[57]\n",
      "[46]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[45]\n",
      "[44]\n",
      "[56]\n",
      "[53]\n",
      "[47]\n",
      "[45]\n",
      "[44]\n",
      "[7]\n",
      "[56]\n",
      "[53]\n",
      "[54]\n",
      "[52]\n",
      "[52]\n",
      "[47]\n",
      "[53]\n",
      "[47]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[30]\n",
      "[67]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[63]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[28]\n",
      "[70]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[66]\n",
      "[67]\n",
      "[27]\n",
      "[68]\n",
      "[70]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[47]\n",
      "[67]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[44]\n",
      "[67]\n",
      "[29]\n",
      "[69]\n",
      "[70]\n",
      "[70]\n",
      "[40]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[53]\n",
      "[70]\n",
      "[70]\n",
      "[69]\n",
      "[40]\n",
      "[68]\n",
      "[40]\n",
      "[67]\n",
      "[69]\n",
      "[70]\n",
      "[71]\n",
      "[44]\n",
      "[110]\n",
      "[100]\n",
      "[122]\n",
      "[98]\n",
      "[99]\n",
      "[98]\n",
      "[110]\n",
      "[44]\n",
      "[122]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[121]\n",
      "[98]\n",
      "[98]\n",
      "[110]\n",
      "[121]\n",
      "[121]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[100]\n",
      "[99]\n",
      "[48]\n",
      "[44]\n",
      "[51]\n",
      "[100]\n",
      "[51]\n",
      "[48]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[97]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[71]\n",
      "[97]\n",
      "[100]\n",
      "[97]\n",
      "[98]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[72]\n",
      "[90]\n",
      "[73]\n",
      "[89]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[88]\n",
      "[72]\n",
      "[81]\n",
      "[82]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[76]\n",
      "[86]\n",
      "[89]\n",
      "[75]\n",
      "[80]\n",
      "[86]\n",
      "[87]\n",
      "[75]\n",
      "[81]\n",
      "[81]\n",
      "[83]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[77]\n",
      "[86]\n",
      "[88]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[73]\n",
      "[75]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[78]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[73]\n",
      "[3]\n",
      "[78]\n",
      "[72]\n",
      "[72]\n",
      "[73]\n",
      "[72]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[85]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[83]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[79]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[30]\n",
      "[71]\n",
      "[71]\n",
      "[84]\n",
      "[71]\n",
      "[14]\n",
      "[71]\n",
      "[40]\n",
      "[96]\n",
      "[101]\n",
      "[101]\n",
      "[96]\n",
      "[96]\n",
      "[101]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[101]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[71]\n",
      "[101]\n",
      "[103]\n",
      "[71]\n",
      "[79]\n",
      "[79]\n",
      "[92]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[71]\n",
      "[102]\n",
      "[62]\n",
      "[102]\n",
      "[40]\n",
      "[101]\n",
      "[102]\n",
      "[102]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[102]\n",
      "[101]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[92]\n",
      "[96]\n",
      "[97]\n",
      "[0]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[99]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[0]\n",
      "[97]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[0]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[109]\n",
      "[97]\n",
      "[107]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[71]\n",
      "[71]\n",
      "[97]\n",
      "[71]\n",
      "[97]\n",
      "[71]\n",
      "[98]\n",
      "[105]\n",
      "[105]\n",
      "[107]\n",
      "[111]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[107]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[110]\n",
      "[105]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[108]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[111]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[107]\n",
      "[113]\n",
      "[113]\n",
      "[110]\n",
      "[113]\n",
      "[108]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[111]\n",
      "[110]\n",
      "[111]\n",
      "[107]\n",
      "03/07 11:48:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][647/647]    acc/top1: 0.2427  acc/top5: 0.5935  acc/mean1: 0.2960  data_time: 0.0009  time: 0.0296\n",
      "03/07 11:48:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_23.pth is removed\n",
      "03/07 11:48:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.2427 acc/top1 at 24 epoch is saved to best_acc_top1_epoch_24.pth.\n",
      "03/07 11:48:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 100/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:11:50  time: 0.1391  data_time: 0.0021  memory: 5847  loss: 1.5353  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.5353\n",
      "03/07 11:48:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 200/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:11:37  time: 0.1394  data_time: 0.0022  memory: 5847  loss: 1.3308  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3308\n",
      "03/07 11:49:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 300/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:11:23  time: 0.1382  data_time: 0.0021  memory: 5847  loss: 1.3918  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3918\n",
      "03/07 11:49:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 400/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:11:09  time: 0.1377  data_time: 0.0021  memory: 5847  loss: 1.1881  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1881\n",
      "03/07 11:49:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 500/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:10:55  time: 0.1383  data_time: 0.0020  memory: 5847  loss: 1.2598  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2598\n",
      "03/07 11:49:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:49:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 600/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:10:41  time: 0.1394  data_time: 0.0020  memory: 5847  loss: 1.3049  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3049\n",
      "03/07 11:50:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 700/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:10:27  time: 0.1378  data_time: 0.0022  memory: 5847  loss: 1.6055  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.6055\n",
      "03/07 11:50:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 800/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:10:13  time: 0.1372  data_time: 0.0022  memory: 5847  loss: 1.4434  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4434\n",
      "03/07 11:50:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 900/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:09:59  time: 0.1392  data_time: 0.0020  memory: 5847  loss: 1.2308  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.2308\n",
      "03/07 11:50:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1000/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:09:46  time: 0.1416  data_time: 0.0022  memory: 5847  loss: 1.2518  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2518\n",
      "03/07 11:51:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1100/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:09:32  time: 0.1372  data_time: 0.0021  memory: 5847  loss: 1.4470  top1_acc: 0.0000  top5_acc: 0.0000  loss_cls: 1.4470\n",
      "03/07 11:51:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1200/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:09:18  time: 0.1387  data_time: 0.0022  memory: 5847  loss: 1.2756  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2756\n",
      "03/07 11:51:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1300/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:09:04  time: 0.1382  data_time: 0.0022  memory: 5847  loss: 1.3588  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3588\n",
      "03/07 11:51:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1400/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:08:50  time: 0.1383  data_time: 0.0022  memory: 5847  loss: 1.1751  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1751\n",
      "03/07 11:51:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1500/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:08:36  time: 0.1382  data_time: 0.0020  memory: 5847  loss: 1.5867  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.5867\n",
      "03/07 11:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1600/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:08:22  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.5415  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.5415\n",
      "03/07 11:52:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1700/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:08:09  time: 0.1380  data_time: 0.0021  memory: 5847  loss: 1.6871  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.6871\n",
      "03/07 11:52:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1800/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:07:55  time: 0.1395  data_time: 0.0021  memory: 5847  loss: 1.1087  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.1087\n",
      "03/07 11:52:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][1900/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:07:41  time: 0.1384  data_time: 0.0021  memory: 5847  loss: 1.1619  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1619\n",
      "03/07 11:53:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2000/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:07:27  time: 0.1388  data_time: 0.0019  memory: 5847  loss: 0.9762  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.9762\n",
      "03/07 11:53:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2100/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:07:13  time: 0.1388  data_time: 0.0021  memory: 5847  loss: 1.1510  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1510\n",
      "03/07 11:53:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2200/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:06:59  time: 0.1377  data_time: 0.0020  memory: 5847  loss: 1.0923  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0923\n",
      "03/07 11:53:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2300/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:06:45  time: 0.1381  data_time: 0.0020  memory: 5847  loss: 1.3940  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3940\n",
      "03/07 11:54:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2400/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:06:31  time: 0.1370  data_time: 0.0021  memory: 5847  loss: 1.2576  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 1.2576\n",
      "03/07 11:54:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2500/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:06:18  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 1.3813  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.3813\n",
      "03/07 11:54:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:54:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2600/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:06:04  time: 0.1400  data_time: 0.0022  memory: 5847  loss: 1.1446  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.1446\n",
      "03/07 11:54:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2700/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:05:50  time: 0.1391  data_time: 0.0021  memory: 5847  loss: 1.1580  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1580\n",
      "03/07 11:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2800/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:05:36  time: 0.1398  data_time: 0.0019  memory: 5847  loss: 0.9017  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.9017\n",
      "03/07 11:55:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][2900/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:05:22  time: 0.1379  data_time: 0.0019  memory: 5847  loss: 1.1314  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1314\n",
      "03/07 11:55:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3000/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:05:08  time: 0.1386  data_time: 0.0020  memory: 5847  loss: 1.8659  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.8659\n",
      "03/07 11:55:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3100/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:04:54  time: 0.1383  data_time: 0.0023  memory: 5847  loss: 1.2210  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.2210\n",
      "03/07 11:55:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3200/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:04:40  time: 0.1378  data_time: 0.0020  memory: 5847  loss: 1.1121  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1121\n",
      "03/07 11:56:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3300/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:04:27  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 2.0364  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 2.0364\n",
      "03/07 11:56:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3400/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:04:13  time: 0.1388  data_time: 0.0019  memory: 5847  loss: 1.2149  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.2149\n",
      "03/07 11:56:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3500/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:03:59  time: 0.1411  data_time: 0.0022  memory: 5847  loss: 1.3122  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3122\n",
      "03/07 11:56:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:56:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3600/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:03:45  time: 0.1408  data_time: 0.0022  memory: 5847  loss: 1.9035  top1_acc: 0.5000  top5_acc: 0.5000  loss_cls: 1.9035\n",
      "03/07 11:57:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3700/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:03:31  time: 0.1381  data_time: 0.0021  memory: 5847  loss: 1.3861  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3861\n",
      "03/07 11:57:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3800/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:03:17  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 1.3402  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3402\n",
      "03/07 11:57:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][3900/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:03:03  time: 0.1386  data_time: 0.0022  memory: 5847  loss: 1.0285  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0285\n",
      "03/07 11:57:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4000/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:02:49  time: 0.1404  data_time: 0.0024  memory: 5847  loss: 1.3764  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.3764\n",
      "03/07 11:58:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4100/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:02:36  time: 0.1400  data_time: 0.0022  memory: 5847  loss: 1.1795  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.1795\n",
      "03/07 11:58:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4200/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:02:22  time: 0.1394  data_time: 0.0022  memory: 5847  loss: 1.4740  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.4740\n",
      "03/07 11:58:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4300/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:02:08  time: 0.1393  data_time: 0.0023  memory: 5847  loss: 1.2724  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2724\n",
      "03/07 11:58:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4400/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:01:54  time: 0.1379  data_time: 0.0021  memory: 5847  loss: 1.4995  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4995\n",
      "03/07 11:58:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4500/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:01:40  time: 0.1399  data_time: 0.0021  memory: 5847  loss: 1.2769  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2769\n",
      "03/07 11:59:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 11:59:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4600/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:01:26  time: 0.1378  data_time: 0.0021  memory: 5847  loss: 1.0110  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0110\n",
      "03/07 11:59:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4700/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:01:12  time: 0.1385  data_time: 0.0021  memory: 5847  loss: 1.4287  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.4287\n",
      "03/07 11:59:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4800/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:00:58  time: 0.1379  data_time: 0.0022  memory: 5847  loss: 1.2761  top1_acc: 0.0000  top5_acc: 0.5000  loss_cls: 1.2761\n",
      "03/07 11:59:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][4900/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:00:45  time: 0.1385  data_time: 0.0020  memory: 5847  loss: 1.6030  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6030\n",
      "03/07 12:00:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][5000/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:00:31  time: 0.1402  data_time: 0.0021  memory: 5847  loss: 1.5164  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.5164\n",
      "03/07 12:00:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][5100/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:00:17  time: 0.1402  data_time: 0.0021  memory: 5847  loss: 1.6353  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6353\n",
      "03/07 12:00:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][5200/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:00:03  time: 0.1414  data_time: 0.0028  memory: 5847  loss: 1.2980  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.2980\n",
      "03/07 12:00:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin_tiny_anticipation_20250307_064920\n",
      "03/07 12:00:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][5225/5225]  base_lr: 1.1936e-05 lr: 1.1936e-06  eta: 0:00:00  time: 0.1379  data_time: 0.0025  memory: 5847  loss: 1.0046  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 1.0046\n",
      "03/07 12:00:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 25 epochs\n",
      "03/07 12:00:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][100/647]    eta: 0:00:34  time: 0.0624  data_time: 0.0338  memory: 1333  \n",
      "03/07 12:00:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][200/647]    eta: 0:00:27  time: 0.0562  data_time: 0.0277  memory: 1333  \n",
      "03/07 12:00:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][300/647]    eta: 0:00:21  time: 0.0627  data_time: 0.0343  memory: 1333  \n",
      "03/07 12:01:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][400/647]    eta: 0:00:15  time: 0.0587  data_time: 0.0300  memory: 1333  \n",
      "03/07 12:01:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][500/647]    eta: 0:00:09  time: 0.0667  data_time: 0.0382  memory: 1333  \n",
      "03/07 12:01:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][600/647]    eta: 0:00:02  time: 0.0583  data_time: 0.0299  memory: 1333  \n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[3]\n",
      "[11]\n",
      "[4]\n",
      "[7]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[6]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[20]\n",
      "[4]\n",
      "[6]\n",
      "[1]\n",
      "[17]\n",
      "[3]\n",
      "[3]\n",
      "[20]\n",
      "[5]\n",
      "[3]\n",
      "[13]\n",
      "[14]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[6]\n",
      "[6]\n",
      "[14]\n",
      "[12]\n",
      "[17]\n",
      "[6]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[5]\n",
      "[4]\n",
      "[0]\n",
      "[8]\n",
      "[17]\n",
      "[3]\n",
      "[3]\n",
      "[5]\n",
      "[12]\n",
      "[8]\n",
      "[11]\n",
      "[9]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[13]\n",
      "[11]\n",
      "[17]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[5]\n",
      "[8]\n",
      "[0]\n",
      "[4]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[5]\n",
      "[21]\n",
      "[9]\n",
      "[11]\n",
      "[6]\n",
      "[22]\n",
      "[23]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[2]\n",
      "[21]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[22]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[3]\n",
      "[22]\n",
      "[23]\n",
      "[20]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[25]\n",
      "[6]\n",
      "[6]\n",
      "[16]\n",
      "[42]\n",
      "[31]\n",
      "[63]\n",
      "[19]\n",
      "[27]\n",
      "[27]\n",
      "[29]\n",
      "[29]\n",
      "[5]\n",
      "[29]\n",
      "[115]\n",
      "[27]\n",
      "[31]\n",
      "[31]\n",
      "[31]\n",
      "[67]\n",
      "[13]\n",
      "[17]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[27]\n",
      "[13]\n",
      "[41]\n",
      "[42]\n",
      "[17]\n",
      "[42]\n",
      "[19]\n",
      "[33]\n",
      "[33]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[17]\n",
      "[19]\n",
      "[3]\n",
      "[19]\n",
      "[19]\n",
      "[41]\n",
      "[19]\n",
      "[14]\n",
      "[41]\n",
      "[41]\n",
      "[41]\n",
      "[34]\n",
      "[27]\n",
      "[41]\n",
      "[35]\n",
      "[38]\n",
      "[35]\n",
      "[5]\n",
      "[40]\n",
      "[62]\n",
      "[19]\n",
      "[42]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[8]\n",
      "[12]\n",
      "[21]\n",
      "[34]\n",
      "[96]\n",
      "[34]\n",
      "[97]\n",
      "[43]\n",
      "[96]\n",
      "[21]\n",
      "[32]\n",
      "[57]\n",
      "[57]\n",
      "[52]\n",
      "[56]\n",
      "[46]\n",
      "[46]\n",
      "[58]\n",
      "[52]\n",
      "[51]\n",
      "[51]\n",
      "[52]\n",
      "[54]\n",
      "[51]\n",
      "[57]\n",
      "[46]\n",
      "[46]\n",
      "[9]\n",
      "[56]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[53]\n",
      "[9]\n",
      "[54]\n",
      "[10]\n",
      "[10]\n",
      "[9]\n",
      "[54]\n",
      "[54]\n",
      "[15]\n",
      "[58]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[44]\n",
      "[57]\n",
      "[58]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[48]\n",
      "[56]\n",
      "[54]\n",
      "[44]\n",
      "[51]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[54]\n",
      "[47]\n",
      "[44]\n",
      "[55]\n",
      "[52]\n",
      "[54]\n",
      "[59]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[52]\n",
      "[52]\n",
      "[54]\n",
      "[56]\n",
      "[57]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[59]\n",
      "[45]\n",
      "[44]\n",
      "[56]\n",
      "[59]\n",
      "[47]\n",
      "[45]\n",
      "[56]\n",
      "[7]\n",
      "[56]\n",
      "[54]\n",
      "[12]\n",
      "[54]\n",
      "[57]\n",
      "[48]\n",
      "[53]\n",
      "[47]\n",
      "[44]\n",
      "[56]\n",
      "[56]\n",
      "[31]\n",
      "[67]\n",
      "[31]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[63]\n",
      "[67]\n",
      "[67]\n",
      "[29]\n",
      "[29]\n",
      "[28]\n",
      "[70]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[69]\n",
      "[40]\n",
      "[67]\n",
      "[27]\n",
      "[68]\n",
      "[70]\n",
      "[47]\n",
      "[7]\n",
      "[47]\n",
      "[47]\n",
      "[67]\n",
      "[67]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[44]\n",
      "[67]\n",
      "[29]\n",
      "[69]\n",
      "[70]\n",
      "[70]\n",
      "[40]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[53]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[40]\n",
      "[68]\n",
      "[40]\n",
      "[67]\n",
      "[69]\n",
      "[70]\n",
      "[71]\n",
      "[44]\n",
      "[98]\n",
      "[100]\n",
      "[122]\n",
      "[98]\n",
      "[99]\n",
      "[98]\n",
      "[110]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[53]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[121]\n",
      "[53]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[98]\n",
      "[100]\n",
      "[99]\n",
      "[48]\n",
      "[44]\n",
      "[52]\n",
      "[100]\n",
      "[100]\n",
      "[48]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[97]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[71]\n",
      "[97]\n",
      "[100]\n",
      "[97]\n",
      "[98]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[71]\n",
      "[80]\n",
      "[90]\n",
      "[73]\n",
      "[89]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[88]\n",
      "[72]\n",
      "[81]\n",
      "[82]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[76]\n",
      "[86]\n",
      "[88]\n",
      "[80]\n",
      "[80]\n",
      "[86]\n",
      "[87]\n",
      "[80]\n",
      "[81]\n",
      "[81]\n",
      "[83]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[77]\n",
      "[86]\n",
      "[88]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[73]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[76]\n",
      "[73]\n",
      "[3]\n",
      "[78]\n",
      "[72]\n",
      "[72]\n",
      "[73]\n",
      "[75]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[83]\n",
      "[85]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[76]\n",
      "[84]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[79]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[71]\n",
      "[71]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[30]\n",
      "[71]\n",
      "[71]\n",
      "[84]\n",
      "[71]\n",
      "[14]\n",
      "[71]\n",
      "[40]\n",
      "[96]\n",
      "[101]\n",
      "[101]\n",
      "[96]\n",
      "[96]\n",
      "[101]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[101]\n",
      "[40]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[71]\n",
      "[79]\n",
      "[103]\n",
      "[71]\n",
      "[79]\n",
      "[79]\n",
      "[92]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[102]\n",
      "[62]\n",
      "[102]\n",
      "[40]\n",
      "[101]\n",
      "[102]\n",
      "[102]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[101]\n",
      "[100]\n",
      "[101]\n",
      "[92]\n",
      "[92]\n",
      "[96]\n",
      "[97]\n",
      "[0]\n",
      "[79]\n",
      "[79]\n",
      "[0]\n",
      "[79]\n",
      "[92]\n",
      "[100]\n",
      "[92]\n",
      "[92]\n",
      "[0]\n",
      "[97]\n",
      "[96]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[0]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[109]\n",
      "[97]\n",
      "[107]\n",
      "[71]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[71]\n",
      "[100]\n",
      "[97]\n",
      "[98]\n",
      "[97]\n",
      "[98]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[107]\n",
      "[111]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[107]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[110]\n",
      "[105]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[111]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[112]\n",
      "[106]\n",
      "[107]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[111]\n",
      "[107]\n",
      "[111]\n",
      "[107]\n",
      "03/07 12:01:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][647/647]    acc/top1: 0.2442  acc/top5: 0.6090  acc/mean1: 0.2965  data_time: 0.0324  time: 0.0610\n",
      "03/07 12:01:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint c:\\Users\\eddie\\Trauma_THOMPSON\\Trauma_THOMPSON\\VideoSwin\\exps\\swin_tiny_anticipation_regular\\best_acc_top1_epoch_24.pth is removed\n",
      "03/07 12:01:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.2442 acc/top1 at 25 epoch is saved to best_acc_top1_epoch_25.pth.\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "\n",
    "import torch\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "from multiprocessing import Process\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    # Check MMAction2 installaation\n",
    "    import mmaction\n",
    "    print(mmaction.__version__)\n",
    "\n",
    "    import mmcv\n",
    "    print(mmcv.__version__)\n",
    "\n",
    "    # Check MMCV installation\n",
    "    from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "    print(get_compiling_cuda_version())\n",
    "    print(get_compiler_version())\n",
    "\n",
    "    # Check MMEngine installation\n",
    "    from mmengine.utils.dl_utils import collect_env\n",
    "    print(collect_env())\n",
    "\n",
    "    from mmaction.apis import inference_recognizer, init_recognizer\n",
    "    from mmengine import Config\n",
    "\n",
    "    from operator import itemgetter\n",
    "\n",
    "    import os.path as osp\n",
    "    import mmengine\n",
    "    from mmengine.runner import Runner\n",
    "\n",
    "    # Choose to use a config and initialize the recognizer\n",
    "    # cfg = './swin-small-p244-w877_in1k-pre_8xb8-amp-32x2x1-30e_kinetics400-rgb.py'\n",
    "    cfg = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/swin_tiny_anticipation.py'\n",
    "    cfg = Config.fromfile(cfg)\n",
    "\n",
    "    # Set up working dir to save files and logs.\n",
    "    cfg.work_dir = './exps/swin_tiny_anticipation_regular'\n",
    "\n",
    "    # Create work_dir\n",
    "    mmengine.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "\n",
    "    # The original learning rate (LR) is set for 8-GPU training.\n",
    "    # We divide it by 8 since we only use one GPU.\n",
    "    cfg.train_dataloader.batch_size = cfg.train_dataloader.batch_size // 4\n",
    "    cfg.val_dataloader.batch_size = cfg.val_dataloader.batch_size // 4\n",
    "    cfg.test_dataloader.batch_size = 1\n",
    "    cfg.optim_wrapper.optimizer.lr = cfg.optim_wrapper.optimizer.lr / 8\n",
    "    cfg.train_cfg.max_epochs = 25\n",
    "\n",
    "\n",
    "    # We can initialize the logger for training and have a look\n",
    "    # at the final config used for training\n",
    "    print(f'Config:\\n{cfg.pretty_text}')\n",
    "\n",
    "    # Setup a checkpoint file to load\n",
    "    # checkpoint = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/videomaev2/best_acc_top1_epoch_23.pth'\n",
    "    # file = open('/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/uniformerv2_large/swin_last_checkpoint.pth', \"r\")\n",
    "    # checkpoint = file.read()\n",
    "    # file.close()\n",
    "\n",
    "    # Initialize the recognizer\n",
    "    model = init_recognizer(cfg, checkpoint=None, device='cuda:0')\n",
    "\n",
    "    # build the runner from config\n",
    "    runner = Runner.from_cfg(cfg)\n",
    "\n",
    "    # start training\n",
    "    runner.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryVoSfZVmogw"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu124 True\n",
      "1.2.0\n",
      "2.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddie\\anaconda3\\envs\\openmmlab\\Lib\\site-packages\\mmengine\\optim\\optimizer\\zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n",
      "MSVC 194134120\n",
      "OrderedDict([('sys.platform', 'win32'), ('Python', '3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]'), ('CUDA available', True), ('MUSA available', False), ('numpy_random_seed', 2147483648), ('GPU 0', 'NVIDIA GeForce RTX 4080 SUPER'), ('CUDA_HOME', 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.4'), ('NVCC', 'Cuda compilation tools, release 12.4, V12.4.99'), ('MSVC', 'n/a, reason: fileno'), ('PyTorch', '2.4.1+cu124'), ('PyTorch compiling details', 'PyTorch built with:\\n  - C++ Version: 201703\\n  - MSVC 192930154\\n  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\\n  - OpenMP 2019\\n  - LAPACK is enabled (usually provided by MKL)\\n  - CPU capability usage: AVX2\\n  - CUDA Runtime 12.4\\n  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\\n  - CuDNN 90.1\\n  - Magma 2.5.4\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \\n'), ('TorchVision', '0.19.1+cu124'), ('OpenCV', '4.10.0'), ('MMEngine', '0.10.5')])\n",
      "03/10 22:54:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 770021036\n",
      "    GPU 0: NVIDIA GeForce RTX 4080 SUPER\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.4\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.99\n",
      "    MSVC: n/a, reason: fileno\n",
      "    PyTorch: 2.4.1+cu124\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 201703\n",
      "  - MSVC 192930154\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.4\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 90.1\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.19.1+cu124\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 770021036\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/10 22:54:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt'\n",
      "ann_file_train = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_train_balanced.txt'\n",
      "ann_file_val = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt'\n",
      "auto_scale_lr = dict(base_batch_size=8, enable=False)\n",
      "data_root = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train/'\n",
      "data_root_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "dataset_type = 'RawframeDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=3, max_keep_ckpts=5, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/videomae_anticipation_regular/best_acc_top1_epoch_24.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=12,\n",
      "        embed_dims=384,\n",
      "        img_size=224,\n",
      "        mlp_ratio=4,\n",
      "        norm_cfg=dict(eps=1e-06, type='LN'),\n",
      "        num_frames=32,\n",
      "        num_heads=6,\n",
      "        patch_size=16,\n",
      "        pretrained=\n",
      "        '/Users/eddie/Downloads/vit-base-p16_videomaev2-vit-g-dist-k710-pre_16x4x1_kinetics-400_20230510-3e7f93b2 (1)',\n",
      "        qkv_bias=True,\n",
      "        type='VisionTransformer'),\n",
      "    cls_head=dict(\n",
      "        average_clips='prob',\n",
      "        in_channels=384,\n",
      "        num_classes=160,\n",
      "        type='TimeSformerHead'),\n",
      "    data_preprocessor=dict(\n",
      "        format_shape='NCTHW',\n",
      "        mean=[\n",
      "            114.75,\n",
      "            114.75,\n",
      "            114.75,\n",
      "        ],\n",
      "        std=[\n",
      "            57.375,\n",
      "            57.375,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='ActionDataPreprocessor'),\n",
      "    type='Recognizer3D')\n",
      "optim_wrapper = dict(\n",
      "    constructor='SwinOptimWrapperConstructor',\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=0.001, type='AdamW', weight_decay=0.02),\n",
      "    paramwise_cfg=dict(\n",
      "        absolute_pos_embed=dict(decay_mult=0.0),\n",
      "        backbone=dict(lr_mult=0.1),\n",
      "        norm=dict(decay_mult=0.0),\n",
      "        relative_position_bias_table=dict(decay_mult=0.0)),\n",
      "    type='AmpOptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=2.5,\n",
      "        start_factor=0.1,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        T_max=30,\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=30,\n",
      "        eta_min=0,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=4,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='ThreeCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(type='AccMetric')\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=4,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='ThreeCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=100, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_train_balanced.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                224,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(flip_ratio=0.5, type='Flip'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(clip_len=32, frame_interval=2, num_clips=1, type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        224,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(flip_ratio=0.5, type='Flip'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(type='AccMetric')\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='CenterCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './exps/videomae_anticipation_regular'\n",
      "\n",
      "03/10 22:54:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/10 22:54:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: /Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/videomae_anticipation_regular/best_acc_top1_epoch_24.pth\n",
      "03/10 22:54:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/videomae_anticipation_regular/best_acc_top1_epoch_24.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddie\\anaconda3\\envs\\openmmlab\\Lib\\site-packages\\mmengine\\runner\\checkpoint.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, map_location=map_location)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 69\u001b[0m\n\u001b[0;32m     64\u001b[0m    runner_test \u001b[38;5;241m=\u001b[39m Runner\u001b[38;5;241m.\u001b[39mbuild(cfg)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# start testing\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m \u001b[43mrunner_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eddie\\anaconda3\\envs\\openmmlab\\Lib\\site-packages\\mmengine\\runner\\runner.py:1823\u001b[0m, in \u001b[0;36mRunner.test\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1820\u001b[0m \u001b[38;5;66;03m# make sure checkpoint-related hooks are triggered after `before_run`\u001b[39;00m\n\u001b[0;32m   1821\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_or_resume()\n\u001b[1;32m-> 1823\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1824\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_run\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "File \u001b[1;32mc:\\Users\\eddie\\anaconda3\\envs\\openmmlab\\Lib\\site-packages\\mmengine\\runner\\loops.py:463\u001b[0m, in \u001b[0;36mTestLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loss\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, data_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader):\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;66;03m# compute metrics\u001b[39;00m\n\u001b[0;32m    466\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader\u001b[38;5;241m.\u001b[39mdataset))\n",
      "File \u001b[1;32mc:\\Users\\eddie\\anaconda3\\envs\\openmmlab\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eddie\\anaconda3\\envs\\openmmlab\\Lib\\site-packages\\mmengine\\runner\\loops.py:491\u001b[0m, in \u001b[0;36mTestLoop.run_iter\u001b[1;34m(self, idx, data_batch)\u001b[0m\n\u001b[0;32m    487\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtest_step(data_batch)\n\u001b[0;32m    489\u001b[0m outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loss \u001b[38;5;241m=\u001b[39m _update_losses(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loss)\n\u001b[1;32m--> 491\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_test_iter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    494\u001b[0m     batch_idx\u001b[38;5;241m=\u001b[39midx,\n\u001b[0;32m    495\u001b[0m     data_batch\u001b[38;5;241m=\u001b[39mdata_batch,\n\u001b[0;32m    496\u001b[0m     outputs\u001b[38;5;241m=\u001b[39moutputs)\n",
      "File \u001b[1;32mc:\\Users\\eddie\\anaconda3\\envs\\openmmlab\\Lib\\site-packages\\mmengine\\evaluator\\evaluator.py:60\u001b[0m, in \u001b[0;36mEvaluator.process\u001b[1;34m(self, data_samples, data_batch)\u001b[0m\n\u001b[0;32m     57\u001b[0m         _data_samples\u001b[38;5;241m.\u001b[39mappend(data_sample)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics:\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_data_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\eddie\\trauma_thompson\\trauma_thompson\\mmaction2\\mmaction\\evaluation\\metrics\\acc_metric.py:86\u001b[0m, in \u001b[0;36mAccMetric.process\u001b[1;34m(self, data_batch, data_samples)\u001b[0m\n\u001b[0;32m     84\u001b[0m         pred[item_name] \u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     88\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pred\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;66;03m# single-label\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "from multiprocessing import Process\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    # Check MMAction2 installaation\n",
    "    import mmaction\n",
    "    print(mmaction.__version__)\n",
    "\n",
    "    import mmcv\n",
    "    print(mmcv.__version__)\n",
    "\n",
    "    # Check MMCV installation\n",
    "    from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "    print(get_compiling_cuda_version())\n",
    "    print(get_compiler_version())\n",
    "\n",
    "    # Check MMEngine installation\n",
    "    from mmengine.utils.dl_utils import collect_env\n",
    "    print(collect_env())\n",
    "\n",
    "    from mmaction.apis import inference_recognizer, init_recognizer\n",
    "    from mmengine import Config\n",
    "\n",
    "    from operator import itemgetter\n",
    "\n",
    "    import os.path as osp\n",
    "    import mmengine\n",
    "    from mmengine.runner import Runner\n",
    "\n",
    "from mmengine.runner import Runner\n",
    "checkpoint = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/videomae_anticipation_regular/best_acc_top1_epoch_24.pth'\n",
    "\n",
    "\n",
    "\n",
    "cfg = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/videomae_anticipation_regular.py'\n",
    "\n",
    "cfg = Config.fromfile(cfg)\n",
    "\n",
    "cfg.load_from = checkpoint\n",
    "\n",
    "cfg.work_dir = './exps/videomae_anticipation_regular'\n",
    "\n",
    "cfg.test_dataloader.dataset.ann_file = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt'\n",
    "\n",
    "cfg.test_dataloader.dataset.data_prefix.img = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
    "\n",
    "\n",
    "# build the runner from config\n",
    "\n",
    "if 'runner_type' not in cfg:\n",
    "\n",
    "   # build the default runner\n",
    "\n",
    "   runner_test = Runner.from_cfg(cfg)\n",
    "\n",
    "else:\n",
    "\n",
    "   # build customized runner from the registry\n",
    "\n",
    "   # if 'runner_type' is set in the cfg\n",
    "\n",
    "   runner_test = Runner.build(cfg)\n",
    "\n",
    "\n",
    "# start testing\n",
    "\n",
    "runner_test.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/07 17:50:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1663756078\n",
      "    GPU 0: NVIDIA GeForce RTX 4080 SUPER\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.4\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.99\n",
      "    MSVC: n/a, reason: fileno\n",
      "    PyTorch: 2.4.1+cu124\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 201703\n",
      "  - MSVC 192930154\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.4\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 90.1\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.19.1+cu124\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1663756078\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/07 17:50:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt'\n",
      "ann_file_train = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_train_balanced.txt'\n",
      "ann_file_val = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt'\n",
      "auto_scale_lr = dict(base_batch_size=8, enable=False)\n",
      "data_root = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train/'\n",
      "data_root_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "dataset_type = 'RawframeDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=3, max_keep_ckpts=5, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/swin_tiny_anticipation_regular/best_acc_top1_epoch_25.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        arch='tiny',\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1,\n",
      "        drop_rate=0.0,\n",
      "        mlp_ratio=4.0,\n",
      "        patch_norm=True,\n",
      "        patch_size=(\n",
      "            2,\n",
      "            4,\n",
      "            4,\n",
      "        ),\n",
      "        pretrained=\n",
      "        'https://download.openmmlab.com/mmaction/v1.0/recognition/swin/swin_tiny_patch4_window7_224.pth',\n",
      "        pretrained2d=False,\n",
      "        qk_scale=None,\n",
      "        qkv_bias=True,\n",
      "        type='SwinTransformer3D',\n",
      "        window_size=(\n",
      "            8,\n",
      "            7,\n",
      "            7,\n",
      "        )),\n",
      "    cls_head=dict(\n",
      "        average_clips='prob',\n",
      "        dropout_ratio=0.5,\n",
      "        in_channels=768,\n",
      "        num_classes=160,\n",
      "        spatial_type='avg',\n",
      "        type='I3DHead'),\n",
      "    data_preprocessor=dict(\n",
      "        format_shape='NCTHW',\n",
      "        mean=[\n",
      "            113.8477,\n",
      "            104.25,\n",
      "            100.3492,\n",
      "        ],\n",
      "        std=[\n",
      "            60.7003,\n",
      "            56.8895,\n",
      "            57.735,\n",
      "        ],\n",
      "        type='ActionDataPreprocessor'),\n",
      "    type='Recognizer3D')\n",
      "optim_wrapper = dict(\n",
      "    constructor='SwinOptimWrapperConstructor',\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=0.001, type='AdamW', weight_decay=0.02),\n",
      "    paramwise_cfg=dict(\n",
      "        absolute_pos_embed=dict(decay_mult=0.0),\n",
      "        backbone=dict(lr_mult=0.1),\n",
      "        norm=dict(decay_mult=0.0),\n",
      "        relative_position_bias_table=dict(decay_mult=0.0)),\n",
      "    type='AmpOptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=2.5,\n",
      "        start_factor=0.1,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        T_max=30,\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=30,\n",
      "        eta_min=0,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=4,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='ThreeCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(type='AccMetric')\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=4,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='ThreeCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=100, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_train_balanced.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                224,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(flip_ratio=0.5, type='Flip'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(clip_len=32, frame_interval=2, num_clips=1, type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        224,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(flip_ratio=0.5, type='Flip'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(type='AccMetric')\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='CenterCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './exps/swin_tiny_anticipation_regular'\n",
      "\n",
      "03/07 17:50:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/07 17:50:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddie\\anaconda3\\envs\\openmmlab\\Lib\\site-packages\\torch\\functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3610.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/swin_tiny_anticipation_regular/best_acc_top1_epoch_25.pth\n",
      "03/07 17:50:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/swin_tiny_anticipation_regular/best_acc_top1_epoch_25.pth\n",
      "03/07 17:51:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [100/647]    eta: 0:03:31  time: 0.3603  data_time: 0.0071  memory: 8149  \n",
      "03/07 17:52:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [200/647]    eta: 0:02:46  time: 0.3518  data_time: 0.0069  memory: 8149  \n",
      "03/07 17:52:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [300/647]    eta: 0:02:06  time: 0.3521  data_time: 0.0071  memory: 8149  \n",
      "03/07 17:53:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [400/647]    eta: 0:01:29  time: 0.3519  data_time: 0.0069  memory: 8149  \n",
      "03/07 17:53:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [500/647]    eta: 0:00:52  time: 0.3518  data_time: 0.0071  memory: 8149  \n",
      "03/07 17:54:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [600/647]    eta: 0:00:16  time: 0.3522  data_time: 0.0071  memory: 8149  \n",
      "[0]\n",
      "[1]\n",
      "[17]\n",
      "[20]\n",
      "[4]\n",
      "[5]\n",
      "[4]\n",
      "[7]\n",
      "[11]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[11]\n",
      "[17]\n",
      "[21]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[20]\n",
      "[4]\n",
      "[0]\n",
      "[1]\n",
      "[17]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[5]\n",
      "[3]\n",
      "[1]\n",
      "[20]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[11]\n",
      "[6]\n",
      "[13]\n",
      "[13]\n",
      "[5]\n",
      "[17]\n",
      "[16]\n",
      "[17]\n",
      "[17]\n",
      "[20]\n",
      "[21]\n",
      "[4]\n",
      "[0]\n",
      "[21]\n",
      "[17]\n",
      "[6]\n",
      "[13]\n",
      "[5]\n",
      "[13]\n",
      "[5]\n",
      "[17]\n",
      "[17]\n",
      "[11]\n",
      "[11]\n",
      "[9]\n",
      "[12]\n",
      "[13]\n",
      "[13]\n",
      "[17]\n",
      "[17]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[5]\n",
      "[4]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[5]\n",
      "[5]\n",
      "[22]\n",
      "[4]\n",
      "[9]\n",
      "[11]\n",
      "[22]\n",
      "[23]\n",
      "[23]\n",
      "[25]\n",
      "[26]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[5]\n",
      "[0]\n",
      "[21]\n",
      "[2]\n",
      "[3]\n",
      "[21]\n",
      "[5]\n",
      "[22]\n",
      "[20]\n",
      "[9]\n",
      "[11]\n",
      "[11]\n",
      "[22]\n",
      "[23]\n",
      "[20]\n",
      "[25]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[25]\n",
      "[25]\n",
      "[25]\n",
      "[26]\n",
      "[19]\n",
      "[31]\n",
      "[19]\n",
      "[19]\n",
      "[27]\n",
      "[27]\n",
      "[100]\n",
      "[29]\n",
      "[31]\n",
      "[29]\n",
      "[63]\n",
      "[3]\n",
      "[31]\n",
      "[63]\n",
      "[31]\n",
      "[35]\n",
      "[13]\n",
      "[19]\n",
      "[42]\n",
      "[42]\n",
      "[42]\n",
      "[27]\n",
      "[13]\n",
      "[41]\n",
      "[19]\n",
      "[17]\n",
      "[19]\n",
      "[19]\n",
      "[27]\n",
      "[27]\n",
      "[42]\n",
      "[42]\n",
      "[36]\n",
      "[27]\n",
      "[41]\n",
      "[42]\n",
      "[17]\n",
      "[19]\n",
      "[27]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[19]\n",
      "[41]\n",
      "[19]\n",
      "[19]\n",
      "[41]\n",
      "[27]\n",
      "[35]\n",
      "[35]\n",
      "[35]\n",
      "[35]\n",
      "[21]\n",
      "[37]\n",
      "[62]\n",
      "[19]\n",
      "[42]\n",
      "[19]\n",
      "[41]\n",
      "[42]\n",
      "[8]\n",
      "[21]\n",
      "[21]\n",
      "[97]\n",
      "[96]\n",
      "[21]\n",
      "[97]\n",
      "[43]\n",
      "[96]\n",
      "[21]\n",
      "[100]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[56]\n",
      "[51]\n",
      "[46]\n",
      "[58]\n",
      "[52]\n",
      "[51]\n",
      "[51]\n",
      "[52]\n",
      "[52]\n",
      "[51]\n",
      "[57]\n",
      "[45]\n",
      "[45]\n",
      "[56]\n",
      "[56]\n",
      "[52]\n",
      "[56]\n",
      "[54]\n",
      "[54]\n",
      "[57]\n",
      "[54]\n",
      "[9]\n",
      "[54]\n",
      "[9]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[58]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[9]\n",
      "[57]\n",
      "[54]\n",
      "[57]\n",
      "[57]\n",
      "[57]\n",
      "[54]\n",
      "[52]\n",
      "[54]\n",
      "[55]\n",
      "[51]\n",
      "[46]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[54]\n",
      "[54]\n",
      "[15]\n",
      "[55]\n",
      "[52]\n",
      "[54]\n",
      "[52]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[54]\n",
      "[27]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[56]\n",
      "[56]\n",
      "[12]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[45]\n",
      "[44]\n",
      "[44]\n",
      "[57]\n",
      "[57]\n",
      "[44]\n",
      "[56]\n",
      "[57]\n",
      "[56]\n",
      "[59]\n",
      "[12]\n",
      "[59]\n",
      "[52]\n",
      "[8]\n",
      "[44]\n",
      "[47]\n",
      "[56]\n",
      "[56]\n",
      "[56]\n",
      "[31]\n",
      "[67]\n",
      "[70]\n",
      "[70]\n",
      "[31]\n",
      "[31]\n",
      "[67]\n",
      "[67]\n",
      "[63]\n",
      "[29]\n",
      "[29]\n",
      "[28]\n",
      "[70]\n",
      "[69]\n",
      "[27]\n",
      "[67]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[63]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[40]\n",
      "[67]\n",
      "[27]\n",
      "[70]\n",
      "[70]\n",
      "[47]\n",
      "[7]\n",
      "[29]\n",
      "[47]\n",
      "[67]\n",
      "[29]\n",
      "[70]\n",
      "[68]\n",
      "[69]\n",
      "[69]\n",
      "[70]\n",
      "[29]\n",
      "[29]\n",
      "[70]\n",
      "[70]\n",
      "[70]\n",
      "[69]\n",
      "[69]\n",
      "[69]\n",
      "[63]\n",
      "[68]\n",
      "[70]\n",
      "[66]\n",
      "[40]\n",
      "[70]\n",
      "[69]\n",
      "[70]\n",
      "[67]\n",
      "[69]\n",
      "[70]\n",
      "[71]\n",
      "[44]\n",
      "[98]\n",
      "[100]\n",
      "[122]\n",
      "[98]\n",
      "[100]\n",
      "[99]\n",
      "[110]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[44]\n",
      "[53]\n",
      "[98]\n",
      "[98]\n",
      "[99]\n",
      "[98]\n",
      "[98]\n",
      "[53]\n",
      "[98]\n",
      "[99]\n",
      "[98]\n",
      "[98]\n",
      "[51]\n",
      "[99]\n",
      "[48]\n",
      "[52]\n",
      "[51]\n",
      "[51]\n",
      "[51]\n",
      "[52]\n",
      "[100]\n",
      "[71]\n",
      "[71]\n",
      "[52]\n",
      "[71]\n",
      "[100]\n",
      "[52]\n",
      "[52]\n",
      "[100]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[100]\n",
      "[97]\n",
      "[8]\n",
      "[52]\n",
      "[52]\n",
      "[52]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[100]\n",
      "[72]\n",
      "[90]\n",
      "[73]\n",
      "[89]\n",
      "[80]\n",
      "[76]\n",
      "[77]\n",
      "[88]\n",
      "[72]\n",
      "[81]\n",
      "[82]\n",
      "[7]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[86]\n",
      "[89]\n",
      "[86]\n",
      "[86]\n",
      "[88]\n",
      "[80]\n",
      "[80]\n",
      "[73]\n",
      "[87]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[90]\n",
      "[86]\n",
      "[88]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[73]\n",
      "[80]\n",
      "[80]\n",
      "[80]\n",
      "[77]\n",
      "[90]\n",
      "[80]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[73]\n",
      "[86]\n",
      "[90]\n",
      "[76]\n",
      "[76]\n",
      "[73]\n",
      "[76]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[86]\n",
      "[86]\n",
      "[86]\n",
      "[87]\n",
      "[74]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[86]\n",
      "[88]\n",
      "[78]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[30]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[100]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[30]\n",
      "[91]\n",
      "[91]\n",
      "[31]\n",
      "[88]\n",
      "[71]\n",
      "[71]\n",
      "[83]\n",
      "[71]\n",
      "[71]\n",
      "[43]\n",
      "[40]\n",
      "[96]\n",
      "[101]\n",
      "[101]\n",
      "[64]\n",
      "[64]\n",
      "[102]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[101]\n",
      "[40]\n",
      "[64]\n",
      "[102]\n",
      "[102]\n",
      "[71]\n",
      "[101]\n",
      "[103]\n",
      "[101]\n",
      "[79]\n",
      "[79]\n",
      "[92]\n",
      "[101]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[101]\n",
      "[71]\n",
      "[102]\n",
      "[62]\n",
      "[102]\n",
      "[40]\n",
      "[96]\n",
      "[102]\n",
      "[102]\n",
      "[102]\n",
      "[100]\n",
      "[100]\n",
      "[92]\n",
      "[101]\n",
      "[102]\n",
      "[102]\n",
      "[92]\n",
      "[92]\n",
      "[96]\n",
      "[96]\n",
      "[0]\n",
      "[96]\n",
      "[96]\n",
      "[0]\n",
      "[98]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[0]\n",
      "[96]\n",
      "[0]\n",
      "[96]\n",
      "[96]\n",
      "[97]\n",
      "[0]\n",
      "[104]\n",
      "[92]\n",
      "[92]\n",
      "[92]\n",
      "[97]\n",
      "[97]\n",
      "[107]\n",
      "[71]\n",
      "[97]\n",
      "[100]\n",
      "[71]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[95]\n",
      "[100]\n",
      "[100]\n",
      "[71]\n",
      "[100]\n",
      "[97]\n",
      "[96]\n",
      "[100]\n",
      "[105]\n",
      "[105]\n",
      "[107]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[112]\n",
      "[105]\n",
      "[112]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[105]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[108]\n",
      "[111]\n",
      "[108]\n",
      "[105]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[111]\n",
      "[107]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[111]\n",
      "[109]\n",
      "[107]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[113]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[111]\n",
      "[107]\n",
      "[111]\n",
      "[107]\n",
      "03/07 17:54:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [647/647]    acc/top1: 0.2427  acc/top5: 0.6121  acc/mean1: 0.2980  data_time: 0.0106  time: 0.3583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc/top1': 0.2426584234930448,\n",
       " 'acc/top5': 0.6120556414219475,\n",
       " 'acc/mean1': 0.29803733863472115}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmengine.runner import Runner\n",
    "checkpoint = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/swin_tiny_anticipation_regular/best_acc_top1_epoch_25.pth'\n",
    "\n",
    "\n",
    "\n",
    "cfg = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/swin_tiny_anticipation.py'\n",
    "\n",
    "cfg = Config.fromfile(cfg)\n",
    "\n",
    "cfg.load_from = checkpoint\n",
    "\n",
    "cfg.work_dir = './exps/swin_tiny_anticipation_regular'\n",
    "\n",
    "cfg.test_dataloader.dataset.ann_file = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt'\n",
    "\n",
    "cfg.test_dataloader.dataset.data_prefix.img = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
    "\n",
    "# build the runner from config\n",
    "\n",
    "if 'runner_type' not in cfg:\n",
    "\n",
    "   # build the default runner\n",
    "\n",
    "   runner_test = Runner.from_cfg(cfg)\n",
    "\n",
    "else:\n",
    "\n",
    "   # build customized runner from the registry\n",
    "\n",
    "   # if 'runner_type' is set in the cfg\n",
    "\n",
    "   runner_test = Runner.build(cfg)\n",
    "\n",
    "\n",
    "# start testing\n",
    "\n",
    "runner_test.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/06 13:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 310071720\n",
      "    GPU 0: NVIDIA GeForce RTX 4080 SUPER\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.4\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.99\n",
      "    MSVC: n/a, reason: fileno\n",
      "    PyTorch: 2.4.1+cu124\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 201703\n",
      "  - MSVC 192930154\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.4\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 90.1\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.19.1+cu124\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 310071720\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/06 13:44:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/annotations_test.txt'\n",
      "ann_file_train = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/annotations_train_balanced.txt'\n",
      "ann_file_val = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/annotations_test.txt'\n",
      "auto_scale_lr = dict(base_batch_size=8, enable=False)\n",
      "data_root = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train'\n",
      "data_root_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test'\n",
      "dataset_type = 'RawframeDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=3, max_keep_ckpts=5, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/mvitv2_regular/best_acc_top1_epoch_53.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        arch='small',\n",
      "        drop_path_rate=0.2,\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmaction/v1.0/recognition/mvit/converted/mvit-small-p244_16x4x1_kinetics400-rgb_20221021-9ebaaeed.pth',\n",
      "            prefix='backbone.',\n",
      "            type='Pretrained'),\n",
      "        type='MViT'),\n",
      "    cls_head=dict(\n",
      "        average_clips='prob',\n",
      "        in_channels=768,\n",
      "        label_smooth_eps=0.1,\n",
      "        num_classes=162,\n",
      "        type='MViTHead'),\n",
      "    data_preprocessor=dict(\n",
      "        format_shape='NCTHW',\n",
      "        mean=[\n",
      "            114.75,\n",
      "            114.75,\n",
      "            114.75,\n",
      "        ],\n",
      "        std=[\n",
      "            57.375,\n",
      "            57.375,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='ActionDataPreprocessor'),\n",
      "    type='Recognizer3D')\n",
      "optim_wrapper = dict(\n",
      "    constructor='SwinOptimWrapperConstructor',\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=0.001, type='AdamW', weight_decay=0.02),\n",
      "    paramwise_cfg=dict(\n",
      "        absolute_pos_embed=dict(decay_mult=0.0),\n",
      "        backbone=dict(lr_mult=0.1),\n",
      "        norm=dict(decay_mult=0.0),\n",
      "        relative_position_bias_table=dict(decay_mult=0.0)),\n",
      "    type='AmpOptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=2.5,\n",
      "        start_factor=0.1,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        T_max=30,\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=30,\n",
      "        eta_min=0,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/annotations_regular_train.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=4,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='ThreeCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(type='AccMetric')\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=4,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='ThreeCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=100, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/annotations_train_balanced.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                224,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(flip_ratio=0.5, type='Flip'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(clip_len=32, frame_interval=2, num_clips=1, type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        224,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(flip_ratio=0.5, type='Flip'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/annotations_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(type='AccMetric')\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='CenterCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './exps/mvitv2_regular'\n",
      "\n",
      "03/06 13:44:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/06 13:44:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: /Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/mvitv2_regular/best_acc_top1_epoch_53.pth\n",
      "03/06 13:44:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/mvitv2_regular/best_acc_top1_epoch_53.pth\n",
      "03/06 13:49:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 100/2476]    eta: 2:12:05  time: 3.2568  data_time: 0.0067  memory: 10770  \n",
      "03/06 13:55:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 200/2476]    eta: 2:05:04  time: 3.2585  data_time: 0.0070  memory: 10770  \n",
      "03/06 14:00:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 300/2476]    eta: 1:59:06  time: 3.2579  data_time: 0.0068  memory: 10770  \n",
      "03/06 14:06:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 400/2476]    eta: 1:53:24  time: 3.2588  data_time: 0.0066  memory: 10770  \n",
      "03/06 14:11:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 500/2476]    eta: 1:47:48  time: 3.2582  data_time: 0.0066  memory: 10770  \n",
      "03/06 14:17:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 600/2476]    eta: 1:42:16  time: 3.2589  data_time: 0.0065  memory: 10770  \n",
      "03/06 14:22:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 700/2476]    eta: 1:36:46  time: 3.2574  data_time: 0.0067  memory: 10770  \n",
      "03/06 14:27:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 800/2476]    eta: 1:31:16  time: 3.2586  data_time: 0.0067  memory: 10770  \n",
      "03/06 14:33:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 900/2476]    eta: 1:25:48  time: 3.2578  data_time: 0.0066  memory: 10770  \n",
      "03/06 14:38:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1000/2476]    eta: 1:20:20  time: 3.2586  data_time: 0.0067  memory: 10770  \n",
      "03/06 14:44:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1100/2476]    eta: 1:14:53  time: 3.2588  data_time: 0.0068  memory: 10770  \n",
      "03/06 14:49:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1200/2476]    eta: 1:09:25  time: 3.2565  data_time: 0.0069  memory: 10770  \n",
      "03/06 14:55:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1300/2476]    eta: 1:03:58  time: 3.2575  data_time: 0.0066  memory: 10770  \n",
      "03/06 15:00:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1400/2476]    eta: 0:58:31  time: 3.2565  data_time: 0.0066  memory: 10770  \n",
      "03/06 15:05:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1500/2476]    eta: 0:53:05  time: 3.2582  data_time: 0.0066  memory: 10770  \n",
      "03/06 15:11:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1600/2476]    eta: 0:47:38  time: 3.2576  data_time: 0.0065  memory: 10770  \n",
      "03/06 15:16:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1700/2476]    eta: 0:42:12  time: 3.2744  data_time: 0.0066  memory: 10770  \n",
      "03/06 15:22:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1800/2476]    eta: 0:36:46  time: 3.2737  data_time: 0.0069  memory: 10770  \n",
      "03/06 15:27:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1900/2476]    eta: 0:31:20  time: 3.2584  data_time: 0.0069  memory: 10770  \n",
      "03/06 15:33:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2000/2476]    eta: 0:25:53  time: 3.2570  data_time: 0.0068  memory: 10770  \n",
      "03/06 15:38:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2100/2476]    eta: 0:20:27  time: 3.2576  data_time: 0.0070  memory: 10770  \n",
      "03/06 15:43:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2200/2476]    eta: 0:15:00  time: 3.2562  data_time: 0.0072  memory: 10770  \n",
      "03/06 15:49:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2300/2476]    eta: 0:09:34  time: 3.2576  data_time: 0.0068  memory: 10770  \n",
      "03/06 15:54:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2400/2476]    eta: 0:04:07  time: 3.2587  data_time: 0.0067  memory: 10770  \n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[9]\n",
      "[8]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[19]\n",
      "[20]\n",
      "[21]\n",
      "[6]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[0]\n",
      "[8]\n",
      "[9]\n",
      "[10]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[10]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[21]\n",
      "[6]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[10]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[9]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[21]\n",
      "[6]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[9]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[21]\n",
      "[6]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[10]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[21]\n",
      "[6]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[21]\n",
      "[6]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[7]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[6]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[6]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[6]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[6]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[11]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[6]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[6]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[22]\n",
      "[22]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[22]\n",
      "[22]\n",
      "[23]\n",
      "[23]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[6]\n",
      "[12]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[22]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[20]\n",
      "[6]\n",
      "[6]\n",
      "[25]\n",
      "[26]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[25]\n",
      "[26]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[20]\n",
      "[6]\n",
      "[6]\n",
      "[25]\n",
      "[26]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[25]\n",
      "[26]\n",
      "[3]\n",
      "[1]\n",
      "[2]\n",
      "[6]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[20]\n",
      "[21]\n",
      "[6]\n",
      "[25]\n",
      "[26]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[23]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[20]\n",
      "[6]\n",
      "[25]\n",
      "[25]\n",
      "[26]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[11]\n",
      "[12]\n",
      "[22]\n",
      "[23]\n",
      "[10]\n",
      "[15]\n",
      "[24]\n",
      "[16]\n",
      "[20]\n",
      "[21]\n",
      "[21]\n",
      "[25]\n",
      "[26]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[4]\n",
      "[4]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "[5]\n",
      "[29]\n",
      "[30]\n",
      "[31]\n",
      "[31]\n",
      "[7]\n",
      "[8]\n",
      "[8]\n",
      "[8]\n",
      "[8]\n",
      "[8]\n",
      "[8]\n",
      "[12]\n",
      "[13]\n",
      "[41]\n",
      "[14]\n",
      "[16]\n",
      "[32]\n",
      "[17]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "[19]\n",
      "[20]\n",
      "[21]\n",
      "[6]\n",
      "[33]\n",
      "[34]\n",
      "[35]\n",
      "[36]\n",
      "[37]\n",
      "[37]\n",
      "[38]\n",
      "[39]\n",
      "[40]\n",
      "[41]\n",
      "[42]\n",
      "[41]\n",
      "[43]\n",
      "[42]\n",
      "[42]\n",
      "[0]\n",
      "[44]\n",
      "[2]\n",
      "[3]\n",
      "[63]\n",
      "[44]\n",
      "[9]\n",
      "[0]\n",
      "[8]\n",
      "[44]\n",
      "[46]\n",
      "[46]\n",
      "[15]\n",
      "[48]\n",
      "[48]\n",
      "[15]\n",
      "[16]\n",
      "[48]\n",
      "[7]\n",
      "[0]\n",
      "[8]\n",
      "[12]\n",
      "[7]\n",
      "[11]\n",
      "[12]\n",
      "[15]\n",
      "[16]\n",
      "[34]\n",
      "[35]\n",
      "[16]\n",
      "[19]\n",
      "[20]\n",
      "[21]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[7]\n",
      "[8]\n",
      "[11]\n",
      "[49]\n",
      "[13]\n",
      "[13]\n",
      "[0]\n",
      "[14]\n",
      "[14]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[32]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[34]\n",
      "[35]\n",
      "[35]\n",
      "[19]\n",
      "[20]\n",
      "[21]\n",
      "[35]\n",
      "[43]\n",
      "[0]\n",
      "[7]\n",
      "[8]\n",
      "[13]\n",
      "[13]\n",
      "[14]\n",
      "[50]\n",
      "[15]\n",
      "[16]\n",
      "[32]\n",
      "[16]\n",
      "[32]\n",
      "[50]\n",
      "[7]\n",
      "[7]\n",
      "[12]\n",
      "[32]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[18]\n",
      "[19]\n",
      "[20]\n",
      "[19]\n",
      "[6]\n",
      "[34]\n",
      "[35]\n",
      "[33]\n",
      "[36]\n",
      "[43]\n",
      "[7]\n",
      "[8]\n",
      "[12]\n",
      "[44]\n",
      "[0]\n",
      "[46]\n",
      "[48]\n",
      "[10]\n",
      "[59]\n",
      "[15]\n",
      "[51]\n",
      "[9]\n",
      "[52]\n",
      "[52]\n",
      "[53]\n",
      "[53]\n",
      "[54]\n",
      "[45]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[10]\n",
      "[7]\n",
      "[8]\n",
      "[12]\n",
      "[44]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[59]\n",
      "[59]\n",
      "[15]\n",
      "[16]\n",
      "[10]\n",
      "[54]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[0]\n",
      "[7]\n",
      "[8]\n",
      "[45]\n",
      "[44]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[15]\n",
      "[51]\n",
      "[9]\n",
      "[52]\n",
      "[53]\n",
      "[48]\n",
      "[10]\n",
      "[54]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[0]\n",
      "[7]\n",
      "[0]\n",
      "[8]\n",
      "[8]\n",
      "[9]\n",
      "[9]\n",
      "[8]\n",
      "[9]\n",
      "[10]\n",
      "[12]\n",
      "[44]\n",
      "[46]\n",
      "[47]\n",
      "[59]\n",
      "[59]\n",
      "[48]\n",
      "[15]\n",
      "[51]\n",
      "[52]\n",
      "[53]\n",
      "[48]\n",
      "[54]\n",
      "[45]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[1]\n",
      "[0]\n",
      "[2]\n",
      "[3]\n",
      "[27]\n",
      "[4]\n",
      "[60]\n",
      "[28]\n",
      "[29]\n",
      "[5]\n",
      "[5]\n",
      "[44]\n",
      "[15]\n",
      "[51]\n",
      "[63]\n",
      "[63]\n",
      "[61]\n",
      "[53]\n",
      "[50]\n",
      "[46]\n",
      "[46]\n",
      "[46]\n",
      "[48]\n",
      "[51]\n",
      "[52]\n",
      "[53]\n",
      "[48]\n",
      "[52]\n",
      "[40]\n",
      "[62]\n",
      "[63]\n",
      "[63]\n",
      "[63]\n",
      "[40]\n",
      "[64]\n",
      "[43]\n",
      "[0]\n",
      "[7]\n",
      "[7]\n",
      "[12]\n",
      "[7]\n",
      "[59]\n",
      "[59]\n",
      "[46]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[59]\n",
      "[59]\n",
      "[10]\n",
      "[15]\n",
      "[51]\n",
      "[52]\n",
      "[53]\n",
      "[48]\n",
      "[54]\n",
      "[45]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[12]\n",
      "[7]\n",
      "[8]\n",
      "[12]\n",
      "[44]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[45]\n",
      "[9]\n",
      "[59]\n",
      "[15]\n",
      "[16]\n",
      "[54]\n",
      "[10]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[0]\n",
      "[7]\n",
      "[8]\n",
      "[12]\n",
      "[54]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[9]\n",
      "[59]\n",
      "[45]\n",
      "[15]\n",
      "[16]\n",
      "[10]\n",
      "[54]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[9]\n",
      "[7]\n",
      "[7]\n",
      "[12]\n",
      "[44]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[45]\n",
      "[9]\n",
      "[59]\n",
      "[15]\n",
      "[44]\n",
      "[51]\n",
      "[52]\n",
      "[53]\n",
      "[48]\n",
      "[45]\n",
      "[54]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[0]\n",
      "[7]\n",
      "[8]\n",
      "[12]\n",
      "[44]\n",
      "[9]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[45]\n",
      "[9]\n",
      "[45]\n",
      "[15]\n",
      "[44]\n",
      "[51]\n",
      "[52]\n",
      "[53]\n",
      "[48]\n",
      "[45]\n",
      "[9]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[7]\n",
      "[0]\n",
      "[8]\n",
      "[12]\n",
      "[10]\n",
      "[44]\n",
      "[46]\n",
      "[46]\n",
      "[48]\n",
      "[16]\n",
      "[15]\n",
      "[54]\n",
      "[16]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[59]\n",
      "[8]\n",
      "[8]\n",
      "[12]\n",
      "[12]\n",
      "[59]\n",
      "[10]\n",
      "[59]\n",
      "[59]\n",
      "[59]\n",
      "[44]\n",
      "[47]\n",
      "[47]\n",
      "[48]\n",
      "[12]\n",
      "[15]\n",
      "[44]\n",
      "[51]\n",
      "[9]\n",
      "[52]\n",
      "[10]\n",
      "[16]\n",
      "[54]\n",
      "[59]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[0]\n",
      "[7]\n",
      "[9]\n",
      "[8]\n",
      "[8]\n",
      "[9]\n",
      "[59]\n",
      "[10]\n",
      "[12]\n",
      "[44]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[12]\n",
      "[59]\n",
      "[59]\n",
      "[9]\n",
      "[15]\n",
      "[44]\n",
      "[51]\n",
      "[9]\n",
      "[9]\n",
      "[52]\n",
      "[53]\n",
      "[54]\n",
      "[54]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[0]\n",
      "[7]\n",
      "[8]\n",
      "[8]\n",
      "[59]\n",
      "[59]\n",
      "[59]\n",
      "[59]\n",
      "[9]\n",
      "[59]\n",
      "[59]\n",
      "[44]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[45]\n",
      "[45]\n",
      "[59]\n",
      "[12]\n",
      "[15]\n",
      "[44]\n",
      "[51]\n",
      "[52]\n",
      "[53]\n",
      "[48]\n",
      "[45]\n",
      "[54]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[0]\n",
      "[7]\n",
      "[0]\n",
      "[8]\n",
      "[12]\n",
      "[9]\n",
      "[59]\n",
      "[59]\n",
      "[15]\n",
      "[44]\n",
      "[51]\n",
      "[9]\n",
      "[9]\n",
      "[52]\n",
      "[48]\n",
      "[54]\n",
      "[55]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[0]\n",
      "[0]\n",
      "[7]\n",
      "[8]\n",
      "[12]\n",
      "[44]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[45]\n",
      "[59]\n",
      "[59]\n",
      "[44]\n",
      "[46]\n",
      "[47]\n",
      "[45]\n",
      "[45]\n",
      "[59]\n",
      "[10]\n",
      "[59]\n",
      "[59]\n",
      "[15]\n",
      "[15]\n",
      "[44]\n",
      "[51]\n",
      "[51]\n",
      "[52]\n",
      "[52]\n",
      "[48]\n",
      "[54]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[2]\n",
      "[3]\n",
      "[30]\n",
      "[31]\n",
      "[4]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "[29]\n",
      "[6]\n",
      "[7]\n",
      "[0]\n",
      "[7]\n",
      "[12]\n",
      "[44]\n",
      "[47]\n",
      "[47]\n",
      "[48]\n",
      "[47]\n",
      "[46]\n",
      "[45]\n",
      "[44]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[46]\n",
      "[10]\n",
      "[46]\n",
      "[46]\n",
      "[48]\n",
      "[9]\n",
      "[10]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[10]\n",
      "[59]\n",
      "[10]\n",
      "[15]\n",
      "[51]\n",
      "[52]\n",
      "[53]\n",
      "[54]\n",
      "[48]\n",
      "[54]\n",
      "[45]\n",
      "[65]\n",
      "[66]\n",
      "[40]\n",
      "[7]\n",
      "[63]\n",
      "[12]\n",
      "[64]\n",
      "[62]\n",
      "[7]\n",
      "[67]\n",
      "[68]\n",
      "[40]\n",
      "[7]\n",
      "[63]\n",
      "[64]\n",
      "[67]\n",
      "[68]\n",
      "[69]\n",
      "[70]\n",
      "[8]\n",
      "[12]\n",
      "[51]\n",
      "[46]\n",
      "[46]\n",
      "[46]\n",
      "[48]\n",
      "[45]\n",
      "[51]\n",
      "[52]\n",
      "[10]\n",
      "[54]\n",
      "[53]\n",
      "[48]\n",
      "[54]\n",
      "[53]\n",
      "[71]\n",
      "[7]\n",
      "[71]\n",
      "[8]\n",
      "[12]\n",
      "[44]\n",
      "[46]\n",
      "[48]\n",
      "[44]\n",
      "[44]\n",
      "[46]\n",
      "[46]\n",
      "[48]\n",
      "[45]\n",
      "[46]\n",
      "[46]\n",
      "[54]\n",
      "[46]\n",
      "[48]\n",
      "[54]\n",
      "[59]\n",
      "[59]\n",
      "[10]\n",
      "[44]\n",
      "[51]\n",
      "[51]\n",
      "[52]\n",
      "[53]\n",
      "[54]\n",
      "[45]\n",
      "[54]\n",
      "[0]\n",
      "[7]\n",
      "[8]\n",
      "[12]\n",
      "[44]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[59]\n",
      "[59]\n",
      "[15]\n",
      "[16]\n",
      "[8]\n",
      "[55]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[0]\n",
      "[7]\n",
      "[8]\n",
      "[12]\n",
      "[44]\n",
      "[46]\n",
      "[59]\n",
      "[7]\n",
      "[8]\n",
      "[12]\n",
      "[44]\n",
      "[46]\n",
      "[46]\n",
      "[48]\n",
      "[46]\n",
      "[47]\n",
      "[53]\n",
      "[46]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[48]\n",
      "[48]\n",
      "[59]\n",
      "[59]\n",
      "[44]\n",
      "[44]\n",
      "[51]\n",
      "[46]\n",
      "[10]\n",
      "[53]\n",
      "[48]\n",
      "[54]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[7]\n",
      "[7]\n",
      "[12]\n",
      "[44]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[45]\n",
      "[9]\n",
      "[44]\n",
      "[46]\n",
      "[46]\n",
      "[48]\n",
      "[48]\n",
      "[45]\n",
      "[9]\n",
      "[45]\n",
      "[15]\n",
      "[44]\n",
      "[51]\n",
      "[10]\n",
      "[52]\n",
      "[53]\n",
      "[45]\n",
      "[45]\n",
      "[54]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[0]\n",
      "[7]\n",
      "[8]\n",
      "[12]\n",
      "[45]\n",
      "[44]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[44]\n",
      "[59]\n",
      "[59]\n",
      "[10]\n",
      "[15]\n",
      "[44]\n",
      "[51]\n",
      "[9]\n",
      "[52]\n",
      "[52]\n",
      "[53]\n",
      "[48]\n",
      "[45]\n",
      "[55]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[0]\n",
      "[7]\n",
      "[8]\n",
      "[12]\n",
      "[7]\n",
      "[8]\n",
      "[12]\n",
      "[44]\n",
      "[46]\n",
      "[48]\n",
      "[9]\n",
      "[53]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[45]\n",
      "[9]\n",
      "[59]\n",
      "[12]\n",
      "[7]\n",
      "[8]\n",
      "[12]\n",
      "[59]\n",
      "[59]\n",
      "[10]\n",
      "[48]\n",
      "[15]\n",
      "[51]\n",
      "[52]\n",
      "[53]\n",
      "[53]\n",
      "[45]\n",
      "[54]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[0]\n",
      "[7]\n",
      "[8]\n",
      "[59]\n",
      "[10]\n",
      "[8]\n",
      "[59]\n",
      "[59]\n",
      "[10]\n",
      "[12]\n",
      "[44]\n",
      "[48]\n",
      "[47]\n",
      "[48]\n",
      "[48]\n",
      "[59]\n",
      "[15]\n",
      "[51]\n",
      "[52]\n",
      "[53]\n",
      "[48]\n",
      "[54]\n",
      "[59]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[0]\n",
      "[7]\n",
      "[8]\n",
      "[12]\n",
      "[44]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[45]\n",
      "[15]\n",
      "[44]\n",
      "[51]\n",
      "[52]\n",
      "[53]\n",
      "[48]\n",
      "[45]\n",
      "[54]\n",
      "[55]\n",
      "[55]\n",
      "[58]\n",
      "[58]\n",
      "[0]\n",
      "[7]\n",
      "[0]\n",
      "[8]\n",
      "[9]\n",
      "[8]\n",
      "[9]\n",
      "[9]\n",
      "[8]\n",
      "[9]\n",
      "[9]\n",
      "[10]\n",
      "[12]\n",
      "[44]\n",
      "[46]\n",
      "[47]\n",
      "[48]\n",
      "[9]\n",
      "[59]\n",
      "[10]\n",
      "[45]\n",
      "[15]\n",
      "[51]\n",
      "[52]\n",
      "[53]\n",
      "[48]\n",
      "[54]\n",
      "[45]\n",
      "[55]\n",
      "[56]\n",
      "[57]\n",
      "[58]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[74]\n",
      "[74]\n",
      "[75]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[79]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[0]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[88]\n",
      "[77]\n",
      "[4]\n",
      "[89]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[74]\n",
      "[76]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[79]\n",
      "[79]\n",
      "[80]\n",
      "[82]\n",
      "[0]\n",
      "[83]\n",
      "[84]\n",
      "[83]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[76]\n",
      "[77]\n",
      "[89]\n",
      "[89]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[74]\n",
      "[90]\n",
      "[77]\n",
      "[78]\n",
      "[79]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[0]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[76]\n",
      "[77]\n",
      "[4]\n",
      "[89]\n",
      "[72]\n",
      "[73]\n",
      "[74]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[0]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[87]\n",
      "[4]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[77]\n",
      "[4]\n",
      "[89]\n",
      "[91]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[74]\n",
      "[81]\n",
      "[80]\n",
      "[82]\n",
      "[0]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[88]\n",
      "[88]\n",
      "[76]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[77]\n",
      "[4]\n",
      "[89]\n",
      "[91]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[74]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[4]\n",
      "[4]\n",
      "[77]\n",
      "[78]\n",
      "[77]\n",
      "[4]\n",
      "[89]\n",
      "[91]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[74]\n",
      "[81]\n",
      "[82]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[4]\n",
      "[4]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[77]\n",
      "[4]\n",
      "[89]\n",
      "[79]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[74]\n",
      "[74]\n",
      "[80]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[4]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[77]\n",
      "[4]\n",
      "[89]\n",
      "[79]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[74]\n",
      "[81]\n",
      "[82]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[88]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[77]\n",
      "[77]\n",
      "[89]\n",
      "[79]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[81]\n",
      "[81]\n",
      "[80]\n",
      "[82]\n",
      "[83]\n",
      "[85]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[88]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[77]\n",
      "[4]\n",
      "[89]\n",
      "[79]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[74]\n",
      "[74]\n",
      "[80]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[4]\n",
      "[75]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[86]\n",
      "[4]\n",
      "[89]\n",
      "[79]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[74]\n",
      "[81]\n",
      "[80]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[88]\n",
      "[88]\n",
      "[88]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[77]\n",
      "[4]\n",
      "[89]\n",
      "[79]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[74]\n",
      "[81]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[4]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[78]\n",
      "[4]\n",
      "[89]\n",
      "[79]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[81]\n",
      "[81]\n",
      "[80]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[76]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[77]\n",
      "[4]\n",
      "[89]\n",
      "[79]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[74]\n",
      "[81]\n",
      "[80]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[4]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[77]\n",
      "[4]\n",
      "[89]\n",
      "[79]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[74]\n",
      "[4]\n",
      "[60]\n",
      "[75]\n",
      "[60]\n",
      "[77]\n",
      "[78]\n",
      "[79]\n",
      "[80]\n",
      "[80]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[88]\n",
      "[88]\n",
      "[90]\n",
      "[77]\n",
      "[89]\n",
      "[89]\n",
      "[79]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[74]\n",
      "[75]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[79]\n",
      "[81]\n",
      "[80]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[90]\n",
      "[77]\n",
      "[4]\n",
      "[89]\n",
      "[79]\n",
      "[72]\n",
      "[73]\n",
      "[2]\n",
      "[74]\n",
      "[81]\n",
      "[80]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[76]\n",
      "[76]\n",
      "[77]\n",
      "[78]\n",
      "[77]\n",
      "[4]\n",
      "[89]\n",
      "[79]\n",
      "[71]\n",
      "[71]\n",
      "[1]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[30]\n",
      "[31]\n",
      "[30]\n",
      "[31]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[92]\n",
      "[92]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[76]\n",
      "[77]\n",
      "[4]\n",
      "[89]\n",
      "[92]\n",
      "[92]\n",
      "[81]\n",
      "[82]\n",
      "[82]\n",
      "[2]\n",
      "[1]\n",
      "[0]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[76]\n",
      "[77]\n",
      "[4]\n",
      "[89]\n",
      "[21]\n",
      "[88]\n",
      "[80]\n",
      "[93]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[84]\n",
      "[92]\n",
      "[81]\n",
      "[82]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[80]\n",
      "[76]\n",
      "[4]\n",
      "[21]\n",
      "[77]\n",
      "[4]\n",
      "[19]\n",
      "[89]\n",
      "[21]\n",
      "[6]\n",
      "[40]\n",
      "[94]\n",
      "[95]\n",
      "[95]\n",
      "[80]\n",
      "[81]\n",
      "[82]\n",
      "[92]\n",
      "[83]\n",
      "[84]\n",
      "[85]\n",
      "[86]\n",
      "[87]\n",
      "[88]\n",
      "[76]\n",
      "[77]\n",
      "[19]\n",
      "[19]\n",
      "[89]\n",
      "[21]\n",
      "[6]\n",
      "[40]\n",
      "[94]\n",
      "[95]\n",
      "[0]\n",
      "[85]\n",
      "[96]\n",
      "[84]\n",
      "[85]\n",
      "[84]\n",
      "[84]\n",
      "[84]\n",
      "[85]\n",
      "[87]\n",
      "[76]\n",
      "[77]\n",
      "[97]\n",
      "[71]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[80]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[93]\n",
      "[97]\n",
      "[40]\n",
      "[64]\n",
      "[62]\n",
      "[103]\n",
      "[97]\n",
      "[71]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[80]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[93]\n",
      "[97]\n",
      "[40]\n",
      "[64]\n",
      "[62]\n",
      "[103]\n",
      "[97]\n",
      "[71]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[80]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[93]\n",
      "[97]\n",
      "[40]\n",
      "[64]\n",
      "[62]\n",
      "[103]\n",
      "[97]\n",
      "[71]\n",
      "[62]\n",
      "[2]\n",
      "[3]\n",
      "[80]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[93]\n",
      "[97]\n",
      "[40]\n",
      "[64]\n",
      "[62]\n",
      "[103]\n",
      "[97]\n",
      "[71]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[3]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[93]\n",
      "[97]\n",
      "[40]\n",
      "[64]\n",
      "[62]\n",
      "[104]\n",
      "[103]\n",
      "[97]\n",
      "[71]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[80]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[93]\n",
      "[97]\n",
      "[40]\n",
      "[64]\n",
      "[62]\n",
      "[103]\n",
      "[71]\n",
      "[30]\n",
      "[1]\n",
      "[2]\n",
      "[2]\n",
      "[30]\n",
      "[30]\n",
      "[31]\n",
      "[30]\n",
      "[31]\n",
      "[80]\n",
      "[92]\n",
      "[60]\n",
      "[71]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[80]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[105]\n",
      "[93]\n",
      "[71]\n",
      "[71]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[80]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[101]\n",
      "[93]\n",
      "[71]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[80]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[93]\n",
      "[99]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[80]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[93]\n",
      "[71]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[80]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[101]\n",
      "[93]\n",
      "[71]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[80]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[80]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[80]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[93]\n",
      "[93]\n",
      "[71]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[80]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[93]\n",
      "[71]\n",
      "[99]\n",
      "[2]\n",
      "[100]\n",
      "[101]\n",
      "[71]\n",
      "[99]\n",
      "[2]\n",
      "[3]\n",
      "[80]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[93]\n",
      "[71]\n",
      "[98]\n",
      "[99]\n",
      "[76]\n",
      "[71]\n",
      "[100]\n",
      "[71]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[98]\n",
      "[99]\n",
      "[71]\n",
      "[100]\n",
      "[101]\n",
      "[71]\n",
      "[98]\n",
      "[99]\n",
      "[71]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[80]\n",
      "[71]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[98]\n",
      "[98]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[98]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[80]\n",
      "[71]\n",
      "[98]\n",
      "[71]\n",
      "[98]\n",
      "[99]\n",
      "[71]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[101]\n",
      "[99]\n",
      "[99]\n",
      "[71]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[71]\n",
      "[98]\n",
      "[99]\n",
      "[100]\n",
      "[101]\n",
      "[102]\n",
      "[106]\n",
      "[106]\n",
      "[107]\n",
      "[108]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[112]\n",
      "[113]\n",
      "[113]\n",
      "[106]\n",
      "[106]\n",
      "[107]\n",
      "[108]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[112]\n",
      "[113]\n",
      "[113]\n",
      "[106]\n",
      "[106]\n",
      "[108]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[112]\n",
      "[113]\n",
      "[113]\n",
      "[106]\n",
      "[106]\n",
      "[107]\n",
      "[108]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[112]\n",
      "[113]\n",
      "[113]\n",
      "[107]\n",
      "[106]\n",
      "[108]\n",
      "[110]\n",
      "[109]\n",
      "[111]\n",
      "[112]\n",
      "[113]\n",
      "[106]\n",
      "[107]\n",
      "[108]\n",
      "[110]\n",
      "[109]\n",
      "[111]\n",
      "[112]\n",
      "[113]\n",
      "[106]\n",
      "[106]\n",
      "[108]\n",
      "[110]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[112]\n",
      "[113]\n",
      "[113]\n",
      "[106]\n",
      "[108]\n",
      "[110]\n",
      "[109]\n",
      "[111]\n",
      "[112]\n",
      "[113]\n",
      "[107]\n",
      "[108]\n",
      "[110]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[112]\n",
      "[113]\n",
      "[106]\n",
      "[108]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[109]\n",
      "[111]\n",
      "[112]\n",
      "[111]\n",
      "[111]\n",
      "[107]\n",
      "[107]\n",
      "[114]\n",
      "[114]\n",
      "[110]\n",
      "[110]\n",
      "[109]\n",
      "[109]\n",
      "[111]\n",
      "[112]\n",
      "[107]\n",
      "[108]\n",
      "[110]\n",
      "[109]\n",
      "[111]\n",
      "[112]\n",
      "[113]\n",
      "[111]\n",
      "[113]\n",
      "[113]\n",
      "[106]\n",
      "[107]\n",
      "[108]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[113]\n",
      "[112]\n",
      "[112]\n",
      "[115]\n",
      "[116]\n",
      "[113]\n",
      "[117]\n",
      "[106]\n",
      "[107]\n",
      "[108]\n",
      "[108]\n",
      "[118]\n",
      "[111]\n",
      "[112]\n",
      "[116]\n",
      "[113]\n",
      "[117]\n",
      "[106]\n",
      "[107]\n",
      "[108]\n",
      "[114]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[112]\n",
      "[113]\n",
      "[107]\n",
      "[108]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[111]\n",
      "[117]\n",
      "[107]\n",
      "[108]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[112]\n",
      "[107]\n",
      "[108]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[112]\n",
      "[113]\n",
      "[110]\n",
      "[111]\n",
      "[113]\n",
      "[107]\n",
      "[108]\n",
      "[109]\n",
      "[119]\n",
      "[120]\n",
      "[109]\n",
      "[108]\n",
      "[109]\n",
      "[119]\n",
      "[120]\n",
      "[121]\n",
      "[108]\n",
      "[109]\n",
      "[122]\n",
      "[123]\n",
      "[110]\n",
      "[111]\n",
      "[112]\n",
      "[108]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[112]\n",
      "[108]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[112]\n",
      "[108]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[112]\n",
      "[108]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[112]\n",
      "[108]\n",
      "[109]\n",
      "[109]\n",
      "[111]\n",
      "[112]\n",
      "[108]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[112]\n",
      "[106]\n",
      "[107]\n",
      "[108]\n",
      "[109]\n",
      "[110]\n",
      "[109]\n",
      "[113]\n",
      "[112]\n",
      "[106]\n",
      "[107]\n",
      "[108]\n",
      "[109]\n",
      "[112]\n",
      "[111]\n",
      "[112]\n",
      "[107]\n",
      "[108]\n",
      "[109]\n",
      "[111]\n",
      "[111]\n",
      "[112]\n",
      "[108]\n",
      "[109]\n",
      "[110]\n",
      "[111]\n",
      "[112]\n",
      "03/06 15:58:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [2476/2476]    acc/top1: 0.8954  acc/top5: 0.9834  acc/mean1: 0.9565  data_time: 0.0076  time: 3.2628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc/top1': 0.8953957996768982,\n",
       " 'acc/top5': 0.9834410339256866,\n",
       " 'acc/mean1': 0.9565178922102758}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmengine.runner import Runner\n",
    "checkpoint = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/mvitv2_regular/best_acc_top1_epoch_53.pth'\n",
    "\n",
    "\n",
    "\n",
    "cfg = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/mvitv2_recognition_regular.py'\n",
    "\n",
    "cfg = Config.fromfile(cfg)\n",
    "\n",
    "cfg.load_from = checkpoint\n",
    "\n",
    "cfg.work_dir = './exps/mvitv2_regular'\n",
    "\n",
    "cfg.test_dataloader.dataset.ann_file = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/annotations_regular_train.txt'\n",
    "\n",
    "cfg.test_dataloader.dataset.data_prefix.img = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train/'\n",
    "\n",
    "\n",
    "# build the runner from config\n",
    "\n",
    "if 'runner_type' not in cfg:\n",
    "\n",
    "   # build the default runner\n",
    "\n",
    "   runner_test = Runner.from_cfg(cfg)\n",
    "\n",
    "else:\n",
    "\n",
    "   # build customized runner from the registry\n",
    "\n",
    "   # if 'runner_type' is set in the cfg\n",
    "\n",
    "   runner_test = Runner.build(cfg)\n",
    "\n",
    "\n",
    "# start testing\n",
    "\n",
    "runner_test.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/29 01:22:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 281367488\n",
      "    GPU 0: NVIDIA GeForce RTX 4080 SUPER\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.4\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.99\n",
      "    MSVC: n/a, reason: fileno\n",
      "    PyTorch: 2.4.1+cu124\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 201703\n",
      "  - MSVC 192930154\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.4\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 90.1\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.19.1+cu124\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 281367488\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "12/29 01:22:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/annotations_test.txt'\n",
      "ann_file_train = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/annotations_train_balanced.txt'\n",
      "ann_file_val = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/annotations_test.txt'\n",
      "auto_scale_lr = dict(base_batch_size=8, enable=False)\n",
      "data_root = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train'\n",
      "data_root_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test'\n",
      "dataset_type = 'RawframeDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=3, max_keep_ckpts=5, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/mvitv2_regular/best_acc_top1_epoch_53.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        arch='small',\n",
      "        drop_path_rate=0.2,\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmaction/v1.0/recognition/mvit/converted/mvit-small-p244_16x4x1_kinetics400-rgb_20221021-9ebaaeed.pth',\n",
      "            prefix='backbone.',\n",
      "            type='Pretrained'),\n",
      "        type='MViT'),\n",
      "    cls_head=dict(\n",
      "        average_clips='prob',\n",
      "        in_channels=768,\n",
      "        label_smooth_eps=0.1,\n",
      "        num_classes=162,\n",
      "        type='MViTHead'),\n",
      "    data_preprocessor=dict(\n",
      "        format_shape='NCTHW',\n",
      "        mean=[\n",
      "            114.75,\n",
      "            114.75,\n",
      "            114.75,\n",
      "        ],\n",
      "        std=[\n",
      "            57.375,\n",
      "            57.375,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='ActionDataPreprocessor'),\n",
      "    type='Recognizer3D')\n",
      "optim_wrapper = dict(\n",
      "    constructor='SwinOptimWrapperConstructor',\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=0.001, type='AdamW', weight_decay=0.02),\n",
      "    paramwise_cfg=dict(\n",
      "        absolute_pos_embed=dict(decay_mult=0.0),\n",
      "        backbone=dict(lr_mult=0.1),\n",
      "        norm=dict(decay_mult=0.0),\n",
      "        relative_position_bias_table=dict(decay_mult=0.0)),\n",
      "    type='AmpOptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=2.5,\n",
      "        start_factor=0.1,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        T_max=30,\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=30,\n",
      "        eta_min=0,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/annotations_regular_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=4,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='ThreeCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(type='ConfusionMatrix')\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=4,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='ThreeCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=100, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/annotations_train_balanced.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                224,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(flip_ratio=0.5, type='Flip'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(clip_len=32, frame_interval=2, num_clips=1, type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        224,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(flip_ratio=0.5, type='Flip'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/annotations_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(type='ConfusionMatrix')\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='CenterCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './exps/mvitv2_regular'\n",
      "\n",
      "12/29 01:22:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "12/29 01:22:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: /Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/mvitv2_regular/best_acc_top1_epoch_53.pth\n",
      "12/29 01:22:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/mvitv2_regular/best_acc_top1_epoch_53.pth\n",
      "12/29 01:29:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [100/683]    eta: 0:39:02  time: 3.8058  data_time: 0.0100  memory: 10378  \n",
      "12/29 01:35:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [200/683]    eta: 0:32:22  time: 4.0628  data_time: 0.0078  memory: 10378  \n",
      "12/29 01:42:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [300/683]    eta: 0:25:20  time: 3.8607  data_time: 0.0073  memory: 10378  \n",
      "12/29 01:48:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [400/683]    eta: 0:18:36  time: 3.8527  data_time: 0.0079  memory: 10378  \n",
      "12/29 01:55:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [500/683]    eta: 0:11:58  time: 3.8350  data_time: 0.0072  memory: 10378  \n",
      "12/29 02:01:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [600/683]    eta: 0:05:25  time: 3.8777  data_time: 0.0077  memory: 10378  \n",
      "12/29 02:06:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [683/683]    confusion_matrix/result: [(tensor(23), tensor(0.5217)), (tensor(12), tensor(1.)), (tensor(19), tensor(1.)), (tensor(12), tensor(0.7500)), (tensor(17), tensor(0.4118)), (tensor(8), tensor(1.)), (tensor(13), tensor(0.4615)), (tensor(15), tensor(0.9333)), (tensor(20), tensor(0.9500)), (tensor(22), tensor(0.3636)), (tensor(18), tensor(0.1111)), (tensor(6), tensor(0.8333)), (tensor(16), tensor(0.3750)), (tensor(5), tensor(0.8000)), (tensor(5), tensor(1.)), (tensor(15), tensor(0.7333)), (tensor(10), tensor(0.6000)), (tensor(5), tensor(1.)), (tensor(5), tensor(0.6000)), (tensor(3), tensor(0.6667)), (tensor(7), tensor(0.4286)), (tensor(7), tensor(0.5714)), (tensor(2), tensor(1.)), (tensor(2), tensor(1.)), (tensor(2), tensor(1.)), (tensor(2), tensor(1.)), (tensor(2), tensor(1.)), (tensor(2), tensor(0.)), (tensor(2), tensor(0.5000)), (tensor(2), tensor(1.)), (tensor(6), tensor(0.8333)), (tensor(6), tensor(1.)), (tensor(2), tensor(0.)), (tensor(1), tensor(1.)), (tensor(2), tensor(0.)), (tensor(2), tensor(0.5000)), (tensor(1), tensor(0.)), (tensor(3), tensor(0.)), (tensor(1), tensor(0.)), (tensor(1), tensor(1.)), (tensor(6), tensor(0.8333)), (tensor(2), tensor(1.)), (tensor(2), tensor(1.)), (tensor(1), tensor(0.)), (tensor(13), tensor(0.5385)), (tensor(10), tensor(0.1000)), (tensor(12), tensor(0.5000)), (tensor(14), tensor(0.0714)), (tensor(17), tensor(0.4118)), (tensor(0), tensor(nan)), (tensor(1), tensor(0.)), (tensor(6), tensor(1.)), (tensor(7), tensor(0.5714)), (tensor(6), tensor(0.)), (tensor(10), tensor(0.4000)), (tensor(4), tensor(1.)), (tensor(4), tensor(0.5000)), (tensor(4), tensor(1.)), (tensor(4), tensor(1.)), (tensor(9), tensor(0.3333)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(4), tensor(0.7500)), (tensor(0), tensor(nan)), (tensor(5), tensor(0.6000)), (tensor(1), tensor(0.)), (tensor(1), tensor(0.)), (tensor(0), tensor(nan)), (tensor(2), tensor(1.)), (tensor(1), tensor(1.)), (tensor(1), tensor(1.)), (tensor(12), tensor(0.8333)), (tensor(4), tensor(1.)), (tensor(4), tensor(0.7500)), (tensor(4), tensor(0.5000)), (tensor(0), tensor(nan)), (tensor(8), tensor(0.6250)), (tensor(10), tensor(0.8000)), (tensor(4), tensor(1.)), (tensor(3), tensor(0.3333)), (tensor(12), tensor(0.6667)), (tensor(5), tensor(0.8000)), (tensor(5), tensor(1.)), (tensor(6), tensor(0.8333)), (tensor(6), tensor(0.8333)), (tensor(6), tensor(0.8333)), (tensor(5), tensor(1.)), (tensor(6), tensor(0.6667)), (tensor(5), tensor(0.6000)), (tensor(5), tensor(1.)), (tensor(0), tensor(nan)), (tensor(1), tensor(0.)), (tensor(1), tensor(1.)), (tensor(6), tensor(0.5000)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(6), tensor(1.)), (tensor(9), tensor(0.7778)), (tensor(6), tensor(0.8333)), (tensor(9), tensor(0.7778)), (tensor(10), tensor(0.9000)), (tensor(8), tensor(0.7500)), (tensor(3), tensor(0.6667)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(6), tensor(0.6667)), (tensor(6), tensor(0.6667)), (tensor(8), tensor(0.8750)), (tensor(8), tensor(0.7500)), (tensor(10), tensor(0.8000)), (tensor(8), tensor(1.)), (tensor(8), tensor(0.5000)), (tensor(8), tensor(0.6250)), (tensor(1), tensor(1.)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), 162]  data_time: 0.0124  time: 3.9085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion_matrix/result': [(tensor(23), tensor(0.5217)),\n",
       "  (tensor(12), tensor(1.)),\n",
       "  (tensor(19), tensor(1.)),\n",
       "  (tensor(12), tensor(0.7500)),\n",
       "  (tensor(17), tensor(0.4118)),\n",
       "  (tensor(8), tensor(1.)),\n",
       "  (tensor(13), tensor(0.4615)),\n",
       "  (tensor(15), tensor(0.9333)),\n",
       "  (tensor(20), tensor(0.9500)),\n",
       "  (tensor(22), tensor(0.3636)),\n",
       "  (tensor(18), tensor(0.1111)),\n",
       "  (tensor(6), tensor(0.8333)),\n",
       "  (tensor(16), tensor(0.3750)),\n",
       "  (tensor(5), tensor(0.8000)),\n",
       "  (tensor(5), tensor(1.)),\n",
       "  (tensor(15), tensor(0.7333)),\n",
       "  (tensor(10), tensor(0.6000)),\n",
       "  (tensor(5), tensor(1.)),\n",
       "  (tensor(5), tensor(0.6000)),\n",
       "  (tensor(3), tensor(0.6667)),\n",
       "  (tensor(7), tensor(0.4286)),\n",
       "  (tensor(7), tensor(0.5714)),\n",
       "  (tensor(2), tensor(1.)),\n",
       "  (tensor(2), tensor(1.)),\n",
       "  (tensor(2), tensor(1.)),\n",
       "  (tensor(2), tensor(1.)),\n",
       "  (tensor(2), tensor(1.)),\n",
       "  (tensor(2), tensor(0.)),\n",
       "  (tensor(2), tensor(0.5000)),\n",
       "  (tensor(2), tensor(1.)),\n",
       "  (tensor(6), tensor(0.8333)),\n",
       "  (tensor(6), tensor(1.)),\n",
       "  (tensor(2), tensor(0.)),\n",
       "  (tensor(1), tensor(1.)),\n",
       "  (tensor(2), tensor(0.)),\n",
       "  (tensor(2), tensor(0.5000)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(3), tensor(0.)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(1), tensor(1.)),\n",
       "  (tensor(6), tensor(0.8333)),\n",
       "  (tensor(2), tensor(1.)),\n",
       "  (tensor(2), tensor(1.)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(13), tensor(0.5385)),\n",
       "  (tensor(10), tensor(0.1000)),\n",
       "  (tensor(12), tensor(0.5000)),\n",
       "  (tensor(14), tensor(0.0714)),\n",
       "  (tensor(17), tensor(0.4118)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(6), tensor(1.)),\n",
       "  (tensor(7), tensor(0.5714)),\n",
       "  (tensor(6), tensor(0.)),\n",
       "  (tensor(10), tensor(0.4000)),\n",
       "  (tensor(4), tensor(1.)),\n",
       "  (tensor(4), tensor(0.5000)),\n",
       "  (tensor(4), tensor(1.)),\n",
       "  (tensor(4), tensor(1.)),\n",
       "  (tensor(9), tensor(0.3333)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(4), tensor(0.7500)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(5), tensor(0.6000)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(2), tensor(1.)),\n",
       "  (tensor(1), tensor(1.)),\n",
       "  (tensor(1), tensor(1.)),\n",
       "  (tensor(12), tensor(0.8333)),\n",
       "  (tensor(4), tensor(1.)),\n",
       "  (tensor(4), tensor(0.7500)),\n",
       "  (tensor(4), tensor(0.5000)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(8), tensor(0.6250)),\n",
       "  (tensor(10), tensor(0.8000)),\n",
       "  (tensor(4), tensor(1.)),\n",
       "  (tensor(3), tensor(0.3333)),\n",
       "  (tensor(12), tensor(0.6667)),\n",
       "  (tensor(5), tensor(0.8000)),\n",
       "  (tensor(5), tensor(1.)),\n",
       "  (tensor(6), tensor(0.8333)),\n",
       "  (tensor(6), tensor(0.8333)),\n",
       "  (tensor(6), tensor(0.8333)),\n",
       "  (tensor(5), tensor(1.)),\n",
       "  (tensor(6), tensor(0.6667)),\n",
       "  (tensor(5), tensor(0.6000)),\n",
       "  (tensor(5), tensor(1.)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(1), tensor(1.)),\n",
       "  (tensor(6), tensor(0.5000)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(6), tensor(1.)),\n",
       "  (tensor(9), tensor(0.7778)),\n",
       "  (tensor(6), tensor(0.8333)),\n",
       "  (tensor(9), tensor(0.7778)),\n",
       "  (tensor(10), tensor(0.9000)),\n",
       "  (tensor(8), tensor(0.7500)),\n",
       "  (tensor(3), tensor(0.6667)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(6), tensor(0.6667)),\n",
       "  (tensor(6), tensor(0.6667)),\n",
       "  (tensor(8), tensor(0.8750)),\n",
       "  (tensor(8), tensor(0.7500)),\n",
       "  (tensor(10), tensor(0.8000)),\n",
       "  (tensor(8), tensor(1.)),\n",
       "  (tensor(8), tensor(0.5000)),\n",
       "  (tensor(8), tensor(0.6250)),\n",
       "  (tensor(1), tensor(1.)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  162]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmengine.runner import Runner\n",
    "checkpoint = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/mvitv2_regular/best_acc_top1_epoch_53.pth'\n",
    "\n",
    "\n",
    "\n",
    "cfg = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/mvitv2_recognition_regular.py'\n",
    "\n",
    "cfg = Config.fromfile(cfg)\n",
    "\n",
    "cfg.load_from = checkpoint\n",
    "\n",
    "cfg.work_dir = './exps/mvitv2_regular'\n",
    "\n",
    "cfg.test_dataloader.dataset.ann_file = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/annotations_regular_test.txt'\n",
    "\n",
    "cfg.test_dataloader.dataset.data_prefix.img = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test'\n",
    "\n",
    "\n",
    "# build the runner from config\n",
    "\n",
    "if 'runner_type' not in cfg:\n",
    "\n",
    "   # build the default runner\n",
    "\n",
    "   runner_test = Runner.from_cfg(cfg)\n",
    "\n",
    "else:\n",
    "\n",
    "   # build customized runner from the registry\n",
    "\n",
    "   # if 'runner_type' is set in the cfg\n",
    "\n",
    "   runner_test = Runner.build(cfg)\n",
    "\n",
    "\n",
    "# start testing\n",
    "\n",
    "runner_test.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu124 True\n",
      "1.2.0\n",
      "2.2.0\n",
      "12.4\n",
      "MSVC 194134120\n",
      "OrderedDict([('sys.platform', 'win32'), ('Python', '3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]'), ('CUDA available', True), ('MUSA available', False), ('numpy_random_seed', 281367488), ('GPU 0', 'NVIDIA GeForce RTX 4080 SUPER'), ('CUDA_HOME', 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.4'), ('NVCC', 'Cuda compilation tools, release 12.4, V12.4.99'), ('MSVC', 'n/a, reason: fileno'), ('PyTorch', '2.4.1+cu124'), ('PyTorch compiling details', 'PyTorch built with:\\n  - C++ Version: 201703\\n  - MSVC 192930154\\n  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\\n  - OpenMP 2019\\n  - LAPACK is enabled (usually provided by MKL)\\n  - CPU capability usage: AVX2\\n  - CUDA Runtime 12.4\\n  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\\n  - CuDNN 90.1\\n  - Magma 2.5.4\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \\n'), ('TorchVision', '0.19.1+cu124'), ('OpenCV', '4.10.0'), ('MMEngine', '0.10.5')])\n",
      "12/29 10:53:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1554238593\n",
      "    GPU 0: NVIDIA GeForce RTX 4080 SUPER\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.4\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.99\n",
      "    MSVC: n/a, reason: fileno\n",
      "    PyTorch: 2.4.1+cu124\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 201703\n",
      "  - MSVC 192930154\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.4\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 90.1\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.19.1+cu124\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1554238593\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "12/29 10:53:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt'\n",
      "ann_file_train = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_train_balanced.txt'\n",
      "ann_file_val = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt'\n",
      "auto_scale_lr = dict(base_batch_size=8, enable=False)\n",
      "data_root = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train/'\n",
      "data_root_test = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "dataset_type = 'RawframeDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=3, max_keep_ckpts=5, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/mvitv2_anticipation_regular/best_acc_top1_epoch_29.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        arch='small',\n",
      "        drop_path_rate=0.2,\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmaction/v1.0/recognition/mvit/converted/mvit-small-p244_16x4x1_kinetics400-rgb_20221021-9ebaaeed.pth',\n",
      "            prefix='backbone.',\n",
      "            type='Pretrained'),\n",
      "        type='MViT'),\n",
      "    cls_head=dict(\n",
      "        average_clips='prob',\n",
      "        in_channels=768,\n",
      "        label_smooth_eps=0.1,\n",
      "        num_classes=160,\n",
      "        type='MViTHead'),\n",
      "    data_preprocessor=dict(\n",
      "        format_shape='NCTHW',\n",
      "        mean=[\n",
      "            114.75,\n",
      "            114.75,\n",
      "            114.75,\n",
      "        ],\n",
      "        std=[\n",
      "            57.375,\n",
      "            57.375,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='ActionDataPreprocessor'),\n",
      "    type='Recognizer3D')\n",
      "optim_wrapper = dict(\n",
      "    constructor='SwinOptimWrapperConstructor',\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=0.001, type='AdamW', weight_decay=0.02),\n",
      "    paramwise_cfg=dict(\n",
      "        absolute_pos_embed=dict(decay_mult=0.0),\n",
      "        backbone=dict(lr_mult=0.1),\n",
      "        norm=dict(decay_mult=0.0),\n",
      "        relative_position_bias_table=dict(decay_mult=0.0)),\n",
      "    type='AmpOptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=2.5,\n",
      "        start_factor=0.1,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        T_max=30,\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=30,\n",
      "        eta_min=0,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/annotations_regular_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=4,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='ThreeCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(type='ConfusionMatrix')\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=4,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='ThreeCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=100, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_train_balanced.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/train/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                224,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(flip_ratio=0.5, type='Flip'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(clip_len=32, frame_interval=2, num_clips=1, type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        224,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(flip_ratio=0.5, type='Flip'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/anticipation_annotations_regular_test.txt',\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test/'\n",
      "        ),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='RawframeDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(type='ConfusionMatrix')\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='CenterCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './exps/mvitv2_anticipation_regular'\n",
      "\n",
      "12/29 10:53:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "12/29 10:53:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: /Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/mvitv2_anticipation_regular/best_acc_top1_epoch_29.pth\n",
      "12/29 10:53:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/mvitv2_anticipation_regular/best_acc_top1_epoch_29.pth\n",
      "12/29 11:00:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [100/683]    eta: 0:38:01  time: 3.8786  data_time: 0.0125  memory: 10378  \n",
      "12/29 11:06:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [200/683]    eta: 0:31:20  time: 3.8686  data_time: 0.0103  memory: 10241  \n",
      "12/29 11:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [300/683]    eta: 0:24:44  time: 3.8181  data_time: 0.0075  memory: 10241  \n",
      "12/29 11:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [400/683]    eta: 0:18:20  time: 3.8961  data_time: 0.0081  memory: 10241  \n",
      "12/29 11:26:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [500/683]    eta: 0:11:52  time: 3.9049  data_time: 0.0117  memory: 10241  \n",
      "12/29 11:32:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [600/683]    eta: 0:05:22  time: 3.8539  data_time: 0.0083  memory: 10241  \n",
      "12/29 11:37:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [683/683]    confusion_matrix/result: [(tensor(23), tensor(0.2174)), (tensor(12), tensor(0.8333)), (tensor(19), tensor(0.6842)), (tensor(12), tensor(0.5000)), (tensor(17), tensor(0.2941)), (tensor(8), tensor(0.7500)), (tensor(13), tensor(0.3077)), (tensor(15), tensor(0.2000)), (tensor(20), tensor(0.2500)), (tensor(22), tensor(0.0455)), (tensor(18), tensor(0.1111)), (tensor(6), tensor(0.1667)), (tensor(16), tensor(0.)), (tensor(5), tensor(0.)), (tensor(5), tensor(0.2000)), (tensor(15), tensor(0.)), (tensor(10), tensor(0.1000)), (tensor(5), tensor(0.)), (tensor(5), tensor(0.)), (tensor(3), tensor(0.3333)), (tensor(7), tensor(0.)), (tensor(7), tensor(0.)), (tensor(2), tensor(0.)), (tensor(2), tensor(0.)), (tensor(2), tensor(0.)), (tensor(2), tensor(0.)), (tensor(2), tensor(0.)), (tensor(2), tensor(0.)), (tensor(2), tensor(0.)), (tensor(2), tensor(0.)), (tensor(6), tensor(0.)), (tensor(6), tensor(0.5000)), (tensor(2), tensor(0.)), (tensor(1), tensor(0.)), (tensor(2), tensor(0.)), (tensor(2), tensor(0.)), (tensor(1), tensor(0.)), (tensor(3), tensor(0.3333)), (tensor(1), tensor(0.)), (tensor(1), tensor(0.)), (tensor(6), tensor(0.)), (tensor(2), tensor(0.)), (tensor(2), tensor(0.5000)), (tensor(1), tensor(0.)), (tensor(13), tensor(0.0769)), (tensor(10), tensor(0.)), (tensor(12), tensor(0.)), (tensor(14), tensor(0.0714)), (tensor(17), tensor(0.)), (tensor(0), tensor(nan)), (tensor(1), tensor(0.)), (tensor(6), tensor(0.)), (tensor(7), tensor(0.)), (tensor(6), tensor(0.)), (tensor(10), tensor(0.1000)), (tensor(4), tensor(0.)), (tensor(4), tensor(0.5000)), (tensor(4), tensor(0.)), (tensor(4), tensor(1.)), (tensor(9), tensor(0.1111)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(4), tensor(0.)), (tensor(0), tensor(nan)), (tensor(5), tensor(0.2000)), (tensor(1), tensor(0.)), (tensor(1), tensor(0.)), (tensor(0), tensor(nan)), (tensor(2), tensor(0.)), (tensor(1), tensor(0.)), (tensor(1), tensor(1.)), (tensor(12), tensor(0.1667)), (tensor(4), tensor(1.)), (tensor(4), tensor(0.)), (tensor(4), tensor(0.)), (tensor(0), tensor(nan)), (tensor(8), tensor(0.6250)), (tensor(10), tensor(0.4000)), (tensor(4), tensor(0.2500)), (tensor(3), tensor(0.3333)), (tensor(12), tensor(0.)), (tensor(5), tensor(0.4000)), (tensor(5), tensor(0.6000)), (tensor(6), tensor(1.)), (tensor(6), tensor(0.8333)), (tensor(6), tensor(0.5000)), (tensor(5), tensor(1.)), (tensor(6), tensor(0.6667)), (tensor(5), tensor(0.)), (tensor(5), tensor(0.)), (tensor(0), tensor(nan)), (tensor(1), tensor(0.)), (tensor(1), tensor(0.)), (tensor(6), tensor(0.)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(6), tensor(0.)), (tensor(9), tensor(0.4444)), (tensor(6), tensor(0.)), (tensor(9), tensor(0.)), (tensor(10), tensor(0.)), (tensor(8), tensor(0.)), (tensor(3), tensor(0.)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(6), tensor(0.3333)), (tensor(6), tensor(0.6667)), (tensor(8), tensor(0.5000)), (tensor(8), tensor(0.5000)), (tensor(10), tensor(0.8000)), (tensor(8), tensor(1.)), (tensor(8), tensor(0.3750)), (tensor(8), tensor(0.)), (tensor(1), tensor(0.)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), (tensor(0), tensor(nan)), 160]  data_time: 0.0133  time: 3.8823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion_matrix/result': [(tensor(23), tensor(0.2174)),\n",
       "  (tensor(12), tensor(0.8333)),\n",
       "  (tensor(19), tensor(0.6842)),\n",
       "  (tensor(12), tensor(0.5000)),\n",
       "  (tensor(17), tensor(0.2941)),\n",
       "  (tensor(8), tensor(0.7500)),\n",
       "  (tensor(13), tensor(0.3077)),\n",
       "  (tensor(15), tensor(0.2000)),\n",
       "  (tensor(20), tensor(0.2500)),\n",
       "  (tensor(22), tensor(0.0455)),\n",
       "  (tensor(18), tensor(0.1111)),\n",
       "  (tensor(6), tensor(0.1667)),\n",
       "  (tensor(16), tensor(0.)),\n",
       "  (tensor(5), tensor(0.)),\n",
       "  (tensor(5), tensor(0.2000)),\n",
       "  (tensor(15), tensor(0.)),\n",
       "  (tensor(10), tensor(0.1000)),\n",
       "  (tensor(5), tensor(0.)),\n",
       "  (tensor(5), tensor(0.)),\n",
       "  (tensor(3), tensor(0.3333)),\n",
       "  (tensor(7), tensor(0.)),\n",
       "  (tensor(7), tensor(0.)),\n",
       "  (tensor(2), tensor(0.)),\n",
       "  (tensor(2), tensor(0.)),\n",
       "  (tensor(2), tensor(0.)),\n",
       "  (tensor(2), tensor(0.)),\n",
       "  (tensor(2), tensor(0.)),\n",
       "  (tensor(2), tensor(0.)),\n",
       "  (tensor(2), tensor(0.)),\n",
       "  (tensor(2), tensor(0.)),\n",
       "  (tensor(6), tensor(0.)),\n",
       "  (tensor(6), tensor(0.5000)),\n",
       "  (tensor(2), tensor(0.)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(2), tensor(0.)),\n",
       "  (tensor(2), tensor(0.)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(3), tensor(0.3333)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(6), tensor(0.)),\n",
       "  (tensor(2), tensor(0.)),\n",
       "  (tensor(2), tensor(0.5000)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(13), tensor(0.0769)),\n",
       "  (tensor(10), tensor(0.)),\n",
       "  (tensor(12), tensor(0.)),\n",
       "  (tensor(14), tensor(0.0714)),\n",
       "  (tensor(17), tensor(0.)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(6), tensor(0.)),\n",
       "  (tensor(7), tensor(0.)),\n",
       "  (tensor(6), tensor(0.)),\n",
       "  (tensor(10), tensor(0.1000)),\n",
       "  (tensor(4), tensor(0.)),\n",
       "  (tensor(4), tensor(0.5000)),\n",
       "  (tensor(4), tensor(0.)),\n",
       "  (tensor(4), tensor(1.)),\n",
       "  (tensor(9), tensor(0.1111)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(4), tensor(0.)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(5), tensor(0.2000)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(2), tensor(0.)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(1), tensor(1.)),\n",
       "  (tensor(12), tensor(0.1667)),\n",
       "  (tensor(4), tensor(1.)),\n",
       "  (tensor(4), tensor(0.)),\n",
       "  (tensor(4), tensor(0.)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(8), tensor(0.6250)),\n",
       "  (tensor(10), tensor(0.4000)),\n",
       "  (tensor(4), tensor(0.2500)),\n",
       "  (tensor(3), tensor(0.3333)),\n",
       "  (tensor(12), tensor(0.)),\n",
       "  (tensor(5), tensor(0.4000)),\n",
       "  (tensor(5), tensor(0.6000)),\n",
       "  (tensor(6), tensor(1.)),\n",
       "  (tensor(6), tensor(0.8333)),\n",
       "  (tensor(6), tensor(0.5000)),\n",
       "  (tensor(5), tensor(1.)),\n",
       "  (tensor(6), tensor(0.6667)),\n",
       "  (tensor(5), tensor(0.)),\n",
       "  (tensor(5), tensor(0.)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(6), tensor(0.)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(6), tensor(0.)),\n",
       "  (tensor(9), tensor(0.4444)),\n",
       "  (tensor(6), tensor(0.)),\n",
       "  (tensor(9), tensor(0.)),\n",
       "  (tensor(10), tensor(0.)),\n",
       "  (tensor(8), tensor(0.)),\n",
       "  (tensor(3), tensor(0.)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(6), tensor(0.3333)),\n",
       "  (tensor(6), tensor(0.6667)),\n",
       "  (tensor(8), tensor(0.5000)),\n",
       "  (tensor(8), tensor(0.5000)),\n",
       "  (tensor(10), tensor(0.8000)),\n",
       "  (tensor(8), tensor(1.)),\n",
       "  (tensor(8), tensor(0.3750)),\n",
       "  (tensor(8), tensor(0.)),\n",
       "  (tensor(1), tensor(0.)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  (tensor(0), tensor(nan)),\n",
       "  160]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "from multiprocessing import Process\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    # Check MMAction2 installaation\n",
    "    import mmaction\n",
    "    print(mmaction.__version__)\n",
    "\n",
    "    import mmcv\n",
    "    print(mmcv.__version__)\n",
    "\n",
    "    # Check MMCV installation\n",
    "    from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "    print(get_compiling_cuda_version())\n",
    "    print(get_compiler_version())\n",
    "\n",
    "    # Check MMEngine installation\n",
    "    from mmengine.utils.dl_utils import collect_env\n",
    "    print(collect_env())\n",
    "\n",
    "    from mmaction.apis import inference_recognizer, init_recognizer\n",
    "    from mmengine import Config\n",
    "\n",
    "    from operator import itemgetter\n",
    "\n",
    "    import os.path as osp\n",
    "    import mmengine\n",
    "    from mmengine.runner import Runner\n",
    "\n",
    "from mmengine.runner import Runner\n",
    "checkpoint = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/exps/mvitv2_anticipation_regular/best_acc_top1_epoch_29.pth'\n",
    "\n",
    "\n",
    "\n",
    "cfg = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/VideoSwin/mvitv2_anticipation_regular.py'\n",
    "\n",
    "cfg = Config.fromfile(cfg)\n",
    "\n",
    "cfg.load_from = checkpoint\n",
    "\n",
    "cfg.work_dir = './exps/mvitv2_anticipation_regular'\n",
    "\n",
    "cfg.test_dataloader.dataset.ann_file = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/annotations_regular_test.txt'\n",
    "\n",
    "cfg.test_dataloader.dataset.data_prefix.img = '/Users/eddie/Trauma_THOMPSON/Trauma_THOMPSON/new_dataset/regular/test'\n",
    "\n",
    "\n",
    "# build the runner from config\n",
    "\n",
    "if 'runner_type' not in cfg:\n",
    "\n",
    "   # build the default runner\n",
    "\n",
    "   runner_test = Runner.from_cfg(cfg)\n",
    "\n",
    "else:\n",
    "\n",
    "   # build customized runner from the registry\n",
    "\n",
    "   # if 'runner_type' is set in the cfg\n",
    "\n",
    "   runner_test = Runner.build(cfg)\n",
    "\n",
    "\n",
    "# start testing\n",
    "\n",
    "runner_test.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "model.cpu()\n",
    "del model, checkpoint\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
